---
title: Comment d√©ployer un mod√®le NLP avec FastAPI
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2021-06-28T20:35:12.000Z'
originalURL: https://freecodecamp.org/news/how-to-deploy-an-nlp-model-with-fastapi
coverImage: https://www.freecodecamp.org/news/content/images/2021/06/1_u3IjD13EgKyfby4MD6SAmw.jpeg
tags:
- name: deployment
  slug: deployment
- name: Machine Learning
  slug: machine-learning
- name: natural language processing
  slug: natural-language-processing
- name: nlp
  slug: nlp
seo_title: Comment d√©ployer un mod√®le NLP avec FastAPI
seo_desc: 'By Davis David

  If you''re working with Natural Language Processing, knowing how to deploy a model
  is one of the most important skills you''ll need to have.

  Model deployment is the process of integrating your model into an existing production
  environmen...'
---

Par Davis David

Si vous travaillez avec le traitement du langage naturel, savoir comment d√©ployer un mod√®le est l'une des comp√©tences les plus importantes que vous devrez avoir.

Le d√©ploiement de mod√®le est le processus d'int√©gration de votre mod√®le dans un environnement de production existant. Le mod√®le recevra des entr√©es et pr√©dira une sortie pour la prise de d√©cision pour un cas d'utilisation sp√©cifique.

> _"Seulement lorsque un mod√®le est enti√®rement int√©gr√© aux syst√®mes m√©tiers, nous pouvons extraire une r√©elle valeur de ses pr√©dictions" ‚Äî Christopher Samiullah_

Il existe diff√©rentes fa√ßons de d√©ployer votre mod√®le [NLP](https://hackernoon.com/your-guide-to-natural-language-processing-nlp-dw8g360f?ref=hackernoon.com) en production, comme utiliser Flask, Django, Bottle ou d'autres frameworks. Mais dans l'article d'aujourd'hui, vous apprendrez comment construire et d√©ployer votre mod√®le NLP avec **FastAPI**.

Dans cet article, vous apprendrez :

* Comment construire un mod√®le NLP qui classe les critiques de films IMDB en diff√©rents sentiments.
* Qu'est-ce que FastAPI et comment l'installer.
* Comment d√©ployer votre mod√®le avec FastAPI.
* Comment utiliser votre mod√®le NLP d√©ploy√© dans n'importe quelle application Python.

Alors, commen√ßons. üöÄ

## Comment construire un mod√®le NLP

Tout d'abord, nous devons construire notre mod√®le NLP. Nous allons utiliser le [jeu de donn√©es IMDB Movie](https://www.kaggle.com/c/word2vec-nlp-tutorial/data?ref=hackernoon.com) pour construire un mod√®le simple qui peut classer si une critique de film est positive ou n√©gative. Voici les √©tapes que vous devez suivre pour cela.

### Importer les packages importants

Tout d'abord, nous devons importer certains packages Python pour charger les donn√©es, nettoyer les donn√©es, cr√©er un mod√®le de machine learning (classificateur) et sauvegarder le mod√®le pour le d√©ploiement.

```python
# importer les modules importants
import numpy as np
import pandas as pd
# modules sklearn
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB # classificateur
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    plot_confusion_matrix,
)
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
# modules de pr√©traitement de texte
from string import punctuation
# modules de pr√©traitement de texte
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re # expression r√©guli√®re
# T√©l√©charger les d√©pendances
for dependency in (
    "brown",
    "names",
    "wordnet",
    "averaged_perceptron_tagger",
    "universal_tagset",
):
    nltk.download(dependency)

import warnings
warnings.filterwarnings("ignore")
# initialisation du g√©n√©rateur de nombres al√©atoires
np.random.seed(123)
```

Charger le jeu de donn√©es depuis le dossier de donn√©es :

```python
# charger les donn√©es
data = pd.read_csv("../data/labeledTrainData.tsv", sep='\t')
```

Puis afficher un √©chantillon du jeu de donn√©es :

```python
# afficher les cinq premi√®res lignes des donn√©es
data.head()
```

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0_esD8-cAwTmwoXXFY.jpeg)

Notre jeu de donn√©es a 3 colonnes :

* **Id** ‚Äî Il s'agit de l'identifiant de la critique
* **Sentiment** ‚Äî soit positif (1) ou n√©gatif (0)
* **Review** ‚Äî commentaire sur le film

Ensuite, v√©rifions la forme du jeu de donn√©es :

```python
# v√©rifier la forme des donn√©es
data.shape
```

(25000, 3)

Le jeu de donn√©es contient 25 000 critiques.

Maintenant, nous devons v√©rifier si le jeu de donn√©es contient des valeurs manquantes :

```python
# v√©rifier les valeurs manquantes dans les donn√©es
data.isnull().sum()
```

id 0  
sentiment 0  
review 0  
dtype: int64

La sortie montre que notre jeu de donn√©es ne contient aucune valeur manquante.

### Comment √©valuer la distribution des classes

Nous pouvons utiliser la m√©thode **`value_counts()`** du package Pandas pour √©valuer la distribution des classes de notre jeu de donn√©es.

```python
# √©valuer la distribution des sentiments des nouvelles
data.sentiment.value_counts()
```

1 12500  
0 12500  
Name: sentiment, dtype: int64

Dans ce jeu de donn√©es, nous avons un nombre √©gal de critiques positives et n√©gatives.

### Comment traiter les donn√©es

Apr√®s avoir analys√© le jeu de donn√©es, l'√©tape suivante consiste √† pr√©traiter le jeu de donn√©es dans le bon format avant de cr√©er notre mod√®le de machine learning.

Les critiques de ce jeu de donn√©es contiennent beaucoup de mots et de caract√®res inutiles dont nous n'avons pas besoin lors de la cr√©ation d'un mod√®le de machine learning.

Nous allons nettoyer les messages en supprimant les stopwords, les nombres et la ponctuation. Ensuite, nous convertirons chaque mot en sa forme de base en utilisant le processus de lemmatisation dans le package NLTK.

La fonction `text_cleaning()` g√©rera toutes les √©tapes n√©cessaires pour nettoyer notre jeu de donn√©es.

```python
stop_words = stopwords.words('english')
def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):
    # Nettoyer le texte, avec l'option de supprimer les stop_words et de lemmatiser les mots
    # Nettoyer le texte
    text = re.sub(r"[^A-Za-z0-9]", " ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r'http\S+',' link ', text)
    text = re.sub(r'\b\d+(?:\.\d+)?\s+', '', text) # supprimer les nombres
    
    # Supprimer la ponctuation du texte
    text = ''.join([c for c in text if c not in punctuation])
    
    # Optionnellement, supprimer les stop words
    if remove_stop_words:
        text = text.split()
        text = [w for w in text if not w in stop_words]
        text = " ".join(text)
    
    # Optionnellement, raccourcir les mots √† leurs racines
    if lemmatize_words:
        text = text.split()
        lemmatizer = WordNetLemmatizer()
        lemmatized_words = [lemmatizer.lemmatize(word) for word in text]
        text = " ".join(lemmatized_words)
    
    # Retourner une liste de mots
    return(text)
```

Maintenant, nous pouvons nettoyer notre jeu de donn√©es en utilisant la fonction **text_cleaning()** :

```python
# nettoyer la critique
data["cleaned_review"] = data["review"].apply(text_cleaning)
```

Ensuite, diviser les donn√©es en variables de fonctionnalit√©s et de cible comme ceci :

```python
# diviser les fonctionnalit√©s et la cible des donn√©es
X = data["cleaned_review"]
y = data.sentiment.values
```

Notre fonctionnalit√© pour l'entra√Ænement est la variable **`cleaned_review`** et la cible est la variable **`sentiment`**.

Nous divisons ensuite notre jeu de donn√©es en donn√©es d'entra√Ænement et de test. La taille du test est de 15 % de l'ensemble du jeu de donn√©es.

```python
# diviser les donn√©es en entra√Ænement et validation
X_train, X_valid, y_train, y_valid = train_test_split(
    X,
    y,
    test_size=0.15,
    random_state=42,
    shuffle=True,
    stratify=y,
)
```

### Comment cr√©er un mod√®le NLP

Nous allons entra√Æner l'algorithme Multinomial [Naive Bayes](https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/) pour classer si une critique est positive ou n√©gative. Il s'agit de l'un des algorithmes les plus courants utilis√©s pour la classification de texte.

Mais avant d'entra√Æner le mod√®le, nous devons transformer nos critiques nettoy√©es en valeurs num√©riques afin que le mod√®le puisse comprendre les donn√©es.

Dans ce cas, nous allons utiliser la m√©thode [**`TfidfVectorizer`**](https://www.freecodecamp.org/news/how-to-extract-keywords-from-text-with-tf-idf-and-pythons-scikit-learn-b2a0f3d7e667/) de scikit-learn. TfidfVectorizer nous aidera √† convertir une collection de documents textuels en une matrice de fonctionnalit√©s TF-IDF.

Pour appliquer cette s√©rie d'√©tapes (pr√©traitement et entra√Ænement), nous allons utiliser une [classe Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html?ref=hackernoon.com) de scikit-learn qui applique s√©quentiellement une liste de transformations et un estimateur final.

```python
# Cr√©er un classificateur dans un pipeline
sentiment_classifier = Pipeline(steps=[
                               ('pre_processing',TfidfVectorizer(lowercase=False)),
                                 ('naive_bayes',MultinomialNB())
                                 ])
```

Ensuite, nous entra√Ænons notre classificateur comme ceci :

```python
# entra√Æner le classificateur de sentiment
sentiment_classifier.fit(X_train,y_train)
```

Nous cr√©ons ensuite une pr√©diction √† partir de l'ensemble de validation :

```python
# tester les performances du mod√®le sur les donn√©es valides
y_preds = sentiment_classifier.predict(X_valid)
```

Les performances du mod√®le seront √©valu√©es en utilisant la m√©trique d'√©valuation **`accuracy_score`**. Nous utilisons accuracy_score parce que nous avons un nombre √©gal de classes dans la variable sentiment.

```python
accuracy_score(y_valid,y_preds)
```

0.8629333333333333

La pr√©cision de notre mod√®le est d'environ **86,29 %**, ce qui est une bonne performance.

### Comment sauvegarder le pipeline du mod√®le

Nous pouvons sauvegarder le pipeline du mod√®le dans le r√©pertoire du mod√®le en utilisant le package Python **`joblib`**.

```python
# sauvegarder le mod√®le
import joblib
joblib.dump(sentiment_classifier, '../models/sentiment_model_pipeline.pkl')
```

Maintenant que nous avons construit notre mod√®le NLP, apprenons √† utiliser FastAPI.

## Qu'est-ce que FastAPI ?

FastAPI est un framework web Python rapide et moderne pour construire diff√©rentes [APIs](https://hackernoon.com/how-to-use-the-requests-python-library-to-make-an-api-call-and-save-it-as-a-pandas-dataframe-z43k33rm?ref=hackernoon.com). Il offre des performances plus √©lev√©es, il est plus facile √† coder et il est livr√© avec une documentation automatique et interactive.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/zVaxL0LohRUpfDQhznRQ9z3y5tj1-rzu32nl.jpeg)

FastAPI est construit sur deux biblioth√®ques Python majeures **‚Äî Starlette** (pour la gestion web) et **Pydantic** (pour la gestion et la validation des donn√©es). FastAPI est tr√®s rapide par rapport √† Flask car il apporte des gestionnaires de fonctions asynchrones.

Si vous voulez en savoir plus sur FastAPI, je vous recommande de lire cet [article](https://tiangolo.medium.com/introducing-fastapi-fdc1206d453f?ref=hackernoon.com) de Sebasti√°n Ram√≠rez.

Dans cet article, nous allons essayer d'utiliser certaines des fonctionnalit√©s de FastAPI pour servir notre mod√®le NLP.

### Comment installer FastAPI

Tout d'abord, assurez-vous d'installer la derni√®re version de FastAPI (avec pip) :

```python
pip install fastapi
```

Vous aurez √©galement besoin d'un serveur ASGI pour la production tel que [uvicorn](http://www.uvicorn.org/?ref=hackernoon.com).

```python
pip install uvicorn
```

## Comment d√©ployer un mod√®le NLP avec FastAPI

Dans cette section, nous allons d√©ployer notre mod√®le [NLP](https://www.freecodecamp.org/news/learn-natural-language-processing-no-experience-required/) entra√Æn√© en tant qu'API REST avec FastAPI. Nous sauvegarderons le code pour notre API dans un fichier Python appel√© **main.py**. Ce fichier sera responsable de l'ex√©cution de notre application FastAPI.

### Importer les packages

La premi√®re √©tape consiste √† importer les packages qui nous aideront √† construire l'application FastAPI et √† ex√©cuter le mod√®le NLP.

```python
# modules de pr√©traitement de texte
from string import punctuation
# modules de pr√©traitement de texte
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re  # expression r√©guli√®re
import os
from os.path import dirname, join, realpath
import joblib
import uvicorn
from fastapi import FastAPI
```

### Comment initialiser une instance d'application FastAPI

Nous pouvons utiliser le code suivant pour initialiser l'application FastAPI :

```python
app = FastAPI(
    title="API de mod√®le de sentiment",
    description="Une API simple qui utilise un mod√®le NLP pour pr√©dire le sentiment des critiques de films",
    version="0.1",
)
```

Comme vous pouvez le voir, nous avons personnalis√© la configuration de notre application FastAPI en incluant :

* Le titre de l'API
* La description de l'API.
* La version de l'API.

### Comment charger le mod√®le NLP

Pour charger le mod√®le NLP, nous utiliserons la m√©thode **`joblib.load()`** et ajouterons le chemin vers le r√©pertoire du mod√®le. Le nom du mod√®le NLP est **`sentiment_model_pipeline.pkl`** :

```python
# charger le mod√®le de sentiment
with open(
    join(dirname(realpath(__file__)), "models/sentiment_model_pipeline.pkl"), "rb"
) as f:
    model = joblib.load(f)
```

### Comment d√©finir une fonction pour nettoyer les donn√©es

Nous utiliserons la m√™me fonction appel√©e **`text_cleaning()`** de la Partie 1 qui nettoie les donn√©es de critique en supprimant les stopwords, les nombres et la ponctuation. Enfin, nous convertirons chaque mot en sa forme de base en utilisant le processus de lemmatisation dans le [package NLTK](https://www.freecodecamp.org/news/natural-language-processing-tutorial-with-python-nltk/).

```python
def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):
    # Nettoyer le texte, avec l'option de supprimer les stop_words et de lemmatiser les mots
    # Nettoyer le texte
    text = re.sub(r"[^A-Za-z0-9]", " ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"http\S+", " link ", text)
    text = re.sub(r"\b\d+(?:\.\d+)?\s+", "", text)  # supprimer les nombres
    # Supprimer la ponctuation du texte
    text = "".join([c for c in text if c not in punctuation])
    # Optionnellement, supprimer les stop words
    if remove_stop_words:
        # charger les stopwords
        stop_words = stopwords.words("english")
        text = text.split()
        text = [w for w in text if not w in stop_words]
        text = " ".join(text)
    # Optionnellement, raccourcir les mots √† leurs racines
    if lemmatize_words:
        text = text.split()
        lemmatizer = WordNetLemmatizer()
        lemmatized_words = [lemmatizer.lemmatize(word) for word in text]
        text = " ".join(lemmatized_words)
    # Retourner une liste de mots
    return text
```

### Comment cr√©er un point de terminaison de pr√©diction

L'√©tape suivante consiste √† ajouter notre point de terminaison de pr√©diction appel√© ¬´ **/predict-review** ¬ª avec la m√©thode de requ√™te GET.

```python
@app.get("/predict-review")
```

> Un point de terminaison d'API est le point d'entr√©e dans un canal de communication lorsque deux syst√®mes interagissent. Il fait r√©f√©rence aux points de contact de la communication entre une API et un serveur.

Ensuite, nous d√©finissons une fonction de pr√©diction pour ce point de terminaison. Le nom de la fonction est **`predict_sentiment()`** avec un param√®tre de critique.

La fonction predict_sentiment() effectuera les t√¢ches suivantes :

* Recevoir la critique de film.
* Nettoyer la critique de film en utilisant la fonction **text_cleaning()**. 
* Faire une pr√©diction en utilisant notre mod√®le NLP.
* Sauvegarder le r√©sultat de la pr√©diction dans la variable **output** (soit 0 soit 1).
* Sauvegarder la probabilit√© de la pr√©diction dans la variable **probas** et la formater en 2 d√©cimales.
* Enfin, retourner les r√©sultats de la pr√©diction et de la probabilit√©.

```python
@app.get("/predict-review")
def predict_sentiment(review: str):
    """
    Une fonction simple qui re√ßoit un contenu de critique et pr√©dit le sentiment du contenu.
    :param review:
    :return: prediction, probabilities
    """
    # nettoyer la critique
    cleaned_review = text_cleaning(review)
    
    # effectuer la pr√©diction
    prediction = model.predict([cleaned_review])
    output = int(prediction[0])
    probas = model.predict_proba([cleaned_review])
    output_probability = "{:.2f}".format(float(probas[:, output]))
    
    # dictionnaire de sortie
    sentiments = {0: "Negative", 1: "Positive"}
    
    # montrer les r√©sultats
    result = {"prediction": sentiments[output], "Probability": output_probability}
    return result
```

Voici tous les blocs de code dans le fichier **main.py** :

```python
# modules de pr√©traitement de texte
from string import punctuation
# modules de pr√©traitement de texte
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re  # expression r√©guli√®re
import os
from os.path import dirname, join, realpath
import joblib
import uvicorn
from fastapi import FastAPI

app = FastAPI(
    title="API de mod√®le de sentiment",
    description="Une API simple qui utilise un mod√®le NLP pour pr√©dire le sentiment des critiques de films",
    version="0.1",
)

# charger le mod√®le de sentiment
with open(
    join(dirname(realpath(__file__)), "models/sentiment_model_pipeline.pkl"), "rb"
) as f:
    model = joblib.load(f)


# nettoyer les donn√©es
def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):
    # Nettoyer le texte, avec l'option de supprimer les stop_words et de lemmatiser les mots
    # Nettoyer le texte
    text = re.sub(r"[^A-Za-z0-9]", " ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"http\S+", " link ", text)
    text = re.sub(r"\b\d+(?:\.\d+)?\s+", "", text)  # supprimer les nombres
    
    # Supprimer la ponctuation du texte
    text = "".join([c for c in text if c not in punctuation])
    
    # Optionnellement, supprimer les stop words
    if remove_stop_words:
        # charger les stopwords
        stop_words = stopwords.words("english")
        text = text.split()
        text = [w for w in text if not w in stop_words]
        text = " ".join(text)
        
    # Optionnellement, raccourcir les mots √† leurs racines
    if lemmatize_words:
        text = text.split()
        lemmatizer = WordNetLemmatizer()
        lemmatized_words = [lemmatizer.lemmatize(word) for word in text]
        text = " ".join(lemmatized_words)
        
    # Retourner une liste de mots
    return text

@app.get("/predict-review")
def predict_sentiment(review: str):
    """
    Une fonction simple qui re√ßoit un contenu de critique et pr√©dit le sentiment du contenu.
    :param review:
    :return: prediction, probabilities
    """
    # nettoyer la critique
    cleaned_review = text_cleaning(review)
    
    # effectuer la pr√©diction
    prediction = model.predict([cleaned_review])
    output = int(prediction[0])
    probas = model.predict_proba([cleaned_review])
    output_probability = "{:.2f}".format(float(probas[:, output]))
    
    # dictionnaire de sortie
    sentiments = {0: "Negative", 1: "Positive"}
    
    # montrer les r√©sultats
    result = {"prediction": sentiments[output], "Probability": output_probability}
    return result
```

### Comment ex√©cuter l'API

La commande suivante nous aidera √† ex√©cuter l'application FastAPI que nous avons cr√©√©e.

```python
uvicorn main:app --reload
```

Voici les param√®tres que nous avons d√©finis pour uvicorn pour ex√©cuter notre application FastAPI.

* **main** : le fichier main.py qui contient l'application FastAPI.
* **app** : l'objet cr√©√© √† l'int√©rieur de main.py avec la ligne app = FastAPI().
* **‚Äîreload** : Permet au serveur de red√©marrer automatiquement chaque fois que nous apportons des modifications au code.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0_EP-YBqB9hbsOL9Rt.jpeg)

FastAPI fournit une page de documentation interactive automatique. Pour y acc√©der, naviguez vers [**http://127.0.0.1:8000/docs**](http://127.0.0.1:8000/docs) dans votre navigateur et vous verrez la page de documentation cr√©√©e automatiquement par FastAPI.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0_KjAI4upfMAZcUGBR.jpeg)

La page de documentation montre le nom de notre API, la description et sa version. Elle montre √©galement une liste des routes disponibles dans l'API avec lesquelles vous pouvez interagir.

Pour faire une pr√©diction, cliquez d'abord sur la route ¬´ **predict-review** ¬ª, puis sur le bouton ¬´ **Try it out** ¬ª. Cela vous permet de remplir le param√®tre de critique et d'interagir directement avec l'API.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0__XOHgx7DAjF74r1N.jpeg)

Remplissez le champ de critique en ajoutant une critique de film de votre choix. J'ai ajout√© la critique suivante sur le film **Zack Snyder's Justice League** sorti en 2021.

> ¬´ J'ai ador√© le film du d√©but √† la fin. Tout comme Ray Fisher l'a dit, j'esp√©rais que le film ne se termine pas. La sc√®ne d'ouverture √©tait √©poustouflante, j'ai beaucoup aim√© cette sc√®ne. Contrairement √† 'Justice League', le film montre que chaque h√©ros est le meilleur dans son domaine, ce qui nous fait aimer chaque personnage. Merci, Zack et toute l'√©quipe. ¬ª

Ensuite, cliquez sur le bouton d'ex√©cution pour faire une pr√©diction et obtenir le r√©sultat.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0_QAM6VjtcDlhgEbQ6.jpeg)

Enfin, le r√©sultat de l'API montre que notre mod√®le NLP pr√©dit que la critique fournie a un sentiment **Positif** avec une probabilit√© de **0,70** :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/0_YUFkGlke1PWVoeyo.jpeg)

## Comment utiliser un mod√®le NLP dans n'importe quelle application Python

Pour utiliser notre API NLP dans n'importe quelle application Python, nous devons installer le package Python requests. Ce package nous aidera √† envoyer des requ√™tes HTTP √† l'application FastAPI que nous avons d√©velopp√©e.

Pour installer le package requests, ex√©cutez la commande suivante :

```python
pip install requests
```

Ensuite, cr√©ez un simple fichier Python appel√© **`python_app.py`**. Ce fichier sera responsable de l'envoi de nos requ√™tes HTTP.

Nous importons d'abord le package requests :

```python
import requests as r
```

Ajoutez une critique de film sur le film **Godzilla vs Kong (2021)** :

```python
# ajouter une critique
review = "Ce film √©tait exactement ce que je voulais dans un film Godzilla vs Kong. Il est grand, bruyant, audacieux et stupide, dans les meilleurs sens possibles. Il a aussi un c≈ìur sous la forme de Jia (Kaylee Hottle) et un Kong super expressif. Les sc√®nes de lui dans le monde creux sont particuli√®rement percutantes et magnifiquement tourn√©es/anim√©es. Kong est vraiment le c≈ìur √©motionnel du film (avec Godzilla plus comme une force indiff√©rente de la nature), et il est si bien fait qu'il pourrait m√™me convertir quelques membres de l'√©quipe Godzilla."
```

Ensuite, ajoutez la critique dans un param√®tre cl√© √† passer √† la requ√™te HTTP :

```python
keys = {"review": review}
```

Enfin, nous envoyons une requ√™te √† notre API pour faire une pr√©diction de la critique :

```python
prediction = r.get("http://127.0.0.1:8000/predict-review/", params=keys)
```

Ensuite, nous pouvons voir les r√©sultats de la pr√©diction :

```python
results = prediction.json()

print(results["prediction"])
print(results["Probability"])
```

Cela affichera la pr√©diction et sa probabilit√©. Voici les r√©sultats :

Positive
0.54

## Conclusion

F√©licitations üëèüëè, vous √™tes arriv√© √† la fin de cet article. J'esp√®re que vous avez appris quelque chose de nouveau et que vous savez maintenant comment d√©ployer votre mod√®le NLP avec FastAPI.

Si vous voulez en savoir plus sur FastAPI, je vous recommande de suivre ce [cours complet sur FastAPI](https://www.youtube.com/watch?v=7t2alSnE2-I&ref=hackernoon.com) cr√©√© par [Bitfumes](https://twitter.com/bitfumes?ref=hackernoon.com).

Vous pouvez t√©l√©charger le [code source du projet utilis√© dans cet article ici](https://github.com/Davisy/Deploy-NLP-Model-with-FastAPI).

Si vous avez appris quelque chose de nouveau ou si vous avez appr√©ci√© la lecture de cet article, veuillez le partager afin que d'autres puissent le voir. En attendant, √† la prochaine dans le prochain article !.

Vous pouvez √©galement me trouver sur Twitter [@Davis_McDavid](https://twitter.com/Davis_McDavid?ref=hackernoon.com)