---
title: Exécuter du Javascript non fiable en tant que SaaS est difficile. Voici comment
  j'ai dompté les démons.
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2018-01-17T10:21:33.000Z'
originalURL: https://freecodecamp.org/news/running-untrusted-javascript-as-a-saas-is-hard-this-is-how-i-tamed-the-demons-973870f76e1c
coverImage: https://cdn-media-1.freecodecamp.org/images/1*TmAzIIgSaJ1Oy2lHsuVL0Q.jpeg
tags:
- name: education
  slug: education
- name: Life lessons
  slug: life-lessons
- name: startup
  slug: startup
- name: 'tech '
  slug: tech
- name: Web Development
  slug: web-development
seo_title: Exécuter du Javascript non fiable en tant que SaaS est difficile. Voici
  comment j'ai dompté les démons.
seo_desc: 'By Tim Nolet ??‍?

  Imagine the following:


  You have a Saas service that allows users to run server side Node.js code.

  The code is executed on your servers.

  The code can download anything from the internet.

  Any output generated by the code is made avai...'
---

Par Tim Nolet ???

Imaginez ce qui suit :

* Vous avez un service SaaS qui permet aux utilisateurs d'exécuter du code Node.js côté serveur.
* Le code est exécuté sur vos serveurs.
* Le code peut télécharger n'importe quoi depuis Internet.
* Toute sortie générée par le code est mise à la disposition de l'utilisateur.

C'est un cauchemar en termes de performance et de sécurité. C'est aussi la situation dans laquelle je me suis retrouvé en construisant un nouvel [outil](https://trypuppeteer.com) pour mon nouveau SaaS solo [endeavour](https://checklyhq.com).

### Le cas d'utilisation

L'une des fonctionnalités clés de mon nouvel outil est de permettre aux utilisateurs anonymes d'exécuter des scripts Puppeteer dans un environnement sandbox. Puppeteer est un projet de l'équipe Google Chrome (22k étoiles Github ✨) qui permet aux utilisateurs d'exécuter Chrome en mode headless, c'est-à-dire sans écran, et d'automatiser les interactions avec une page web.

Cela est très utile pour les tests, le web scraping, la surveillance et une multitude d'autres cas d'utilisation. Le but du nouvel outil est que les utilisateurs puissent rapidement essayer ces scripts sans le tracas d'installer et d'exécuter Puppeteer sur leurs propres machines. Très similaire à JSFiddle, CodePen et autres playgrounds de code.

L'essentiel ici est que l'utilisateur a un accès complet à JavaScript et Node.js, peut télécharger tout ce qu'il veut depuis Internet et que moi (ou plutôt mes serveurs) allons exécuter ce code pour eux ! ? Aïe !

### Qu'est-ce qui pourrait mal se passer ?

Voici quelques-unes des façons dont les gens (mes utilisateurs) peuvent tout gâcher avec leurs morceaux de code :

![Image](https://cdn-media-1.freecodecamp.org/images/aE71MDvFQcbqJhBMFDzfOZoGGB-VzzoFNwIZ)
_Aïe ! Encore !_

Et, comme nous exécutons un SaaS multi-locataires, il y a probablement des moyens de détourner d'autres sessions et de jeter un coup d'œil aux processus et au code des autres. Oui, c'est assez désagréable.

Que cela soit dû à une intention malveillante ou simplement à l'écriture de code bogué n'a pas vraiment d'importance. Le résultat final est soit des serveurs lents/morts, vos (et éventuellement d'autres utilisateurs) identifiants dans la rue, et juste un mauvais moment en général.

### Couches, couches... couches !

La solution à ce problème que j'ai trouvée est la suivante.

![Image](https://cdn-media-1.freecodecamp.org/images/7alAq6rMyUwYhS0fCcs-GT8pEh4QPk1l4bSK)
_Note aux hackers russes : sauvegardez cette image sur le disque_

Une demande d'exécution de code non fiable est d'abord limitée en débit à (1), après quoi elle est placée dans une file d'attente de messages AWS SQS à (2). Les messages sont récupérés par ce que j'appelle un processus de lancement (3) qui exécute le travail. Il s'agit d'un modèle typique de type fan out / master-worker. Le lanceur prépare et lance un conteneur Docker (4) qui à son tour exécute le code de l'utilisateur à l'intérieur d'une VM2 Node.js « soft container » (5). Examinons chacune de ces étapes en détail.

### 1. Limitation du débit

Pour éviter les scénarios de DDOS, où les utilisateurs bombardent votre API avec des requêtes HTTP, nous devons d'abord ajouter une limitation du débit, également appelée throttling des requêtes. Cela est encore plus important dans mon scénario spécifique. Chaque requête HTTP légère peut potentiellement déclencher un travail en arrière-plan beaucoup plus lourd. (Puppeteer lance un navigateur Chrome complet.)

Cela signifie que le serveur API pourrait devenir non réactif, mais aussi que les serveurs de travail pourraient commencer à être submergés. Comme je prévois d'ajouter une fonctionnalité d'autoscaling aux serveurs de travail, plus de requêtes de travail équivaut à plus d'utilisation de ressources. Cela entraînerait une augmentation des coûts des serveurs. Pas bon pour le pauvre propriétaire de startup solo-dev.

Il existe de nombreux frameworks et plugins de limitation de débit. Comme j'utilise le framework Hapi.js, j'ai opté pour le plugin hapi-rate-limit. Et il n'y a pas grand-chose d'autre à dire à ce sujet. Installez-le, ajoutez-le aux routes API que vous souhaitez protéger et voilà, cela fonctionne. Ce plugin vous offre quelques grandes options qui couvrent de nombreux scénarios de limitation de débit :

* Liste blanche d'IP et d'utilisateurs.
* Limitation par utilisateur, par chemin ou les deux.
* Prise en compte de X-Forward-For, pratique pour fonctionner derrière un équilibreur de charge.

De plus, le plugin ajoute quelques en-têtes de réponse HTTP à chaque requête, montrant l'état de l'algorithme de limitation de débit.

![Image](https://cdn-media-1.freecodecamp.org/images/b3LBd-nwYfc2G6MUxcdzFgG6vQ5rFR6Re22R)
_En-têtes de limitation de débit ajoutés par le plugin hapi-rate-limit_

Dans l'image ci-dessus, vous pouvez voir que j'ai fait une requête. Cette requête est soustraite du nombre maximum de requêtes que je peux faire selon ma UserPathLimit. Cela est défini comme le nombre total de requêtes qui peuvent être faites sur un chemin donné par utilisateur par période. Cette période se réinitialise après un certain temps.

Que se passe-t-il si quelqu'un atteint la limite de débit ? Nous les mettons dans le coin des vilains pour un moment et leur servons du fromage. La devise étant que le client a toujours raison, mais qu'il ne doit pas être autorisé à saccager votre système.

![Image](https://cdn-media-1.freecodecamp.org/images/hZhsaYdLL-nH6oP8HhdsDdU24lxrMdp7oVZ8)

### 2. Travaux en arrière-plan asynchrones

Déléguer l'exécution réelle du code non fiable à des travaux en arrière-plan est un modèle assez courant. Vous ne voulez pas encombrer le cycle de requête de votre serveur HTTP avec des travaux de longue durée. L'avantage supplémentaire ici est que si quelque chose de mauvais se produit lors de l'exécution du code non fiable, cela n'affectera pas ou ne compromettra pas votre serveur API orienté client.

Dans ma solution, la requête HTTP POST qui contient le code à exécuter est déballée et placée dans une file d'attente de messages SQS. Le message reste là jusqu'à ce qu'un nœud lanceur récupère le message et tente de le traiter. C'est là que se termine le rôle du serveur API. La devise étant de ne jamais déranger votre serveur API orienté client avec des requêtes longues et potentiellement dangereuses.

### 3. Isolation des processus : séparation du lanceur et de l'exécuteur

En construisant cette architecture, j'ai réalisé que je devais séparer le code du lanceur et de l'exécuteur ET placer l'exécuteur dans un conteneur Docker. La raison de cela devient évidente lorsque nous examinons ce que le combo lanceur/exécuteur doit faire.

Voici les tâches assignées au processus de lancement :

* Écouter SQS, déballer le message et extraire le code non fiable.
* Écrire le code dans un répertoire de travail dédié.
* Lancer un conteneur Docker (l'exécuteur) monté avec le répertoire de travail en utilisant l'excellent [Dockerode](https://github.com/apocas/dockerode).
* Lire la sortie de l'exécuteur et relayer le message via AWS IOT à l'utilisateur en attente.
* Surveiller l'état du conteneur en cours d'exécution.
* Télécharger les captures d'écran sur S3.
* Passer un message final après la fin de l'exécution à la base de données.
* Nettoyer les fichiers, le répertoire de travail temporaire et autres débris.

Pour effectuer tout ce travail, le lanceur a beaucoup de privilèges et a besoin d'un accès à de nombreuses informations d'identification comme les services AWS, l'accès à la base de données, l'accès au système de fichiers. Tous ceux-ci sont des vecteurs d'attaque faciles à exploiter par quiconque fait un `console.log(.../configuration/config.json)`, `console.log(process.env)` ou quelque chose de similaire.

Encore une fois... aïe ! ?

C'est pourquoi le code non fiable ne doit jamais s'exécuter dans le même contexte que le lanceur.

La stabilité est également augmentée en séparant le lanceur et l'exécuteur. Si le lanceur se bloque ou meurt, le système entier perd effectivement de la capacité. Quelque chose comme le moniteur de processus PM2 redémarrerait bien sûr le processus, mais il y aurait certainement du bruit et des frictions dus à ces plantages.

Ergo, dans la conception actuelle, le lanceur n'est jamais directement exposé à un code non fiable. La devise étant de toujours protéger le code du serveur, même au détriment du code de l'utilisateur.

L'exécuteur est un peu bizarre, examinons-le.

### 4. Sandboxing OS avec Docker

La partie exécuteur de cette équation est démarrée par le lanceur qui lance un conteneur Docker contenant le processus exécuteur. L'exécuteur exécute ensuite le code non fiable des utilisateurs. L'utilisation d'un conteneur Docker apporte plusieurs avantages :

1. Le processus Node n'a pas accès à l'hôte parent. Toutes les variables d'environnement, fichiers, etc. ne sont pas accessibles, donc il n'y a pas de fouinage dans les fichiers sensibles. En fait, la lecture des fichiers n'est pas possible, mais nous y reviendrons plus tard.
2. Isolation des travaux : les travaux de plusieurs utilisateurs s'exécutent sur une seule machine et nous voulons à tout moment éviter toute possibilité de « pollinisation croisée ».
3. Nettoyage facile : chaque conteneur est détruit lorsqu'il termine son exécution, ainsi que tous les téléchargements horribles, le code et tout ce qu'il a pu traîner comme morceaux malveillants.

Docker offre en général des réglages de sécurité assez approfondis en utilisant les flags `--cap-add` décrits dans la [documentation sur les privilèges d'exécution et les capacités Linux](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities). J'étais heureux de ne pas avoir à plonger dans le horrible gâchis qu'est selinux...

En dehors de ces avantages de sécurité, le conteneur Docker facilite également le déploiement et les tests. Faire fonctionner Puppeteer à l'intérieur d'un environnement Docker a été un peu un défi, nécessitant beaucoup de paquets supplémentaires, mais il existe quelques [excellentes directives](https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md#running-puppeteer-in-docker) qui devraient aider avec la plupart des distributions basées sur Debian / Ubuntu.

### 5. Sandboxing Node avec VM2

La solution exécuteur-dans-Docker est effectivement une prison. Mais nous permettons toujours aux détenus d'utiliser tous les outils que la bibliothèque standard Node.js leur donne pour fouiner. Ne serait-il pas préférable de réduire sévèrement la boîte à outils ? Oui, c'est le cas, et la première étape est Node VM.

Node VM fait partie de la distribution standard Node et fournit des capacités de sandboxing au sein du moteur V8 : il a simplement une interprétation très limitée du terme « sandbox », c'est-à-dire que vous pouvez en sortir très facilement et vous pouvez ajouter des paquets et faire tous les dégâts que vous voulez. Admettons que les gars de Node ont mis cela en gros caractères dans la documentation :

![Image](https://cdn-media-1.freecodecamp.org/images/aqK8n6NYqwp5N42qfbrDTBHlmpOjpM-9VNsc)
_Je ne le ferai pas ! JAMAIS !! (insistance de ma part)_

Heureusement, il y a [VM2](https://github.com/patriksimek/vm2), une sorte de dérivé conçu pour réprimer le code non fiable et les choses qu'il peut exécuter. Ses principaux tours de magie sont que vous pouvez mettre sur liste blanche les modules auxquels le code injecté dans la VM a accès.

Par exemple, vous pourriez mettre sur liste blanche uniquement `fs.write()` mais pas `fs.read()`. Ou vous pouvez bloquer l'utilisation de `process` pour éviter le redouté `process.exit()` ou `process.env`. C'est assez incroyable et tout le crédit revient à [@patricksimek](https://twitter.com/patriksimek)

Les paquets externes peuvent également être mis sur liste blanche, vous donnant la possibilité d'autoriser l'utilisation de paquets populaires comme lodash ou d'autres bibliothèques utilitaires sans donner aux utilisateurs l'accès à `npm install`.

Nous sommes enfin arrivés au point où le code non fiable est exécuté. Avec VM2, cela est aussi simple que d'invoquer la méthode run() avec une version stringifiée du code non fiable.

```
vm.run(untrustedCode)  .then(output => {    console.log(output)})
```

Cependant, nous avons encore un problème. Comment renvoyer la sortie à l'utilisateur ? Nous n'autorisons pas l'exécuteur à l'intérieur du processus VM2 à l'intérieur du conteneur Docker à avoir un accès quelconque à un bus de messages ou à quoi que ce soit d'autre en dehors de son contexte. Le processus est également découplé du processus de lancement, donc nous ne pouvons pas utiliser un simple rappel.

À ce stade, j'ai résolu ce problème en permettant à l'exécuteur d'écrire uniquement des logs sur stdout et d'écrire des images dans un répertoire temporaire protégé qui est effacé après l'exécution.

Cela signifie que le lanceur lit le stdout de l'exécuteur, analysant essentiellement une longue chaîne et découpant les données utiles en fonction des codes de contrôle préfixés et suffixés. De cette manière, les données sont assainies et passées dans les canaux en amont. Les fichiers image sont lus depuis le disque et directement poussés vers S3, en tenant compte de la taille des fichiers et de la possible corruption des fichiers.

### Conclusion

Exécuter du code non fiable est un peu comme construire un château médiéval. Ce n'est pas une question de porte magique incassable, de douves profondes ou d'une tour élevée qui résout tous vos problèmes. Il s'agit de couches de solutions qui sont suffisamment ennuyeuses pour effrayer les intrus et attraper les erreurs de la couche supérieure ou inférieure.

P.S. Si vous avez aimé cet article, montrez votre appréciation en **applaudissant** ? ci-dessous et en me **suivant sur Twitter !** [](https://twitter.com/tim_nolet) **M**ais attendez, il y a plus !

Je construis une solution de surveillance active pour les développeurs et les startups [https://checklyhq.com](https://checklyhq.com?utm_campaign=untrustedjavascript&utm_source=freecodecamp)

![Image](https://cdn-media-1.freecodecamp.org/images/NPjYBTz411rDqUTY9znTjAW-T4JaV21nVMgz)

Fou fou ! ?