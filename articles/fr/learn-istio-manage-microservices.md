---
title: Apprendre Istio ‚Äì Comment g√©rer, surveiller et s√©curiser les microservices
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2022-05-23T14:00:55.000Z'
originalURL: https://freecodecamp.org/news/learn-istio-manage-microservices
coverImage: https://www.freecodecamp.org/news/content/images/2022/05/how-traces-are-generated-1.png
tags:
- name: Microservices
  slug: microservices
seo_title: Apprendre Istio ‚Äì Comment g√©rer, surveiller et s√©curiser les microservices
seo_desc: "By Rinor Maloku\nThree years ago, I wrote an article titled \"Back to Microservices\
  \ with Istio\" for Google Cloud Community. I published it there to reach people\
  \ interested in the latest technologies built on top of Kubernetes. \nAt that point,\
  \ Istio was..."
---

Par Rinor Maloku

Il y a trois ans, j'ai √©crit un article intitul√© ["Back to Microservices with Istio"](https://medium.com/google-cloud/back-to-microservices-with-istio-p1-827c872daa53) pour la Google Cloud Community. Je l'ai publi√© l√†-bas pour toucher les personnes int√©ress√©es par les derni√®res technologies construites au-dessus de Kubernetes.

√Ä ce moment-l√†, Istio √©tait une technologie de niche. Mais trois ans plus tard :

* J'ai co-√©crit le livre "[Istio in Action](https://www.manning.com/books/istio-in-action?utm_source=rinor&utm_medium=affiliate&utm_campaign=book_posta2_istio_9_30_18&a_aid=rinor&a_bid=9f6a70f3)" avec Christian Posta ([@christianposta](https://twitter.com/christianposta)), qui a √©t√© r√©cemment publi√© par Manning.
* J'ai rejoint [Solo.io](https://www.solo.io/), o√π je collabore quotidiennement avec des clients pour utiliser au mieux les capacit√©s de Service Mesh d'Istio. Que ce soit pour am√©liorer la r√©silience, r√©duire les risques li√©s au d√©ploiement de nouveaux logiciels, am√©liorer la posture de s√©curit√© ou l'une des innombrables capacit√©s qu'il permet.

Kubernetes, qui atteignait d√©j√† une large adoption √† l'√©poque, est maintenant devenu une [technologie mondiale grand public](https://www.cncf.io/reports/cncf-annual-survey-2021/#:~:text=Kubernetes%20has%20crossed%20the%20adoption%20chasm%20to%20become%20a%20mainstream%20global%20technology%C2%A0). Et √† mesure que le nombre de services fonctionnant sur cette plateforme augmente, le nombre d'organisations adoptant Istio augmentera √©galement.

De plus, **Istio n'est plus une technologie de niche !** Apr√®s de nombreuses am√©liorations de l'exp√©rience utilisateur ‚Äî par exemple, l'installation et les op√©rations de jour 2 sont devenues beaucoup plus faciles ‚Äî Istio a √©t√© adopt√© par des organisations de diff√©rentes tailles et industries.

En m√™me temps, il continue d'√©tendre son ensemble d'outils en ajoutant le support des machines virtuelles, en permettant au maillage de s'√©tendre sur plusieurs clusters, et bien plus encore.

La derni√®re chose que vous devez savoir est que le march√© manque de personnes poss√©dant ce genre de connaissances. Nous avons besoin de *vous !* C'est pourquoi j'ai enti√®rement r√©√©crit cet article pour en faire une introduction approfondie √† Istio et montrer ce qu'il fait sous le capot ‚Äì car je ne veux pas seulement que vous sachiez "ce qu'il fait", mais aussi "comment" il le fait.

Voici le contenu que nous allons couvrir dans ce guide :

* [Que fait Istio ?](#heading-que-fait-istio)
* [Introduction √† Istio](#heading-introduction-a-istio)
* [Architecture d'Istio](#heading-architecture-distio)
* [Comment utiliser Istio en pratique](#heading-comment-utiliser-istio-en-pratique)
* [Comment ex√©cuter les services sur le maillage](#heading-comment-executer-les-services-sur-le-maillage)
* [Ingress Gateway ‚Äì Comment autoriser le trafic dans le maillage](#heading-ingress-gateway-comment-autoriser-le-trafic-dans-le-maillage)
* [Observabilit√©](#heading-observabilite)
* [Gestion du trafic ‚Äì D√©ploiements Canary](#heading-gestion-du-trafic-deploiements-canary)
* [S√©curit√© Istio](#heading-securite-istio)

## Que fait Istio ?

**Istio** est un projet open-source qui a d√©but√© par un partenariat entre des √©quipes de Google, IBM et Lyft. Aujourd'hui, le nombre de contributeurs s'est √©largi pour inclure de nombreuses autres organisations telles que Solo.io, Tetrate, Aspen Mesh, et plus encore.

Il r√©sout de nombreuses pr√©occupations li√©es aux microservices, telles que :

* **Gestion du trafic :** R√©soudre le manque de fiabilit√© du r√©seau avec des timeouts, des tentatives (retries) et de l'√©quilibrage de charge (load balancing).
* **S√©curit√© :** Chiffrer le trafic en transit, authentification et autorisation des utilisateurs finaux et des services.
* **Observabilit√© :** Rendre le syst√®me observable avec des traces, des m√©triques et des journaux (logs).

Ces complexit√©s ou pr√©occupations peuvent √™tre r√©solues dans la couche applicative, mais vos services deviennent alors surcharg√©s de biblioth√®ques qui g√®rent la gestion du trafic, la d√©couverte de services, l'authentification, l'instrumentation et tout ce qui n'est pas au c≈ìur de votre m√©tier.

Illustrons cela par une conversation entre un chef de produit (PM) et un d√©veloppeur :

> **PM :** Combien de temps faudra-t-il pour ajouter une fonctionnalit√© de feedback √† l'application ?
>
> **Dev :** Deux sprints.
>
> **PM :** Quoi... ?! C'est juste un CRUD !
>
> **Dev :** Cr√©er le CRUD est facile, mais nous devons authentifier et autoriser les utilisateurs et les services. Et comme le r√©seau n'est pas fiable, nous devons impl√©menter des retries et des circuit breakers. Nous avons besoin de timeouts et de cloisons (bulkheads) pour nous assurer de ne pas faire tomber tout le syst√®me. De plus, pour d√©tecter les probl√®mes, nous avons besoin de monitoring et de tracing [...]

Vous voyez l'id√©e. Toute la c√©r√©monie et l'effort n√©cessaires pour ajouter un simple service sont √©normes.

La figure ci-dessous visualise toutes les couches impl√©ment√©es dans votre code applicatif qui √©puisent les ressources de votre √©quipe. Des ressources qui seraient mieux d√©pens√©es en se concentrant sur les fonctionnalit√©s m√©tier de base.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/layers-of-a-microservices.png)
*Les couches d'un microservice en plus de la fonctionnalit√© m√©tier de base*

Istio supprime toutes les pr√©occupations transversales mentionn√©es ci-dessus de vos services et les impl√©mente au niveau de la couche plateforme. Voyons comment cela se passe.

**NOTE :** Cet article suppose que vous avez une connaissance pratique de Kubernetes. Si ce n'est pas le cas, je vous recommande de lire [mon introduction √† Kubernetes](https://www.freecodecamp.org/news/learn-kubernetes-in-under-3-hours-a-detailed-guide-to-orchestrating-containers-114ff420e882/) puis de poursuivre avec cet article.

## Introduction √† Istio

Dans un monde sans Istio, un service fait des requ√™tes directes √† un autre et, en cas d'√©chec, le service est responsable de la gestion de ces √©checs. Il peut le faire en r√©essayant, en abandonnant les requ√™tes qui prennent trop de temps, en ouvrant le circuit breaker pour prot√©ger les services de la surcharge, et ainsi de suite.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/service-to-service-traffic.png)
*Trafic de service √† service*

C'est pourquoi nous avons tant de biblioth√®ques pour la d√©couverte de services, la r√©silience, l'instrumentation, etc. √âtant donn√© que chaque service doit r√©pondre √† ces pr√©occupations, il est logique de les r√©soudre sur la couche plateforme plut√¥t que dans le code applicatif.

Istio a con√ßu une solution ing√©nieuse. Il intercepte toutes les communications r√©seau et les redirige vers un proxy sidecar capable qui s'ex√©cute aux c√¥t√©s de chaque service. **Et c'est la responsabilit√© des proxys de r√©soudre toutes les pr√©occupations mentionn√©es ci-dessus.**

L'animation ci-dessous montre comment les proxys sidecar servent d'interm√©diaires au trafic et impl√©mentent les retries et les basculements (failovers) pour les requ√™tes √©chou√©es.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/services-in-istio.gif)
*Trafic de service √† service dans Istio*

Le proxy sidecar fait plus que cela. Nous d√©taillerons bon nombre de ses fonctionnalit√©s dans cet article. Mais ce qu'il est essentiel de noter, c'est que l'application elle-m√™me ignore totalement l'existence du proxy de service ou m√™me de l'ensemble du maillage. Si on l'interrogeait sur le Service Mesh, votre application r√©pondrait : "C'est quoi un Service Mesh ?!"

![Image](https://www.freecodecamp.org/news/content/images/2022/05/fish-in-water.png)
*Dessin par Victoria Dimitrakopoulos*

### Le proxy sidecar

Pour que le proxy sidecar puisse discerner si la requ√™te a √©chou√© ou non, il doit comprendre les protocoles de la couche applicative, tels que HTTP. Les proxys qui agissent √† cette couche sont des *proxys de couche applicative* ou *proxys de couche 7*. J'utiliserai ces termes de mani√®re interchangeable dans la suite de l'article.

En interceptant tout le trafic de service √† service, les proxys de couche applicative peuvent impl√©menter les √©l√©ments suivants :

* **Tol√©rance aux pannes** ‚Äî En utilisant les codes d'√©tat de r√©ponse, le proxy comprend quand une requ√™te √©choue et la r√©essaie.
* **Gestion fine du trafic** ‚Äî Router les requ√™tes avec des en-t√™tes sp√©cifiques vers les services pr√©vus. Par exemple, envoyer uniquement les utilisateurs b√™ta vers une nouvelle version b√™ta d'une application.
* **M√©triques** ‚Äî Le nombre de r√©ponses r√©ussies et √©chou√©es, le temps mis par un service pour r√©pondre, et ainsi de suite.
* **Tra√ßage (Tracing)** ‚Äî Ajoute des en-t√™tes sp√©ciaux dans chaque requ√™te et les suit √† travers les services du cluster.
* **S√©curit√©** ‚Äî Authentifie les services et les utilisateurs finaux √† l'aide de certificats et de jetons JWT, respectivement.

Ce ne sont l√† que quelques-unes des capacit√©s offertes par la gestion du trafic au niveau de la couche r√©seau applicative.

## Architecture d'Istio

Istio est compos√© du *plan de donn√©es (data plane)* et du *plan de contr√¥le (control plane)*.

### Le plan de donn√©es

Le plan de donn√©es comprend tous les pods dans lesquels le proxy sidecar a √©t√© inject√©. Dans la communaut√© Istio, nous les appelons fr√©quemment workloads du maillage ou simplement *workloads*.

Pendant ce temps, nous appelons les workloads sans sidecar des *workloads h√©rit√©s (legacy workloads)* parce qu'ils sont mauvais et dangereux, comme vous le verrez plus tard dans la section s√©curit√©.

**NOTE :** *"Pourquoi ne pas simplement les appeler des pods ?"* ‚Äî Parce que les workloads du maillage ne sont pas li√©s √† un cluster et peuvent s'ex√©cuter dans diff√©rents clusters, ou sur des machines virtuelles, et en fait partout o√π vous pouvez ex√©cuter et configurer le proxy sidecar.

#### Zoom sur un workload

Chaque workload poss√®de les quatre composants suivants :

* **Le conteneur init** ‚Äì vous n'avez pas √† vous en soucier. Il suffit de savoir qu'il configure la redirection du trafic vers le proxy sidecar.
* **Le pilot-agent** ‚Äì vous n'avez pas non plus √† vous en soucier. Il suffit de savoir qu'il effectue l'amor√ßage (bootstrapping) initial du proxy sidecar.
* **Le proxy sidecar** ‚Äì vous n'avez pas non plus besoin de vous en soucier. Il suffit de savoir que c'est le composant concret qui impl√©mente les fonctionnalit√©s de gestion du trafic, de s√©curit√© et d'observabilit√©.
* **L'application elle-m√™me**

Istio utilise Envoy comme proxy sidecar. Envoy est un proxy de couche 7 polyvalent, hautement extensible et soutenu par une communaut√© dynamique.

Envoy se diff√©rencie des autres proxys en √©tant configurable dynamiquement via une API qu'il expose.

Vous pourriez demander : "**Pourquoi est-ce important ?**" Parce qu'Envoy doit √™tre tenu √† jour des changements qui surviennent dans l'environnement.

Par exemple, dans Kubernetes, les workloads ont une dur√©e de vie courte. De nouveaux services sont constamment d√©ploy√©s, les workloads sont replanifi√©s et les utilisateurs peuvent d√©finir de nouvelles r√®gles de routage ou politiques. Par cons√©quent, nous avons besoin de *"quelque chose"* qui met continuellement √† jour la configuration du proxy.

Ce "quelque chose" est le *plan de contr√¥le*, qui utilise l'API Envoy pour synchroniser le proxy avec les changements survenant dans la plateforme sous-jacente.

### Le plan de contr√¥le Istio

Le plan de contr√¥le d'Istio est un contr√¥leur Kubernetes qui surveille le serveur API Kubernetes pour en savoir plus sur les workloads s'ex√©cutant dans la plateforme et g√©n√®re la configuration Envoy sur la fa√ßon de router le trafic vers et depuis ces workloads.

De plus, Istio expose une API au format Custom Resource Definitions (CRDs) Kubernetes avec laquelle les op√©rateurs de services (*vous*) peuvent configurer le plan de donn√©es.

Par *configuration du plan de donn√©es*, on entend que vous configurez les workloads avec des politiques, des r√®gles de routage, des retries, etc.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/istio-control-plane.png)
*Le plan de contr√¥le configure le plan de donn√©es*

Nous avons appris pas mal de choses sur l'architecture d'Istio. √Ä partir de maintenant, nous allons r√©duire la th√©orie au strict minimum et passer √† des exemples pratiques qui vous aideront √† comprendre et √† m√©moriser le contenu.

## Comment utiliser Istio en pratique

### Pr√©requis : Comment configurer un cluster Kubernetes

Avant d'apprendre Istio et comment l'utiliser, vous devez disposer d'un cluster Kubernetes avec un acc√®s administrateur.

Naturellement, vous aurez besoin de `kubectl` pour interagir avec le cluster. Pour installer `kubectl`, rendez-vous sur [la documentation officielle et suivez les instructions pour votre syst√®me d'exploitation](https://kubernetes.io/docs/tasks/tools/install-kubectl/).

Cet article utilise *Kubernetes In Docker*, √©galement connu sous le nom de `kind`. Vous pouvez utiliser toute autre distribution Kubernetes locale telle que Docker-Desktop ([comment l'installer](https://docs.docker.com/desktop/) et [l'utiliser](https://docs.docker.com/desktop/kubernetes/)), [Rancher Desktop](https://rancherdesktop.io/), ou [Minikube](https://minikube.sigs.k8s.io/docs/start/). Assurez-vous simplement d'√™tre au moins sur la version 1.23 de Kubernetes.

Pour installer `kind`, suivez les instructions d'installation sur [https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/).

### Comment cr√©er un cluster avec `kind`

Apr√®s avoir install√© `kind`, cr√©ez un cluster Kubernetes avec la commande ci-dessous :

`kind create cluster --image=kindest/node:v1.23.1`

Cette commande t√©l√©charge une image de conteneur avec la version 1.23.1 de Kubernetes et l'ex√©cute sur votre moteur de conteneur. Par exemple, si votre moteur est `docker`, vous pouvez voir le conteneur en cours d'ex√©cution en ex√©cutant `docker ps`.

Votre sortie affichera un nouveau conteneur en cours d'ex√©cution :

```
CONTAINER ID   IMAGE                  COMMAND        NAMES
2974301ffa31   kindest/node:v1.23.1   "/usr/loca‚Ä¶"   kind-control-plane
```

**NOTE :** Istio 1.13 est compatible avec les versions 1.20 et ult√©rieures de Kubernetes. Pour en savoir plus sur les versions de Kubernetes prises en charge, consultez la documentation officielle sur [Istio: Supported Kubernetes releases.](https://istio.io/latest/docs/releases/supported-releases/)

### Comment installer Istio sur le cluster

Vous pouvez installer Istio soit avec l'utilitaire `istioctl`, soit avec le gestionnaire de paquets `helm`. Pour obtenir `istioctl`, t√©l√©chargez les artefacts de la version d'Istio, comme indiqu√© ci-dessous.

```bash
curl -L https://istio.io/downloadIstio | \
  ISTIO_VERSION=1.13.2 TARGET_ARCH=x86_64 sh -
```

Dans le r√©pertoire t√©l√©charg√©, vous trouverez l'outil CLI `istioctl` sous `istio-1.13.2/bin/istioctl`. Ensuite, d√©placez le binaire dans votre variable d'environnement PATH afin de pouvoir ex√©cuter les commandes `istioctl` depuis n'importe quel r√©pertoire.

Apr√®s cela, installez Istio avec la commande ci-dessous :

```bash
istioctl install --set profile=demo -y
```

L'ex√©cution de cette commande peut prendre plusieurs minutes car elle attend que tous les Pods soient op√©rationnels. Une fois termin√©e, affichez les Pods d√©ploy√©s dans l'espace de noms d'installation d'Istio.

```bash
kubectl get pods -n istio-system
```

Vous devriez voir la sortie ci-dessous.

```
NAME                                   READY   STATUS    RESTARTS
istio-egressgateway-6cf5fb4756-r569f   1/1     Running   0
istio-ingressgateway-dc9c8f588-cn2z4   1/1     Running   0
istiod-7586c7dfd8-2nbsk                1/1     Running   0
```

Les composants install√©s sont :

* **Istio egress gateway** ‚Äì utilis√© pour s√©curiser le trafic sortant.
* **Istio ingress gateway** ‚Äì le point d'entr√©e du trafic arrivant dans votre cluster.
* **Istiod** ‚Äì le plan de contr√¥le d'Istio qui configure les proxys de service.

### Comment installer les add-ons Istio

Les artefacts Istio t√©l√©charg√©s pr√©c√©demment contiennent des exemples d'outils pour visualiser la t√©l√©m√©trie g√©n√©r√©e. Pour les d√©ployer dans votre cluster, ex√©cutez la commande ci-dessous :

```bash
kubectl apply -f istio-1.13.2/samples/addons/
```

Ceci installe les outils suivants : Prometheus, Grafana, Kiali et Jaeger. Nous y jetterons un ≈ìil plus tard. Mais d'abord, nous avons besoin de services.

### L'application exemple : Analyse de sentiment

Nous allons ex√©cuter l'application de microservices utilis√©e dans mon [article d'introduction √† Kubernetes](https://www.freecodecamp.org/news/learn-kubernetes-in-under-3-hours-a-detailed-guide-to-orchestrating-containers-114ff420e882). Elle est suffisamment complexe pour pr√©senter les fonctionnalit√©s d'Istio en pratique.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/sentiment-analysis-app.png)
*Les services d'analyse de sentiment*

La figure ci-dessus montre les services qui composent l'application :

* Le service **SA-Frontend** ‚Äî sert le frontend ; une application React JavaScript.
* Le service **SA-WebApp** ‚Äî g√®re les requ√™tes pour analyser le sentiment des phrases.
* Le service **SA-Logic** ‚Äî effectue l'analyse de sentiment.
* Le service **SA-Feedback** ‚Äî enregistre les commentaires des utilisateurs sur la pr√©cision de l'analyse.

De plus, la figure montre un proxy de couche 7 qui effectue un reverse-proxy du trafic en fonction du chemin de la requ√™te. Dans le maillage d'Istio, l'*Ingress Gateway* est le point d'entr√©e du trafic et le route vers les services.

## Comment ex√©cuter les services sur le maillage

Pour int√©grer des services au maillage, vous devez injecter le proxy sidecar dans leurs pods applicatifs. Vous pouvez le faire manuellement ou automatiquement.

Pour l'injection automatique de sidecar, vous √©tiquetez les espaces de noms avec `istio-injection: enabled`. Apr√®s cela, tous les pods d√©ploy√©s dans ces espaces de noms auront le sidecar inject√© (en utilisant une fonctionnalit√© de Kubernetes appel√©e mutating webhooks qui modifie la d√©finition du pod).

Cr√©ez un espace de noms et √©tiquetez-le pour l'injection automatique.

```bash
kubectl create ns demo
kubectl label ns demo istio-injection=enabled
```

Basculez le contexte kubectl vers l'espace de noms `demo` pour y appliquer les commandes suivantes.

```bash
kubectl config set-context --current --namespace=demo
```

Ensuite, clonez le d√©p√¥t contenant les services et la configuration dont nous avons besoin tout au long de l'article :

```bash
git clone https://github.com/rinormaloku/master-istio.git 
cd master-istio
```

Proc√©dez au d√©ploiement des services :

```
kubectl apply -f ./kube
```

Ensuite, v√©rifiez que le sidecar a √©t√© inject√© dans chacun des pods de service avec la commande suivante :

```bash
$ kubectl get pods -n demo

NAME                           READY     STATUS    RESTARTS   AGE
sa-feedback-55f5dc4d9c-c9wfv   2/2       Running   0          12m
sa-frontend-558f8986-hhkj9     2/2       Running   0          12m
sa-logic-568498cb4d-2sjwj      2/2       Running   0          12m
sa-logic-568498cb4d-p4f8c      2/2       Running   0          12m
sa-web-app-599cf47c7c-s7cvd    2/2       Running   0          12m
```

Assurez-vous que sous la colonne `READY`, vous voyez la valeur "2/2". Cela montre que les deux conteneurs sont en cours d'ex√©cution : le conteneur de l'application et le proxy sidecar. Visualis√© dans la figure ci-dessous, o√π nous zoomons sur un Pod.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/zoom-into-workload.png)
*Figure 7. Zoom sur un Pod : Le conteneur sidecar est inject√© dans le pod*

Nos services sont pr√™ts √† recevoir le trafic des utilisateurs finaux. Pour cela, nous devons les exposer ensuite.

## Ingress Gateway ‚Äì Comment autoriser le trafic dans le maillage

L'Ingress Gateway d'Istio est un proxy sp√©cial √† la p√©riph√©rie du maillage qui autorise le trafic provenant du r√©seau public et le route vers les services au sein du cluster.

Plus t√¥t, lorsque nous avons list√© les pods dans l'espace de noms d'installation d'Istio, nous l'avons vu √† l'√©tat `Running`. Cette passerelle est expos√©e par un service Kubernetes de type `LoadBalancer`. Nous pouvons l'interroger comme suit :

```bash
$ kubectl get svc -n istio-system -l istio=ingressgateway

NAME                   TYPE           CLUSTER-IP     EXTERNAL-IP
istio-ingressgateway   LoadBalancer   10.96.176.88   <pending>
```

Si vous utilisez `kind`, l'adresse IP externe sera √† l'√©tat `Pending`. Cependant, dans les clusters Kubernetes manag√©s, le fournisseur de cloud fournirait un √©quilibreur de charge avec une adresse IP statique que vous pouvez utiliser pour router le trafic vers la passerelle.

Comme solution de contournement, nous pouvons effectuer une redirection de port vers notre environnement local. Ouvrez un deuxi√®me terminal, ex√©cutez la commande suivante et laissez-la s'ex√©cuter pendant toute la dur√©e de l'article.

```bash
kubectl port-forward -n istio-system svc/istio-ingressgateway 8080:80
```

D√©sormais, le trafic vers `localhost:8080` sera transf√©r√© vers l'Ingress Gateway. Si vous ouvrez le navigateur, tapez cette adresse et appuyez sur entr√©e, vous d√©couvrirez que la passerelle rejette votre requ√™te. C'est le comportement par d√©faut de la passerelle.

### API Gateway : autoriser le trafic

Istio d√©finit la ressource personnalis√©e `Gateway` avec laquelle vous pouvez configurer le type de trafic √† autoriser dans le maillage. Par exemple, pour accepter le trafic HTTP sur le port 80, nous utiliserons la configuration ci-dessous :

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: http-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "*"
```

La majeure partie de la configuration ci-dessus est explicite, mais ce qui peut ressortir est le s√©lecteur `istio: ingressgateway`.

La question est : *"Pourquoi en avons-nous besoin ?"*

Un Service Mesh peut avoir plusieurs Ingress Gateways. Habituellement, vous utiliseriez cela dans des environnements multi-tenants. Dans notre cas, nous appliquerons la configuration `Gateway` √† l'Ingress Gateway par d√©faut, qui est √©tiquet√©e avec `istio=ingressgateway`.

Appliquez la `Gateway` au cluster :

```bash
kubectl apply -f istio/http-gateway.yaml
```

Apr√®s avoir appliqu√© la configuration `Gateway`, le trafic sur le port 80 sera admis pour tous les h√¥tes (comme indiqu√© par l'h√¥te g√©n√©rique "*").

Ensuite, nous devons configurer ce qu'il faut faire avec le trafic admis.

### API VirtualService : Router le trafic

La ressource `VirtualService` configure le routage du trafic au sein du maillage pour tous les proxys et passerelles. Dans notre cas, nous voulons router le trafic de l'Ingress Gateway vers un ensemble de workloads, comme indiqu√© ci-dessous.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/istio-ingress-gateway-routing.png)
*L'Ingress Gateway d'Istio route le trafic en fonction de l'en-t√™te de localisation HTTP*

D√©composons les requ√™tes qui doivent √™tre rout√©es vers SA-Frontend :

* **Les chemins correspondant exactement √†** `/` doivent √™tre rout√©s vers SA-Frontend pour obtenir le fichier Index.html.
* **Les chemins pr√©fix√©s par** `/static/*` doivent √™tre rout√©s vers SA-Frontend pour obtenir tous les fichiers statiques n√©cessaires au frontend, comme les feuilles de style en cascade (CSS) et les fichiers JavaScript.
* **Les chemins qui correspondent √† l'expression r√©guli√®re** `'^.*\.(ico|png|jpg)$'` doivent √™tre rout√©s vers SA-Frontend.

Ceci est r√©alis√© avec la configuration suivante :

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: sa-external-services
spec:
  hosts:
  - "*"
  gateways:
  - http-gateway                      # 1
  http:
  - match:
    - uri:
        exact: /
    - uri:
        prefix: /static
    - uri:
        regex: '^.*\.(ico|png|jpg)$'
    route:
    - destination:
        host: sa-frontend             # 2
        port:
          number: 80
```

1. Ce `VirtualService` s'applique aux requ√™tes arrivant via la `http-gateway` que nous avons d√©finie dans la section pr√©c√©dente.
2. Destination d√©finit le service vers lequel router le trafic.

**NOTE :** La configuration ci-dessus se trouve dans le fichier `vs-route-ingress.yaml`. Elle contient √©galement les r√®gles de routage pour le trafic vers SA-WebApp et SA-Feedback. Elle est omise par souci de bri√®vet√© dans la liste ci-dessus.

Appliquez le `VirtualService` au cluster.

```bash
kubectl apply -f istio/vs-route-ingress.yaml
```

Le plan de contr√¥le propage la configuration √† la passerelle en quelques secondes. Apr√®s cela, vous pouvez acc√©der √† l'application √† l'adresse [http://localhost:8080/](http://localhost:8080/), √† condition de toujours effectuer la redirection de port de l'Ingress Gateway d'Istio vers votre environnement local.

Ouvrez le navigateur √† cette adresse. Vous verrez l'application, comme le montre l'image ci-dessous.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/sentiment-analysis.gif)

La figure ci-dessous montre comment ces deux ressources configurent l'Ingress Gateway. La ressource `Gateway` la configure pour autoriser le trafic et le `VirtualService` configure l'endroit o√π router le trafic admis.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/gateway-vs-in-context.png)
*Configuration de l'Ingress Gateway d'Istio pour autoriser et router le trafic*

Hourra ! Nous avons r√©ussi √† faire fonctionner les services. Nous avons inject√© le sidecar et rout√© le trafic des utilisateurs finaux vers ceux-ci.

Vous pourriez vous demander : *"Pourquoi tout ce foin autour de l'ex√©cution de workloads dans le maillage ? Apr√®s tout, le routage du trafic vers les workloads √† l'aide d'un routage bas√© sur le chemin peut √™tre effectu√© avec n'importe quel contr√¥leur d'ingress de couche 7."*

Nous y r√©pondrons ensuite, lorsque nous montrerons les avantages en mati√®re de s√©curit√© et d'observabilit√© que vous avez acquis. Alors, commen√ßons.

## Observabilit√©

Le proxy sidecar d'Istio ‚Äî √† savoir le proxy Envoy ‚Äî g√©n√®re des journaux d'acc√®s, des m√©triques et des traces pour tout le trafic entrant et sortant. Les m√©triques fournissent des informations sur le fonctionnement du syst√®me et aident √† r√©pondre √† des questions telles que : Le syst√®me est-il sain ? Quel est le taux de r√©ussite d'un service ? Et ainsi de suite.

G√©n√©rer les m√©triques n'est que la moiti√© de l'histoire. L'autre moiti√© consiste √† collecter et √† visualiser les informations d'une mani√®re qui incite √† l'action. Nous allons utiliser les add-ons Istio que nous avons install√©s plus t√¥t :

* **Prometheus** pour collecter les m√©triques.
* **Grafana** pour les visualiser.
* **Jaeger** pour d√©nicher les traces.
* **Kiali** rassemble toutes les donn√©es de t√©l√©m√©trie.

Mais que se passe-t-il si vous avez d√©j√† des outils d'observabilit√© dans votre organisation ? Encore mieux, vous pouvez int√©grer Istio avec ceux-ci :)

### Grafana : Visualiser les m√©triques

Grafana visualise les m√©triques collect√©es par Prometheus. Ouvrez le tableau de bord Grafana et voyons ce que nous obtenons par d√©faut.

```bash
istioctl dashboard grafana
```

La commande ci-dessus effectuera une redirection de port de Grafana vers votre environnement local et l'ouvrira dans votre navigateur par d√©faut. Ensuite, naviguez vers "Istio" > "Istio Service Dashboard" et filtrez la sortie en utilisant le menu d√©roulant "Service" et s√©lectionnez le service "sa-webapp".

Si les graphiques de votre c√¥t√© semblent un peu vides, g√©n√©rez du trafic en ex√©cutant la commande ci-dessous :

```bash
while true; do \
  curl -i http://localhost:8080/sentiment \
  -H "Content-type: application/json" \
  -d '{"sentence": "I love yogobella"}'; \
  sleep .$RANDOM; done
```

Laissez cette commande s'ex√©cuter pour le reste de l'article, car nous aurons √©galement besoin de l'afflux de trafic par la suite.

Ci-dessous, nous visualisons les m√©triques du service `sa-webapp`.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/grafana-dashboard.png)
*Grafana : Visualisation des m√©triques pour le service sa-webapp*

Prometheus et Grafana nous permettent de comprendre la sant√©, les performances et les am√©liorations ou d√©gradations de nos services au fil du temps. C'est √† vous d'approfondir l'√©tude des graphiques et des informations qu'ils visualisent.

Ensuite, nous allons examiner le tra√ßage des requ√™tes lorsqu'elles passent √† travers les services.

### Jaeger : D√©nicher les traces d'une requ√™te

Il est raisonnable de se demander : "Pourquoi tra√ßons-nous les requ√™tes *de nos jours* ? Nous ne le faisions pas pour les monolithes ?" ‚Äî passer aux microservices r√©sout certaines difficult√©s, bien que par inadvertance, cela apporte certaines des propri√©t√©s inh√©rentes aux syst√®mes distribu√©s qui n√©cessitent d'autres solutions.

Par exemple, la propri√©t√© d'√™tre distribu√© rend la localisation des pannes relativement d√©licate.

Imaginez qu'un utilisateur final re√ßoive une requ√™te √©chou√©e ‚Äî "quelle en √©tait la cause ?" Pour localiser la panne, vous devriez v√©rifier tous les services qui ont particip√© au traitement de la requ√™te.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/localizing-failures-is-hard.png)

Sans outils appropri√©s, la seule option disponible est d'enlever votre chapeau d'*Ing√©nieur* et de mettre votre chapeau de *D√©tective*. Ensuite, vous devriez reconstituer l'histoire de la "*requ√™te √©chou√©e*" en interrogeant tous les journaux de service, en filtrant par horodatage et en essayant de donner un sens √† toutes les donn√©es. Ensuite, vous arriveriez lentement mais s√ªrement au fond des choses et trouveriez le coupable !

Jouer au d√©tective peut √™tre une activit√© amusante la premi√®re fois ‚Äî mais cela deviendra vite r√©barbatif car les pannes sont monnaie courante. Nous avons besoin d'outils efficaces pour les localiser dans les syst√®mes distribu√©s.

**Jaeger est un tel outil.**

Jaeger vient du mot allemand signifiant "chasseur" (√©crit J√§ger). Cela implique de "chasser les pannes". Cependant, je pr√©f√®re de loin mon analogie avec le d√©tective. Ainsi, rayez Jaeger ‚ùå et remplacez-le par **Inspecteur Gadget** ‚úÖ

Pour tracer des requ√™tes sans Istio, vous devriez instrumenter tous vos services pour g√©n√©rer des traces et les envoyer √† **Inspecteur Gadget**. *(ouais‚Ä¶ je continue sur ma lanc√©e* ü§£)

Au contraire, avec Istio, les proxys sidecar g√©n√®rent des en-t√™tes de trace (sous forme d'en-t√™tes HTTP) et les envoient √† Inspecteur Gadget (*c'est la derni√®re fois, je le promets* üòú). Ceci est fait par chaque service qui poss√®de le proxy sidecar.

Vous n'avez qu'√† **mettre √† jour vos services pour propager les en-t√™tes de trace g√©n√©r√©s aux services amont**. Sinon, chaque proxy g√©n√®re √† nouveau les en-t√™tes. Et lorsque les traces sont assembl√©es, cela ne nous donnerait pas une image compl√®te de la requ√™te.

Le diagramme ci-dessous visualise le processus.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/how-traces-are-generated.png)
*Comment les informations de tra√ßage sont g√©n√©r√©es et envoy√©es aux serveurs de traces*

Faites attention √† l'√©tape 4 du diagramme. Il est de la responsabilit√© de l'application de transmettre les en-t√™tes de tra√ßage √† l'amont.

La transmission des en-t√™tes de tra√ßage est critique, car le proxy suivant r√©cup√©rera les en-t√™tes existants et comprendra qu'il s'agit de la suite d'une requ√™te d√©j√† trac√©e. Ainsi, il r√©utilisera les en-t√™tes de tra√ßage (tels que le `x-request-id`), puis il ajoutera les donn√©es suppl√©mentaires qu'il enregistre. Les en-t√™tes de trace sont utilis√©s pour combiner toutes les informations d'une requ√™te dans Jaeger.

Ouvrez le tableau de bord Jaeger et voyez comment les traces montrent toute l'√©tendue d'une requ√™te.

```bash
istioctl dashboard jaeger
```

La commande ci-dessus effectuera une redirection de port de Jaeger vers votre environnement local et l'ouvrira dans votre navigateur par d√©faut.

Explorez l'interface utilisateur de Jaeger et examinez les requ√™tes individuelles. Par exemple, l'image ci-dessous montre les traces d'une requ√™te pour analyser le sentiment d'une phrase.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/jaeger-request-trace.png)
*Le flux complet de la requ√™te √† travers le maillage*

L'image montre comment la requ√™te a commenc√© √† l'Ingress Gateway (c'est le premier contact avec un workload du Service Mesh). Ensuite, la requ√™te a √©t√© rout√©e vers `sa-webapp` et `sa-logic`, respectivement.

**NOTE :** Pour en savoir plus sur les en-t√™tes que votre application doit propager et les biblioth√®ques clientes pour cela, consultez la [FAQ sur le tra√ßage distribu√© d'Istio](https://istio.io/latest/about/faq/distributed-tracing) et lisez la r√©ponse √† ["What is required for distributed tracing with Istio"](https://istio.io/latest/about/faq/distributed-tracing/#how-to-support-tracing)?"

Les traces clarifient l'endroit o√π la requ√™te a √©chou√© et quel service a renvoy√© l'erreur, et ainsi de suite. Mais nous en apprenons davantage sur l'√©chec en utilisant les journaux d'acc√®s du proxy et les journaux de l'application.

### Journaux d'acc√®s (Access logs)

Envoy enregistre chaque requ√™te individuelle sous forme de journaux d'acc√®s. Imprimons une entr√©e de journal du service `sa-webapp` pour voir les donn√©es enregistr√©es.

```bash
$ kubectl logs deploy/sa-webapp -c istio-proxy | tail -n 1

[2022-04-18T12:09:44.091Z] "POST /sentiment HTTP/1.1" 200 - via_upstream - "-" 32 46 5 5 "10.244.0.6" "curl/7.74.0" "bfb9e6e5-2968-9b25-b256-f0917aa6b0bb" "localhost:8080" "10.244.0.16:8080" inbound|8080|| 127.0.0.6:51819 10.244.0.16:8080 10.244.0.6:0 outbound_.80_._.sa-webapp.demo.svc.cluster.local default
```

Cela ressemble beaucoup √† du charabia, n'est-ce pas ? C'est le format TEXTE, o√π chaque information est s√©par√©e par un espace. Vous pouvez apprendre ce que signifie chaque champ s√©par√© par un espace en affichant le format du journal d'acc√®s ‚Äî obtenu avec la commande ci-dessous :

```bash
$ istioctl pc all deploy/sa-webapp -o json | \
    grep log_format -A 2 | tail -n 2

"text_format_source": {
  "inline_string": "[%START_TIME%] \"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\" %RESPONSE_CODE% %RESPONSE_FLAGS% %RESPONSE_CODE_DETAILS% %CONNECTION_TERMINATION_DETAILS% \"%UPSTREAM_TRANSPORT_FAILURE_REASON%\" %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \"%REQ(X-FORWARDED-FOR)%\" \"%REQ(USER-AGENT)%\" \"%REQ(X-REQUEST-ID)%\" \"%REQ(:AUTHORITY)%\" \"%UPSTREAM_HOST%\" %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\n"
```

Ainsi, la premi√®re entr√©e est `[%START_TIME%]` qui, d'apr√®s le journal list√© pr√©c√©demment, est la valeur `[2022-04-18T12:09:44.091Z]`, et ainsi de suite. Vous pouvez en savoir plus sur les journaux d'acc√®s dans ce document Istio : "[Envoy Access Logs](https://istio.io/latest/docs/tasks/observability/logs/access-log/#default-access-log-format)".

### Comment personnaliser le format du journal d'acc√®s

Vous pouvez personnaliser le format du journal d'acc√®s. Par exemple, la commande suivante met √† jour l'installation d'Istio pour imprimer les journaux au format JSON.

```bash
istioctl install --set profile=demo \
    --set meshConfig.accessLogEncoding="JSON"
```

Au format JSON, les donn√©es du journal ont des valeurs associ√©es √† des cl√©s qui expliquent la signification de la valeur.

### Kiali ‚Äì La console pour le Service Mesh d'Istio

Kiali est une console puissante pour Istio. Elle utilise les donn√©es de t√©l√©m√©trie pour visualiser le trafic de service √† service. Elle corr√®le les informations de t√©l√©m√©trie collect√©es, telles que les m√©triques, les traces, ainsi que les journaux d'acc√®s et d'application. Ainsi, le d√©bogage des probl√®mes d'application devient un jeu d'enfant.

**NOTE :** Kiali dispose d'une liste de validateurs qui d√©couvrent √©galement les mauvaises configurations au sein du maillage. Ceci, cependant, d√©passe le cadre de cet article. En savoir plus sur les [validateurs Kiali](https://kiali.io/docs/features/validations/).

Ouvrez le tableau de bord Kiali avec la commande suivante :

```bash
istioctl dashboard kiali
```

La figure ci-dessous montre les informations visualis√©es dans le tableau de bord.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/kiali-dashboard-annotated.png)

Et ensuite, nous passons √† ma fonctionnalit√© pr√©f√©r√©e : la corr√©lation des m√©triques et des traces, comme indiqu√© ci-dessous.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/correlation-requests-and-traces.png)

La corr√©lation des m√©triques et des traces permet aux √©quipes applicatives de trouver facilement la requ√™te la plus lente et le chemin qu'elle a emprunt√© √† travers les services. De cette fa√ßon, il est facile de d√©couvrir les goulots d'√©tranglement sur lesquels les √©quipes peuvent se concentrer pour am√©liorer les performances de leur application.

**CONSEIL :** Consultez la documentation officielle pour en savoir plus sur la [corr√©lation des m√©triques](https://kiali.io/docs/features/tracing/#metric-correlation).

C'est ainsi que nous concluons la section sur l'observabilit√© de cet article. Bien s√ªr, tous les outils pr√©sent√©s ont plus d'ampleur et de profondeur. Cependant, la couverture ici est suffisante pour vous donner une id√©e de l'observabilit√© que vous gagnez sur le syst√®me lors de l'adoption de Service Meshes.

## Gestion du trafic ‚Äì D√©ploiements Canary

Le fait que le trafic de service √† service soit interm√©di√© par des proxys de couche 7 permet des capacit√©s complexes de gestion du trafic. √Ä titre d'exemple, nous l'utilisons d√©j√† lorsque nous routons les requ√™tes en fonction de l'en-t√™te de chemin dans l'Ingress Gateway.

Nous pouvons baser les d√©cisions de routage sur n'importe quelle autre information HTTP. Voyons ensuite comment les capacit√©s de gestion du trafic nous permettent de s√©curiser les d√©ploiements.

### Comment s√©curiser la livraison continue (Continuous Delivery)

Dans toute l'industrie technologique, nous avons appris de mani√®re empirique que les pannes de service les plus fr√©quentes surviennent pendant les jours ouvrables ‚Äî et rarement le week-end. C'est parce que, pendant la semaine, des changements sont introduits dans le syst√®me. Nous ne pouvons pas √©viter les changements, mais nous devons trouver des moyens de rendre leur livraison plus s√ªre.

La livraison continue peut √™tre pens√©e en deux phases :

1. **Phase de d√©ploiement** : D√©ployer l'application.
2. **Phase de publication (Release)** : Envoyer le trafic des utilisateurs finaux vers l'application.

#### Mod√®les de livraison

La "Phase de d√©ploiement" est g√©r√©e par la plateforme. Par exemple, c'est ce pour quoi nous utilisons les Deployments Kubernetes.

La "Phase de publication" est celle o√π les capacit√©s de gestion du trafic d'Istio s'av√®rent utiles et permettent la mise en ≈ìuvre des mod√®les de livraison suivants :

* **D√©ploiements Canary** ‚Äî Valider le nouveau d√©ploiement en ne routant qu'une fraction du trafic vers la derni√®re version. Valider ensuite les changements et ne le publier √† tous les utilisateurs qu'apr√®s cela.
* **D√©ploiements progressifs** ‚Äî Une variante des d√©ploiements canary o√π vous augmentez progressivement le pourcentage de trafic envoy√© vers la nouvelle version.
* **Dark launch** ‚Äî Pas pr√©cis√©ment pour publier des logiciels en toute s√©curit√©, mais pour les publier √† un sous-ensemble d'utilisateurs (tels que des utilisateurs b√™ta) et v√©rifier comment les changements sont re√ßus.
* **Mise en miroir du trafic (Traffic mirroring)** ‚Äî Reproduit le trafic r√©el des utilisateurs vers la nouvelle version de l'application et ignore les r√©ponses.

Dans cet article, nous allons montrer le mod√®le de d√©ploiement canary pour valider la nouvelle version de l'application avant de la publier au trafic r√©el. Nous couvrons plus de mod√®les de d√©ploiement dans le livre [Istio in Action.](https://livebook.manning.com/book/istio-in-action/chapter-5/73#:~:text=v1%20of%20catalog-,5.2.5%20Routing%20specific%20requests%20to%20v2,-Maybe%20we%20wish)

### D√©ploiements Canary avec Istio

Lors du d√©ploiement d'une autre version d'une application dans Kubernetes, elle re√ßoit imm√©diatement du trafic, ce qui signifie que nos utilisateurs sont rout√©s vers le nouveau service. Ce n'est pas ce que nous voulons !

Nous voulons en fait que le trafic ne soit rout√© que vers la premi√®re version, m√™me apr√®s le d√©ploiement de la deuxi√®me version de l'application (et plus tard, nous d√©cidons de publier la deuxi√®me version au trafic des utilisateurs finaux).

Dans Istio, la distinction entre les versions se fait √† l'aide de l'API DestinationRule. Avec la r√®gle de destination ci-dessous, nous d√©finissons les sous-ensembles (subsets) suivants :

* Sous-ensemble `v1` ‚Äî cible les pods avec l'√©tiquette `version: v1`.
* Sous-ensemble `v2` ‚Äî cible les pods avec l'√©tiquette `version: v2`.

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: sa-logic
spec:
  host: sa-logic
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
```

Appliquons-le au cluster pour que cette distinction existe.

```bash
kubectl apply -f istio/sa-logic-dr.yaml
```

Ensuite, cr√©ons un VirtualService qui configure les proxys de service pour router le trafic uniquement vers le sous-ensemble `v1` pour tout trafic ciblant le service `sa-logic` :

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: sa-logic
spec:
  hosts:
  - sa-logic
  http:
  - route:
    - destination:
        host: sa-logic
        subset: v1
      weight: 100
```

Appliquez au cluster en ex√©cutant la commande suivante :

```bash
kubectl apply -f istio/sa-logic-vs.yaml
```

D√©sormais, le d√©ploiement de la deuxi√®me version du service ne la publiera pas au trafic des utilisateurs finaux.

```bash
kubectl apply -f kube/canary/sa-logic-v2.yaml
```

V√©rifiez que tout le trafic est rout√© vers le sous-ensemble `v1` √† l'aide du tableau de bord Kiali Graph (voir figure ci-dessous).

![Image](https://www.freecodecamp.org/news/content/images/2022/05/sa-logic-v1-only-kiali.png)
*Taux de r√©ussite du sous-ensemble v1*

Ensuite, envoyons seulement 10 % du trafic des utilisateurs finaux vers la nouvelle version de `sa-logic`, comme visualis√© dans l'image ci-dessous.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/subsets-istio-config.png)
*Comment Istio configure le routage vers les sous-ensembles*

```yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: sa-logic
spec:
  hosts:
  - sa-logic
  http:
  - route:
    - destination:
        host: sa-logic
        subset: v1
      weight: 90
    - destination:
        host: sa-logic
        subset: v2
      weight: 10
```

Appliquez-le au cluster.

```bash
kubectl apply -f istio/sa-logic-vs-canary.yaml
```

Apr√®s avoir publi√© la nouvelle version au trafic des utilisateurs finaux, vous pouvez la surveiller et la valider. Utilisez les outils d'observabilit√© que nous avons explor√©s plus t√¥t.

Par exemple, apr√®s avoir appliqu√© le changement, nous pouvons observer dans le graphique Kiali le taux de r√©ussite et d'erreur des sous-ensembles.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/sa-logic-v2-errors-kiali.png)

Saperlipopette ! Nous avons une augmentation du taux d'erreur. Mettons √† jour le VirtualService pour rediriger tout le trafic vers `v1`, qui n'avait aucune erreur.

```bash
kubectl apply -f istio/sa-logic-vs.yaml
```

Si vous v√©rifiez √† nouveau les graphiques Kiali, vous constaterez que 100 % du trafic est rout√© vers la version 1, qui n'avait aucune erreur.

**R√©sum√© :** Les publications dans Kubernetes sont toujours des "big bangs". Vous avez un changement que vous voulez exp√©dier, et s'il contient des bugs, il impacte tous vos utilisateurs.

Mais Istio utilise les proxys de service pour prendre des d√©cisions de routage fines qui, lorsqu'elles sont utilis√©es, s√©curisent les publications.

Ensuite, examinons les fonctionnalit√©s de s√©curit√© d'Istio ‚Äî √ßa devient passionnant !

## S√©curit√© Istio

Je n'aurais jamais (au grand jamais) cru que la s√©curit√© serait un sujet qui m'enthousiasmerait. Que pourrait bien faire Istio sur le spectre technologique pour rendre ce sujet divertissant ? Et plus important encore, pourquoi devriez-vous √™tre enthousiaste vous aussi ?

**La r√©ponse est simple :** Istio d√©charge les responsabilit√©s de s√©curit√© de notre code applicatif vers la plateforme (plus pr√©cis√©ment, les proxys Envoy). Ainsi, lorsque le trafic atteint nos applications, il est d√©j√† authentifi√© et autoris√©.

Dans les sections suivantes, nous montrerons comment authentifier et autoriser √† la fois le trafic de service √† service et le trafic des utilisateurs finaux √† l'aide d'Istio.

Mais d'abord, assurons-nous d'avoir une compr√©hension commune de l'authentification et de l'autorisation :

* **L'authentification** se produit lorsqu'un client ou un serveur prouve son identit√© (c'est-√†-dire r√©pond √† la question "qui" il est) en utilisant quelque chose qu'il poss√®de, comme un certificat et/ou un JWT.
* **L'autorisation** est le processus consistant √† autoriser ou √† rejeter les actions des utilisateurs authentifi√©s.

### Auto mTLS : authentification de service √† service

Istio utilise le *Secure Production Identity Framework for Everyone* ‚Äî √©galement connu sous le nom de SPIFFE ‚Äî pour d√©livrer une identit√© aux workloads.

L'explication du fonctionnement de SPIFFE d√©passe le cadre de cet article. Mais il suffit de savoir qu'Istio forge l'identit√© du workload sous la forme d'un certificat x509.

Istio utilise le `serviceaccount` Kubernetes attribu√© au Pod Kubernetes par Kubernetes lui-m√™me comme source d'identit√©. Si votre d√©ploiement ne sp√©cifie pas de compte de service, le compte de service `default` lui est attribu√©.

**NOTE :** Pour ceux qui souhaitent en savoir plus sur SPIFFE, nous lui avons d√©di√© l'["appendix C. Istio security: SPIFFE"](https://livebook.manning.com/book/istio-in-action/appendix-c/).

Le certificat forg√© contient des m√©tadonn√©es de workload encod√©es, telles que l'espace de noms, le compte de service, etc. Les proxys utilisent ce certificat pour initier des connexions mutuellement authentifi√©es (mTLS). Vous pouvez trouver le certificat dans la configuration d'Envoy.

La commande suivante interroge la configuration d'Envoy, la filtre pour obtenir la sortie dont nous avons besoin et d√©code le certificat. Vous devez installer [step-cli](https://smallstep.com/docs/step-cli/installation) et [jq](https://stedolan.github.io/jq/download/) pour l'ex√©cuter.

```bash
istioctl proxy-config all deploy/sa-webapp -o json | \
  jq -r '.. |."secret"? | select(.name == "default")' | \
  jq -r '.tls_certificate.certificate_chain.inline_bytes' | \
  base64 -d - | step certificate inspect
```

Ma sortie est pr√©sent√©e ci-dessous.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/SVID.png)

Nous avons mentionn√© que les certificats sont utilis√©s pour chiffrer le trafic et le prot√©ger contre les attaques de l'homme du milieu (man-in-the-middle). V√©rifions cela ensuite.

#### Le trafic de service √† service est chiffr√©

Pour savoir si le trafic est chiffr√©, nous devons capturer le trafic passant par le pod. Pour cela, nous allons ex√©cuter un conteneur de d√©bogage au sein du pod avec l'image suivante `nicolaka/netshoot` (l'ex√©cution de conteneurs de d√©bogage n√©cessite la version 1.23 de Kubernetes).

L'image `netshoot` contient de nombreux utilitaires r√©seau, dont `tcpdump`, un utilitaire de capture r√©seau que nous allons utiliser.

Ex√©cutez le conteneur de d√©bogage avec la commande suivante :

```bash
# Interroger le nom du pod sa-webapp
POD_NAME=$(kubectl get pods -l app=sa-webapp -o jsonpath={.items..metadata.name} | cut -d ' ' -f1)

# Ex√©cuter un conteneur de d√©bogage avec l'utilitaire tcpdump
kubectl debug -q -i $POD_NAME --image=nicolaka/netshoot -- \
  tcpdump -l --immediate-mode -vv -s 0 '(((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'
```

Cela peut prendre une minute ou deux (*voire plus*) jusqu'√† ce que le conteneur de d√©bogage soit t√©l√©charg√© et ex√©cut√©. Si vous ex√©cutez toujours des requ√™tes continues vers `sa-webapp`, vous verrez beaucoup de trafic captur√©. Cependant, vous ne pourrez en tirer aucune information. Ce qui est une bonne chose, car **c'est l'id√©e m√™me ‚Äî c'est chiffr√©. Tada !** ü•≥

Sachez que cet avantage ne s'√©tend pas aux workloads h√©rit√©s, comme nous le verrons ensuite.

#### Le trafic provenant des workloads h√©rit√©s est en clair

Commencez par ex√©cuter un workload h√©rit√© qui s'ex√©cute ind√©finiment. Nous allons cr√©er un nouvel espace de noms et nous ne l'√©tiquetterons pas pour l'injection automatique de sidecar. Ainsi, le workload n'aura pas de sidecar inject√©, il n'aura pas d'identit√© et il ne pourra pas s'authentifier mutuellement.

```bash
kubectl create ns legacy
kubectl -n legacy run workload --image=radial/busyboxplus:curl -- tail -f /dev/null
```

Lorsque le Pod est en cours d'ex√©cution, ex√©cutez une requ√™te cURL depuis le workload h√©rit√© vers le workload `sa-web-app`.

```bash
kubectl -n legacy exec workload -- \
  curl -i http://sa-webapp.demo/sentiment \
  -H "Content-type: application/json" \
  -d '{"sentence": "I love yogobella"}'
```

En regardant la sortie de la commande `tcpdump` s'ex√©cutant dans le pod `sa-webapp`, vous verrez la r√©ponse en clair, comme indiqu√© ci-dessous.

```bash
HTTP/1.1 200 OK
content-type: application/json;charset=UTF-8
date: Mon, 25 Apr 2022 12:14:02 GMT
x-envoy-upstream-service-time: 13
server: istio-envoy
x-envoy-decorator-operation: sa-web-app.demo.svc.cluster.local:80/*
transfer-encoding: chunked

2e
{"sentence":"I love yogobella","polarity":0.5}
```

Supposons que les donn√©es soient sensibles, telles que des mots de passe, des JWT (qui peuvent √™tre utilis√©s dans des attaques par rejeu), etc. Cela repr√©sente un vecteur d'attaque dangereux et un risque pour votre organisation.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/mtls-and-non-mtls-traffic.png)

Istio nous donne les outils pour emp√™cher les workloads du maillage de recevoir du trafic en clair.

### PeerAuthentication ‚Äì comment am√©liorer les param√®tres de s√©curit√© par d√©faut

Par d√©faut, Istio configure les proxys de service pour utiliser le mode *mTLS permissive*, ce qui signifie que le trafic non authentifi√© est autoris√©.

C'est un param√®tre par d√©faut raisonnable, car il permet une migration progressive des services dans le maillage sans causer d'interruption de service.

Une fois que les workloads ont √©t√© migr√©s dans le maillage, il est recommand√© de basculer le mode mTLS pour exiger strictement un trafic mutuellement authentifi√©. Vous pouvez le faire avec la configuration `PeerAuthentication` suivante.

```yaml
apiVersion: "security.istio.io/v1beta1"
kind: "PeerAuthentication"
metadata:
  name: "default"
  namespace: "istio-system"
spec:
  mtls:
    mode: STRICT
```

Cette configuration s'applique √† tous les workloads, car Istio utilise une convention selon laquelle la configuration dans l'espace de noms d'installation d'Istio (dans notre cas `istio-system`) s'applique globalement. Cependant, elle peut √™tre √©cras√©e par une configuration *√† l'√©chelle de l'espace de noms* ou une configuration *sp√©cifique au sidecar*.

En savoir plus sur la ["Port√©e, h√©ritage et surcharges"](https://istio.io/latest/docs/tasks/observability/telemetry/#scope-inheritance-and-overrides) de la configuration d'Istio. L'explication concerne l'API Telemetry mais s'applique de la m√™me mani√®re √† `PeerAuthentication` et aux autres API d'Istio.

Appliquez la configuration d'authentification des pairs au cluster.

```bash
kubectl apply -f istio/security/peer-authentication.yaml
```

V√©rifiez que le trafic provenant des workloads h√©rit√©s est rejet√©.

```bash
$ kubectl -n legacy exec workload -- \
    curl -i -Ss http://sa-webapp.demo/sentiment \
    -H "Content-type: application/json" \
    -d '{"sentence": "I love yogobella"}'

curl: (56) Recv failure: Connection reset by peer
command terminated with exit code 56
```

La commande cURL √©choue avec l'erreur `Recv failure: Connection reset by peer` car le proxy de service n'accepte pas la connexion non authentifi√©e.

### Comment autoriser le trafic de service √† service

L'authentification mutuelle des services et le chiffrement du trafic entre eux prot√®gent nos donn√©es en transit.

*Mais que se passe-t-il lorsqu'un utilisateur malveillant s'empare de l'identit√© de l'un des workloads ?*

**L'utilisateur malveillant pourrait s'authentifier aupr√®s de chaque service et interroger des donn√©es sensibles.**

Cependant, si nous adh√©rons au principe du moindre privil√®ge, nous r√©duisons l'acc√®s de chaque workload √† ce qui est uniquement n√©cessaire √† ses fonctions. Ainsi, nous r√©duisons la port√©e des dommages lorsqu'une identit√© est vol√©e √† ce qu'elle √©tait autoris√©e √† consulter.

Dans Istio, nous contr√¥lons l'acc√®s √† l'aide de politiques d'autorisation (authorization policies). Fondamentalement, une fois que les workloads s'authentifient mutuellement et que nous connaissons leur identit√©, √† savoir "qui" c'est, nous pouvons alors appliquer des politiques, c'est-√†-dire sp√©cifier quelles actions l'identit√© est autoris√©e √† effectuer.

Je vous laisse cela comme exercice facultatif. Vous devriez impl√©menter des politiques d'autorisation afin que le maillage adh√®re au principe du moindre privil√®ge.

Istio propose un [exemple rapide](https://istio.io/latest/docs/tasks/security/authorization/authz-http/) pour vous mettre sur la bonne voie, et vous trouverez utiles les descriptions d√©taill√©es de la [r√©f√©rence de l'API AuthorizationPolicy](https://istio.io/latest/docs/reference/config/security/authorization-policy/).

*R√©sum√© des acc√®s dont chaque service a besoin :*

* L'`istio-ingressgateway` peut acc√©der √† `sa-frontend`, `sa-feedback` et `sa-web-app`.
* Le `sa-web-app` peut acc√©der au service `sa-logic`.
* Tout autre acc√®s doit √™tre interdit.

### Authentification de l'utilisateur final

Istio authentifie les requ√™tes des utilisateurs finaux en utilisant des JWT comme moyen d'authentification.

Pour que les utilisateurs finaux re√ßoivent un jeton Web JSON, nous avons besoin d'un fournisseur d'identit√© (IdP). Nous utiliserons Keycloak comme IdP. Cependant, toute solution impl√©mentant la norme OpenID Connect Discovery (OIDC) fonctionnera de la m√™me mani√®re.

#### Ex√©cuter Keycloak dans le cluster

Commencez par cr√©er un espace de noms et y d√©ployer `keycloak`.

```bash
kubectl create ns keycloak
kubectl -n keycloak apply -f kube/idp/keycloak.yaml

# attendre le d√©ploiement
kubectl -n keycloak rollout status deploy/keycloak
```

Attendez que *keycloak* soit op√©rationnel. Ensuite, cr√©ez une application cliente pour repr√©senter l'application monopage `sa-frontend`. De plus, ajoutez les utilisateurs list√©s dans le tableau ci-dessous.

<table style="box-sizing: border-box; border-spacing: 0px; border-collapse: collapse; margin-top: 0px; margin-bottom: 16px; display: block; width: max-content; max-width: 100%; overflow: auto;"><thead style="box-sizing: border-box;"><tr style="box-sizing: border-box; background-color: var(--color-canvas-default); border-top: 1px solid var(--color-border-muted);"><th style="box-sizing: border-box; padding: 6px 13px; font-weight: 600; border: 1px solid var(--color-border-default);">Nom d'utilisateur</th><th style="box-sizing: border-box; padding: 6px 13px; font-weight: 600; border: 1px solid var(--color-border-default);">Mot de passe</th><th style="box-sizing: border-box; padding: 6px 13px; font-weight: 600; border: 1px solid var(--color-border-default);">Groupe</th><th style="box-sizing: border-box; padding: 6px 13px; font-weight: 600; border: 1px solid var(--color-border-default);">Type d'utilisateur</th></tr></thead><tbody style="box-sizing: border-box;"><tr style="box-sizing: border-box; background-color: var(--color-canvas-default); border-top: 1px solid var(--color-border-muted);"><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">user</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">password</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">users</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">regular</p></td></tr><tr style="box-sizing: border-box; background-color: var(--color-canvas-subtle); border-top: 1px solid var(--color-border-muted);"><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">beta</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">password</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">users</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">beta</p></td></tr><tr style="box-sizing: border-box; background-color: var(--color-canvas-default); border-top: 1px solid var(--color-border-muted);"><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">moderator</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">password</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">moderator</p></td><td style="box-sizing: border-box; padding: 6px 13px; border: 1px solid var(--color-border-default);"><p dir="auto" style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px;">regular</p></td></tr></tbody></table>

> NOTE : Les attributs `group` et `usertype` sont ajout√©s en tant que revendications (claims) dans le JWT apr√®s l'authentification.

La cr√©ation de l'application cliente et des utilisateurs est automatis√©e avec le script ci-dessous. Cela vous √©vite de passer par l'interface utilisateur de Keycloak et de les cr√©er manuellement.

```bash
# 1. Redirection de port vers l'environnement local
kubectl port-forward svc/keycloak -n keycloak  8081:8080 &
PID=$!
sleep 2

# 2. Cr√©er le client et les utilisateurs
export KEYCLOAK_URL=http://localhost:8081/auth

export KEYCLOAK_TOKEN=$(curl -d "client_id=admin-cli" -d "username=admin" -d "password=admin" -d "grant_type=password" "$KEYCLOAK_URL/realms/master/protocol/openid-connect/token" | jq -r .access_token)
echo $KEYCLOAK_TOKEN

# Cr√©er le jeton initial pour enregistrer le client
read -r client token <<<$(curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"expiration": 0, "count": 1}' $KEYCLOAK_URL/admin/realms/master/clients-initial-access | jq -r '[.id, .token] | @tsv')

# Enregistrer le client
read -r id secret <<<$(curl -X POST -d "{ \"clientId\": \"sa-frontend\", \"implicitFlowEnabled\": true }" -H "Content-Type:application/json" -H "Authorization: bearer ${token}" ${KEYCLOAK_URL}/realms/master/clients-registrations/default| jq -r '[.id, .secret] | @tsv')

# Ajouter les URI de redirection autoris√©es
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X PUT \
  -H "Content-Type: application/json" -d "{\"serviceAccountsEnabled\": true, \"directAccessGrantsEnabled\": true, \"authorizationServicesEnabled\": true, \"redirectUris\": [\"http://localhost:8080/\"]}" $KEYCLOAK_URL/admin/realms/master/clients/${id}

# Ajouter l'attribut de groupe dans le JWT renvoy√© par Keycloak
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"name": "group", "protocol": "openid-connect", "protocolMapper": "oidc-usermodel-attribute-mapper", "config": {"claim.name": "group", "jsonType.label": "String", "user.attribute": "group", "id.token.claim": "true", "access.token.claim": "true"}}' $KEYCLOAK_URL/admin/realms/master/clients/${id}/protocol-mappers/models

# Ajouter l'attribut de type d'utilisateur dans le JWT renvoy√© par Keycloak
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"name": "usertype", "protocol": "openid-connect", "protocolMapper": "oidc-usermodel-attribute-mapper", "config": {"claim.name": "usertype", "jsonType.label": "String", "user.attribute": "usertype", "id.token.claim": "true", "access.token.claim": "true"}}' $KEYCLOAK_URL/admin/realms/master/clients/${id}/protocol-mappers/models

# Cr√©er l'utilisateur r√©gulier
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"username": "user", "email": "user@acme.com", "enabled": true, "attributes": {"group": "users", "usertype": "regular"}, "credentials": [{"type": "password", "value": "password", "temporary": false}]}' $KEYCLOAK_URL/admin/realms/master/users

# Cr√©er l'utilisateur b√™ta
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"username": "beta", "email": "beta@acme.com", "enabled": true, "attributes": {"group": "users", "usertype": "beta"}, "credentials": [{"type": "password", "value": "password", "temporary": false}]}' $KEYCLOAK_URL/admin/realms/master/users

# Cr√©er l'utilisateur mod√©rateur
curl -H "Authorization: Bearer ${KEYCLOAK_TOKEN}" -X POST -H "Content-Type: application/json" -d '{"username": "moderator", "email": "moderator@acme.com", "enabled": true, "attributes": {"group": "moderator", "usertype": "regular"}, "credentials": [{"type": "password", "value": "password", "temporary": false}]}' $KEYCLOAK_URL/admin/realms/master/users

# 3. Arr√™ter la redirection de port
kill $PID
```

Une fois que cela est termin√© avec succ√®s, vous pourrez passer √† la section suivante.

### Comment exposer le service Keycloak

La norme OIDC permet aux applications clientes d'identifier les utilisateurs finaux. L'application cliente commence le processus en redirigeant les utilisateurs vers le serveur d'authentification. Tout d'abord, les utilisateurs s'authentifient, puis le serveur d'authentification renvoie l'utilisateur √† l'application cliente avec un jeton repr√©sentant son identit√©.

Le serveur d'authentification doit √™tre accessible aux utilisateurs finaux. C'est pourquoi nous devons √©galement exposer `keycloak` via l'Ingress Gateway d'Istio.

Le VirtualService mis √† jour qui configure le routage du trafic vers Keycloak peut √™tre appliqu√© avec la commande ci-dessous. N'h√©sitez pas √† consulter le fichier pour en savoir plus sur les changements.

```bash
kubectl apply -f istio/vs-route-ingress-keycloak.yaml
```

Ensuite, nous devons mettre √† jour l'application cliente ‚Äî `sa-frontend` ‚Äî pour rediriger l'utilisateur vers le frontend. Vous pouvez en savoir plus sur le code [ici](https://github.com/rinormaloku/master-istio/blob/main/services/sa-frontend/src/App.js#L80-L83). Cependant, vous pouvez vous √©pargner les d√©tails et simplement appliquer l'image pr√©-construite avec ces changements.

```bash
kubectl set image deployment/sa-frontend \
    sa-frontend=rinormaloku/sentiment-analysis-frontend:keycloak
```

Attendez que le Pod soit en cours d'ex√©cution, puis rafra√Æchissez la page `sa-frontend`.

La nouvelle version vous redirige vers `Keycloak` pour l'authentification. Utilisez les identifiants `user / password` pour vous connecter. Une fois la connexion r√©ussie, vous recevrez un JWT et serez redirig√© vers le client.

Par cons√©quent, les requ√™tes ult√©rieures pour l'analyse de phrases contiendront le JWT sur la base duquel nous pourrons authentifier et autoriser l'utilisateur final.

### RequestAuthentication ‚Äì comment authentifier les requ√™tes des utilisateurs finaux

L'approche recommand√©e pour authentifier le trafic des utilisateurs finaux se situe au niveau de l'Ingress Gateway. Cela r√©duit la quantit√© de traitement car le trafic non authentifi√© et non autoris√© est rejet√© d√®s le d√©but. Mais si vous souhaitez propager le JWT √† travers les services, vous devez mettre √† jour vos services pour le transmettre.

La figure ci-dessous montre les r√¥les et leurs acc√®s √† nos services que nous allons impl√©menter ensuite.

Voici un r√©sum√© des niveaux d'acc√®s :

* Tous les utilisateurs peuvent acc√©der au service `sa-frontend` (ce qui est important pour initier le flux d'authentification).
* Les utilisateurs authentifi√©s peuvent acc√©der √† `sa-webapp` en plus de l'acc√®s √† `sa-frontend`.
* Les mod√©rateurs peuvent acc√©der √† tous les services.

![Image](https://www.freecodecamp.org/news/content/images/2022/05/different-access-levels.png)

L'API `RequestAuthentication` est utilis√©e pour configurer l'authentification des JWT des utilisateurs finaux. Par exemple, avec la configuration ci-dessous, nous authentifions les JWT √©mis par `keycloak`.

```
apiVersion: "security.istio.io/v1beta1"
kind: "RequestAuthentication"
metadata:
  name: "keycloak-request-authn"
  namespace: istio-system
spec:
  selector:
    matchLabels:
      app: istio-ingressgateway
  jwtRules:
  - issuer: "http://localhost:8080/auth/realms/master" (1)
    jwksUri: http://keycloak.keycloak.svc:8080/auth/realms/master/protocol/openid-connect/certs (2)
```

Explication des attributs de la r√®gle JWT vus dans la liste ci-dessus :

1. Les jetons qui correspondent √† cet √©metteur (issuer) sont authentifi√©s avec cette r√®gle JWT.
2. Les jetons correspondants sont valid√©s par rapport aux JSON Web Key Sets (JWKS) trouv√©s √† cette URI.

Appliquez-le au cluster.

```bash
kubectl apply -f istio/security/request-authentication.yaml
```

Vous pourriez vous attendre √† ce que les requ√™tes sans JWT soient rejet√©es √† partir de maintenant, mais ce n'est pas correct. La ressource `RequestAuthentication` authentifie uniquement les requ√™tes contenant le JWT. Les autres requ√™tes sont transmises telles quelles.

V√©rifiez cela en d√©clenchant une requ√™te sans jeton, elle est admise et servie, comme indiqu√© ci-dessous :

```bash
$ curl -S http://localhost:8080/sentiment \
    -H "Content-type: application/json" \
    -d '{"sentence": "I love yogobella"}'

{"sentence":"I love yogobella","polarity":0.5}
```

Cependant, il existe une diff√©rence entre les requ√™tes qui contiennent un JWT et celles qui n'en ont pas.

Les premi√®res auront les donn√©es d'identit√© stock√©es dans les m√©tadonn√©es de connexion. En revanche, les secondes n'ont pas de donn√©es d'identit√© dans les m√©tadonn√©es de connexion. Les m√©tadonn√©es de connexion sont appel√©es identit√© de connexion ou identit√© de requ√™te.

**NOTE :** L'identit√© de la requ√™te est compos√©e des donn√©es authentifi√©es via `RequestAuthentication` et `PeerAuthentication`. Ainsi, vous pouvez contr√¥ler l'acc√®s en fonction √† la fois de l'utilisateur final et du service effectuant la requ√™te.

Les politiques prennent des d√©cisions pour autoriser ou rejeter le trafic en fonction de l'identit√© de la requ√™te.

### AuthorizationPolicy ‚Äì Comment autoriser et rejeter les requ√™tes

En utilisant l'API `AuthorizationPolicy`, vous pouvez configurer les proxys pour accepter ou rejeter le trafic.

Nous voulons que *tous les utilisateurs*, m√™me non authentifi√©s, acc√®dent aux services `sa-frontend` et `keycloak` (afin que les utilisateurs puissent s'authentifier en premier lieu). Et ce n'est qu'apr√®s cela que nous savons "qui" est l'utilisateur, et nous pouvons appliquer des politiques pour d√©terminer "quelles" actions il est autoris√© √† effectuer.

Nous y parvenons avec la politique ci-dessous. Elle autorise tout trafic vers les chemins list√©s (les chemins concernent les services `sa-frontend` et `keycloak`).

```yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-view
  namespace: istio-system
spec:
  selector:
    matchLabels:
      app: istio-ingressgateway
  action: ALLOW
  rules:
  - to:
    - operation:
        paths: ["/", "/static*", "/auth*"]
```

Appliquez-le au cluster.

```bash
kubectl apply -f istio/security/allow-view.yaml
```

D√©sormais, les utilisateurs peuvent s'authentifier et recevoir un JWT, qui est utilis√© dans les requ√™tes ult√©rieures vers les services du cluster. La configuration `RequestAuthentication` authentifie le JWT et, par cons√©quent, les revendications du jeton sont stock√©es en tant que m√©tadonn√©es de connexion.

La m√©tadonn√©e cl√© que nous utilisons dans la section suivante est `requestPrincipals`, qu'Istio construit en combinant les revendications `iss` et `sub` du JWT.

#### Comment autoriser les requ√™tes en fonction des m√©tadonn√©es de connexion

Avec la politique ci-dessous, nous autorisons les requ√™tes de n'importe quel `requestPrincipals` correspondant pour tous les chemins pr√©fix√©s par `/sentiment`.

```yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-analysis
  namespace: istio-system
spec:
  selector:
    matchLabels:
      app: istio-ingressgateway
  action: ALLOW
  rules:
  - from:
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        paths: ["/sentiment*"]
```

Pour qu'une politique s'applique au trafic entrant, elle doit correspondre √† la fois √† la source (`source`) et √† l'op√©ration (`operation`). Par exemple, la politique ci-dessus s'appliquera et autorisera le trafic uniquement si :

* **source** correspond √† tous les requestPrincipals en raison du caract√®re g√©n√©rique. Cependant, elle ne correspondra pas si la requ√™te n'a pas de principal de requ√™te. Le principal de requ√™te pour une requ√™te n'est attribu√© qu'apr√®s qu'une `RequestAuthentication` a valid√© le JWT.
* **operation** correspond √† toutes les requ√™tes dont les chemins sont pr√©fix√©s par `/sentiment`.

Appliquez-le au cluster.

```bash
kubectl apply -f istio/security/allow-analysis.yaml
```

V√©rifiez que vous pouvez analyser des phrases. Si tout va bien, passez √† la section suivante.

#### Diff√©rents niveaux d'acc√®s

Le `sa-frontend` permet aux utilisateurs d'envoyer un feedback apr√®s avoir analys√© une phrase. Mais actuellement, si vous essayez d'envoyer un feedback, la requ√™te √©chouera avec "Not authorized."

![Image](https://www.freecodecamp.org/news/content/images/2022/05/frontend-unauthorized-1.png)

Cela se produit car aucune politique n'a explicitement autoris√© la requ√™te. Elle sera donc refus√©e par d√©faut. Ensuite, nous voulons autoriser cette action uniquement pour les mod√©rateurs.

Nous faisons la distinction entre les mod√©rateurs et les utilisateurs √† l'aide de la revendication `group`. Nous pouvons y parvenir avec la politique suivante :

```yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-feedback-for-mods
  namespace: istio-system
spec:
  selector:
    matchLabels:
      app: istio-ingressgateway
  action: ALLOW
  rules:
  - from:
    - source:
        requestPrincipals: ["*"]
    when:
    - key: request.auth.claims[group]
      values: ["moderator"]
```

Appliquez-le au cluster.

```bash
kubectl apply -f istio/security/allow-feedback.yaml
```

Pour v√©rifier que les mod√©rateurs peuvent envoyer des feedbacks, suivez ces √©tapes : ouvrez une fen√™tre de navigation priv√©e, connectez-vous avec les identifiants `moderator / password`, tapez une phrase et soumettez un feedback. Cela r√©ussira !

Dans la section s√©curit√©, nous avons appris trois ressources personnalis√©es :

* `PeerAuthentication` ‚Äî pour l'authentification des pairs.
* `RequestAuthentication` ‚Äî pour l'authentification des utilisateurs finaux.
* `AuthorizationPolicy` ‚Äî pour autoriser ou rejeter les requ√™tes en fonction des donn√©es authentifi√©es.

## R√©sum√©

H√© ! Vous √™tes arriv√© au bout de cet article. F√©licitations et bravo ! C'√©tait un article plut√¥t long, mais apr√®s y avoir investi quelques heures ‚Äî et sur vous-m√™me ‚Äî vous avez une id√©e claire de ce qu'est `Istio` et de ce qu'il peut faire pour vous et votre entreprise.

Un r√©sum√© de ce que nous avons couvert :

* Les Service Meshes sont impl√©ment√©s en ajoutant un proxy aux c√¥t√©s de l'application et en interceptant tout le trafic r√©seau vers et depuis celle-ci.
* Le proxy permet :
  * **Gestion avanc√©e du trafic**
    * En utilisant les `Gateways`, nous d√©finissons le trafic qui est accept√© dans un proxy de service (y compris l'Ingress Gateway).
    * En utilisant les `VirtualServices`, nous d√©finissons comment router le trafic vers une destination.
    * En utilisant les `DestinationRules`, nous d√©finissons des politiques apr√®s le routage. Dans notre cas, nous ne l'avons utilis√© que pour d√©finir des sous-ensembles.
  * **Rendre un syst√®me observable en g√©n√©rant de la t√©l√©m√©trie**
    * Les journaux d'acc√®s enregistrent les r√©sultats des requ√™tes individuelles.
    * Les traces montrent le flux d'une requ√™te √† travers les services. Visualis√© par Inspecteur Gadget (*je n'ai pas pu r√©sister, mais vous savez que je veux dire Jaeger ;P*) et Kiali.
    * Les m√©triques mesurent les propri√©t√©s du syst√®me, le taux de r√©ussite, les op√©rations par seconde, et ainsi de suite.
  * **S√©curit√©**
    * La ressource `PeerAuthentication` impose uniquement un trafic mutuellement authentifi√©, garantissant que tout le trafic de service √† service est chiffr√© et que le trafic en clair est rejet√©.
    * La ressource `RequestAuthentication` authentifie les JWT par rapport aux JWKS configur√©s.
    * La ressource `AuthorizationPolicy` nous permet de prendre des d√©cisions sur l'acceptation ou le rejet du trafic.

### Lectures compl√©mentaires

Apr√®s avoir lu jusqu'ici, vous en savez plus sur Istio que beaucoup de gens, m√™me certains qui font tourner des services en production avec. 

Cependant, certaines particularit√©s d'Istio pourraient vous surprendre. Parfois, votre application et le proxy peuvent mal se comporter. Et vous aurez d'autres questions telles que :

* Comment d√©panner le proxy de service ou l'Ingress Gateway ?
* Comment donner un sens √† la configuration Envoy appliqu√©e ?
* Comment utiliser l'injection de fautes (fault injection) ?
* S√©curiser le trafic √† la p√©riph√©rie (edge).
* Comment configurer des Service Meshes multi-clusters ? Que se passe-t-il dans les coulisses ?
* L'int√©gration de workloads bas√©s sur des machines est-elle possible ? Si oui, comment ?
* Comment utiliser des serveurs d'autorisation externes ?
* Op√©rations de jour 2.

Nous r√©pondons √† ces questions et √† bien d'autres dans le livre ["Istio in Action."](https://www.manning.com/books/istio-in-action?utm_source=rinor&utm_medium=affiliate&utm_campaign=book_posta2_istio_9_30_18&a_aid=rinor&a_bid=9f6a70f3) Ce qui me rend vraiment fier de ce livre ‚Äî en plus d'√™tre l'√©laboration la plus approfondie d'Istio ‚Äî c'est sa valeur de r√©f√©rence.

C'est fou. Je me surprends, ainsi que d'autres ing√©nieurs de terrain ici chez Solo, √† y revenir chaque fois que nous r√©solvons un probl√®me d√©licat, tel que la r√©solution DNS, le d√©pannage du trafic inter-clusters, et ainsi de suite.

Voici d'autres ressources utiles :

* [R√©f√©rence de configuration Istio](https://istio.io/latest/docs/reference/config/)
* [Blog d'Istio](https://istio.io/latest/blog/)
* Le [blog](https://www.solo.io/blog/) et la [cha√Æne YouTube](https://www.youtube.com/channel/UCuketWAG3WqYjjxtQ9Q8ApQ) de Solo
* [Blog de Christian Posta](https://blog.christianposta.com/)
* [Blog de Karl Stoney](https://karlstoney.com/tag/istio/)

Je saisis l'occasion pour vous remercier de m'avoir rejoint dans ce voyage. Ce n'√©tait pas facile, et vous √™tes incroyable d'avoir tenu bon.

J'aimerais beaucoup conna√Ætre votre avis, alors n'h√©sitez pas √† me contacter sur Twitter ([@rinormaloku](https://twitter.com/rinormaloku)) ou sur ma page [rinormaloku.com](https://rinormaloku.com/).