---
title: Construire une IA sûre – Réduire les risques existentiels en apprentissage
  automatique
subtitle: ''
author: Beau Carnes
co_authors: []
series: null
date: '2023-08-03T12:38:54.000Z'
originalURL: https://freecodecamp.org/news/building-safe-ai-reducing-existential-risks-in-machine-learning
coverImage: https://www.freecodecamp.org/news/content/images/2023/08/aisafety3.png
tags:
- name: Artificial Intelligence
  slug: artificial-intelligence
- name: youtube
  slug: youtube
seo_title: Construire une IA sûre – Réduire les risques existentiels en apprentissage
  automatique
seo_desc: As technology advances at an unprecedented pace, so does the development
  of Machine Learning (ML) and Artificial Intelligence (AI) systems. These systems
  have grown exponentially in size, capability, and are now being deployed in critical
  and high-st...
---

Alors que la technologie progresse à un rythme sans précédent, le développement des systèmes de Machine Learning (ML) et d'Intelligence Artificielle (IA) suit la même tendance. Ces systèmes ont connu une croissance exponentielle en taille et en capacité, et sont désormais déployés dans des environnements critiques et à haut risque. Comme pour toute technologie puissante, la sécurité devient une préoccupation importante.

Nous venons de publier un cours complet sur la chaîne YouTube de freeCodeCamp.org qui aborde la question importante de la sécurité de l'IA.

Dan Hendrycks a développé ce cours. Dan est un chercheur en apprentissage automatique et possède un doctorat en informatique. Il est le directeur du Center for AI Safety.

Ce cours est conçu pour fournir aux chercheurs et aux passionnés de ML les connaissances et les compétences nécessaires pour garantir le développement et le déploiement sûrs des systèmes d'IA. Le cours reconnaît l'importance de prioriser la sécurité à mesure que les systèmes d'IA continuent d'évoluer, et il vise à orienter le processus de développement de l'IA vers une direction plus sûre et plus contrôlée.

Le cours couvre un ensemble de sujets techniques visant à atténuer les risques existentiels (X-Risks) associés aux systèmes d'IA puissants. Le programme est structuré autour de quatre piliers principaux :

1. **Robustesse** : Dans cette section, le cours explore les techniques et stratégies pour résister aux dangers potentiels dans les systèmes d'IA. Vous apprendrez à renforcer les modèles de ML contre les attaques adverses et les incertitudes, garantissant que l'IA est résiliente et fiable même dans des scénarios difficiles.
2. **Surveillance** : L'identification des dangers est un aspect crucial de la construction d'une IA sûre. Dans cette section, vous apprendrez diverses techniques de surveillance qui aident les chercheurs à détecter les problèmes potentiels et les anomalies au sein des systèmes d'IA. En reconnaissant proactivement les risques, vous serez mieux équipé pour les traiter avant qu'ils ne s'aggravent.
3. **Contrôle** : Réduire les dangers inhérents aux systèmes de ML est d'une importance capitale. Vous apprendrez à mettre en œuvre des mécanismes de contrôle efficaces qui régissent le comportement des systèmes d'IA, réduisant ainsi les chances d'actions nuisibles non intentionnelles.
4. **Sécurité systémique** : Cette section se concentre sur la réduction des dangers systémiques dans les déploiements d'IA. Vous apprendrez comment les systèmes d'IA interagissent avec leur environnement, les parties prenantes et d'autres systèmes, et explorerez des stratégies pour garantir la sécurité et la fiabilité globales de l'écosystème IA.

Vers la fin, le cours fait un pas en arrière et discute des dangers existentiels abstraits. Vous obtiendrez des informations sur les implications potentielles à long terme du développement de l'IA et explorerez des moyens d'améliorer la sécurité sans conséquences non intentionnelles. Vous acquerrez une meilleure compréhension des impacts éthiques et sociétaux plus larges de l'IA.

Pour tirer le meilleur parti de ce cours, vous devez avoir une solide expérience en Machine Learning et en Deep Learning. Une familiarité avec les concepts clés, les algorithmes et les applications pratiques assurera une expérience d'apprentissage fluide.

Vous pouvez regarder le cours complet [sur la chaîne YouTube de freeCodeCamp.org](https://youtu.be/agEPmYdbQLs) (9 heures de visionnage).

%[https://youtu.be/agEPmYdbQLs]