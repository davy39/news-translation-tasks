---
title: Si nous voulons que l'IA travaille pour nous — et non contre nous — nous avons
  besoin d'une conception collaborative
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2017-08-31T22:05:23.000Z'
originalURL: https://freecodecamp.org/news/if-we-want-ai-to-work-for-us-and-not-against-us-we-need-collaborative-design-a627175e5d60
coverImage: https://cdn-media-1.freecodecamp.org/images/1*VBJAnRAdaf13nnzc0J5Ehg.jpeg
tags:
- name: Artificial Intelligence
  slug: artificial-intelligence
- name: Machine Learning
  slug: machine-learning
- name: startup
  slug: startup
- name: 'tech '
  slug: tech
- name: technology
  slug: technology
seo_title: Si nous voulons que l'IA travaille pour nous — et non contre nous — nous
  avons besoin d'une conception collaborative
seo_desc: 'By Mariya Yao

  The trope “there’s an app for that” is becoming “there’s an AI for that.”

  Want to assess the narrative quality of a story? Disney’s got an AI for that.

  Got a shortage of doctors but still need to treat patients? IBM Watson prescribes
  th...'
---

Par Mariya Yao

Le cliché « il y a une appli pour ça » devient « il y a une IA pour ça ».

Vous voulez évaluer la qualité narrative d'une histoire ? Disney a [une IA pour ça](https://www.engadget.com/2017/08/21/disney-research-taught-ai-to-judge-short-stories/).

Vous manquez de médecins mais vous devez toujours soigner des patients ? IBM Watson prescrit le même plan de traitement que les médecins humains [99 % du temps](https://futurism.com/ibms-watson-ai-recommends-same-treatment-as-doctors-in-99-of-cancer-cases/).

Vous en avez assez d'attendre que George R.R. Martin termine d'écrire Game of Thrones ? Détendez-vous, car un réseau de neurones a [fait le travail difficile pour lui](https://motherboard.vice.com/en_us/article/evvq3n/game-of-thrones-winds-of-winter-neural-network).

Mais tout ce progrès rapide est-il bon pour l'humanité ? Elon Musk, notre alarmiste préféré en matière d'IA, a récemment [critiqué](https://techcrunch.com/2017/07/25/elon-musk-mark-zuckerberg-artificial-intelligence/) l'optimisme de Mark Zuckerberg concernant l'IA. Il a qualifié les vues de ce dernier de « limitées ».

Que vous soyez dans le Camp Zuck de « l'IA est géniale » ou dans le Camp Musk de « l'IA nous condamnera tous », un fait est clair. Avec l'IA touchant tous les aspects de notre vie, la technologie intelligente a besoin d'une conception délibérée pour refléter et servir les besoins et les valeurs humains.

### L'IA biaisée a des conséquences inattendues et graves

Les applications logicielles utilisées par les agences gouvernementales américaines pour la litige et la prévention des crimes génèrent algorithmiquement des informations qui influencent les décisions humaines concernant les peines, les cautions et les libérations conditionnelles. Certains de ces programmes ont été trouvés pour [attribuer de manière erronée](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) une probabilité beaucoup plus élevée de commettre d'autres activités criminelles aux accusés noirs. Les mêmes algorithmes se trompent également en attribuant des scores d'évaluation des risques beaucoup plus bas aux accusés blancs.

Selon [une étude](https://www.cmu.edu/news/stories/archives/2015/july/online-ads-research.html) de l'Université Carnegie Mellon, Google a servi des publicités ciblées pour obtenir des emplois bien rémunérés (ceux qui paient plus de 200 000 $) beaucoup plus souvent aux hommes (1 800 fois) qu'aux femmes (seulement 300).

Il n'est pas clair si la divergence est le résultat des préférences des annonceurs. Ou si c'est un résultat involontaire des algorithmes de machine learning (ML) derrière le moteur de recommandation de publicités. Le résultat est qu'un paysage professionnel qui démontre déjà un traitement préférentiel pour un genre par rapport à un autre est renforcé à grande échelle avec la technologie.

Dans le domaine de la santé, les systèmes d'IA risquent de produire des informations peu fiables même si les algorithmes étaient parfaitement implémentés. Les données sous-jacentes de la santé sont motivées par des inégalités sociales. Les communautés pauvres n'ont pas accès aux soins de santé numériques. Cela laisse un trou béant dans le trésor d'informations médicales que les systèmes d'IA alimentent aux algorithmes. Les essais contrôlés randomisés excluent souvent [des groupes](https://qz.com/1023448/if-youre-not-a-white-male-artificial-intelligences-use-in-healthcare-could-be-dangerous/) tels que les femmes enceintes, les personnes âgées ou celles souffrant d'autres complications médicales.

Une étude de l'Université de Princeton a [démontré](http://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/ai-learns-gender-and-racial-biases-from-language) que les systèmes de ML héritent des biais humains trouvés dans les textes en langue anglaise. Puisque le langage est un reflet de la culture et de la société, nos biais quotidiens sont repris dans les modèles mathématiques derrière les tâches de traitement du langage naturel (NLP). Le fait de ne pas examiner et de ne pas débiaiser soigneusement de tels modèles a des conséquences dans le monde réel. L'API Perspective de Google est destinée à analyser les conversations en ligne et à signaler le contenu « toxique ». Mais elle [signale involontairement](https://blog.conceptnet.io/2017/08/12/you-werent-supposed-to-actually-implement-it-google/) les entités non blanches comme les noms et les aliments comme étant beaucoup plus toxiques que leurs homologues blancs.

De nombreux biais de genre, économiques et raciaux dans l'IA ont été documentés au cours des dernières années.

Avec l'IA devenant également intégrale dans les domaines de la sécurité, de la défense et de la guerre, comment concevoir des systèmes qui ne se retournent pas contre nous ?

### Les mécanismes et les manifestes sont un début...

Les systèmes d'IA ne peuvent pas seulement réussir à accomplir leurs tâches principales. Ils doivent le faire sans nuire à la société humaine. Concevoir une IA sûre et éthique est un défi monumental, mais crucial à relever maintenant.

Dans une [étude conjointe](http://www.popsci.com/google-researches-big-red-button-to-stop-dangerous-ai), Google DeepMind et The Future of Humanity Institute ont exploré la possibilité que l'IA devienne incontrôlable. Ils ont recommandé que l'IA soit conçue pour avoir un « gros bouton rouge » qui peut être activé par un opérateur humain pour « empêcher un agent IA de continuer une séquence d'actions nuisibles ». En termes pratiques, ce bouton rouge sera un déclencheur ou un signal qui « trompera » la machine pour qu'elle prenne interne une décision de s'arrêter, sans le reconnaître comme un signal d'arrêt par un agent externe.

Pendant ce temps, la plus grande association mondiale de professionnels techniques, l'Institute of Electrical and Electronics Engineers (IEEE), a publié ses [Principes généraux pour une conception éthiquement alignée](https://standards.ieee.org/develop/indconn/ec/ead_general_principles.pdf). Il couvre tous les types d'intelligence artificielle et de systèmes autonomes.

Le document établit une norme générale pour les concepteurs afin de garantir que l'IA et les systèmes autonomes :

1. ne portent pas atteinte aux droits de l'homme
2. qu'ils sont transparents pour un large éventail de parties prenantes
3. que leurs avantages et risques associés peuvent être étendus ou minimisés
4. que la responsabilité de leur conception et de leur fonctionnement est clairement définie

#### ...mais la conception collaborative est cruciale pour le succès

Les mécanismes de sécurité hypothétiques et les manifestes optimistes sont importants. Mais ils sont insuffisants pour répondre aux nombreuses façons dont les systèmes d'IA peuvent mal tourner. Les créations adoptent les biais de leurs créateurs. Les équipes de développement homogènes, la pensée insulaire et le manque de perspective sont à la [racine](https://www.topbots.com/fighting-homogenous-thinking-algorithmic-bias-ai/) de nombreux défis déjà manifestes dans l'IA aujourd'hui.

La diversité et la conception centrée sur l'utilisateur dans la technologie n'ont jamais été aussi importantes. Heureusement, à mesure que l'éducation et les outils en IA deviennent [plus accessibles](https://www.topbots.com/artificial-intelligence-deep-learning-education-free/), les concepteurs et autres experts du domaine sont de plus en plus habilités à contribuer à un domaine qui était auparavant réservé aux universitaires et à une communauté restreinte d'experts.

### Trois approches pour améliorer la collaboration dans l'IA

#### **Approche #1 : Créer des produits conviviaux pour collecter de meilleures données pour l'IA**

Elaine Lee, une conceptrice d'IA chez eBay, [souligne](https://uxdesign.cc/design-makes-ai-smarter-34a346e92b47) que l'entrée humaine et les données générées par les utilisateurs sont cruciales pour une IA plus intelligente. Si les produits collectant les données requises pour alimenter les systèmes d'IA n'encouragent pas une interaction positive, alors les données générées à partir des interactions des utilisateurs tendent à être incomplètes, incorrectes ou compromises. En termes de Lee, « Nous devons concevoir des expériences qui incitent à l'interaction et améliorent l'IA. »

Jess Holbrook de Google Design recommande une approche en [7 étapes](https://medium.com/google-design/human-centered-machine-learning-a770d10562cd) pour concevoir des systèmes de ML centrés sur l'humain. Il met en garde contre le fait de se fier aux algorithmes pour vous dire quels problèmes résoudre. Au lieu de cela, il encourage les concepteurs à construire des systèmes qui permettent un « co-apprentissage et une adaptation » entre l'homme et la machine à mesure que les technologies évoluent. Holbrook souligne également que de nombreux problèmes légitimes n'ont pas besoin de ML pour être résolus avec succès.

Collaborer avec les utilisateurs semble être une procédure de bon sens. Mais peu d'entreprises vont au-delà de la recherche utilisateur superficielle et de la collecte passive de données comportementales. La prochaine étape consiste à permettre une boucle de rétroaction productive et à long terme afin que les utilisateurs des systèmes d'IA définissent activement la fonctionnalité et la vision de votre technologie, tout en effectuant des tâches importantes comme le signalement et la minimisation des biais.

#### **Approche #2 : Prioriser l'expertise du domaine et la valeur commerciale plutôt que les algorithmes**

Michael Schrage, chercheur associé au MIT Sloan, [soutient](https://hbr.org/2017/04/ai-wont-change-companies-without-great-ux) que « stratégiquement parlant, un algorithme brillant basé sur les données compte généralement moins qu'une conception UX réfléchie. Les conceptions UX réfléchies peuvent mieux former les systèmes de machine learning à devenir encore plus intelligents.

« Afin de développer une « UX réfléchie », vous avez besoin d'une expertise du domaine et d'une valeur commerciale. Un schéma courant dans les équipes d'ingénierie universitaire et industrielle est la propension à optimiser les victoires tactiques plutôt que les initiatives stratégiques. Alors que des esprits brillants s'inquiètent d'atteindre des améliorations marginales dans les benchmarks de compétition, les problèmes épineux de la productisation et de l'opérationnalisation de l'IA pour des cas d'utilisation réels sont souvent ignorés. Qui se soucie si vous pouvez résoudre un problème avec une précision de 99 %, si personne n'a besoin que ce problème soit résolu ? Ou si votre outil est si obscur que personne n'est sûr du problème qu'il essaie de résoudre en premier lieu ?

« En travaillant avec des entreprises du Fortune 500 cherchant à réinventer leurs flux de travail avec l'automatisation et l'IA, une plainte que j'entends couramment à propos des startups prometteuses en IA est la suivante : « Ces gars semblent vraiment intelligents et leur produit a beaucoup de clochettes et de sifflets. Mais ils ne comprennent pas mon entreprise. »

#### **Approche #3 : Autonomiser les concepteurs humains avec l'intelligence machine**

La conception de l'IA est un autre défi où l'homme et la machine peuvent combiner leurs forces pour obtenir des résultats supérieurs. Le développeur de logiciels, auteur et inventeur Patrick Hebron [démontre](https://medium.com/artists-and-machine-intelligence/rethinking-design-tools-in-the-age-of-machine-learning-369f3f07ab6c) que le machine learning peut être utilisé pour simplifier les outils de conception sans limiter la créativité ou retirer le contrôle des concepteurs humains.

Hebron décrit plusieurs façons dont le ML peut transformer la manière dont les gens interagissent avec les outils de conception. Cela inclut les ensembles de fonctionnalités émergentes, la conception par exploration, la conception par description, l'organisation des processus et les interfaces conversationnelles. Il croit que ces approches peuvent rationaliser le processus de conception et permettre aux concepteurs humains de se concentrer sur le côté créatif et imaginatif du processus plutôt que sur les aspects techniques (c'est-à-dire, comment utiliser un logiciel de conception particulier). De cette manière, « les concepteurs mèneront l'outil, et non l'inverse ».

La conception de l'IA est un autre défi où l'homme et la machine peuvent combiner leurs forces pour obtenir des résultats supérieurs. Le développeur de logiciels, auteur et inventeur Patrick Hebron [démontre](https://medium.com/artists-and-machine-intelligence/rethinking-design-tools-in-the-age-of-machine-learning-369f3f07ab6c) que le machine learning peut être utilisé pour simplifier les outils de conception sans limiter la créativité ou retirer le contrôle des concepteurs humains.

Hebron décrit plusieurs façons dont le ML peut transformer la manière dont les gens interagissent avec les outils de conception. Cela inclut les ensembles de fonctionnalités émergentes, la conception par exploration, la conception par description, l'organisation des processus et les interfaces conversationnelles. Il croit que ces approches peuvent rationaliser le processus de conception et permettre aux concepteurs humains de se concentrer sur le côté créatif et imaginatif du processus plutôt que sur les aspects techniques, tels que l'utilisation d'un logiciel de conception particulier. De cette manière, « les concepteurs mèneront l'outil, et non l'inverse ».

Le domaine de la « Conception d'IA » est naissant. Nous essayons toujours de déterminer quelles sont les meilleures pratiques à préserver et quelles nouvelles pratiques nous devons inventer. Mais de nombreux outils créatifs prometteurs basés sur l'IA [existent déjà](https://www.topbots.com/artificial-intelligence-creativity-art-design/). Un accès accru aux outils et à l'éducation signifie que des experts de tous les domaines et fonctions peuvent aider à faire évoluer un domaine traditionnellement dirigé par une élite. Avec l'impact exponentiel de l'IA sur tous les aspects de notre vie, cette collaboration sera essentielle pour développer une technologie qui fonctionne pour tout le monde, tous les jours.

Merci d'avoir lu. Vous pouvez lire plus de mes écrits sur l'IA en me suivant ici et en consultant le [blog TOPBOTS](https://www.topbots.com/collaborative-design-critical-ai/?utm_medium=article&utm_source=Medium&utm_campaign=collaborativeai).