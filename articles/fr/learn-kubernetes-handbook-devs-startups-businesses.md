---
title: Apprendre Kubernetes â€“ Guide complet pour les dÃ©veloppeurs, les startups et
  les entreprises
subtitle: ''
author: Prince Onukwili
co_authors: []
series: null
date: '2025-05-02T17:34:12.079Z'
originalURL: https://freecodecamp.org/news/learn-kubernetes-handbook-devs-startups-businesses
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1746205417767/d9d6b0d3-f2a5-44eb-83b5-d1a614bead9f.png
tags:
- name: Kubernetes
  slug: kubernetes
- name: containers
  slug: containers
- name: Docker
  slug: docker
- name: Devops
  slug: devops
- name: Cloud
  slug: cloud
- name: Cloud Computing
  slug: cloud-computing
seo_title: Apprendre Kubernetes â€“ Guide complet pour les dÃ©veloppeurs, les startups
  et les entreprises
seo_desc: Youâ€™ve probably heard the word Kubernetes floating around, or itâ€™s cooler
  nickname k8s (pronounced â€œkatesâ€œ). Maybe in a job post, a tech podcast, or from
  that one DevOps friend who always brings it up like itâ€™s the secret sauce to everything
  ğŸ˜…. It s...
---

Vous avez probablement entendu le mot Kubernetes circuler, ou son surnom plus cool k8s (prononcÃ© "kates"). Peut-Ãªtre dans une offre d'emploi, un podcast tech, ou de la part de cet ami DevOps qui en parle toujours comme si c'Ã©tait la solution secrÃ¨te Ã  tout ğŸ˜…. Cela semble important, mais aussi... un peu mystÃ©rieux.

Alors, qu'est-ce que Kubernetes, vraiment ? Pourquoi est-il partout ? Et devriez-vous vous en soucier ?

Dans ce guide, nous allons dÃ©composer Kubernetes de maniÃ¨re Ã  ce que cela ait rÃ©ellement du sens. Pas de jargon. Pas de discours technique Ã©crasant. Juste des explications claires. Vous apprendrez ce qu'est Kubernetes, comment il est apparu, et pourquoi il est devenu si important â€“ surtout pour les Ã©quipes qui construisent et exÃ©cutent des applications massives avec des millions d'utilisateurs.

Nous allons revenir un peu en arriÃ¨re pour voir comment les choses Ã©taient faites avant l'arrivÃ©e de Kubernetes (spoiler : ce n'Ã©tait pas joli), et nous allons passer en revue les vrais problÃ¨mes qu'il a Ã©tÃ© conÃ§u pour rÃ©soudre.

Ã€ la fin, vous comprendrez non seulement le but de Kubernetes, mais vous saurez Ã©galement comment dÃ©ployer une application simple sur un cluster Kubernetes â€“ mÃªme si vous dÃ©butez.

Oui, d'ici la fin, vous passerez de *Â« J'entends toujours parler de Kubernetes Â»* Ã  *Â« HÃ©, je commence Ã  comprendre maintenant ! Â»* ğŸ˜„

## ğŸ“œ Table des matiÃ¨res

1. [Qu'est-ce que Kubernetes ?](#heading-quest-ce-que-kubernetes)

2. [Comment les applications Ã©taient dÃ©ployÃ©es avant Kubernetes](#heading-comment-les-applications-etaient-deployees-avant-kubernetes)

3. [Le problÃ¨me que Kubernetes rÃ©sout ğŸ¦¸](#heading-le-probleme-que-kubernetes-resout)

4. [Comment Kubernetes fonctionne â€“ Composants d'un environnement Kubernetes ğŸ‘¨â€ğŸ’»](#heading-comment-kubernetes-fonctionne-composants-dun-environnement-kubernetes)

5. [Charges de travail Kubernetes ğŸ¢ â€“ Pods, DÃ©ploiements, Services, & Plus](#heading-charges-de-travail-kubernetes-pods-deploiements-services-amp-plus)

6. [Comment crÃ©er un cluster Kubernetes dans un environnement de dÃ©monstration avec play-with-k8s](#heading-comment-creer-un-cluster-kubernetes-dans-un-environnement-de-demonstration-avec-play-with-k8s)

   * [Se connecter Ã  Play with Kubernetes](#heading-se-connecter-a-play-with-kubernetes)

   * [CrÃ©er votre cluster Kubernetes](#heading-creer-votre-cluster-kubernetes)

7. [Comment dÃ©ployer une application sur votre cluster Kubernetes](#heading-comment-deployer-votre-application-sur-un-cluster-kubernetes)

8. [âœ… Avantages de l'utilisation de Kubernetes en entreprise](#heading-avantages-de-lutilisation-de-kubernetes-en-entreprise)

9. [ğŸ˜¬ InconvÃ©nients de l'utilisation de Kubernetes](#heading-inconvenients-de-lutilisation-de-kubernetes)

10. [Cas d'utilisation : Quand (et quand ne pas) utiliser Kubernetes](#heading-cas-dutilisation-quand-et-quand-ne-pas-utiliser-kubernetes)

11. [Conclusion](#heading-conclusion)

12. [Ã‰tudier plus loin ğŸ“š](#heading-etudier-plus-loin)

13. [Ã€ propos de l'auteur ğŸ‘¨â€ğŸ’»](#heading-a-propos-de-lauteur)

## **Qu'est-ce que Kubernetes ?**

Imaginez que vous construisez une Ã©norme plateforme logicielle, comme une application bancaire. Cette application a besoin de nombreuses fonctionnalitÃ©s, comme l'inscription des utilisateurs, les dÃ©pÃ´ts d'argent, les retraits, les paiements, et ainsi de suite. Ces fonctionnalitÃ©s sont si grandes et complexes qu'il est plus facile de les diviser en applications sÃ©parÃ©es. Ces applications individuelles sont appelÃ©es microservices.

**Alors, que sont les Microservices** ? Pensez Ã  eux comme Ã  de petits blocs de construction qui travaillent ensemble pour crÃ©er une plateforme plus grande. Ainsi, vous pourriez avoir :

* Un microservice pour l'inscription des utilisateurs

* Un autre pour le traitement des dÃ©pÃ´ts

* Un autre pour la gestion des paiements

* Et bien d'autres encore !

Pour l'utilisateur, cela ressemble toujours Ã  une application bancaire fluide et unifiÃ©e. Mais en coulisses, c'est comme un ensemble de petites applications qui travaillent ensemble pour que tout fonctionne.

### Mais voici oÃ¹ les choses se compliquent...

Lorsque vous avez des dizaines (voire des centaines) de ces microservices, les gÃ©rer devient un cauchemar. Vous pourriez avoir besoin de :

* **DÃ©ployer** chacun sÃ©parÃ©ment

* **Les surveiller** individuellement (pour vous assurer qu'ils ne plantent pas/ne deviennent pas lents en raison d'une charge trop importante)

* **Les mettre Ã  l'Ã©chelle** (les rendre plus grands pour gÃ©rer plus d'utilisateurs) lorsque le trafic augmente, un par un

Ainsi, si votre application bancaire reÃ§oit soudainement des millions d'utilisateurs, vous devriez ajuster et mettre Ã  jour manuellement chaque microservice pour qu'il continue Ã  fonctionner sans problÃ¨me. ğŸ˜– C'est beaucoup de travail, et si quelque chose ne va pas, vous Ãªtes dans de beaux draps.

### C'est lÃ  que Kubernetes vient Ã  la rescousse ! ğŸš€

Kubernetes est comme un manager super-efficace pour tous ces microservices. C'est une plateforme qui vous aide Ã  :

* **Automatiser** le dÃ©ploiement (mettre les applications en route)

* **Mettre Ã  l'Ã©chelle** les microservices (les rendre plus grands ou plus petits selon les besoins en fonction de l'afflux de trafic â€“ vos clients)

* **Les surveiller** (garder un Å“il sur leur santÃ©)

* **Assurer la fiabilitÃ©** (ainsi, si un microservice tombe en panne/Ã©choue, k8s le remplace immÃ©diatement)

En termes simples, Kubernetes prend tous vos petits microservices et les organise, en s'assurant qu'ils fonctionnent bien ensemble, peu importe la quantitÃ© de trafic que votre application reÃ§oit. Il gÃ¨re tout en coulisses, comme un chef d'orchestre dirigeant un orchestre, afin que vos microservices travaillent ensemble sans chaos.

## **Comment les applications Ã©taient dÃ©ployÃ©es avant Kubernetes**

Avant l'arrivÃ©e de Kubernetes, les Ã©quipes logicielles avaient un vÃ©ritable numÃ©ro d'Ã©quilibriste lorsqu'il s'agissait de dÃ©ployer des applications â€“ surtout lorsqu'elles Ã©taient composÃ©es de nombreux microservices.

Une mÃ©thode populaire consistait Ã  utiliser une configuration de **systÃ¨me distribuÃ©**. Voici Ã  quoi cela ressemblait :

Imaginez que chaque microservice (comme votre inscription d'utilisateurs, vos paiements, vos dÃ©pÃ´ts, etc.) est installÃ© sur des serveurs sÃ©parÃ©s (ordinateurs physiques ou machines virtuelles). Chacun de ces serveurs devait Ãªtre soigneusement prÃ©parÃ© :

* Le microservice lui-mÃªme devait Ãªtre installÃ©.

* Les dÃ©pendances logicielles dont il avait besoin (comme les langages de programmation, les bibliothÃ¨ques, les outils) devaient Ã©galement Ãªtre installÃ©es.

* Tout devait Ãªtre configurÃ© manuellement SUR CHAQUE serveur.

Et tous ces serveurs devaient communiquer entre eux â€“ parfois via l'internet public, ou via des rÃ©seaux privÃ©s comme les VPN.

Cela semble Ãªtre beaucoup de travail, n'est-ce pas ? ğŸ˜® C'Ã©tait le cas ! GÃ©rer les mises Ã  jour, corriger les bugs, mettre Ã  l'Ã©chelle pendant les pics de trafic et Ã©viter les plantages pouvait devenir un casse-tÃªte Ã  temps plein pour les dÃ©veloppeurs et les administrateurs systÃ¨me. ğŸ˜–

### Puis vinrent les conteneurs ğŸš‚

Une solution plus moderne qui a attÃ©nuÃ© la douleur (un peu) Ã©tait l'utilisation de conteneurs.

**Alors, que sont les conteneurs ?**

Pensez Ã  un conteneur comme Ã  une boÃ®te Ã  lunch pour votre microservice. Au lieu d'installer le microservice et ses outils de support directement sur un serveur, vous emballez tout ce dont il a besoin â€“ code, paramÃ¨tres, bibliothÃ¨ques logicielles â€“ dans ce seul et mÃªme conteneur bien rangÃ©. OÃ¹ que le conteneur aille, le microservice s'exÃ©cute exactement de la mÃªme maniÃ¨re. Pas de surprises !

Des outils comme [Docker](https://www.docker.com/) ont rendu cela super facile. Une fois votre microservice emballÃ© dans un conteneur, vous pouviez le dÃ©ployer sur :

* Un seul serveur

* Plusieurs serveurs

* Ou des plateformes cloud comme AWS Elastic Beanstalk, Azure App Service, ou Google Cloud Run.

## **Le problÃ¨me que Kubernetes rÃ©sout** ğŸ¦¸

Au dÃ©but, lorsque les conteneurs sont arrivÃ©s sur le marchÃ©, cela semblait comme si les dÃ©veloppeurs avaient trouvÃ© l'or.

Vous pouviez emballer un microservice dans un petit conteneur bien rangÃ© et l'exÃ©cuter n'importe oÃ¹ â€“ plus besoin d'installer le mÃªme logiciel sur chaque serveur encore et encore. Des outils comme Docker et Docker Compose ont rendu cela fluide pour les petits projets.

Mais le monde rÃ©el ? C'est lÃ  que cela devient compliquÃ©.

### La gestion croissante des conteneurs devient un casse-tÃªte ğŸ¤’

Lorsque vous n'avez que quelques microservices, vous pouvez dÃ©ployer et gÃ©rer manuellement leurs conteneurs sans trop de stress. Mais lorsque votre application grandit â€“ et que vous avez soudainement des dizaines ou mÃªme des centaines de microservices â€“ les gÃ©rer devient une bataille difficile :

* Vous deviez dÃ©ployer chaque conteneur manuellement.

* Vous deviez les redÃ©marrer si l'un d'eux plantait.

* Vous deviez les mettre Ã  l'Ã©chelle un par un lorsque plus d'utilisateurs commenÃ§aient Ã  affluer.

Docker et Docker Compose Ã©taient excellents pour un petit terrain de jeu ou des startups, mais pas pour une application d'entreprise avec un trafic Ã©levÃ©.

### Les services cloud gÃ©rÃ©s ont aidÃ©... mais seulement jusqu'Ã  un certain point ğŸ‘¨â€ğŸ’»

Les services cloud comme AWS Elastic Beanstalk, Azure App Service et Google Code Engine offraient un raccourci. Ils vous permettaient de dÃ©ployer des conteneurs sans vous soucier de la configuration des serveurs.

Vous pouviez :

* DÃ©ployer chaque conteneur sur sa propre instance cloud gÃ©rÃ©e.

* Les mettre Ã  l'Ã©chelle automatiquement en fonction du trafic.

MAIS il y avait encore quelques gros casse-tÃªtes :

#### ğŸ“§ Regrouper les microservices Ã©tait maladroit et coÃ»teux

Bien sÃ»r, vous pouviez organiser les conteneurs par environnement (comme "test" ou "production") ou mÃªme par Ã©quipe (comme "Finance" ou "RH"). Mais chaque nouveau microservice avait gÃ©nÃ©ralement besoin de sa propre instance cloud â€“ par exemple, un service Azure App Service ou un environnement Elastic Beanstalk sÃ©parÃ© POUR CHAQUE CONTENAIR.

Imaginez ceci :

* Chaque instance App Service coÃ»te ~50 $ par mois.

* Vous avez 10 microservices.

* Cela fait 500 $/mois... mÃªme s'ils sont Ã  peine utilisÃ©s. ğŸ’¸ Yikes !

### Kubernetes : Plus intelligent, plus lÃ©ger et plus flexible ğŸš€

Avec Kubernetes, vous n'avez pas besoin de lancer un serveur sÃ©parÃ© pour chaque microservice. Vous pouvez commencer avec seulement un ou deux serveurs (VM) â€“ et Kubernetes dÃ©cidera automatiquement quel conteneur va oÃ¹ en fonction de l'espace et des ressources disponibles.

Pas de stress, pas de gaspillage ! ğŸ¤’

### ğŸ‘¨â€ğŸ³ **Kubernetes vous permet de tout personnaliser**

1. Vous pouvez attribuer des ressources Ã  chaque conteneur de microservice. 
   
   ğŸ‘‰ Exemple : Si vous avez un microservice "Paiement" lÃ©ger, vous pourriez lui donner 0,5 vCPU et 512 Mo de mÃ©moire. Si vous avez un microservice "Analyse de donnÃ©es" gourmand en ressources, vous pourriez lui donner 2 vCPU et 4 Go de mÃ©moire.
   
2. Vous pouvez dÃ©finir un nombre minimum d'instances pour chaque microservice. 
   
   ğŸ‘‰ Exemple : Si vous voulez au moins 2 copies de votre service "Connexion" toujours en cours d'exÃ©cution (pour que votre application ne tombe pas en panne si l'une Ã©choue), Kubernetes s'assure que vous avez toujours 2 copies en direct Ã  tout moment.
   
3. Vous pouvez regrouper vos conteneurs comme vous le souhaitez : 
   
   ğŸ‘‰ Par Ã©quipes (Finance, RH, DevOps) ou par environnements (Test, Staging, Production). Kubernetes rend ce regroupement super propre et logique.
   
4. Vous pouvez mettre Ã  l'Ã©chelle automatiquement des conteneurs individuels. 
   
   ğŸ‘‰ Lorsque plus d'utilisateurs inondent votre application, Kubernetes peut crÃ©er des copies supplÃ©mentaires (appelÃ©es "rÃ©plicas") uniquement des conteneurs qui sont sous pression. Plus de gaspillage de ressources sur des conteneurs qui n'en ont pas besoin.
   
5. Vous pouvez mÃªme mettre Ã  l'Ã©chelle vos serveurs ! 
   
   ğŸ‘‰ Kubernetes peut automatiquement augmenter le nombre de serveurs (VM) dans votre environnement â€“ appelÃ© un **Cluster** â€“ lorsque le trafic augmente. Vous pourriez commencer avec 2 VM Ã  30 $ chacune (60 $/mois) et laisser Kubernetes ajouter plus de serveurs uniquement lorsque nÃ©cessaire, plutÃ´t que de vous engager dans des coÃ»ts fixes Ã©levÃ©s comme 500 $/mois pour des services cloud gÃ©rÃ©s.
   

De plus, Kubernetes fonctionne **de la mÃªme maniÃ¨re partout**. Que vous dÃ©ployiez vos conteneurs sur AWS, Google Cloud, Azure, ou mÃªme votre propre ordinateur portable â€“ Kubernetes s'en moque. Votre configuration reste la mÃªme.

Comparez cela aux services gÃ©rÃ©s comme Elastic Beanstalk ou Azure App Service â€“ qui vous lient Ã  leur plateforme, rendant trÃ¨s difficile le changement plus tard.

âœ… **En bref** : Kubernetes vous fait Ã©conomiser de l'argent, du temps et beaucoup de maux de tÃªte. Il vous permet d'exÃ©cuter, de mettre Ã  l'Ã©chelle et d'organiser vos microservices sans Ãªtre enchaÃ®nÃ© Ã  un seul fournisseur cloud â€“ et sans vous noyer dans le travail manuel.

## **Comment Kubernetes fonctionne â€“ Composants d'un environnement Kubernetes** ğŸ‘¨â€ğŸ’»

Ã€ ce stade, vous avez vu le problÃ¨me : exÃ©cuter des dizaines (ou des centaines !) de microservices manuellement, c'est comme jongler avec trop de balles â€“ vous Ãªtes sÃ»r d'en laisser tomber certaines.

C'est pourquoi Kubernetes a Ã©tÃ© crÃ©Ã©. Mais... comment fait-il toute cette magie ? CommenÃ§ons par le dÃ©finir techniquement (simple mais prÃ©cis â€“ parfait pour les entretiens) puis par une analogie pour les non-initiÃ©s (pour que cela reste dans votre tÃªte !).

### 1ï¸âƒ£ **Cluster ğŸŒ**

Un cluster Kubernetes est l'ensemble complet des machines (physiques ou basÃ©es sur le cloud) oÃ¹ Kubernetes s'exÃ©cute. Il est composÃ© d'un ou plusieurs nÅ“uds maÃ®tres et nÅ“uds travailleurs, travaillant ensemble pour dÃ©ployer et gÃ©rer des applications conteneurisÃ©es.

Pensez Ã  un cluster Kubernetes comme votre terrain de jeu entier. C'est l'environnement oÃ¹ vivent, grandissent et jouent ensemble tous vos microservices.

Un cluster est composÃ© de deux types d'ordinateurs (appelÃ©s nÅ“uds) :

* NÅ“ud maÃ®tre (de nos jours souvent appelÃ© le plan de contrÃ´le)

* NÅ“uds travailleurs

### 2ï¸âƒ£ **NÅ“ud maÃ®tre (Plan de contrÃ´le) ğŸ‘‘**

Le nÅ“ud maÃ®tre est comme le cerveau de Kubernetes. Il gÃ¨re et coordonne l'ensemble du cluster â€“ en dÃ©cidant quelles applications s'exÃ©cutent oÃ¹, en surveillant la santÃ© et en mettant Ã  l'Ã©chelle les choses selon les besoins.

C'est comme le patron de l'ensemble du cluster. Il n'exÃ©cute pas vos applications directement. Au lieu de cela, il :

* Surveille les nÅ“uds travailleurs

* DÃ©cide quel microservice (conteneur) va oÃ¹

* S'assure que tout fonctionne en douceur et Ã©quitablement

Pensez Ã  cela comme Ã  un gestionnaire d'usine qui dit aux machines quoi faire, quand commencer, quand s'arrÃªter et oÃ¹ envoyer le prochain paquet.

Ã€ l'intÃ©rieur du nÅ“ud maÃ®tre se trouvent quelques mini-composants intelligents qui gÃ¨rent le vrai travail.

### 3ï¸âƒ£ **Serveur API ğŸ’¬**

Le serveur API est la porte d'entrÃ©e de Kubernetes. Il gÃ¨re la communication entre les utilisateurs et le systÃ¨me, en prenant des commandes et en les alimentant dans le cluster.

C'est ici que vous (ou votre Ã©quipe) donnez des instructions Ã  Kubernetes. Que vous dÃ©ployiez une nouvelle application ou que vous mettiez Ã  l'Ã©chelle une application existante, vous "parlez" d'abord au serveur API. C'est comme soumettre une demande Ã  la rÃ©ception â€“ le serveur API la transmet aux bonnes personnes (ou machines).

### 4ï¸âƒ£ **Planificateur ğŸ“…**

Le planificateur attribue des Pods (applications) aux nÅ“uds travailleurs en fonction des ressources disponibles et des besoins.

Imaginez que vous avez demandÃ© Ã  Kubernetes de lancer un nouveau microservice. Le planificateur vÃ©rifie :

* Quel nÅ“ud travailleur a assez d'espace ?

* Quel nÅ“ud a assez de mÃ©moire et de CPU ?

* OÃ¹ ce service fonctionnerait-il le mieux ?

Il prend la dÃ©cision et attribue le microservice Ã  l'endroit parfait. Intelligent, non ?

### 5ï¸âƒ£ **Gestionnaire de contrÃ´leurs ğŸ¨**

Le gestionnaire de contrÃ´leurs exÃ©cute des contrÃ´leurs qui surveillent le cluster et s'assurent que l'Ã©tat rÃ©el du systÃ¨me correspond Ã  l'Ã©tat souhaitÃ©.

Ce composant surveille le systÃ¨me comme un faucon. Supposons que vous ayez dit Ã  Kubernetes : 
*"Hey, je veux 3 copies de mon microservice de paiement en cours d'exÃ©cution Ã  tout moment."*

Si l'une d'elles plante, le gestionnaire de contrÃ´leurs le voit et en lance une nouvelle pour la remplacer automatiquement. Il s'assure que la rÃ©alitÃ© correspond toujours au plan.

### 6ï¸âƒ£ **etcd ğŸ“š**

etcd est la mÃ©moire de Kubernetes â€“ un magasin de valeurs-clÃ©s distribuÃ© oÃ¹ les donnÃ©es du cluster sont sauvegardÃ©es : fichiers de configuration, Ã©tat et mÃ©tadonnÃ©es.

Imaginez un cahier oÃ¹ toutes les rÃ¨gles, enregistrements et plans sont Ã©crits. Sans etcd, Kubernetes oublierait tout.

### 7ï¸âƒ£ **NÅ“uds travailleurs ğŸš€**

Les nÅ“uds travailleurs sont les serveurs qui exÃ©cutent les conteneurs d'applications rÃ©els, faisant le gros du travail dans le cluster.

Ce sont les machines oÃ¹ vos microservices vivent et s'exÃ©cutent rÃ©ellement. Le nÅ“ud maÃ®tre donne des ordres, mais les nÅ“uds travailleurs font le gros du travail â€“ ils exÃ©cutent vos conteneurs !

Chaque nÅ“ud travailleur a quelques assistants pour gÃ©rer ses microservices :

* Le Kubelet

* Le Kube Proxy

### 8ï¸âƒ£ **Kubelet ğŸ“§**

Le Kubelet est l'agent qui vit sur chaque nÅ“ud travailleur et qui s'assure que les conteneurs sont sains et fonctionnent comme prÃ©vu.

Il Ã©coute les instructions du nÅ“ud maÃ®tre. Si le nÅ“ud maÃ®tre dit : *"Hey, exÃ©cute ce conteneur !"*, le Kubelet le fait et le maintient en cours d'exÃ©cution. Si quelque chose ne va pas, le Kubelet rapporte au nÅ“ud maÃ®tre.

### 9ï¸âƒ£ **Kube Proxy ğŸš¦**

Kube Proxy gÃ¨re le trafic rÃ©seau, en s'assurant que les Pods peuvent communiquer entre eux et avec le monde extÃ©rieur.

Imaginez que le service de connexion de votre application bancaire doit communiquer avec le service de paiements. Le Kube Proxy gÃ¨re le routage afin que la demande atteigne le bon endroit. Il gÃ¨re Ã©galement l'Ã©quilibrage de charge, afin qu'aucun microservice ne soit surchargÃ©.

Donc, pour rÃ©sumer :

* Le nÅ“ud maÃ®tre est le patron â€“ il planifie, surveille et attribue des tÃ¢ches.

* Les nÅ“uds travailleurs font le vrai travail â€“ exÃ©cuter vos microservices.

* Des composants comme etcd, Kubelet, Planificateur, Gestionnaire de contrÃ´leurs et Kube Proxy travaillent tous ensemble comme des parties d'une machine bien huilÃ©e.

Kubernetes est conÃ§u pour gÃ©rer vos microservices automatiquement â€“ les garder en vie, les mettre Ã  l'Ã©chelle, les dÃ©placer et les redÃ©marrer s'ils plantent â€“ afin que vous n'ayez pas Ã  les surveiller vous-mÃªme.

## Charges de travail Kubernetes ğŸ¢ â€“ Pods, DÃ©ploiements, Services, & Plus

Les charges de travail Kubernetes sont les objets que vous utilisez pour gÃ©rer et exÃ©cuter vos applications. Pensez Ã  eux comme des plans ğŸ“œ qui disent Ã  Kubernetes **quoi** exÃ©cuter et **comment** l'exÃ©cuter â€“ qu'il s'agisse d'un conteneur d'application unique, d'un groupe de conteneurs, d'une base de donnÃ©es ou d'un travail par lots. Voici quelques-unes des charges de travail dans Kubernetes :

### 1ï¸âƒ£ **Pods**

Un **Pod** est la plus petite et la plus simple unitÃ© dans le modÃ¨le d'objet Kubernetes. Il reprÃ©sente une seule instance d'un processus en cours d'exÃ©cution dans votre cluster et peut contenir un ou plusieurs conteneurs qui partagent des ressources de stockage et de rÃ©seau. 

Pensez Ã  un Pod comme une enveloppe autour d'un ou plusieurs conteneurs qui doivent travailler ensemble. Ils partagent la mÃªme adresse IP rÃ©seau et le mÃªme stockage, ce qui leur permet de communiquer facilement et de partager des donnÃ©es. Les Pods sont Ã©phÃ©mÃ¨res (ils vivent pendant une courte durÃ©e, ils peuvent Ãªtre remplacÃ©s trÃ¨s facilement). Si un Pod meurt, Kubernetes peut en crÃ©er un nouveau pour le remplacer presque instantanÃ©ment.

Supposons que vous avez une application qui est divisÃ©e en 2 monolithes distribuÃ©s â€“ un frontend et un backend. Le frontend s'exÃ©cutera dans un conteneur dans le Pod A, tandis que l'application backend s'exÃ©cutera dans un conteneur dans un autre Pod B.

### 2ï¸âƒ£ **DÃ©ploiements**

Un **DÃ©ploiement** fournit des mises Ã  jour dÃ©claratives pour les Pods et les ReplicaSets. Vous dÃ©crivez un Ã©tat souhaitÃ© dans un DÃ©ploiement, et le ContrÃ´leur de DÃ©ploiement modifie l'Ã©tat rÃ©el pour qu'il corresponde Ã  l'Ã©tat souhaitÃ© Ã  un rythme contrÃ´lÃ©.

Les DÃ©ploiements gÃ¨rent le cycle de vie de vos Pods d'application. Ils garantissent que le nombre spÃ©cifiÃ© de Pods sont en cours d'exÃ©cution et peuvent gÃ©rer les mises Ã  jour, les retours en arriÃ¨re et la mise Ã  l'Ã©chelle. Si un Pod Ã©choue, le DÃ©ploiement le remplace automatiquement pour maintenir l'Ã©tat souhaitÃ©.

Imaginez que vous gÃ©rez un magasin. Un DÃ©ploiement est comme le gÃ©rant du magasin â€“ vous lui dites combien de travailleurs (Pods) vous voulez, et il s'assure qu'ils sont toujours prÃ©sents. Si l'un d'eux ne se prÃ©sente pas au travail, le gÃ©rant trouve un remplaÃ§ant automatiquement. Vous pouvez Ã©galement lui dire d'embaucher plus de travailleurs ou d'en licencier lorsque cela est nÃ©cessaire.

### 3ï¸âƒ£ **Services**

Un **Service** dans Kubernetes dÃ©finit une maniÃ¨re d'accÃ©der/communiquer avec les Pods. Les Services permettent la communication entre diffÃ©rents Pods (par exemple, votre Pod frontend A peut communiquer avec votre Pod backend B via un service) et peuvent exposer votre application au trafic externe (par exemple, l'internet public). 

Les Services agissent comme un point de terminaison stable pour accÃ©der Ã  un ensemble de Pods. MÃªme si les Pods sous-jacents changent, l'IP et le nom DNS du Service restent constants, garantissant la communication entre les Pods au sein du cluster ou avec l'internet.

Un Service est comme la porte d'entrÃ©e de votre application. Peu importe quel travailleur (Pod) se trouve derriÃ¨re, les gens utilisent toujours la mÃªme entrÃ©e pour y accÃ©der. Il cache les choses compliquÃ©es qui se passent en coulisses et donne aux utilisateurs un moyen simple de se connecter Ã  votre application.

### 4ï¸âƒ£ **ReplicaSets**

Un **ReplicaSet** garantit qu'un nombre spÃ©cifiÃ© de Pods identiques sont en cours d'exÃ©cution Ã  tout moment. Il est souvent utilisÃ© pour garantir la disponibilitÃ© d'un nombre spÃ©cifiÃ© de Pods (mise Ã  l'Ã©chelle horizontale). 

Les ReplicaSets maintiennent un ensemble stable de Pods en cours d'exÃ©cution. Si un Pod plante ou est supprimÃ©, le ReplicaSet crÃ©e automatiquement un nouveau pour le remplacer, garantissant que votre application reste disponible.

Pensez Ã  un ReplicaSet comme Ã  un robot qui compte combien de copies de votre application sont en cours d'exÃ©cution. Si l'une d'elles disparaÃ®t, il en crÃ©e automatiquement une nouvelle. Il maintient le nombre stable, exactement comme vous le lui avez dit.

### 5ï¸âƒ£ **DaemonSets**

Un **DaemonSet** garantit que tous (ou certains) NÅ“uds exÃ©cutent une instance (une copie) d'un Pod spÃ©cifique. Lorsque des nÅ“uds sont ajoutÃ©s au cluster, des Pods sont ajoutÃ©s Ã  eux. Lorsque des nÅ“uds sont retirÃ©s du cluster, ces Pods sont Ã©galement retirÃ©s. 

Les DaemonSets sont utilisÃ©s pour dÃ©ployer un Pod sur chaque nÅ“ud du cluster. Cela est utile pour exÃ©cuter des tÃ¢ches en arriÃ¨re-plan comme la collecte de logs ou des agents de surveillance sur tous les nÅ“uds (par exemple pour obtenir l'utilisation du CPU, de la mÃ©moire et du disque de chaque nÅ“ud).

Un DaemonSet est comme dire : Â« Je veux que cette application d'assistance s'exÃ©cute sur **chaque ordinateur** que nous avons. Â» Comme mentionnÃ© prÃ©cÃ©demment, c'est idÃ©al pour des choses comme les collecteurs de logs ou les vÃ©rificateurs de sÃ©curitÃ© â€“ de petits assistants que chaque machine devrait avoir.

### 6ï¸âƒ£ **StatefulSets**

Un **StatefulSet** est l'objet API de charge de travail utilisÃ© pour gÃ©rer les applications stateful (applications qui stockent des donnÃ©es, par exemple dans leur systÃ¨me de fichiers â€“ bases de donnÃ©es). Il gÃ¨re le dÃ©ploiement et la mise Ã  l'Ã©chelle d'un ensemble de Pods et fournit des garanties concernant l'ordre et l'unicitÃ© de ces Pods.

Les StatefulSets sont conÃ§us pour les applications qui nÃ©cessitent un stockage persistant et des identitÃ©s rÃ©seau stables, comme les bases de donnÃ©es.

Disons que vous exÃ©cutez une base de donnÃ©es ou tout ce qui doit sauvegarder des informations. Un StatefulSet est comme donner Ã  chaque application une Ã©tiquette de nom et un tiroir personnel pour stocker leurs affaires. MÃªme si vous les redÃ©marrez, ils reviennent avec le mÃªme nom et le mÃªme tiroir.

### 7ï¸âƒ£ **Jobs**

Un **Job** crÃ©e un ou plusieurs Pods et garantit qu'un nombre spÃ©cifiÃ© d'entre eux se termine avec succÃ¨s. Ã€ mesure que les Pods se terminent avec succÃ¨s, le Job suit les terminaisons rÃ©ussies. Lorsqu'un nombre spÃ©cifiÃ© de terminaisons rÃ©ussies est atteint, le Job est terminÃ©. 

Un Job est comme une tÃ¢che ponctuelle. Imaginez envoyer un lot d'e-mails ou traiter un rapport. Vous voulez que la tÃ¢che s'exÃ©cute, se termine, puis s'arrÃªte. C'est exactement ce qu'un Job fait.

### 8ï¸âƒ£ **CronJobs**

Un **CronJob** crÃ©e des Jobs selon un calendrier basÃ© sur le temps. Il exÃ©cute un Job pÃ©riodiquement selon un calendrier donnÃ©, Ã©crit au format Cron.

Un CronJob est comme dÃ©finir un rappel ou une alarme. Il indique Ã  votre application (dans ce cas, le Job) de faire quelque chose tous les soirs Ã  2 heures, tous les lundis matins, ou une fois par mois â€“ quel que soit le calendrier que vous lui donnez.

## ğŸ¢ Comment crÃ©er un cluster Kubernetes dans un environnement de dÃ©monstration avec `play-with-k8s`

Comme nous l'avons discutÃ© prÃ©cÃ©demment, un cluster Kubernetes est un ensemble de machines (appelÃ©es nÅ“uds) qui exÃ©cutent des applications conteneurisÃ©es.

Configurer un cluster Kubernetes localement ou dans le cloud peut Ãªtre complexe et coÃ»teux. Pour simplifier le processus d'apprentissage, Docker fournit une plateforme gratuite basÃ©e sur un navigateur appelÃ©e [Play with Kubernetes](https://labs.play-with-k8s.com/). Cet environnement vous permet de crÃ©er et d'interagir avec un cluster Kubernetes sans installer quoi que ce soit sur votre machine locale. C'est un excellent outil pour les dÃ©butants afin d'acquÃ©rir une expÃ©rience pratique avec Kubernetes.

### ğŸ”‘ Se connecter Ã  Play with Kubernetes

1. **Visitez la plateforme** Ã  l'adresse [https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/).
   
2. **Authentifiez-vous** :
   
   * Cliquez sur le bouton "Login".
   
   * Vous pouvez vous connecter en utilisant votre compte Docker Hub ou GitHub.
   
   * Si vous n'avez pas de compte, vous pouvez en crÃ©er un gratuitement sur [Docker Hub](https://hub.docker.com/) ou [GitHub](https://github.com/).

![Se connecter Ã  Play with k8s](https://cdn.hashnode.com/res/hashnode/image/upload/v1746083007442/a038ee6c-b471-4880-ba17-2e8927678780.png align="center")

### ğŸš€ CrÃ©er votre cluster Kubernetes

Une fois connectÃ©, suivez ces Ã©tapes pour configurer votre cluster :

#### Ã‰tape 1 : DÃ©marrer une nouvelle session :

Cliquez sur le bouton **"Start"** pour initier une nouvelle session. Cela crÃ©era une nouvelle session vous donnant environ 4 heures de temps de jeu, aprÃ¨s quoi le cluster et ses ressources seront automatiquement terminÃ©s.

![Session chronomÃ©trÃ©e Play with k8s](https://cdn.hashnode.com/res/hashnode/image/upload/v1746083204331/8410e18b-4ed4-4374-8d4f-44f0fefa1623.png align="center")

#### Ã‰tape 2 : Ajouter des instances :

Ensuite, cliquez sur **"+ Add New Instance"** pour crÃ©er un nouveau nÅ“ud (machine virtuelle).  

![CrÃ©er un nouveau nÅ“ud maÃ®tre (VM)](https://cdn.hashnode.com/res/hashnode/image/upload/v1746083280594/740d963a-c70f-43c6-8354-e6ea0c3d7f41.png align="center")

Cela ouvrira une fenÃªtre de terminal oÃ¹ vous pourrez exÃ©cuter des commandes.  

![Terminal du nÅ“ud nouvellement crÃ©Ã©](https://cdn.hashnode.com/res/hashnode/image/upload/v1746083304493/ffd34d73-e5cd-41d0-908a-2240924e7ad0.png align="center")

#### Ã‰tape 3 : Initialiser le nÅ“ud maÃ®tre :

Dans le terminal, exÃ©cutez la commande suivante pour initialiser le nÅ“ud maÃ®tre :

```bash
kubeadm init --apiserver-advertise-address $(hostname -i) --pod-network-cidr <SPECIFIED_IP_ADDRESS>
```

Vous pouvez trouver la commande dans le terminal. Dans mon cas, l'adresse IP est `10.5.0.0/16`. Remplacez le `<SPECIFIED_IP_ADDRESS>` par l'adresse IP spÃ©cifiÃ©e dans votre terminal.

![Initialiser le nÅ“ud maÃ®tre et le plan de contrÃ´le](https://cdn.hashnode.com/res/hashnode/image/upload/v1746083865451/fdf18710-c987-4221-bc02-369cd709a849.png align="center")

Ce processus configurera le plan de contrÃ´le de votre cluster Kubernetes.

#### Ã‰tape 4 : Ajouter des nÅ“uds travailleurs :

Si vous souhaitez ajouter des nÅ“uds travailleurs, dans le terminal du nÅ“ud maÃ®tre, vous trouverez une commande `kubeadm join...` aprÃ¨s avoir exÃ©cutÃ© la commande `kubeadm init --apiserver-advertise-address $(hostname -i) --pod-network-cidr <SPECIFIED_IP_ADDRESS>`.

![Commande pour ajouter un nÅ“ud travailleur au plan de contrÃ´le](https://cdn.hashnode.com/res/hashnode/image/upload/v1746084559142/6e539ef6-0219-40da-95e7-42abc9f1af8c.png align="center")

Cliquez sur **"+ Add New Instance"** pour crÃ©er un autre nÅ“ud comme vous l'avez fait prÃ©cÃ©demment.

ExÃ©cutez cette commande dans le terminal du nouveau nÅ“ud pour le joindre au cluster :

![Ajouter un nÅ“ud travailleur au plan de contrÃ´le](https://cdn.hashnode.com/res/hashnode/image/upload/v1746084666411/78f07ba1-7f1f-402e-9ed8-c4d6054bdcab.png align="center")

#### Ã‰tape 5 : Configurer la mise en rÃ©seau du cluster :

AccÃ©dez au nÅ“ud maÃ®tre et exÃ©cutez la commande ci-dessous pour configurer la mise en rÃ©seau du cluster.

```bash
kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml
```

![Configurer la mise en rÃ©seau dans le cluster](https://cdn.hashnode.com/res/hashnode/image/upload/v1746085296963/ba35966c-5dd1-4e17-b4b5-85639cb3a80d.png align="center")

#### Ã‰tape 6 : VÃ©rifier le cluster :

Dans le terminal du nÅ“ud maÃ®tre (le premier nÅ“ud avec le profil utilisateur mis en Ã©vidence), exÃ©cutez :

```bash
kubectl get nodes
```

Vous devriez voir une liste de nÅ“uds dans votre cluster, y compris le maÃ®tre et tous les nÅ“uds travailleurs que vous avez ajoutÃ©s.

![NÅ“uds dans le cluster](https://cdn.hashnode.com/res/hashnode/image/upload/v1746085583418/45e55418-4b0f-461f-98d8-3b0c8f19b839.png align="center")

FÃ©licitations ! Vous venez de crÃ©er votre tout premier cluster Kubernetes avec 2 VM : le nÅ“ud maÃ®tre (oÃ¹ rÃ©side le plan de contrÃ´le), et les nÅ“uds travailleurs (oÃ¹ les charges de travail Kubernetes, par exemple les Pods, seront dÃ©ployÃ©s).

## ğŸš€ Comment dÃ©ployer une application sur votre cluster Kubernetes

Maintenant que nous avons configurÃ© notre cluster Kubernetes en utilisant Play with Kubernetes, il est temps de dÃ©ployer l'application et de la rendre accessible sur Internet.

### ğŸ¦¸ Comprendre les approches impÃ©rative et dÃ©clarative dans Kubernetes

Avant de continuer, il est essentiel de comprendre les deux mÃ©thodes principales pour gÃ©rer les ressources dans Kubernetes : **ImpÃ©rative** et **DÃ©clarative**.

### ğŸ”® Approche impÃ©rative

Dans l'approche impÃ©rative, vous Ã©mettez directement des commandes Ã  l'API Kubernetes pour crÃ©er ou modifier des ressources. Chaque commande spÃ©cifie l'action souhaitÃ©e, et Kubernetes l'exÃ©cute immÃ©diatement.

Imaginez dire Ã  quelqu'un : "Allume la lumiÃ¨re." Vous donnez un ordre direct, et l'action se produit immÃ©diatement. De mÃªme, avec les commandes impÃ©ratives, vous instruisez Kubernetes Ã©tape par Ã©tape sur ce qu'il doit faire.

**Exemple :**  
Pour crÃ©er un pod exÃ©cutant un conteneur NGINX, exÃ©cutez la commande ci-dessous dans le terminal du nÅ“ud maÃ®tre :

```bash
kubectl run nginx-pod --image=nginx
```

Attendez quelques secondes et exÃ©cutez la commande ci-dessous pour vÃ©rifier l'Ã©tat du pod :

```bash
kubectl get pods
```

Vous devriez obtenir une rÃ©ponse similaire Ã  celle-ci

![Obtenir les pods en cours d'exÃ©cution dans le cluster](https://cdn.hashnode.com/res/hashnode/image/upload/v1746087463204/52ef26e5-96df-4d91-8a2d-7527a38786d2.png align="center")

Maintenant, exposons notre Pod Ã  Internet en crÃ©ant un **Service**. ExÃ©cutez la commande ci-dessous pour exposer le Pod :

```bash
kubectl expose pod nginx-pod --type=NodePort --port=80
```

Pour obtenir l'adresse IP du Cluster afin que nous puissions accÃ©der Ã  notre Pod, exÃ©cutez la commande ci-dessous :

```bash
kubectl get svc
```

La commande affiche l'adresse IP Ã  partir de laquelle nous pouvons accÃ©der Ã  notre service. Vous devriez obtenir une sortie similaire Ã  celle-ci :

![Obtenir l'adresse IP du service](https://cdn.hashnode.com/res/hashnode/image/upload/v1746088678881/a4f3bdbc-c7eb-4696-ba6e-587637be5792.png align="center")

Maintenant, copiez l'adresse IP pour le service `nginx-pod` et exÃ©cutez la commande ci-dessous pour faire une requÃªte Ã  votre Pod :

```bash
curl <YOUR-SERVICE-IP-ADDRESS>
```

Remplacez le `<YOUR-SERVICE-IP-ADDRESS>` par l'adresse IP de votre service `nginx-pod`. Dans mon cas, c'est `10.98.108.173`.

Vous devriez obtenir une rÃ©ponse de votre Pod `nginx-pod` :

![Faire une requÃªte au Pod Nginx en cours d'exÃ©cution dans le Cluster](https://cdn.hashnode.com/res/hashnode/image/upload/v1746088937046/8b86cd63-21f0-45d3-9ab5-59bd630fb37c.png align="center")

Nous n'avons pas pu accÃ©der au Pod depuis Internet, c'est-Ã -dire notre navigateur, car notre Cluster n'est pas connectÃ© Ã  un service cloud comme AWS ou Google Cloud qui peut nous fournir un Ã©quilibreur de charge externe.

Maintenant, essayons de faire la mÃªme chose mais en utilisant la mÃ©thode dÃ©clarative.

### ğŸš€ Approche dÃ©clarative

Jusqu'Ã  prÃ©sent, nous avons utilisÃ© l'approche impÃ©rative, oÃ¹ nous avons tapÃ© des commandes comme `kubectl run` ou `kubectl expose` directement dans le terminal pour faire faire quelque chose Ã  Kubernetes immÃ©diatement.

Mais Kubernetes a une autre (et souvent meilleure) faÃ§on de faire les choses : l'approche dÃ©clarative.

#### ğŸ§‘â€ğŸ³ Qu'est-ce que l'approche dÃ©clarative ?

Au lieu de donner des instructions Ã  Kubernetes Ã©tape par Ã©tape comme un chef dans une cuisine, vous lui donnez une recette complÃ¨te â€“ un fichier qui dÃ©crit exactement ce que vous voulez (par exemple, quelle application exÃ©cuter, combien de copies, comment l'exposer, etc.).

Cette recette est Ã©crite dans un fichier appelÃ© un **manifest**.

#### ğŸ“„ Qu'est-ce qu'un manifest ?

Un manifest est un fichier (gÃ©nÃ©ralement Ã©crit au format YAML) qui dÃ©crit un objet Kubernetes â€“ comme un Pod, un DÃ©ploiement ou un Service.

C'est comme Ã©crire ce que vous voulez, le remettre Ã  Kubernetes et dire : "Hey, s'il te plaÃ®t, fais en sorte que cela existe exactement comme je l'ai dÃ©crit."

Nous utiliserons deux manifests :

1. Un pour dÃ©ployer notre application

2. Un autre pour l'exposer Ã  Internet


Passons en revue cela !

#### ğŸ“ Ã‰tape 1 : Cloner le dÃ©pÃ´t GitHub

Nous avons dÃ©jÃ  un dÃ©pÃ´t GitHub qui contient les deux fichiers manifest dont nous avons besoin. Clonons-le dans notre environnement Kubernetes.

ExÃ©cutez ceci dans le terminal (sur votre nÅ“ud maÃ®tre) :

```bash
git clone https://github.com/onukwilip/simple-kubernetes-app
```

Maintenant, entrons dans le dossier :

```bash
cd simple-kubernetes-app
```

Vous devriez voir deux fichiers :

* `deployment.yaml`

* `service.yaml`

#### ğŸ“§ Ã‰tape 2 : Comprendre le manifest de dÃ©ploiement (`deployment.yaml`)

Ce manifest indiquera Ã  Kubernetes de dÃ©ployer notre application et de s'assurer qu'elle est toujours en cours d'exÃ©cution.

Voici ce qu'il contient :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
```

Maintenant, dÃ©composons cela :

* `apiVersion: apps/v1` : Cela indique Ã  Kubernetes quelle version de l'API nous utilisons pour dÃ©finir cet objet.

* `kind: Deployment` : Cela signifie que nous crÃ©ons un DÃ©ploiement (un contrÃ´leur qui gÃ¨re les Pods).

* `metadata.name` : Nous donnons Ã  notre DÃ©ploiement un nom : `nginx-deployment`.

* `spec.replicas: 3` : Nous disons Ã  Kubernetes : "S'il vous plaÃ®t, exÃ©cutez 3 copies (rÃ©plicas) de cette application."

* `selector.matchLabels` : Kubernetes utilisera cette Ã©tiquette pour trouver quels Pods ce DÃ©ploiement gÃ¨re.

* `template.metadata.labels` & `spec.containers` : Cette section dÃ©crit les Pods que le DÃ©ploiement doit crÃ©er â€“ chaque Pod exÃ©cutera un conteneur utilisant l'image officielle `nginx`.

âœ… En termes simples : Nous demandons Ã  Kubernetes de crÃ©er et de maintenir 3 copies d'une application qui exÃ©cute NGINX, et de les redÃ©marrer automatiquement si l'une d'elles Ã©choue.

#### ğŸŒ Ã‰tape 3 : Comprendre le manifest de service (`service.yaml`)

Ce fichier indique Ã  Kubernetes d'exposer notre application NGINX au monde extÃ©rieur en utilisant un Service.

Voici le fichier â€“ dÃ©composons-le Ã©galement :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

* `apiVersion: v1` : Nous utilisons la version 1 de l'API Kubernetes.

* `kind: Service` : Nous crÃ©ons un objet Service.

* `metadata.name: nginx-service` : Nous lui donnons un nom.

* `spec.type: NodePort` : Nous l'exposons via un port sur le nÅ“ud (pour que nous puissions y accÃ©der via l'adresse IP du nÅ“ud).

* `selector.app: nginx` : Cela indique Ã  Kubernetes de connecter ce Service aux Pods avec l'Ã©tiquette `app: nginx`.

* `ports.port` et `targetPort` : Le Service Ã©coutera sur le port 80 et redirigera le trafic vers le port 80 sur le Pod.

âœ… En termes simples : Ce fichier dit : "Exposez notre application NGINX via le rÃ©seau du cluster pour que nous puissions y accÃ©der depuis le monde extÃ©rieur."

#### ğŸ§¹ Ã‰tape 4 : Nettoyer les ressources prÃ©cÃ©dentes

Si vous exÃ©cutez toujours le Pod et le Service que nous avons crÃ©Ã©s en utilisant l'approche impÃ©rative, supprimons-les pour Ã©viter les conflits :

```bash
kubectl delete pod nginx-pod
kubectl delete service nginx-pod
```

#### ğŸ“¤ Ã‰tape 5 : Appliquer les manifests

Maintenant, dÃ©ployons l'application NGINX et exposons-la â€“ cette fois en utilisant la mÃ©thode **dÃ©clarative**.

Depuis le dossier `simple-kubernetes-app`, exÃ©cutez :

```bash
kubectl apply -f deployment.yaml
```

Puis :

```bash
kubectl apply -f service.yaml
```

Cela crÃ©era le DÃ©ploiement et le Service dÃ©crits dans les fichiers. ğŸ‰

#### ğŸ” Ã‰tape 6 : VÃ©rifier qu'il est en cours d'exÃ©cution

VÃ©rifions si les Pods ont Ã©tÃ© crÃ©Ã©s :

```bash
kubectl get pods
```

Vous devriez voir 3 Pods en cours d'exÃ©cution !

Et vÃ©rifions le service :

```bash
kubectl get svc
```

Recherchez le `nginx-service`. Vous verrez quelque chose comme :

![AccÃ©der au NodePort du service](https://cdn.hashnode.com/res/hashnode/image/upload/v1746092825896/617084f1-3a71-4cfd-a287-9f7a9ac08810.png align="center")

Notez le **NodePort** (par exemple, `30001`) car nous l'utiliserons pour accÃ©der Ã  l'application.

#### ğŸŒ Ã‰tape 7 : AccÃ©der Ã  l'application

Vous pouvez maintenant envoyer une requÃªte Ã  votre application comme ceci :

```bash
curl http://<YOUR-NODE-IP>:<NODE-PORT>
```

> Remplacez `<YOUR-NODE-IP>` par l'IP de votre nÅ“ud maÃ®tre (vous trouverez gÃ©nÃ©ralement cela dans Play With Kubernetes en haut de votre terminal), et `<NODE-PORT>` par le NodePort affichÃ© dans la commande `kubectl get svc`.

![Obtenir l'adresse IP du nÅ“ud maÃ®tre](https://cdn.hashnode.com/res/hashnode/image/upload/v1746092570586/b33cabc0-ea1e-4a70-ab55-9f3a0761bec0.png align="center")

Vous devriez voir le contenu HTML de la page de bienvenue NGINX imprimÃ©.

Maintenant, terminez l'environnement du cluster en cliquant sur le bouton **CLOSE SESSION** :

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1746093081895/79139f75-5e6b-4991-be74-38ecbbf2ef66.png align="center")

### ğŸŠ Pourquoi l'approche dÃ©clarative est meilleure (dans la plupart des cas)

* ğŸ” **RÃ©utilisable** : Vous pouvez utiliser les mÃªmes fichiers encore et encore.

* ğŸ“§ **VersionnÃ©** : Vous pouvez pousser ces fichiers sur GitHub et suivre les changements au fil du temps.

* ğŸ¢ **Corrige facilement les erreurs** : Vous voulez changer 3 rÃ©plicas en 5 ? Il suffit de mettre Ã  jour le fichier et de le rÃ©appliquer !

* ğŸ¦¸ **Plus facile Ã  maintenir** : Surtout lorsque vous avez de nombreuses ressources Ã  gÃ©rer.

## ğŸ“œ Avantages de l'utilisation de Kubernetes en entreprise

Kubernetes n'est pas seulement un outil pour les dÃ©veloppeursâ€”c'est aussi un facilitateur pour les entreprises. Il aide les entreprises Ã  livrer des produits plus rapidement, de maniÃ¨re plus fiable et avec une rÃ©duction des coÃ»ts opÃ©rationnels.

DÃ©composons comment Kubernetes se traduit par des avantages commerciaux concrets :

### 1ï¸âƒ£ **Meilleure utilisation des ressources cloud = Ã©conomies de coÃ»ts**

Avant Kubernetes, le dÃ©ploiement de nombreux microservices pour une seule application signifiait souvent la crÃ©ation de ressources cloud sÃ©parÃ©es (comme un service Azure App Service par microservice), ce qui pouvait rapidement engendrer des coÃ»ts Ã©levÃ©s. Imaginez 50 $/mois par service Ã— 10 services = 500 $/mois ğŸ˜¬.

**Avec Kubernetes :**  
Vous pouvez exÃ©cuter plusieurs microservices sur moins de machines virtuelles (VM) tandis que Kubernetes dÃ©cide automatiquement de la maniÃ¨re la plus efficace d'utiliser les serveurs disponibles. Cela signifie que vous payez pour moins de serveurs et en tirez plus parti ğŸ’°.

### 2ï¸âƒ£ **Haute disponibilitÃ© et temps de fonctionnement = clients satisfaits**

Kubernetes surveille vos applications comme un faucon ğŸ‘€. Si l'une d'elles plante ou Ã©choue, Kubernetes la redÃ©marre ou la remplace *immÃ©diatement* â€“ automatiquement.

**Pour votre entreprise :**  
Cela signifie moins de temps d'arrÃªt, moins de tickets de support et des clients plus heureux qui ne remarquent mÃªme pas lorsque les choses vont mal en arriÃ¨re-plan.

### 3ï¸âƒ£ **Mise Ã  l'Ã©chelle facile pendant une forte demande**

Mettre Ã  l'Ã©chelle manuellement les applications pendant un trafic Ã©levÃ© (comme le Black Friday) peut Ãªtre un cauchemar ğŸ˜°. Et si vous n'agissez pas rapidement, les clients subissent des lenteurs ou des plantages.

**Avec Kubernetes :**  
Vous pouvez configurer chaque microservice pour qu'il se mette Ã  l'Ã©chelle automatiquement â€“ ce qui signifie qu'il ajoute plus d'instances de ce service *uniquement lorsque nÃ©cessaire* (trop d'utilisateurs sur votre site essayant d'acheter diffÃ©rents produits) et rÃ©duit l'Ã©chelle lorsque le trafic diminue. Cela garantit que votre application est toujours rÃ©active et que vous ne payez que pour ce que vous utilisez.

### 4ï¸âƒ£ **DÃ©ploiement plus rapide = temps de mise sur le marchÃ© plus rapide**

Kubernetes prend en charge l'automatisation et la rÃ©pÃ©tabilitÃ©. Les Ã©quipes peuvent dÃ©ployer de nouvelles fonctionnalitÃ©s ou microservices plus rapidement sans se soucier de la configuration de l'infrastructure Ã  chaque fois.

**Pour les entreprises :**  
Cela signifie des mises Ã  jour de produits plus rapides, une rÃ©ponse plus rapide aux demandes du marchÃ© et un avantage concurrentiel ğŸš€.

### 5ï¸âƒ£ **Environnements cohÃ©rents = moins de bugs**

Chaque microservice dans Kubernetes est conteneurisÃ©, ce qui signifie qu'il s'exÃ©cute avec toutes ses dÃ©pendances dans un package autonome. Vous pouvez exÃ©cuter la mÃªme configuration d'application exacte dans :

* DÃ©veloppement

* Test

* Production

Cela rÃ©duit les bugs causÃ©s par les problÃ¨mes "Ã§a marche sur ma machine" ğŸ§‘â€ğŸ’» et aide les Ã©quipes Ã  construire en toute confiance.

### 6ï¸âƒ£ **IndÃ©pendance vis-Ã -vis des fournisseurs (Adieu au verrouillage des fournisseurs)**

Lorsque vous utilisez des services cloud gÃ©rÃ©s (comme AWS Elastic Beanstalk ou Azure App Service), il est souvent difficile de passer Ã  un autre fournisseur car tout est adaptÃ© Ã  cette plateforme spÃ©cifique.

**Avec Kubernetes :**  
Il fonctionne de la mÃªme maniÃ¨re sur AWS, Azure, GCP, ou mÃªme votre propre centre de donnÃ©es. Cela signifie que vous pouvez changer de fournisseur cloud facilement et Ã©viter d'Ãªtre verrouillÃ© Ã  un seul fournisseur â€“ alias la libertÃ© du cloud ! â˜ï¸ğŸ”“

### 7ï¸âƒ£ **ClartÃ© organisationnelle**

Kubernetes vous permet d'organiser vos applications clairement. Vous pouvez regrouper les charges de travail par :

* Ã‰quipe (par exemple, Finance, RH)

* Environnement (par exemple, test, staging, production)

Cette structure aide les grandes Ã©quipes Ã  mieux collaborer, Ã  rester organisÃ©es et Ã  gÃ©rer les ressources efficacement.

## ğŸ˜¬ InconvÃ©nients de l'utilisation de Kubernetes

Comme tout dans la tech, Kubernetes n'est pas tout en arc-en-ciel et en fusÃ©es ğŸš€. Tout comme tout autre outil, il a ses avantages et ses inconvÃ©nients. Et il est super important pour les fondateurs de startups, les chefs de produit, ou mÃªme les PDG de savoir quand Kubernetes est le bon choix â€“ et quand il est simplement excessif.

DÃ©composons les principaux inconvÃ©nients de maniÃ¨re simple et honnÃªte :

### ğŸ‘¨â€ğŸ’» 1. Vous aurez probablement besoin d'un ingÃ©nieur DevOps ou d'une Ã©quipe

Kubernetes est puissant, oui. Mais cette puissance s'accompagne d'une grande responsabilitÃ© ğŸ˜….

En termes simples :

* Vous ne cliquez pas simplement sur un bouton et votre application est magiquement en cours d'exÃ©cution.

* Kubernetes a besoin de quelqu'un qui comprend comment le configurer, le maintenir en fonctionnement et rÃ©soudre les problÃ¨mes lorsqu'ils surviennent. Cette personne (ou Ã©quipe) est gÃ©nÃ©ralement appelÃ©e ingÃ©nieur DevOps, ingÃ©nieur de fiabilitÃ© de site ou ingÃ©nieur cloud.

Voici ce qu'ils gÃ©reront typiquement :

* CrÃ©er le cluster (l'environnement oÃ¹ vos applications s'exÃ©cuteront)

* DÃ©finir comment vos conteneurs d'applications doivent se comporter (combien doivent s'exÃ©cuter, combien de mÃ©moire ils ont besoin, quand ils doivent redÃ©marrer, etc.)

* Surveiller les applications et s'assurer qu'elles sont en bonne santÃ©

* Veiller Ã  ce que les rÃ¨gles de sÃ©curitÃ© soient respectÃ©es

* GÃ©rer la mise Ã  l'Ã©chelle automatique, les dÃ©ploiements, les sauvegardes, etc.

ğŸ¤’ **En bref :** Vous aurez besoin de quelqu'un de compÃ©tent pour gÃ©rer cet outil. Si vous Ãªtes un fondateur solo ou une petite Ã©quipe sans expÃ©rience DevOps, Kubernetes pourrait Ãªtre trop pour vous au dÃ©but.

### ğŸ’° 2. Kubernetes peut Ãªtre coÃ»teux (s'il est adoptÃ© prÃ©maturÃ©ment)

Kubernetes permet d'Ã©conomiser de l'argent Ã  grande Ã©chelle â€“ mais peut coÃ»ter plus cher si vous l'adoptez trop tÃ´t ou pour le mauvais cas d'utilisation.

Voici pourquoi :

* Kubernetes est conÃ§u pour gÃ©rer plusieurs applications ou microservices. Si votre entreprise n'a qu'une seule petite application, vous utilisez une fusÃ©e pour livrer une pizza ğŸ• â€“ ce n'est tout simplement pas nÃ©cessaire.

* Kubernetes est Ã©galement idÃ©al lorsque vous avez un trafic Ã©levÃ© ou imprÃ©visible. Il peut automatiquement mettre Ã  l'Ã©chelle vos services lorsque le trafic augmente... mais si votre trafic est stable et faible, vous ne bÃ©nÃ©ficierez pas beaucoup de cette puissance.

Disons que :

* Vous avez une application avec un trafic modÃ©rÃ©.

* Vous la dÃ©ployez sur Kubernetes (ce qui nÃ©cessite au moins 1-2 VM + configuration).

* Vous embauchez un ingÃ©nieur DevOps pour la gÃ©rer.

* Vous payez pour le calcul cloud + le stockage + la surveillance.

Vous pourriez finir par dÃ©penser 300-800 $/mois ou plus... pour quelque chose qui aurait pu Ãªtre hÃ©bergÃ© sur un service simple comme [Render](https://render.com), [Heroku](https://www.heroku.com), ou une VM de base pour une fraction du coÃ»t.

Alors, quand **devriez-vous** envisager Kubernetes ?

* Lorsque votre plateforme est composÃ©e de plusieurs services (par exemple, des services sÃ©parÃ©s pour l'authentification des utilisateurs, les paiements, l'analyse, les notifications, etc.)

* Lorsque vous prÃ©voyez des pics de trafic (par exemple, lancement dans de nouveaux pays, devenir viral, demande saisonniÃ¨re comme le Black Friday)

* Lorsque vous voulez de la flexibilitÃ© dans la gestion de votre infrastructure Ã  travers les fournisseurs cloud (AWS, GCP, Azure) ou mÃªme sur site

## ğŸ¤– Cas d'utilisation : Quand (et quand ne pas) utiliser Kubernetes

Kubernetes est un outil incroyablement puissant ğŸš€ â€“ mais ce n'est pas toujours la bonne solution dÃ¨s le premier jour.

DÃ©composons quand il est judicieux d'utiliser Kubernetes et quand cela peut Ãªtre excessif ğŸ‘‹

### âœ… Quand vous devriez utiliser Kubernetes

Kubernetes devient essentiel dans ces scÃ©narios :

#### 1. Votre application est composÃ©e de nombreux microservices

Si votre application est divisÃ©e en plusieurs microservices â€“ comme l'authentification des utilisateurs, les paiements, les commandes, les notifications, et plus encore â€“ c'est un bon signe que Kubernetes pourrait Ã©ventuellement aider.

Kubernetes peut :

* Aider Ã  gÃ©rer chaque microservice indÃ©pendamment

* Mettre Ã  l'Ã©chelle automatiquement chacun en fonction de la demande

* RedÃ©marrer les services dÃ©faillants automatiquement

* Faciliter le dÃ©ploiement des mises Ã  jour pour des parties spÃ©cifiques de l'application

#### 2. Vous recevez un trafic *constant et Ã©levÃ©*

Ce n'est pas seulement une question de complexitÃ© â€“ c'est une question de demande.

Si votre application reÃ§oit un volume constant et Ã©levÃ© d'utilisateurs (comme des centaines ou des milliers chaque jour), et que vous commencez Ã  voir des signes que vos serveurs sont surchargÃ©s, Kubernetes excelle ici. Il peut :

* Augmenter automatiquement les ressources lorsque le trafic augmente

* Ã‰quilibrer la charge sur plusieurs serveurs

* EmpÃªcher les temps d'arrÃªt dus aux pics de trafic

#### 3. Vous voulez la portabilitÃ© et l'indÃ©pendance du cloud

Si votre entreprise ne veut pas Ãªtre verrouillÃ©e Ã  un seul fournisseur de cloud (par exemple, uniquement AWS), Kubernetes vous offre de la flexibilitÃ©. Vous pouvez dÃ©placer votre application entre AWS, GCP, Azure â€“ ou mÃªme vers votre propre centre de donnÃ©es â€“ avec moins de changements.

#### 4. Votre Ã©quipe DevOps est en croissance

Lorsque vous avez plusieurs dÃ©veloppeurs ou Ã©quipes travaillant sur diffÃ©rentes parties de l'application, Kubernetes aide :

* Organiser et isoler les charges de travail par Ã©quipe

* AmÃ©liorer la collaboration et la cohÃ©rence

* Fournir un contrÃ´le d'accÃ¨s et une surveillance faciles

### âŒ Quand vous ne devriez pas utiliser Kubernetes

Soyons honnÃªtes : Kubernetes n'est pas pour tout le monde, surtout pas au dÃ©but.

#### 1. Vous venez de lancer votre application

Dans les premiers jours de votre produit, lorsque vous venez de le lancer et que le trafic est encore faible, Kubernetes est *excessif*. Vous n'avez pas besoin de sa complexitÃ© (pour l'instant).

ğŸ‘‰ Au lieu de cela, dÃ©ployez votre application ou chaque microservice sur une machine virtuelle simple (VM). C'est moins cher et plus rapide pour commencer.

#### 2. Vous n'avez pas besoin de mise Ã  l'Ã©chelle automatique (pour l'instant)

Si le trafic vers votre application est encore faible et gÃ©rable, un seul serveur (ou quelques-uns) peut facilement gÃ©rer la charge. Dans ce cas, il est prÃ©fÃ©rable de :

* DÃ©ployer vos microservices manuellement ou avec Docker Compose

* Surveiller et mettre Ã  l'Ã©chelle manuellement lorsque nÃ©cessaire

* Garder les choses simples jusqu'Ã  ce que le besoin d'automatisation devienne Ã©vident

#### 3. Vous n'avez pas d'Ã©quipe DevOps

Kubernetes est puissant ğŸš€ â€“ mais il nÃ©cessite une expertise pour le configurer et le maintenir. Si vous n'avez pas d'ingÃ©nieur DevOps ou quelqu'un qui comprend Kubernetes, cela peut causer plus de problÃ¨mes que cela n'en rÃ©sout.

Embaucher une Ã©quipe DevOps peut Ãªtre coÃ»teux, et configurer Kubernetes incorrectement peut entraÃ®ner des pannes, des risques de sÃ©curitÃ© ou un gaspillage de ressources ğŸ’°

### ğŸ“… Quand passer Ã  Kubernetes

Alors, quel est le meilleur chemin Ã  suivre ?

Voici une feuille de route simple :

1. **Commencez petit** : DÃ©ployez votre application (ou microservices) sur une ou quelques VM

2. **Surveillez le trafic** : Ã€ mesure que la demande des utilisateurs augmente, augmentez la taille de la VM ou rÃ©pliquez l'application manuellement

3. **Suivez les points de douleur** : Si la mise Ã  l'Ã©chelle devient trop manuelle, ou si les services plantent sous la charge...

4. **Alors adoptez Kubernetes** ğŸ¦¸

Ce n'est pas une question de complexitÃ© de votre application â€“ c'est une question de quand le trafic et la croissance exigent une mise Ã  niveau dans la faÃ§on dont vous gÃ©rez les choses.

### ğŸ TL;DR pour les fondateurs et les Ã©quipes DevOps

* Ne sautez pas sur Kubernetes juste parce que c'est Ã  la mode

* Utilisez-le uniquement lorsque le trafic augmente rÃ©guliÃ¨rement et que la mise Ã  l'Ã©chelle automatique devient nÃ©cessaire

* Kubernetes est le plus prÃ©cieux lorsque vous voulez mettre Ã  l'Ã©chelle de maniÃ¨re fiable et efficace

* Avant ce point, restez sur des dÃ©ploiements simples â€“ cela vous fera Ã©conomiser du temps, de l'argent et du stress

## ğŸ‰ Conclusion

Wow ! Quel voyage nous avons fait ğŸ˜„

Nous avons commencÃ© par rÃ©pondre Ã  la grande question ğŸš€ â€“ **Qu'est-ce que Kubernetes ?** Nous avons dÃ©couvert que ce n'est pas une bÃªte mythique, mais un outil d'orchestration puissant qui nous aide Ã  gÃ©rer, dÃ©ployer, mettre Ã  l'Ã©chelle et maintenir des applications conteneurisÃ©es de maniÃ¨re plus intelligente.

Ensuite, nous avons fait un pas en arriÃ¨re dans le temps pour voir comment les applications Ã©taient dÃ©ployÃ©es avant Kubernetes ğŸš€ â€“ les maux de tÃªte de l'installation manuelle de logiciels sur les serveurs, la crÃ©ation de sÃ©parÃ©es instances cloud pour chaque microservice, et l'accumulation de factures cloud Ã©normes juste pour rester Ã  flot. Nous avons Ã©galement vu comment les conteneurs ont simplifiÃ© les choses, mais mÃªme eux avaient leurs propres limitations lorsqu'ils Ã©taient gÃ©rÃ©s Ã  grande Ã©chelle.

C'est lÃ  que Kubernetes est venu Ã  la rescousse ğŸ¦¸

Nous avons explorÃ© :

* **Les problÃ¨mes que Kubernetes rÃ©sout** ğŸš€ â€“ comme la mise Ã  l'Ã©chelle automatique, la gestion efficace des ressources, les Ã©conomies de coÃ»ts et le regroupement transparent des conteneurs.

* **L'architecture et les composants de Kubernetes** ğŸš€ â€“ en dÃ©composant des termes complexes comme le cluster, le nÅ“ud maÃ®tre, les nÅ“uds travailleurs, les Pods, les Services, le Kubelet, et plus encore, en idÃ©es simples et faciles Ã  digÃ©rer.

* **Les charges de travail Kubernetes** comme les DÃ©ploiements, les Pods, les Services, les DaemonSets, et les StatefulSets, et ce qu'ils font en coulisses pour garder nos applications en cours d'exÃ©cution de maniÃ¨re fiable.

De la thÃ©orie Ã  la pratique, nous avons mÃªme mis les mains dans le cambouis :

* Nous avons crÃ©Ã© un cluster Kubernetes gratuit en utilisant Play with Kubernetes ğŸ¦¸

* DÃ©ployÃ© une application rÃ©elle en utilisant Ã  la fois les approches impÃ©rative (commande directe) et dÃ©clarative (fichier manifest)

* Compris pourquoi la mÃ©thode dÃ©clarative rend notre infrastructure plus facile Ã  gÃ©rer, surtout lorsque nos systÃ¨mes grandissent.

Ensuite, nous avons pris une perspective commerciale ğŸ” et regardÃ© :

* Les avantages de Kubernetes ğŸš€ â€“ de la mise Ã  l'Ã©chelle automatique pendant les pics de trafic, Ã  l'efficacitÃ© des coÃ»ts, et au dÃ©ploiement agnostique du cloud.

* Et aussi les inconvÃ©nients ğŸ˜¬ â€“ comme le besoin d'ingÃ©nieurs DevOps expÃ©rimentÃ©s et le fait de ne pas Ãªtre idÃ©al pour chaque Ã©tape du cycle de vie d'un produit.

Enfin, nous avons conclu avec des cas d'utilisation rÃ©els, en mettant en Ã©vidence quand Kubernetes est un must-have, et quand il est prÃ©fÃ©rable d'attendre ğŸš€ â€“ surtout pour les startups en phase de dÃ©marrage qui cherchent encore leur public.

Ainsi, que vous soyez un dÃ©butant en DevOps, un fondateur de startup, ou simplement quelqu'un de curieux sur la faÃ§on dont la technologie moderne maintient vos applications prÃ©fÃ©rÃ©es en ligne ğŸš€ â€“ vous avez maintenant une comprÃ©hension fondamentale solide de Kubernetes ğŸš€

Kubernetes est puissant, mais il n'a pas besoin d'Ãªtre Ã©crasant. Avec une bonne comprÃ©hension des bases (que vous avez maintenant ğŸš€), vous Ãªtes bien parti pour gÃ©rer des applications scalables comme un pro.

Commencez simplement. Grandissez intelligemment. Et lorsque le moment sera venu ğŸš€ â€“ Kubernetes sera votre meilleur ami.

## **Ã‰tudier plus loin ğŸ“š**

Si vous souhaitez en apprendre davantage sur Kubernetes, vous pouvez consulter les cours ci-dessous :

* [Docker & Kubernetes : Le Guide Pratique (Academind - Udemy)](https://www.udemy.com/course/docker-kubernetes-the-practical-guide/)

* [Certified Kubernetes Application Developer (CKAD) Specialization (Coursera)](https://www.coursera.org/specializations/certified-kubernetes-application-developer-ckad-course)

## **Ã€ propos de l'auteur ğŸ‘¨â€ğŸ’»**

Bonjour, je m'appelle Prince ! Je suis un ingÃ©nieur DevOps et architecte cloud passionnÃ© par la construction, le dÃ©ploiement et la gestion d'applications scalables et le partage de connaissances avec la communautÃ© tech[.](https://www.udemy.com/course/github-actions-the-complete-guide/?couponCode=CMCPSALE24)

Si vous avez apprÃ©ciÃ© cet article, vous pouvez en apprendre davantage sur moi en explorant plus de mes blogs et projets sur mon [profil LinkedIn.](https://www.linkedin.com/in/prince-onukwili-a82143233/) Vous pouvez trouver mes [articles LinkedIn ici](https://www.linkedin.com/in/prince-onukwili-a82143233/details/publications/). Vous pouvez Ã©galement [visiter mon site web](https://prince-onuk.vercel.app/achievements#articles) pour lire plus de mes articles. Restons en contact et grandissons ensemble ! ğŸ˜Š