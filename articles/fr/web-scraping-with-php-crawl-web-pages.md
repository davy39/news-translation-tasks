---
title: Web Scraping avec PHP ‚Äì Comment parcourir des pages web en utilisant des outils
  open source
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2021-06-22T21:11:53.000Z'
originalURL: https://freecodecamp.org/news/web-scraping-with-php-crawl-web-pages
coverImage: https://www.freecodecamp.org/news/content/images/2021/06/scraping-with-php-image-1.png
tags:
- name: data
  slug: data
- name: open source
  slug: open-source
- name: PHP
  slug: php
- name: web scraping
  slug: web-scraping
seo_title: Web Scraping avec PHP ‚Äì Comment parcourir des pages web en utilisant des
  outils open source
seo_desc: "By Manthan Koolwal\nWeb scraping lets you collect data from web pages across\
  \ the internet. It's also called web crawling or web data extraction. \nPHP is a\
  \ widely used back-end scripting language for creating dynamic websites and web\
  \ applications. And ..."
---

Par Manthan Koolwal

Le web scraping permet de collecter des donn√©es √† partir de pages web sur Internet. On l'appelle aussi web crawling ou extraction de donn√©es web.

PHP est un langage de script back-end largement utilis√© pour cr√©er des sites web dynamiques et des applications web. Et vous pouvez impl√©menter un web scraper en utilisant du code PHP simple.

Mais comme nous ne voulons pas r√©inventer la roue, nous pouvons utiliser certaines biblioth√®ques PHP open source pr√™tes √† l'emploi pour nous aider √† collecter nos donn√©es.

Dans ce tutoriel, nous discuterons des diff√©rents outils et services que vous pouvez utiliser avec PHP pour scraper une page web. Les outils que nous aborderons sont Guzzle, Goutte, Simple HTML DOM et le navigateur headless Symfony Panther.

Note : avant de scraper un site web, vous devez lire attentivement leurs Conditions d'utilisation pour vous assurer qu'ils acceptent d'√™tre scrap√©s. Le scraping de donn√©es ‚Äì m√™me si elles sont publiquement accessibles ‚Äì peut potentiellement surcharger les serveurs d'un site web. (Qui sait ‚Äì si vous demandez poliment, ils pourraient m√™me vous donner une cl√© API pour que vous n'ayez pas √† scraper. üòâ)

## Comment installer le projet

Avant de commencer, si vous souhaitez suivre et essayer le code, voici quelques pr√©requis pour votre environnement de d√©veloppement :

* Assurez-vous d'avoir install√© la derni√®re version de PHP.
* Allez sur ce lien [Composer](https://getcomposer.org/) pour configurer un composer que nous utiliserons pour installer les diff√©rentes d√©pendances PHP pour les biblioth√®ques de web scraping.
* Un √©diteur de votre choix.

Une fois que vous avez termin√© tout cela, cr√©ez un r√©pertoire de projet et naviguez dans le r√©pertoire :

```
mkdir php_scraper

cd php_scraper
```

Ex√©cutez les deux commandes suivantes dans votre terminal pour initialiser le fichier **composer.json** :

```
composer init --require="php >=7.4" --no-interaction

composer update
```

Commen√ßons.

## Web Scraping avec PHP en utilisant Guzzle, XML et XPath

[Guzzle](http://docs.guzzlephp.org/en/stable/) est un client HTTP PHP qui permet d'envoyer des requ√™tes HTTP rapidement et facilement. Il dispose d'une interface simple pour construire des cha√Ænes de requ√™te.

[XML](https://en.wikipedia.org/wiki/XML) est un langage de balisage qui encode les documents pour qu'ils soient lisibles par l'homme et par la machine.

Et [XPath](https://en.wikipedia.org/wiki/XPath) est un langage de requ√™te qui navigue et s√©lectionne les n≈ìuds XML.

Voyons comment nous pouvons utiliser ces trois outils ensemble pour scraper un site web.

Commencez par installer Guzzle via composer en ex√©cutant la commande suivante dans votre terminal :

```
composer require guzzlehttp/guzzle
```

Une fois que vous avez install√© Guzzle, cr√©ons un nouveau fichier PHP auquel nous ajouterons le code. Nous l'appellerons **guzzle_requests.php**.

Pour cette d√©monstration, nous allons scraper le site web [Books to Scrape](https://books.toscrape.com/). Vous devriez pouvoir suivre les m√™mes √©tapes que nous d√©finissons ici pour scraper n'importe quel site web de votre choix.

Le site web Books to Scrape ressemble √† ceci :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/books-to-scrape-website.png)

Nous voulons extraire les titres des livres et les afficher sur le terminal.

La premi√®re √©tape pour scraper un site web est de comprendre sa structure HTML. Dans ce cas, vous pouvez voir la structure HTML de cette page en faisant un clic droit sur la page, juste au-dessus du premier produit de la liste, et en s√©lectionnant **Inspecter**.

Voici une capture d'√©cran montrant un extrait du code source de la page :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free2.png)

Vous pouvez voir que la liste est contenue dans l'√©l√©ment **<ol class="row">**. L'enfant direct suivant est l'√©l√©ment **<li>**.

Ce que nous voulons, c'est le titre du livre. Il se trouve √† l'int√©rieur de la balise **<a>**, qui est elle-m√™me √† l'int√©rieur de la balise **<h3>**, qui est √† l'int√©rieur de la balise **<article>**, qui est enfin √† l'int√©rieur de l'√©l√©ment **<li>**.

Pour initialiser Guzzle, XML et Xpath, ajoutez le code suivant au fichier **guzzle_requests.php** :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \GuzzleHttp\Client();
$response = $httpClient->get('https://books.toscrape.com/');
$htmlString = (string) $response->getBody();
//ajoutez cette ligne pour supprimer les avertissements
libxml_use_internal_errors(true);
$doc = new DOMDocument();
$doc->loadHTML($htmlString);
$xpath = new DOMXPath($doc);
```

Le code ci-dessus chargera la page web dans une cha√Æne. Nous analysons ensuite la cha√Æne en utilisant XML et l'assignons √† la variable **$xpath**.

La chose suivante que vous voulez faire est de cibler le contenu textuel √† l'int√©rieur de la balise **<a>**. Ajoutez le code suivant au fichier :

```php
$titles = $xpath->evaluate('//ol[@class="row"]//li//article//h3/a');
$extractedTitles = [];
foreach ($titles as $title) {
$extractedTitles[] = $title->textContent.PHP_EOL;
echo $title->textContent.PHP_EOL;
}
```

Dans l'extrait de code ci-dessus, **//ol[@class="row"]** obtient toute la liste.

Chaque √©l√©ment de la liste a une balise **<a>** que nous ciblons pour extraire le titre r√©el du livre. Nous n'avons qu'une seule balise <h3> contenant la balise <a>, ce qui facilite le ciblage direct.

Nous utilisons la boucle **foreach** pour extraire les contenus textuels et les afficher sur le terminal.

√Ä cette √©tape, vous pouvez choisir de faire quelque chose avec vos donn√©es extraites, peut-√™tre assigner les donn√©es √† une variable de tableau, √©crire dans un fichier ou les stocker dans une base de donn√©es.

Vous pouvez ex√©cuter le fichier en utilisant PHP sur le terminal en ex√©cutant la commande ci-dessous. N'oubliez pas, la partie surlign√©e est le nom que nous avons donn√© √† notre fichier :

```
php guzzle_requests.php
```

Cela devrait afficher quelque chose comme ceci :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free3.png)

Cela s'est bien pass√©.

Maintenant, que se passe-t-il si nous voulions aussi obtenir le prix du livre ?

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free4.png)

Le prix se trouve dans la balise **<p>**, √† l'int√©rieur d'une balise <div>. Comme vous pouvez le voir, il y a plus d'une balise <p> et plus d'une balise <div>.

Pour trouver la bonne cible, nous utiliserons les s√©lecteurs de classe CSS qui, heureusement pour nous, sont uniques pour chaque balise. Voici l'extrait de code pour obtenir √©galement la balise de prix et la concat√©ner √† la cha√Æne de titre :

```php
$titles = $xpath->evaluate('//ol[@class="row"]//li//article//h3/a');
$prices = $xpath->evaluate('//ol[@class="row"]//li//article//div[@class="product_price"]//p[@class="price_color"]');
foreach ($titles as $key => $title) {
echo $title->textContent . ' @ '. $prices[$key]->textContent.PHP_EOL;
}
```

Si vous ex√©cutez le code sur votre terminal, vous devriez voir quelque chose comme ceci :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free5.png)

Votre code complet devrait ressembler √† ceci :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \GuzzleHttp\Client();
$response = $httpClient->get('https://books.toscrape.com/');
$htmlString = (string) $response->getBody();
//ajoutez cette ligne pour supprimer les avertissements
libxml_use_internal_errors(true);
$doc = new DOMDocument();
$doc->loadHTML($htmlString);
$xpath = new DOMXPath($doc);
$titles = $xpath->evaluate('//ol[@class="row"]//li//article//h3/a');
$prices = $xpath->evaluate('//ol[@class="row"]//li//article//div[@class="product_price"]//p[@class="price_color"]');
foreach ($titles as $key => $title) {
echo $title->textContent . ' @ '. $prices[$key]->textContent.PHP_EOL;
}
```

Bien s√ªr, ceci est un scraper web basique, et vous pouvez certainement l'am√©liorer. Passons √† la biblioth√®que suivante.

## Web Scraping en PHP avec Goutte

[Goutte](https://github.com/FriendsOfPHP/Goutte) est un autre excellent client HTTP pour PHP sp√©cialement con√ßu pour le web scraping. Il a √©t√© d√©velopp√© par le cr√©ateur du [Framework Symfony](https://symfony.com/) et fournit une belle API pour scraper des donn√©es √† partir des r√©ponses HTML/XML des sites web.

Voici quelques-uns des composants qu'il inclut pour simplifier le web crawling :

* [Composant BrowserKit](https://symfony.com/doc/current/components/browser_kit.html) pour simuler le comportement d'un navigateur web.
* [Composant CssSelector](https://symfony.com/doc/current/components/css_selector.html) pour traduire les requ√™tes CSS en requ√™tes XPath.
* [Composant DomCrawler](https://symfony.com/doc/current/components/dom_crawler.html) apporte la puissance de DOMDocument et XPath.
* [Client HTTP Symfony](https://symfony.com/doc/current/http_client.html) est un composant relativement nouveau de l'√©quipe Symfony.

Installez Goutte via composer en ex√©cutant la commande suivante sur votre terminal :

```
composer require fabpot/goutte
```

Une fois que vous avez install√© le package Goutte, cr√©ez un nouveau fichier PHP pour notre code ‚Äì appelons-le **goutte_requests.php**.

Dans cette section, nous discuterons de ce que nous avons fait avec la biblioth√®que Guzzle dans la premi√®re section.

Nous allons scraper les titres de livres du site [Books to Scrape](https://books.toscrape.com/) en utilisant Goutte. Ensuite, nous verrons comment vous pouvez ajouter les prix dans une variable de tableau et utiliser la variable dans le code.

Ajoutez le code suivant √† l'int√©rieur du fichier goutte_requests.php :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \Goutte\Client();
$response = $httpClient->request('GET', 'https://books.toscrape.com/');
$titles = $response->evaluate('//ol[@class="row"]//li//article//h3/a');
$prices = $response->evaluate('//ol[@class="row"]//li//article//div[@class="product_price"]//p[@class="price_color"]');
// nous pouvons stocker les prix dans un tableau
$priceArray = [];
foreach ($prices as $key => $price) {
$priceArray[] = $price->textContent;
}
// nous extrayons les titres et les affichons sur le terminal avec les prix
foreach ($titles as $key => $title) {
echo $title->textContent . ' @ '. $priceArray[$key] . PHP_EOL;
}
```

Ex√©cutez le code en ex√©cutant la commande suivante dans le terminal :

```
php goutte_requests.php
```

Voici le r√©sultat :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free6.png)

C'est une fa√ßon de faire du web scraping avec Goutte.

Discutons d'une autre m√©thode en utilisant le composant **CSS Selector** qui vient avec Goutte. Le s√©lecteur CSS est plus simple que l'utilisation de XPath montr√© dans les m√©thodes pr√©c√©dentes.

Cr√©ez un autre fichier PHP, appelons-le **goutte_css_requests.php**. Ajoutez le code suivant au fichier :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \Goutte\Client();
$response = $httpClient->request('GET', 'https://books.toscrape.com/');
// obtenir les prix dans un tableau
$prices = [];
$response->filter('.row li article div.product_price p.price_color')->each(function ($node) use (&$prices) {
$prices[] = $node->text();
});
// afficher les titres et les prix
$priceIndex = 0;
$response->filter('.row li article h3 a')->each(function ($node) use ($prices, &$priceIndex) {
echo $node->text() . ' @ ' . $prices[$priceIndex] .PHP_EOL;
$priceIndex++;
});
```

Comme vous pouvez le voir, l'utilisation du composant CSS Selector donne un code plus propre et plus lisible.

Vous avez peut-√™tre remarqu√© que nous avons utilis√© l'op√©rateur **`&`**. Cela garantit que nous prenons la r√©f√©rence de la variable dans la boucle "**each**", et pas seulement la valeur de la variable. Si **`&$prices`** est modifi√© dans la boucle, la valeur r√©elle en dehors de la boucle est √©galement modifi√©e.

Vous pouvez lire plus sur [l'assignation par r√©f√©rence dans la documentation officielle de PHP](https://www.php.net/manual/en/language.references.whatdo.php).

Ex√©cutez le fichier dans votre terminal en ex√©cutant la commande :

```
php goutte_css_requests.php
```

Vous devriez voir un r√©sultat similaire √† celui des captures d'√©cran pr√©c√©dentes :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free7.png)

Notre scraper web avec PHP et Goutte se passe bien jusqu'√† pr√©sent. Allons un peu plus loin et voyons si nous pouvons cliquer sur un lien et naviguer vers une page diff√©rente.

Sur notre site de d√©monstration, [Books to Scrape](https://books.toscrape.com/), si vous cliquez sur un titre de livre, une page se chargera montrant les d√©tails du livre tels que :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/a-light-in-the-attic-for-scraping-tut.png)

Nous voulons voir si vous cliquez sur un lien de la liste des livres, naviguez vers la page des d√©tails du livre et extrayez la description. Inspectez la page pour voir ce que nous allons cibler :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free9.png)

Notre flux cible sera √† partir de l'√©l√©ment **<div class="content">**, puis **<div id="content_inner">**, puis la balise **<article>** qui n'appara√Æt qu'une seule fois, et enfin la balise **<p>**.

Nous avons plusieurs balises **<p>** ‚Äì la balise avec la description est la quatri√®me √† l'int√©rieur de l'√©l√©ment parent **<div class="content">**. Comme les tableaux commencent √† 0, nous obtiendrons le n≈ìud √† l'index **3**.

Maintenant que nous savons ce que nous ciblons, √©crivons le code.

Tout d'abord, ajoutez le package composer suivant pour aider √† l'analyse HTML5 :

```
composer require masterminds/html5
```

Ensuite, modifiez le fichier **goutte_css_requests.php** comme suit :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \Goutte\Client();
$response = $httpClient->request('GET', 'https://books.toscrape.com/');
// obtenir les prix dans un tableau
$prices = [];
$response->filter('.row li article div.product_price p.price_color')
->each(function ($node) use (&$prices) {
$prices[] = $node->text();
});
// afficher le titre, le prix et la description
$priceIndex = 0;
$response->filter('.row li article h3 a')
->each(function ($node) use ($prices, &$priceIndex, $httpClient) {
$title = $node->text();
$price = $prices[$priceIndex];
// obtenir la description
$description = $httpClient->click($node->link())
->filter('.content #content_inner article p')->eq(3)->text();
// afficher le r√©sultat
echo "{$title} @ {$price} : {$description}\n\n";
$priceIndex++;
});
```

Si vous ex√©cutez le fichier dans votre terminal, vous devriez voir un titre, un prix et une description affich√©s :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free10.png)

En utilisant le composant **CSS Selector** de Goutte et l'option de cliquer sur une page, vous pouvez facilement parcourir un site web entier avec plusieurs pages et extraire autant de donn√©es que vous le souhaitez.

## Web Scraping en PHP avec Simple HTML DOM

[Simple HTML DOM](https://simplehtmldom.sourceforge.io/manual.htm#section_quickstart) est une autre biblioth√®que PHP minimaliste de web scraping que vous pouvez utiliser pour parcourir un site web. Discutons de la mani√®re dont vous pouvez utiliser cette biblioth√®que pour scraper un site web. Tout comme dans les exemples pr√©c√©dents, nous allons scraper le site Books to Scrape.

Avant de pouvoir installer le package, modifiez votre fichier composer.json et ajoutez les lignes de code suivantes juste en dessous du bloc **`require:{}`** pour √©viter d'obtenir l'erreur de versionnage :

```
"minimum-stability": "dev",
"prefer-stable": true
```

Maintenant, vous pouvez installer la biblioth√®que avec la commande suivante :

```
composer require simplehtmldom/simplehtmldom
```

Une fois la biblioth√®que install√©e, cr√©ez un nouveau fichier PHP appel√© **simplehtmldom_requests.php**.

Nous avons d√©j√† discut√© de la mise en page de la page web que nous scrapons dans les sections pr√©c√©dentes. Nous allons donc passer directement au code. Ajoutez le code suivant au fichier **simplehtmldom_requests.php** :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = new \simplehtmldom\HtmlWeb();
$response = $httpClient->load('https://books.toscrape.com/');
// afficher le titre
echo $response->find('title', 0)->plaintext . PHP_EOL . PHP_EOL;
// obtenir les prix dans un tableau
$prices = [];
foreach ($response->find('.row li article div.product_price p.price_color') as $price) {
$prices[] = $price->plaintext;
}
// afficher les titres et les prix
foreach ($response->find('.row li article h3 a') as $key => $title) {
echo "{$title->plaintext} @ {$prices[$key]} \n";
}
```

Si vous ex√©cutez le code dans votre terminal, il devrait afficher les r√©sultats :

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free11.png)

Vous pouvez trouver plus de m√©thodes pour parcourir une page web en utilisant la [biblioth√®que Simple HTML DOM √† partir de la documentation officielle de l'API](https://simplehtmldom.sourceforge.io/manual_api.htm).

## Web Scraping en PHP avec un navigateur headless (Symfony Panther)

Un navigateur headless est un navigateur sans interface graphique. Les navigateurs headless permettent d'utiliser le terminal pour charger une page web dans un environnement similaire √† un navigateur web. Cela permet d'√©crire du code pour contr√¥ler la navigation comme nous venons de le faire dans les √©tapes pr√©c√©dentes.

Pourquoi est-ce n√©cessaire ?

Dans le d√©veloppement web moderne, la plupart des d√©veloppeurs utilisent des frameworks web JavaScript. Ces frameworks g√©n√®rent le code HTML √† l'int√©rieur des navigateurs. Dans d'autres cas, AJAX charge dynamiquement le contenu.

Dans les exemples pr√©c√©dents, nous avons utilis√© une page HTML statique, donc la sortie √©tait coh√©rente.

Dans les cas dynamiques, o√π vous utilisez JavaScript et AJAX pour g√©n√©rer le HTML, la sortie de l'arbre DOM peut diff√©rer consid√©rablement. Cela pourrait faire √©chouer nos scrapers. Les navigateurs headless entrent en jeu pour g√©rer ces probl√®mes dans les sites web modernes.

La biblioth√®que PHP [Symfony Panther](https://github.com/symfony/panther) fonctionne bien avec les navigateurs headless. Vous pouvez utiliser la biblioth√®que pour scraper des sites web et ex√©cuter des tests en utilisant de vrais navigateurs.

De plus, elle fournit les m√™mes m√©thodes que la biblioth√®que Goutte, donc vous pouvez l'utiliser √† la place de Goutte.

Contrairement aux biblioth√®ques de web scraping pr√©c√©dentes que nous avons discut√©es dans ce tutoriel, Panther peut faire ce qui suit :

* Ex√©cuter du code JavaScript sur les pages web
* Prend en charge les tests de navigateur √† distance
* Prend en charge le chargement asynchrone des √©l√©ments en attendant que d'autres √©l√©ments se chargent avant d'ex√©cuter une ligne de code
* Prend en charge toutes les impl√©mentations de Chrome et Firefox
* Peut prendre des captures d'√©cran
* Permet d'ex√©cuter votre code JS personnalis√© ou des requ√™tes XPath dans le contexte de la page charg√©e.

Nous avons d√©j√† fait beaucoup de scraping, alors essayons quelque chose de diff√©rent. Nous allons charger une page HTML et prendre une capture d'√©cran de la page.

Installez [Symfony Panther](https://github.com/symfony/panther) avec la commande suivante :

```
composer require symfony/panther
```

Cr√©ez un nouveau fichier php, appelons-le **panther_requests.php**. Ajoutez le code suivant au fichier :

```php
<?php
# scraping books to scrape: https://books.toscrape.com/
require 'vendor/autoload.php';
$httpClient = \Symfony\Component\Panther\Client::createChromeClient();
// pour un client Firefox, utilisez la ligne ci-dessous √† la place
//$httpClient = \Symfony\Component\Panther\Client::createFirefoxClient();
// obtenir la r√©ponse
$response = $httpClient->get('https://books.toscrape.com/');
// prendre une capture d'√©cran et la stocker dans le r√©pertoire courant
$response->takeScreenshot($saveAs = 'books_scrape_homepage.jpg');
// affichons quelques titres de livres
$response->getCrawler()->filter('.row li article h3 a')
->each(function ($node) {
echo $node->text() . PHP_EOL;
});
```

Pour que ce code s'ex√©cute sur votre syst√®me, vous devez installer les pilotes pour Chrome ou Firefox, selon le client que vous avez utilis√© dans votre code.

Heureusement, Composer peut le faire automatiquement pour vous. Ex√©cutez la commande suivante dans votre terminal pour installer et d√©tecter les pilotes :

```
composer require --dev dbrekelmans/bdi && vendor/bin/bdi detect drivers
```

Maintenant, vous pouvez ex√©cuter le fichier PHP dans votre terminal et il prendra une capture d'√©cran de la page web et la stockera dans le r√©pertoire courant. Il affichera ensuite une liste de titres du site web.

![Image](https://www.freecodecamp.org/news/content/images/2021/06/free12.png)

## Conclusion

Dans ce tutoriel, nous avons discut√© des diff√©rentes biblioth√®ques PHP open source que vous pouvez utiliser pour scraper un site web.

Si vous avez suivi le tutoriel, vous auriez d√ª √™tre capable de cr√©er un scraper basique pour parcourir une ou deux pages.

Bien que ce soit un article introductif, nous avons couvert la plupart des m√©thodes que vous pouvez utiliser avec les biblioth√®ques. Vous pouvez choisir de construire sur cette connaissance et cr√©er des scrapers web complexes capables de parcourir des milliers de pages. Le code de ce tutoriel est disponible dans ce [d√©p√¥t GitHub](https://github.com/jaymoh/php_web_scraper).

N'h√©sitez pas √† nous contacter si vous avez des questions.

Vous pouvez consulter d'autres articles sur le [web scraping avec Nodejs](https://www.scrapingdog.com/blog/web-scraping-101-with-nodejs) et le [web scraping avec Python](https://www.scrapingdog.com/blog/best-python-web-scraping-libraries/) si vous √™tes int√©ress√©.