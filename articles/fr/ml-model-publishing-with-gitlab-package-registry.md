---
title: Comment automatiser la publication de mod√®les de Machine Learning avec le registre
  de packages Gitlab
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2021-04-15T16:33:05.000Z'
originalURL: https://freecodecamp.org/news/ml-model-publishing-with-gitlab-package-registry
coverImage: https://www.freecodecamp.org/news/content/images/2021/04/photo-1510380290144-9e40d2438af5.jpeg
tags:
- name: automation
  slug: automation
- name: CI/CD
  slug: cicd
- name: GitLab
  slug: gitlab
- name: Machine Learning
  slug: machine-learning
- name: neural networks
  slug: neural-networks
seo_title: Comment automatiser la publication de mod√®les de Machine Learning avec
  le registre de packages Gitlab
seo_desc: 'By Yacine Mahdid

  In this tutorial we''ll learn how to automatically publish machine learning models
  in a Gitlab package registry and make them available for your teammates to use.
  You can also use this technique to share a packaged version of your cod...'
---

Par Yacine Mahdid

Dans ce tutoriel, nous allons apprendre comment publier automatiquement des mod√®les de machine learning dans un registre de packages Gitlab et les rendre disponibles pour vos co√©quipiers. Vous pouvez √©galement utiliser cette technique pour partager une version packag√©e de votre code sous forme de binaire.

Si vous √™tes un utilisateur d√©butant de Gitlab et que vous n'√™tes pas familier avec les techniques CI/CD, ce tutoriel est fait pour vous ! Une compr√©hension de base du machine learning et du deep learning est un plus, mais ce n'est pas une exigence pour comprendre la partie publication CI/CD.

### Voici ce que nous allons couvrir :

* Configuration du code Gitlab
* Code du r√©seau de neurones convolutionnel profond
* Code de reconnaissance d'images
* M√©thodologie de branchement
* T√©l√©chargement CI/CD
* Conclusion

## D'abord, un peu de contexte

√Ä un moment donn√© de votre carri√®re d'ing√©nieur en machine learning, vous devrez peut-√™tre partager un mod√®le que vous avez entra√Æn√© avec d'autres d√©veloppeurs. Il existe plusieurs fa√ßons de faire cela.

### Donner acc√®s au d√©p√¥t

Si vous ne craignez pas de montrer tout votre code, c'est une option tr√®s viable.

Si vous utilisez une bonne m√©thodologie de branchement, vos coll√®gues n'auront besoin de regarder que la branche principale pour savoir quel est le mod√®le le plus √† jour qu'ils peuvent utiliser. Ensuite, ils peuvent consulter le README.md pour apprendre comment l'utiliser.

Cependant, donner un acc√®s complet au d√©p√¥t peut ne pas √™tre une option viable pour vous.

### Partager le dernier mod√®le manuellement

Une autre fa√ßon serait d'extraire le code pertinent que vous souhaitez rendre public et de l'envoyer manuellement.

Cela peut devenir un peu d√©sordonn√© si vous travaillez avec plus d'une personne, car le mod√®le que vous envoyez peut ne pas √™tre √† jour. Cela vous met √©galement √† la charge de vous assurer que les gens utilisent toujours la derni√®re version de votre mod√®le.

### Partager le dernier mod√®le automatiquement

Une solution plus simple, m√™me dans le cas o√π le code du d√©p√¥t est disponible, est de confier la charge de packaging √† un pipeline CI/CD.

C'est le sujet de ce tutoriel, et notre configuration ressemblera √† ceci :

* Le d√©p√¥t de code, l'ensemble d'outils CI/CD et le registre de packages seront sur Gitlab
* Le code que nous allons packager sera un simple r√©seau de neurones PyTorch entra√Æn√© sur le jeu de donn√©es MNIST pour la reconnaissance de chiffres.
* Toutes les instructions et les exigences seront disponibles dans le package.

‚ö†Ô∏è **Avertissement** ‚ö†Ô∏è : Ce n'est pas ainsi que vous devriez d√©ployer un mod√®le PyTorch pr√™t pour la production ! Pour apprendre comment faire cela, consultez ce tutoriel sur [TorchScript](https://pytorch.org/tutorials/advanced/cpp_export.html).

Commen√ßons.

## Configuration du code Gitlab

Pour ce tutoriel, nous allons regrouper quatre fichiers :

* **model.pth** : qui est une version pickl√©e de la derni√®re version du mod√®le entra√Æn√©.
* **run_mnist.py** : script Python simple pour ex√©cuter le mod√®le afin de d√©tecter un chiffre √† partir d'une image png.
* **requirements.txt** : fichier texte contenant toutes les d√©pendances n√©cessaires pour ex√©cuter le mod√®le.
* **INSTRUCTION.md** : instructions √©tape par √©tape pour utiliser le package.

Le package peut ensuite √™tre utilis√© librement par toute personne ayant acc√®s au registre de packages et sera automatiquement mis √† jour.

![Image](https://www.freecodecamp.org/news/content/images/2021/04/package.png)
_Le package ressemblera alors √† ceci sur le registre de packages Gitlab !_

Plongeons dans le code du r√©seau de neurones, qui est une version modifi√©e de cet [article complet sur la reconnaissance de chiffres](https://nextjournal.com/gkoehler/pytorch-mnist). Le code modifi√© peut √™tre trouv√© sur [mon d√©p√¥t public Gitlab](https://gitlab.com/yacineg4/example-ml-packaging-pipeline).

## Code du r√©seau de neurones convolutionnel profond

Dans la section ci-dessous, vous verrez beaucoup de terminologie sur les r√©seaux de neurones profonds. Ce n'est pas un tutoriel sur les r√©seaux de neurones, donc si vous vous sentez un peu submerg√© par les d√©tails, vous pouvez sauter directement √† la section **M√©thodologie de branchement**. 

Gardez simplement √† l'esprit que nous avons entra√Æn√© une sorte de programme de reconnaissance d'images qui, √©tant donn√© un fichier `.png` repr√©sentant un chiffre, sera capable de vous dire quel nombre il contient.

Cependant, pour ceux qui veulent mieux comprendre comment les r√©seaux de neurones profonds fonctionnent sous le capot, vous pouvez consulter [mon tutoriel o√π j'en construis un √† partir de z√©ro](https://youtu.be/b_w4eEiogaE) ou consulter directement [le code dans mon Github](https://github.com/yacineMahdid/artificial-intelligence-and-machine-learning).

### D√©finition du r√©seau de neurones

Le code de d√©finition du r√©seau est tr√®s simple puisque le r√©seau que nous allons utiliser est simple. Il a les caract√©ristiques suivantes :

* 2 couches convolutionnelles.
* [Dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/) est appliqu√© sur la deuxi√®me couche convolutionnelle.
* Fonctions d'activation [Relu](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) appliqu√©es sur tous les neurones.
* 2 couches enti√®rement connect√©es √† la fin pour l'inf√©rence.

```python
import torch
import torchvision

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim


# D√©finir le r√©seau
# C'est un r√©seau √† 2 couches convolutionnelles avec dropout sur la 2√®me et enfin 2 couches enti√®rement connect√©es
# Toutes les couches utilisent relu
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

### Fonction d'entra√Ænement

Nous avons ensuite cr√©√© une fonction d'entra√Ænement utilitaire afin d'am√©liorer de mani√®re it√©rative notre r√©seau d√©fini en utilisant la descente de gradient. Si vous voulez en savoir plus sur le fonctionnement de la descente de gradient, consultez [mon court tutoriel √† ce sujet](https://youtu.be/IH9kqpMORLM).

Ce r√©gime d'entra√Ænement fera ce qui suit :

* It√©rer sur des lots de donn√©es d'entra√Ænement repr√©sentant des chiffres de 28 par 28.
* Utiliser la [fonction de co√ªt de la log-vraisemblance n√©gative](https://medium.com/deeplearningmadeeasy/negative-log-likelihood-6bd79b55d8b6) pour calculer la perte.
* Calculer les gradients.
* Optimiser les poids du r√©seau en utilisant la descente de gradient.
* Sauvegarder le mod√®le √† des intervalles fixes.

```python
def train(network, optimizer, train_loader, epoch_id, log_interval=10):
  """Ex√©cuter le r√©gime d'entra√Ænement sur l'ensemble d'entra√Ænement en utilisant train_loader

    Args:
        network: Le r√©seau instanci√©.
        optimizer: L'optimiseur utilis√© pour changer les poids.
        train_loader: le chargeur pour l'ensemble d'entra√Ænement d√©j√† configur√©
        epoch_id: l'id actuel de l'√©poque utilis√© pour des raisons cosm√©tiques.
        log_interval: intervalle auquel nous imprimons une sortie

    Returns:
        rien, sauvegardera directement au niveau racine l'√©tat du mod√®le et de l'optimiseur

  """

  # Mettre le r√©seau en mode entra√Ænement
  network.train()

  # It√©rer sur l'ensemble complet de l'ensemble d'entra√Ænement
  for batch_idx, (data, target) in enumerate(train_loader):

    # Calculer les gradients pour ce lot de donn√©es
    optimizer.zero_grad()
    output = network(data)
    loss = F.nll_loss(output, target)
    loss.backward()

    # Optimiser le r√©seau
    optimizer.step()

    # Journaliser et sauvegarder √† chaque intervalle s√©lectionn√©
    if batch_idx % log_interval == 0:

      print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
        epoch_id, batch_idx * len(data), len(train_loader.dataset),
        100. * batch_idx / len(train_loader), loss.item()))
      
      # Cela sauvegardera l'√©tat sous forme d'objet pickl√©
      torch.save(network.state_dict(), './model.pth')
      torch.save(optimizer.state_dict(), './optimizer.pth')
```

Les donn√©es pour l'entra√Ænement peuvent √™tre trouv√©es sur le [site web de Yan LeCun](http://yann.lecun.com/exdb/mnist/). Ici, nous utilisons les jeux de donn√©es format√©s en tenseurs PyTorch de 28 par 28 pour l'entra√Ænement.

### Fonction de test

La fonction suivante que nous cr√©ons est une fonction de test pour valider si notre r√©seau a appris quelque chose sans r√©utiliser les m√™mes donn√©es d'entra√Ænement. Cette fonction est simple dans le sens o√π elle comptera simplement les pr√©dictions correctes et incorrectes.

```python
def test(network, test_loader):
  """Ex√©cuter le r√©gime de test sur l'ensemble de test en utilisant test_loader

    Args:
        network: Le r√©seau instanci√© et entra√Æn√©.
        test_loader: le chargeur pour l'ensemble de test d√©j√† configur√©

    Returns:
        rien, imprimera uniquement le r√©sultat

  """

  # Initialisation des variables
  test_loss = 0
  correct = 0

  # Passer le r√©seau en mode √©valuation au lieu de l'entra√Ænement
  network.eval()
  
  # Configurer torch pour ne pas suivre de gradient
  with torch.no_grad():

    # It√©rer sur toutes les donn√©es de test et accumuler la perte
    for data, target in test_loader:
      output = network(data)
      test_loss += F.nll_loss(output, target, size_average=False).item()
      pred = output.data.max(1, keepdim=True)[1]
      correct += pred.eq(target.data.view_as(pred)).sum()

  # Calcul et impression de la perte moyenne
  test_loss /= len(test_loader.dataset)
  print('\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
    test_loss, correct, len(test_loader.dataset),
    100. * correct / len(test_loader.dataset)))
```

Cette fonction sera utile pour v√©rifier √† quel point notre r√©seau a appris apr√®s chaque it√©ration d'entra√Ænement.

### R√©gime d'entra√Ænement

Enfin, nous pouvons rassembler tout ce qui pr√©c√®de avec le corps principal du script d'entra√Ænement ! Plusieurs choses se passent, mais les points les plus importants sont les suivants :

* Nous d√©finissons nos hyperparam√®tres de mani√®re statique. Une meilleure fa√ßon de les d√©finir serait d'utiliser un ensemble de validation pour les d√©terminer en fonction des donn√©es.
* Nous cr√©ons notre chargeur de donn√©es qui ing√©rera les donn√©es et produira des tenseurs de la bonne forme pour le r√©seau. Ces chargeurs transformeront les donn√©es en les normalisant avec la moyenne globale et l'√©cart-type des jeux de donn√©es MNIST.
* Nous utilisons la [descente de gradient stochastique avec momentum](https://youtu.be/7EuiXb6hFAM) comme m√©thode d'optimisation, qui est l'une des nombreuses variantes de la descente de gradient que nous pouvons utiliser.
* Nous parcourons l'ensemble complet des donn√©es d'entra√Ænement "epoch", la dur√©e d'entra√Ænement du r√©seau tout en testant sur les jeux de donn√©es de test mis de c√¥t√©.

```python
# Param√®tres exp√©rimentaux que nous pouvons ajuster
n_epochs = 3
batch_size_train = 64
batch_size_test = 1000
learning_rate = 0.01
momentum = 0.5

# Variable du jeu de donn√©es qui devrait rester telle quelle
global_mean_mnist = 0.1307
global_std_mnist = 0.3081


# Graine al√©atoire pour l'exp√©rimentation reproductible
random_seed = 42
torch.backends.cudnn.enabled = False
torch.manual_seed(random_seed)


# Chargeur de donn√©es pour collecter les donn√©es puis les normaliser
train_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST('./data/', train=True, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (global_mean_mnist,), (global_std_mnist,))
                             ])),
  batch_size=batch_size_train, shuffle=True)

test_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST('./data/', train=False, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (global_mean_mnist,), (global_std_mnist,))
                             ])),
  batch_size=batch_size_test, shuffle=True)

# Initialiser le r√©seau et l'optimiseur
network = Net()
optimizer = optim.SGD(network.parameters(), lr=learning_rate,
                      momentum=momentum)

# Tester d'abord pour montrer que le mod√®le n'a rien appris
test(network, test_loader)

# Entra√Æner sur l'ensemble du jeu de donn√©es plusieurs fois et tester
for epoch_id in range(1, n_epochs + 1):
  train(network, optimizer, train_loader, epoch_id)
  test(network, test_loader)
```

Notez qu'il est tr√®s important de tester votre r√©seau sur un ensemble mis de c√¥t√© pour √©viter le sur-apprentissage sur les donn√©es d'entra√Ænement.

Tous les scripts ci-dessus peuvent √™tre trouv√©s dans le fichier [train_mnist.py dans le d√©p√¥t](https://gitlab.com/yacineg4/example-ml-packaging-pipeline/-/blob/master/train_mnist.py). 

√Ä ce stade, nous pouvons entra√Æner un mod√®le et le sauvegarder √† intervalles r√©guliers dans un format pickl√©.

Nous pouvons maintenant utiliser ce mod√®le entra√Æn√© sauvegard√© pour √©valuer un chiffre dans un fichier `.png`.

## Code de reconnaissance d'images

Supposons que nous avons en entr√©e l'image suivante :

![Image](https://www.freecodecamp.org/news/content/images/2021/01/test_image_0.png)
_un petit chiffre 0_

ou celle-ci :

![Image](https://www.freecodecamp.org/news/content/images/2021/01/test_image_7.png)
_un plus grand chiffre 7_

Comment pouvons-nous faire en sorte que notre r√©seau, qui fonctionne sur un tenseur PyTorch de 28 par 28, √©value les nombres ?

C'est assez simple si nous suivons √† peu pr√®s le m√™me processus que les jeux de donn√©es d'entra√Ænement, qui est :

* Avoir des images en niveaux de gris (pas de canaux de couleur ou alpha)
* Redimensionner les images pour qu'elles soient de 28 par 28 pixels
* Normaliser les images en utilisant la moyenne et l'√©cart-type des jeux de donn√©es MNIST.

```python
if __name__ == "__main__":

    # Initialisation des variables
    global_mean_mnist = 0.1307
    global_std_mnist = 0.3081

    # Chargement du r√©seau avec les bons poids
    result_path = './model.pth'
    model = Net()
    model.load_state_dict(torch.load(result_path))
    model.eval()

    # Configuration de la transformation de l'image en tenseurs normalis√©s
    transform = transforms.Compose([
                        transforms.Resize((28,28)),
                        transforms.ToTensor(),
                        transforms.Normalize(
                            (global_mean_mnist,), (global_std_mnist,))
                        ])
    
    # Analyse de l'entr√©e de l'utilisateur qui devrait √™tre un nom de fichier avec le flag --image
    parser = OptionParser()
    parser.add_option("--image", dest = "input_image_path",
                      help = "Chemin de l'image d'entr√©e")
    (options, args) = parser.parse_args()

    # Obtenir le chemin de l'image √† d√©coder
    input_image_path = str(options.input_image_path)
    
    # Ouvrir l'image(s) et faire l'inf√©rence
    images=glob.glob(input_image_path)
    for image in images:
    
        # Convertir l'image en niveaux de gris
        img = Image.open(image).convert('L')

        # Transformer l'image en tenseur normalis√©
        img_tensor = transform(img).unsqueeze(0)

        # Faire et imprimer la pr√©diction
        output = model(img_tensor).data.max(1, keepdim=True)[1][0][0]
        print(f"L'image est un {int(output)}")
```

Comme vous pouvez le voir, nous utilisons un parseur pour accepter un chemin d'image sur la ligne de commande avant d'appliquer nos transformations. Une fois qu'elles sont appliqu√©es, nous pouvons alimenter cela dans notre mod√®le charg√© et collecter la pr√©diction de sortie.

‚ö†Ô∏è N'oubliez pas d'inclure la d√©finition du r√©seau dans le script (en important ou en copiant-collant), sinon le mod√®le pickl√© ne pourra pas se charger correctement.

Nous pouvons maintenant ex√©cuter notre code comme ceci :

```bash
python run_mnist.py --image NOM_DE_LIMAGE.png
```

Cela imprimera simplement l'inf√©rence du mod√®le sur ce que contient cette image particuli√®re.

Maintenant que nous avons le code d'entra√Ænement et d'√©valuation de base configur√©, discutons un peu plus de la fa√ßon d'utiliser le branchement git √† notre avantage pour publier ce mod√®le dans le registre de packages.

## M√©thodologie de branchement

Si vous travaillez seul sur un projet, il est tr√®s tentant de simplement commiter sur master/main et en finir avec √ßa. Cependant, cette fa√ßon de travailler est tr√®s difficile √† maintenir et elle rend l'incorporation d'outils CI/CD appropri√©s p√©nible. 

Une strat√©gie de branche main / develop comme illustr√© ci-dessous est plus maintenable :

![Image](https://www.freecodecamp.org/news/content/images/2021/01/image-122.png)
_Image de : https://nvie.com/posts/a-successful-git-branching-model/_

En gardant toujours la branche principale propre, nous pouvons facilement d√©clencher notre pipeline CI/CD d√®s que nous poussons sur la branche principale. Nous serons √©galement libres de commiter autant que n√©cessaire dans la branche develop pendant que nous am√©liorons nos mod√®les. 

Lorsque nous sommes pr√™ts pour un nouveau d√©ploiement, nous n'aurons besoin que de fusionner avec la branche principale (ou mieux encore, faire une demande de fusion / pull-request puis fusionner). 

Cette fusion avec la branche principale devrait d√©clencher Gitlab pour t√©l√©charger la nouvelle version de notre mod√®le dans le registre de packages.

Examinons la mani√®re simple d'automatiser la publication dans le registre de packages en utilisant le fichier `.gitlab-ci.yml`.

## Pipeline CI/CD

Le fichier `.gitlab-ci.yml` est un fichier sp√©cial dans votre d√©p√¥t utilis√© par Gitlab pour d√©finir ce que le serveur Gitlab doit faire lorsque vous poussez vers un d√©p√¥t.

Pour en savoir plus sur le fonctionnement de CI/CD dans Gitlab, rendez-vous sur ce [cours acc√©l√©r√© sur Gitlab CI/CD](https://medium.com/faun/gitlab-ci-cd-crash-course-6e7bcf696940).

Dans ce tutoriel, notre fichier `.gitlab-ci.yml` ressemble √† ceci :

```yml
image: pytorch/pytorch

variables:
  VERSION: "0.0.4" # √Ä changer si n√©cessaire

stages:
  - upload
   
upload:
  stage: upload
  only:
    - master
  script:
    - apt-get update
    - apt-get install -y curl wget
    - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ./model.pth "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/model.pth"'
    - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ./run_mnist.py "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/run_mnist.py"'
    - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ./requirements.txt "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/requirements.txt"'
    - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ./INSTRUCTION.md "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/INSTRUCTION.md"'



```

L'anatomie de ce fichier `.yml` est tr√®s basique. Nous n'avons qu'une seule √©tape dans notre pipeline qui est l'√©tape `upload`. 

Dans l'√©tape de t√©l√©chargement, nous ex√©cuterons la section `script` uniquement lorsque la branche `master` est mise √† jour. Le script que nous avons ex√©cut√© utilise simplement `curl` pour transf√©rer les donn√©es de ce d√©p√¥t (4 fichiers) dans le registre de packages.

Examinons l'anatomie de la commande `curl` que nous utilisons :

```python
 - 'curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file ./NOM_DU_FICHIER "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/NOM_DU_FICHIER"'
```

* `--header` est utilis√© pour indiquer √† curl que vous inclurez un [en-t√™te suppl√©mentaire √† la requ√™te](https://curl.se/docs/manpage.html#-H).
* `JOB-TOKEN` est notre en-t√™te et `$CI_JOB_TOKEN` est sa valeur. C'est une variable qui vit dans les serveurs Gitlab lorsqu'un travail est cr√©√©
* `--upload-file` est un flag pour indiquer que nous allons transf√©rer un [fichier local vers l'URL distante](https://curl.se/docs/manpage.html#-T).
* `./NOM_DU_FICHIER` est le nom du fichier local que nous voulons transf√©rer.
* `${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/example-ml-packaging-pipeline/${VERSION}/NOM_DU_FICHIER` est l'emplacement de l'URL distante vers laquelle nous voulons transf√©rer un fichier. 

Ici, `$CI_API_V4_URL` est l'URL de l'API Gitlab que nous utilisons, `$CI_PROJECT_ID` est d√©fini dans Gitlab CI comme l'id pour notre projet, et enfin `VERSION` est le num√©ro de version que nous avons d√©fini en haut du fichier `.yml`.

C'est tout ! Lorsque vous mettez √† jour la branche principale vers le d√©p√¥t distant sur Gitlab, cela d√©clenchera un pipeline qui ex√©cutera votre travail de packaging.

![Image](https://www.freecodecamp.org/news/content/images/2021/04/gitlab-ci.png)
_Le travail sera alors disponible et vous pourrez v√©rifier la trace sur Gitlab !_

Vous et vos co√©quipiers pourrez voir le document dans la section du registre de packages et obtenir les bons fichiers versionn√©s dans le package :

![Image](https://www.freecodecamp.org/news/content/images/2021/04/package-1.png)
_C'est notre v.0.0.5 du package exemple !_

Pour avoir une id√©e plus compl√®te de ce qui est possible avec l'API Packages, rendez-vous sur la [documentation officielle](https://docs.gitlab.com/ee/api/packages.html).

## Conclusion

Dans ce tutoriel, vous avez appris comment regrouper, t√©l√©charger et automatiser le packaging d'un mod√®le de machine learning en utilisant Gitlab CI/CD. 

F√©licitations ! üéâüéâüéâ

Il y a encore beaucoup plus de choses que vous pouvez faire avec Gitlab CI/CD, par exemple :

* Ajouter une √©tape de test avant le regroupement afin de vous assurer qu'il n'y a pas de r√©gression dans le code.
* Ajouter une √©tape de test apr√®s le regroupement pour vous assurer que les performances de votre mod√®le sont satisfaisantes en termes de latence d'inf√©rence.
* Utiliser une version plus optimis√©e du mod√®le avec TorchScript.
* Ajouter une notification sociale automatique de nouvelle version apr√®s l'√©tape de t√©l√©chargement.

Pour en savoir plus sur Gitlab CI/CD, la documentation officielle est un excellent point de d√©part, et la [section de d√©marrage est tr√®s adapt√©e aux d√©butants](https://docs.gitlab.com/ee/ci/quick_start/).

Si vous voulez lire plus de ce type de contenu, consultez mes [articles sur l'ing√©nierie m√©canique/logicielle](https://grad4.com/en/category/blog/grad4-engineering-blog/). Si vous voulez discuter de tout cela, n'h√©sitez pas √† m'envoyer un DM sur [LinkedIn](https://www.linkedin.com/in/yacine-mahdid-809425163/) ou [Twitter](https://twitter.com/CodeThisCodeTh1) üòä