---
title: Comment construire un outil de test de stress pour d√©boguer votre code
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2023-05-02T08:57:35.000Z'
originalURL: https://freecodecamp.org/news/build-a-stress-tester-debugging-tool
coverImage: https://www.freecodecamp.org/news/content/images/2023/04/nathan-dumlao-pMW4jzELQCw-unsplash.jpg
tags:
- name: debugging
  slug: debugging
- name: Python
  slug: python
- name: stress testing
  slug: stress-testing
seo_title: Comment construire un outil de test de stress pour d√©boguer votre code
seo_desc: "By Alberto Gonzalez Rosales\nI recently wrote about how competitive programmers\
  \ debug their solutions during competitions. We take advantage of randomization\
  \ and the computing power in the devices we use daily. \nThat article was selected\
  \ as one of the..."
---

Par Alberto Gonzalez Rosales

J'ai r√©cemment √©crit sur [comment les programmeurs comp√©titifs d√©boguent leurs solutions pendant les comp√©titions](https://www.freecodecamp.org/news/debugging-like-competitive-programmers/). Nous tirons parti de la randomisation et de la puissance de calcul des appareils que nous utilisons quotidiennement. 

Cet article a √©t√© s√©lectionn√© comme l'un des gagnants du [DebuggingFeb Writeathon](https://townhall.hashnode.com/debuggingfeb-writeathon-winners) et a re√ßu beaucoup de visibilit√© de la part de la communaut√© Hashnode.

Les retours que j'ai re√ßus de certains des lecteurs ont √©t√© la meilleure chose qui est venue avec toute cette visibilit√©. Ces lecteurs sont ce que j'aime appeler **Actifs** ‚Äì ceux qui ne s'arr√™tent pas √† la fin de l'article mais continuent √† poser des questions et √† sugg√©rer des am√©liorations.

L'une des demandes les plus fr√©quentes que j'ai re√ßues √©tait de savoir si je pouvais essayer de rendre ce m√©canisme de d√©bogage plus similaire √† un outil que les d√©veloppeurs pourraient utiliser facilement dans leurs t√¢ches de codage quotidiennes.

Cet article est ma proposition pour ceux d'entre vous qui continuent √† repousser les limites de la connaissance en posant les bonnes questions et en donnant les suggestions appropri√©es.

Si vous n'avez pas encore lu l'article qui a motiv√© celui-ci, vous pouvez le faire [ici](https://www.freecodecamp.org/news/debugging-like-competitive-programmers/). Une fois que vous √™tes familier avec le sujet principal que nous allons discuter, vous pouvez plonger dans la section suivante et lire l'article entier.

C'est parti !

## **Qu'est-ce que le Stress Testing ?**

Bien que je n'aie pas donn√© de nom √† cette technique dans le premier [article](https://www.freecodecamp.org/news/debugging-like-competitive-programmers/), elle a un nom propre dans la communaut√© des d√©veloppeurs de logiciels. Ce nom est **Stress Testing**.

Nous pouvons d√©finir le stress testing comme suit :

> Le stress testing est une [activit√© de test de logiciels](https://en.wikipedia.org/wiki/Software_testing) qui d√©termine la [robustesse du logiciel](https://en.wikipedia.org/wiki/Robustness_of_software) en testant au-del√† des limites du fonctionnement normal. Le stress testing est particuli√®rement important pour les logiciels "[mission critical](https://en.wikipedia.org/wiki/Mission_critical)", mais il est utilis√© pour tous les types de logiciels.   
>   
> Les tests de stress mettent g√©n√©ralement plus l'accent sur la robustesse, la [disponibilit√©](https://en.wikipedia.org/wiki/Availability) et la [gestion des erreurs](https://en.wikipedia.org/wiki/Error_handling) sous une charge lourde, que sur ce qui serait consid√©r√© comme un comportement correct dans des circonstances normales.

Bien que cette d√©finition soit plus adapt√©e aux situations r√©elles de d√©veloppement de logiciels, nous pouvons l'extrapoler √† notre cas d'utilisation. Surtout √† cause de la partie _"sous une charge lourde"_.

L'avantage principal de cette approche pour tester les solutions est la capacit√© √† g√©n√©rer des milliers de cas de test et √† les ex√©cuter en quelques secondes. Si ce n'est pas une charge lourde, alors qu'est-ce que c'est ?

L'approche consistant √† g√©n√©rer des milliers de petits cas d'√©chantillon pour tester une solution n'est pas seulement utilis√©e par les programmeurs comp√©titifs lorsqu'ils essaient de trouver des bugs pendant les comp√©titions. Les poseurs de probl√®mes l'utilisent √©galement lorsqu'ils veulent d√©terminer si une solution propos√©e pour un probl√®me est effectivement correcte.

J'ai √©t√© des deux c√¥t√©s, et je peux vous dire que les avantages sont remarquables. La vitesse √† laquelle vous pouvez trouver des contre-tests pour vos solutions augmente d'au moins un facteur de 10. Cela vous permet de passer moins de temps √† d√©boguer les propositions de solution et plus de temps sur des choses importantes.

## **Le Probl√®me d'Exemple**

Rappelons le probl√®me que nous avons r√©solu la derni√®re fois. L'√©nonc√© √©tait le suivant :

> "√âtant donn√© un tableau tri√© d'entiers et un entier `x`, trouver le premier indice du tableau contenant le nombre `x` ou retourner `-1` si le nombre n'appara√Æt pas dans le tableau".

Nous pouvons r√©soudre ce probl√®me avec une solution na√Øve qui parcourt la liste de gauche √† droite et s'arr√™te d√®s qu'elle trouve un √©l√©ment √©gal √† `x`. Si elle atteint la fin de la liste sans trouver l'√©l√©ment que nous cherchons, elle retourne la valeur `-1`.

Une impl√©mentation possible en Python est la suivante :

```python
# solutions/naive.py

def naive(a, x):
    return next((i for i in range(len(a)) if a[i] == x), -1)


if __name__ == "__main__":
    num_list = list(map(int, input().split()))
    x = int(input())
    print(naive(num_list, x))

```

Cette solution, bien qu'elle soit correcte, n'est pas assez rapide. Elle effectue une recherche lin√©aire dans toute la liste, ce qui entra√Æne une complexit√© temporelle de `O(n)`, ce qui est suffisamment bon, mais nous pouvons faire mieux.

Pour am√©liorer notre solution, nous devrions remarquer que nous ne tirons pas parti du fait que notre liste d'entr√©e est tri√©e. Cela signifie que nous pouvons utiliser l'algorithme de recherche binaire pour rechercher le nombre `x`.

Notre solution am√©lior√©e serait quelque chose comme ceci :

```python
# solutions/solution.py

def solution(a, x):
    l = 0
    r = len(a) - 1
    while l <= r:
        m = (l + r) // 2
        if a[m] == x:
            return m

        if a[m] < x:
            l = m + 1
        else:
            r = m - 1
    return -1


if __name__ == "__main__":
    num_list = list(map(int, input().split()))
    x = int(input())
    print(solution(num_list, x))

```

En utilisant la recherche binaire, nous avons r√©duit la complexit√© temporelle de notre solution √† `O(n log n)`. Mais malheureusement, cette solution contient un bug.

Comment le trouver, alors ? Nous pourrions passer des heures √† essayer de g√©n√©rer des cas de test manuels pour v√©rifier o√π notre solution √©choue.

Eh bien, voici o√π nous b√©n√©ficions de la g√©n√©ration de cas al√©atoires. Et voici ma nouvelle proposition pour le faire.

## **Comment Construire un Outil de Test de Stress**

Cr√©ons un nouveau projet avec la structure suivante :

```bash
stress_tester
|-- generators
|---|-- random_generator.py
|-- solutions
|---|-- naive.py
|---|-- solution.py
|-- test_cases

```

Comme vous pouvez le voir, il contient un dossier **"generators"** avec les fichiers de g√©n√©rateur. Dans notre cas, nous utiliserons simplement un g√©n√©rateur al√©atoire, mais parfois des g√©n√©rateurs plus sp√©cifiques sont n√©cessaires.

Il contient √©galement un dossier **"solutions"** qui stockera notre solution na√Øve pour le probl√®me et la solution que nous voulons tester.

Enfin, nous avons cr√©√© un dossier **"test_cases"** qui stockera tous les cas de test que nous g√©n√©rons pour les inspecter chaque fois que nous trouvons une diff√©rence dans la sortie de nos solutions.

Le g√©n√©rateur que nous allons utiliser pour cet exemple est le suivant :

```python
# generators/random_generator.py

import random


def generate_input():
    n = random.randint(1, 10)
    a = [random.randint(1, 10) for _ in range(n)]
    a.sort()
    x = a[random.randint(0, n - 1)]
    return a, x


if __name__ == "__main__":
    a, x = generate_input()
    print(" ".join([str(elem) for elem in a]))
    print(x)

```

Id√©alement, ce que nous voulons, c'est g√©n√©rer des cas de test al√©atoires, les fournir (un √† la fois) √† nos deux solutions, et nous arr√™ter lorsque les sorties retourn√©es pour une entr√©e donn√©e sont diff√©rentes. Ensuite, nous pouvons examiner le cas de test qui fait √©chouer notre solution et commencer √† corriger nos bugs.

Automatisons ce processus.

### Automatisation avec un script **shell**

Le scripting shell semble √™tre l'option privil√©gi√©e ici. Cela est largement utilis√© dans les t√¢ches li√©es √† l'automatisation dans des domaines tels que les syst√®mes d'exploitation et les r√©seaux. Dans notre cas, nous l'utiliserons pour lier des programmes existants ensemble.

Le fait est que la sortie g√©n√©r√©e par notre programme **random_generator** doit √™tre fournie en entr√©e √† nos programmes **na√Øf** et **solution**. Une fois de plus, les sorties de ces deux programmes doivent √™tre fournies en entr√©e √† un autre programme qui indique s'ils sont diff√©rents ou non.

La bonne chose est qu'un simple script shell peut nous aider √† r√©aliser tout cela sans trop d'effort.

Cr√©ons un fichier √† la racine du projet et appelons-le `check.sh`. Le contenu du fichier doit √™tre le suivant :

```bash
# check.sh

# Nombre de cas de test
TEST_CASES=100

# Commandes pour ex√©cuter les scripts Python
RUN_GENERATOR="python3 ./generators/random_generator.py"
RUN_SOLUTION="python3 ./solutions/solution.py"
RUN_NAIVE="python3 ./solutions/naive.py"

# R√©pertoire de test
TEST_CASES_DIRECTORY="./test_cases"

# Couleurs de la console
RESET_COLOR="\x1b[0m"
OK_COLOR="\x1b[32m"
WA_COLOR="\x1b[31m"

echo "D√©marrage du stress testing avec $TEST_CASES cas de test(s)..."

mkdir -p "$TEST_CASES_DIRECTORY" # Cr√©er un r√©pertoire pour stocker les cas de test
for i in `seq -f "%0${#TEST_CASES}g" 1 $TEST_CASES`
do
    INPUT="$TEST_CASES_DIRECTORY/input-$i.in"

    eval "$RUN_GENERATOR" > "$INPUT"  # G√©n√©rer un cas de test
    DIFF=$(diff -w <(eval "$RUN_SOLUTION" < "$INPUT") <(eval "$RUN_NAIVE" < "$INPUT"))  # √âvaluer le cas de test dans les deux solutions et obtenir leurs diff√©rences de sortie
    if [ "$DIFF" == "" ] ; then  # M√™me sortie
        echo -e " ‚Ä¢ Cas de test $i: ${OK_COLOR}OK!${RESET_COLOR}"
    else  # Sortie diff√©rente
        echo -e " ‚Ä¢ Cas de test $i: ${WA_COLOR}Wrong Answer!${RESET_COLOR}"
        break
    fi
done

```

Expliquons ce qui se passe dans ce code :

1. Nous d√©finissons les variables n√©cessaires telles que le nombre de cas de test que nous allons ex√©cuter, les commandes pour ex√©cuter nos scripts Python de g√©n√©rateur et de solution, et les couleurs √† afficher dans la console.
2. Nous it√©rons de `1` au nombre de cas que nous avons d√©fini. Chaque fois, nous appelons le script de g√©n√©rateur et redirigeons la sortie vers un fichier en utilisant l'op√©rateur `>`.
3. Ensuite, nous fournissons ce fichier en entr√©e aux deux solutions en utilisant l'op√©rateur `<` et v√©rifions les diff√©rences en utilisant la commande `diff`.
4. Si aucune diff√©rence n'est trouv√©e, nous imprimons `OK!` dans la console et passons au cas de test suivant. Sinon, nous imprimons `Wrong Answer!` et arr√™tons le script.

Pour ex√©cuter ce script, nous devons taper la commande suivante dans notre console lorsque nous sommes √† la racine de notre projet :

```bash
./check.sh

```

Une sortie similaire √† celle-ci devrait appara√Ætre sur votre console apr√®s avoir ex√©cut√© la commande :

![Image](https://cdn.hashnode.com/res/hashnode/image/upload/v1679248442581/17477848-3ef5-46b5-9a05-a3a6137bafb0.png?auto=compress,format&format=webp)

Dans mon cas, il a d√©tect√© une diff√©rence dans les sorties sur le cas num√©ro `11`. Maintenant, je dois aller analyser ce cas et essayer de corriger les bugs dans mon code. Cela sera beaucoup plus facile maintenant que je connais un cas o√π ma solution √©choue.

Lorsque nous avons fini de corriger notre solution bogu√©e, nous pouvons relancer le script pour v√©rifier si elle passe tous les cas de test. Esp√©rons que vous obtiendrez un r√©sultat similaire √† celui-ci :

![Image](https://cdn.hashnode.com/res/hashnode/image/upload/v1679249134355/2ccafe9d-1948-4b93-b097-48cbae6ca777.png?auto=compress,format&format=webp)

Sinon, corrigez votre solution √† nouveau jusqu'√† ce que vous y arriviez. Maintenant, vous aurez un nouveau cas de test √† analyser.

### Automatisation avec un script **Python**

Bien que nous ayons une solution qui utilise un script **shell** pour automatiser le processus de v√©rification, il contient encore quelques d√©tails d'impl√©mentation qui ne me plaisent pas. Le plus important pour moi est que les variables que nous utilisons sont fixes dans le code.

Disons, par exemple, que nous voulons changer le r√©pertoire o√π se trouvent nos solutions ou o√π nous stockons les cas de test. Nous devrions aller dans le script et changer la valeur de ces variables √† la main.

En cherchant une meilleure solution, j'ai pens√© qu'il serait pr√©f√©rable que les valeurs des variables dont nous avons besoin pour faire fonctionner notre script puissent √™tre pass√©es en arguments via la CLI. Comme je ne connais pas beaucoup le langage de script **shell**, j'ai d√©cid√© de cr√©er une alternative en utilisant **Python**.

Nous allons cr√©er un fichier `check.py` √† la racine de notre projet. Ce fichier contiendra une logique similaire √† celle de notre script shell, mais il inclura √©galement l'analyse des arguments de la CLI.

Pour analyser les arguments de la CLI en Python, je me tourne g√©n√©ralement vers la biblioth√®que **argparse**. Elle est suffisamment simple, et la [documentation](https://docs.python.org/3/library/argparse.html) est excellente. Elle vous aidera √† cr√©er des applications qui re√ßoivent des arguments de la console instantan√©ment.

Voyons un exemple de la fa√ßon dont une fonction qui analyse les arguments dont nous avons besoin pourrait ressembler :

```python
# check.py

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--test-cases", type=int, required=True)
    parser.add_argument("--generator-path", required=True)
    parser.add_argument("--solution-path", required=True)
    parser.add_argument("--naive-path", required=True)
    parser.add_argument("--tests-path", required=True)
    return parser.parse_args()

```

Comme vous pouvez le voir, pour que notre script fonctionne, nous devons sp√©cifier les valeurs des variables suivantes :

* `test-cases` : Le nombre de cas de test √† ex√©cuter.
* `generator-path` : Le chemin vers le fichier g√©n√©rateur.
* `solution-path` : Le chemin vers le fichier solution.
* `naive-path` : Le chemin vers le fichier de solution na√Øve.
* `tests-path` : R√©pertoire pour stocker les cas de test.

Apr√®s que toutes nos variables ont √©t√© analys√©es, nous devons appeler la fonction qui ex√©cutera le m√™me flux de travail que le script shell.

Pour obtenir ce comportement √† partir d'un script Python, j'ai utilis√© la biblioth√®que [**subprocess**](https://docs.python.org/3/library/subprocess.html), qui permet l'ex√©cution de commandes dans la console et redirige les entr√©es et les sorties. Pour les couleurs, j'ai utilis√© la biblioth√®que [**colorama**](https://pypi.org/project/colorama/).

Voici un exemple de la fa√ßon dont cette fonction pourrait ressembler :

```python
# check.py

def check(
    test_cases: int,
    generator_path: str,
    solution_path: str,
    naive_path: str,
    tests_path: str,
) -> bool:
    print(f"D√©marrage du stress testing avec {test_cases} cas de test(s)...")
    for i in range(1, test_cases + 1):
        # G√©n√©rer un cas de test al√©atoire
        with open(f"{tests_path}/input-{i}.in", "w", encoding="utf-8") as test_case:
            subprocess.run(["python3", generator_path], stdout=test_case)

        # Ouvrir le fichier d'entr√©e du cas de test
        with open(f"{tests_path}/input-{i}.in", "r", encoding="utf-8") as test_case:
            # Ex√©cuter la solution et stocker la sortie dans un fichier
            with open(f"{tests_path}/solution-{i}.out", "w", encoding="utf-8") as solution_file:
                test_case.seek(0)
                subprocess.run(["python3", solution_path], stdin=test_case, stdout=solution_file)

            # Ex√©cuter la solution na√Øve et stocker la sortie dans un fichier
            with open(f"{tests_path}/naive-{i}.out", "w", encoding="utf-8") as naive_file:
                test_case.seek(0)
                subprocess.run(["python3", naive_path], stdin=test_case, stdout=naive_file)

            # V√©rifier les diff√©rences dans les deux fichiers de sortie
            output = subprocess.run(
                ["diff", f"{tests_path}/solution-{i}.out", f"{tests_path}/naive-{i}.out"], stdout=subprocess.PIPE
            )

            # Code de retour diff√©rent de 0 signifie que les sorties diff√®rent
            if output.returncode == 0:
                print(f" ‚Ä¢ Cas de test {i}: {Fore.GREEN}OK!{Fore.WHITE}")
            else:
                print(f" ‚Ä¢ Cas de test {i}: {Fore.RED}Wrong Answer!{Fore.WHITE}")
                return False
    return True

```

Et notre fonction principale ressemblerait √† ceci :

```python
# check.py

def _main():
    args = parse_args()
    check(
        args.test_cases,
        args.generator_path,
        args.solution_path,
        args.naive_path,
        args.tests_path,
    )


if __name__ == "__main__":
    _main()

```

Pour ex√©cuter ce script, il est n√©cessaire de lancer la commande suivante √† la racine du projet :

```bash
python3 check.py --test-cases 100 --generator-path ./generators/random_generator.py --solution-path ./solutions/solution.py --naive-path ./solutions/naive.py --tests-path ./test_cases

```

Comme vous pouvez le voir, il est maintenant possible de modifier les valeurs des param√®tres √† partir de la CLI sans avoir √† affecter le code. Par exemple, nous pourrions augmenter le nombre de cas de test que nous voulons ex√©cuter √† `1000`.

Apr√®s avoir ex√©cut√© cette commande, nous obtenons la sortie suivante dans notre console :

![Image](https://cdn.hashnode.com/res/hashnode/image/upload/v1679251044695/6a0caecb-af93-4931-afb3-5a60c3a12034.png?auto=compress,format&format=webp)

Maintenant, il a √©chou√© au cas de test num√©ro `7`. Apr√®s avoir inspect√© le cas de test et corrig√© notre solution, nous devrions obtenir quelque chose comme ceci :

![Image](https://cdn.hashnode.com/res/hashnode/image/upload/v1679251236382/098fd63c-ec63-4c58-88b7-6ee12427653b.png?auto=compress,format&format=webp)

## **Conclusions**

Dans cet article, nous avons appris comment cr√©er un outil automatis√© pour tester nos solutions contre des cas de test g√©n√©r√©s al√©atoirement. Nous avons automatis√© le processus en utilisant un script **shell** puis nous avons fait une version **Python**, en utilisant des biblioth√®ques telles que **argparse** et **subprocess**.

Pouvoir trouver des contre-tests pour vos solutions est un aspect crucial du d√©veloppement de logiciels. Bien que ce soit un exemple √©ducatif et simple, il pr√©sente de multiples similitudes avec des cas r√©els. Essayez cela et faites-moi savoir vos r√©flexions √† ce sujet !

De plus, j'aimerais continuer √† am√©liorer cet outil un peu, mais je n'ai pas beaucoup de temps pour le faire seul. Il serait formidable d'avoir quelques contributeurs sur le d√©p√¥t GitHub o√π je garde le code utilis√© dans cet article. J'ai commenc√© √† √©crire quelques am√©liorations possibles. Contactez-moi si vous voulez collaborer √† cela.

√Ä bient√¥t !

### Sources

* Les exemples de code utilis√©s dans cet article peuvent √™tre trouv√©s [ici](https://github.com/albexl/stress-tester).
* [Stress Testing](https://en.wikipedia.org/wiki/Stress_testing_(software)) : Article de Wikipedia sur le stress testing dans les logiciels.
* [How to test your solution in Competitive Programming](https://www.youtube.com/watch?v=JXTVOyQpSGM&t=1317s) par Kamil Debowski : Vid√©o YouTube expliquant certains des sujets discut√©s, avec des exemples de code en C++.

üëã Bonjour, je suis Alberto, **D√©veloppeur de Logiciels chez** [**doWhile**](https://dowhile.se/), Programmeur Comp√©titif, Enseignant et Passionn√© de Fitness.

üèÜ Si vous avez aim√© cet article, envisagez de le partager.

üîó [**Tous les liens**](https://bio.link/albexl) | [**Twitter**](https://twitter.com/albe_xl) | [**LinkedIn**](https://www.linkedin.com/in/albexl/)