---
title: 'Apprendre Kubernetes en moins de 3 heures : Un guide d√©taill√© pour orchestrer
  des conteneurs'
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2018-04-14T19:10:07.000Z'
originalURL: https://freecodecamp.org/news/learn-kubernetes-in-under-3-hours-a-detailed-guide-to-orchestrating-containers-114ff420e882
coverImage: https://cdn-media-1.freecodecamp.org/images/1*0ju9JOPACF90yXSi-s2gwQ.jpeg
tags:
- name: Devops
  slug: devops
- name: Docker
  slug: docker
- name: Java
  slug: java
- name: Kubernetes
  slug: kubernetes
- name: Web Development
  slug: web-development
seo_title: 'Apprendre Kubernetes en moins de 3 heures : Un guide d√©taill√© pour orchestrer
  des conteneurs'
seo_desc: 'By Rinor Maloku

  Why are banks paying me big bucks for something as simple as Kubernetes? When anybody
  ‚Äî anybody can learn in under three hours?

  If you doubt me, I challenge you to give it a try! By the end of this article, you
  will be able to run a M...'
---

Par Rinor Maloku

Pourquoi les banques me paient-elles des sommes importantes pour quelque chose d'aussi simple que Kubernetes ? Alors que n'importe qui ‚Äî n'importe qui peut l'apprendre en moins de trois heures ?

Si vous me doutez, je vous mets au d√©fi d'essayer ! √Ä la fin de cet article, vous serez capable de faire tourner une application bas√©e sur des microservices sur un cluster Kubernetes. Et je vous le garantis parce que c'est ainsi que je pr√©sente Kubernetes √† nos clients.

_Qu'est-ce que ce guide fait de diff√©rent par rapport aux autres ressources, Rinor ?_

Beaucoup de choses ! La plupart des guides commencent par les bases : les concepts de Kubernetes et les commandes kubectl. Ces guides supposent que le lecteur conna√Æt le d√©veloppement d'applications, les microservices et les conteneurs Docker.

Dans cet article, nous allons passer par :

1. Faire tourner une application bas√©e sur des microservices sur votre ordinateur.
2. Construire des images de conteneurs pour chaque service de l'application de microservices.
3. Introduction √† Kubernetes. D√©ployer une application bas√©e sur des microservices dans un cluster Kubernetes g√©r√©.

La construction progressive fournit la profondeur n√©cessaire pour qu'un simple mortel puisse saisir la _simplicit√©_ de Kubernetes. Oui, Kubernetes est simple lorsque vous connaissez le contexte dans lequel il est utilis√©. Sans plus attendre, voyons ce que nous allons construire.

### D√©monstration de l'application

L'application a une seule fonctionnalit√©. Elle prend une phrase en entr√©e. En utilisant l'analyse de texte, elle calcule l'√©motion de la phrase.

![Image](https://cdn-media-1.freecodecamp.org/images/Rl5B3SRE5U5IiIM-8-1HnZdnwMx1TzegzV3D)
_Fig. 1. Application Web d'analyse de sentiment_

D'un point de vue technique, l'application se compose de trois microservices. Chacun a une fonctionnalit√© sp√©cifique :

* **SA-Frontend** : un serveur web Nginx qui **sert nos fichiers statiques ReactJS**.
* **SA-WebApp** : une application web Java qui **g√®re les requ√™tes** du frontend.
* **SA-Logic** : une application Python qui **effectue l'analyse de sentiment**.

Il est important de savoir que les microservices ne vivent pas en isolation, ils permettent une "s√©paration des pr√©occupations" mais ils doivent **toujours** interagir les uns avec les autres.

![Image](https://cdn-media-1.freecodecamp.org/images/JwIBwPsTfBmelKgSrCCkEZuTzC5Ty1pZi3K7)
_Fig. 2. Flux de donn√©es dans l'application Web d'analyse de sentiment_

Cette interaction est mieux illustr√©e en montrant comment les donn√©es circulent entre eux :

1. Une application cliente demande le fichier index.html (qui √† son tour demande les scripts regroup√©s de l'application ReactJS)
2. L'utilisateur interagissant avec l'application d√©clenche des requ√™tes vers l'application Spring WebApp.
3. Spring WebApp transmet les requ√™tes pour l'analyse de sentiment √† l'application Python.
4. L'application Python calcule le sentiment et retourne le r√©sultat en tant que r√©ponse.
5. Spring WebApp retourne la r√©ponse √† l'application React. (Qui repr√©sente ensuite l'information √† l'utilisateur.)

Le code pour toutes ces applications peut √™tre trouv√© dans [ce d√©p√¥t](https://github.com/rinormaloku/k8s-mastery). Je recommande de le cloner imm√©diatement car nous allons construire des choses incroyables ensemble.

### 1. Faire tourner une application bas√©e sur des microservices sur votre ordinateur

Nous devons d√©marrer les trois services. Commen√ßons par le plus attrayant, l'application frontend.

#### Configuration de React pour le d√©veloppement local

Pour d√©marrer l'application React, vous devez avoir NodeJS et NPM install√©s sur votre ordinateur. Apr√®s avoir install√© ceux-ci, naviguez avec votre terminal vers le r√©pertoire **sa-frontend**. Tapez la commande suivante :

```bash
npm install
```

Cela t√©l√©charge toutes les d√©pendances JavaScript de l'application React et les place dans le dossier **node_modules**. (Les d√©pendances sont d√©finies dans le fichier package.json). Apr√®s que toutes les d√©pendances soient r√©solues, ex√©cutez la commande suivante :

```bash
npm start
```

C'est tout ! Nous avons d√©marr√© notre application React et par d√©faut vous pouvez y acc√©der sur **localhost:3000**. N'h√©sitez pas √† modifier le code et √† voir les effets imm√©diatement sur le navigateur. Cela est rendu possible gr√¢ce au **Hot Module Replacement**. Cela rend le d√©veloppement frontend tr√®s facile !

#### Pr√©parer notre application React pour la production

Pour la production, nous devons construire notre application en fichiers statiques et les servir √† l'aide d'un serveur web.

Pour construire l'application React, naviguez dans votre terminal vers le r√©pertoire **sa-frontend**. Ensuite, ex√©cutez la commande suivante :

```bash
npm run build
```

Cela g√©n√®re un dossier nomm√© **build** dans votre arborescence de projet. Ce dossier contient tous les fichiers statiques n√©cessaires pour notre application ReactJS.

#### Servir des fichiers statiques avec Nginx

Installez et d√©marrez le serveur web Nginx ([comment faire](https://www.nginx.com/resources/wiki/start/topics/tutorials/install/)). Ensuite, d√©placez le contenu du dossier sa-frontend/build vers [_votre_r√©pertoire_d'installation_nginx_]/**html**.

De cette fa√ßon, le fichier index.html g√©n√©r√© sera accessible dans [_votre_r√©pertoire_d'installation_nginx_]/html/index.html. **C'est le fichier par d√©faut que Nginx sert**.

Par d√©faut, le serveur web Nginx √©coute sur le port 80. Vous pouvez sp√©cifier un port diff√©rent en mettant √† jour la propri√©t√© server.listen dans le fichier [_votre_r√©pertoire_d'installation_nginx_]/conf/nginx.conf.

Ouvrez votre navigateur et acc√©dez √† l'endpoint localhost:80, voyez l'application ReactJS appara√Ætre.

![Image](https://cdn-media-1.freecodecamp.org/images/EOcacd0QABnXiFAXVHPpWcD9scHzvr7jq0Fp)
_Fig. 3. Application React servie depuis Nginx_

En tapant dans le champ : ¬´ Tapez votre phrase. ¬ª et en appuyant sur le bouton Envoyer, cela √©chouera avec une erreur 404 (Vous pouvez la v√©rifier dans la console de votre navigateur). Mais pourquoi cela ? Inspectons le code.

#### Inspection du code

Dans le fichier **App.js**, nous pouvons voir que l'appui sur le bouton Envoyer d√©clenche la m√©thode analyzeSentence. Le code de cette m√©thode est montr√© ci-dessous. (Chaque ligne comment√©e avec #Num√©ro sera expliqu√©e sous le script) :

```js
analyzeSentence() {
    fetch('http://localhost:8080/sentiment', {  // #1
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
                       sentence: this.textField.getValue()})// #2
    })
        .then(response => response.json())
        .then(data => this.setState(data));  // #3
}
```

#1 : URL √† laquelle un appel POST est effectu√©. (Une application doit √©couter les appels √† cette URL).

#2 : Le corps de la requ√™te envoy√© √† cette application tel qu'affich√© ci-dessous :

```
{
    sentence: "J'aime yogobella !"
}
```

#3 : La r√©ponse met √† jour l'√©tat du composant. Cela d√©clenche un nouveau rendu du composant. Si nous avons re√ßu les donn√©es, (c'est-√†-dire l'objet JSON contenant la phrase tap√©e et la polarit√©) nous afficherons le composant polarityComponent car la condition sera remplie et nous d√©finirons le composant :

```js
const polarityComponent = this.state.polarity !== undefined ?
    <Polarity sentence={this.state.sentence} 
              polarity={this.state.polarity}/> :
    null;
```

Tout semble correct. Mais qu'est-ce qui nous manque ? Si vous avez devin√© que nous n'avons rien configur√© pour √©couter sur localhost:8080, alors vous avez raison ! Nous devons d√©marrer notre application Spring Web pour qu'elle √©coute sur ce port !

![Image](https://cdn-media-1.freecodecamp.org/images/KNFf142A66wPteChS7IQmcZA8ohQTZRA8U7E)
_Fig. 4. Microservice Spring WebApp manquant_

#### Configuration de l'application web Spring

Pour d√©marrer l'application Spring, vous devez avoir JDK8 et Maven install√©s. (leurs variables d'environnement doivent √©galement √™tre configur√©es). Apr√®s avoir install√© ceux-ci, vous pouvez continuer √† la partie suivante.

#### Emballage de l'application dans un Jar

Naviguez dans votre terminal vers le r√©pertoire **sa-webapp** et tapez la commande suivante :

```
mvn install
```

Cela g√©n√©rera un dossier nomm√© **target**, dans le r√©pertoire **sa-webapp**. Dans le dossier **target**, nous avons notre application Java emball√©e dans un jar : '**sentiment-analysis-web-0.0.1-SNAPSHOT.jar**'

#### D√©marrage de notre application Java

Naviguez vers le r√©pertoire target et d√©marrez l'application avec la commande :

```bash
java -jar sentiment-analysis-web-0.0.1-SNAPSHOT.jar
```

Zut... Nous avons une erreur. Notre application √©choue au d√©marrage et notre seule piste est l'exception dans la trace de la pile :

```bash
Error creating bean with name 'sentimentController': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'sa.logic.api.url' in value "${sa.logic.api.url}"
```

L'information importante ici est le placeholder sa.logic.api.url dans le **SentimentController**. V√©rifions cela !

### Inspection du code

```java
@CrossOrigin(origins = "*")
@RestController
public class SentimentController {

    @Value("${sa.logic.api.url}")    // #1
    private String saLogicApiUrl;
    
    @PostMapping("/sentiment")
    public SentimentDto sentimentAnalysis(
        @RequestBody SentenceDto sentenceDto) 
    {
        RestTemplate restTemplate = new RestTemplate();
        
        return restTemplate.postForEntity(
                saLogicApiUrl + "/analyse/sentiment",    // #2
                sentenceDto, SentimentDto.class)
                .getBody();
    }
}
```

1. Le **SentimentController** a un champ nomm√© saLogicApiUrl. Le champ est d√©fini par la propri√©t√© `sa.logic.api.url`.
2. La cha√Æne saLogicApiUrl est concat√©n√©e avec la valeur "/analyse/sentiment". Ensemble, elles forment l'URL pour faire la requ√™te d'analyse de sentiment.

**D√©finition de la propri√©t√©**

Dans Spring, la source de propri√©t√© par d√©faut est **application.properties**. (Situ√© dans _sa-webapp/src/main/resources_). Mais ce n'est pas le seul moyen de d√©finir une propri√©t√©, cela peut √©galement √™tre fait avec la commande pr√©c√©dente :

```bash
java -jar sentiment-analysis-web-0.0.1-SNAPSHOT.jar 
     --sa.logic.api.url=WHAT.IS.THE.SA.LOGIC.API.URL
```

La propri√©t√© doit √™tre initialis√©e avec la valeur qui d√©finit o√π notre application Python est en cours d'ex√©cution, de cette fa√ßon nous permettrons √† notre application Spring Web de savoir o√π transf√©rer les messages √† l'ex√©cution.

Pour simplifier les choses, d√©cidons que nous allons ex√©cuter l'application Python sur `localhost:5000`. N'oublions pas cela !

Ex√©cutez la commande ci-dessous et nous sommes pr√™ts √† passer au dernier service, l'application Python.

```
java -jar sentiment-analysis-web-0.0.1-SNAPSHOT.jar 
     --sa.logic.api.url=http://localhost:5000
```

![Image](https://cdn-media-1.freecodecamp.org/images/gRyXOa3fibWNB7s1DJiu31nB0ziy38FjCWe5)

#### Configuration de l'application Python

Pour d√©marrer l'application Python, nous devons avoir Python3 et Pip install√©s. (Leurs variables d'environnement doivent √©galement √™tre configur√©es).

#### Installation des d√©pendances

Naviguez dans le terminal vers le r√©pertoire **sa-logic/sa** ([d√©p√¥t](https://github.com/rinormaloku/k8s-mastery)) et tapez la commande suivante :

```bash
python -m pip install -r requirements.txt
python -m textblob.download_corpora
```

#### D√©marrage de l'application

Apr√®s avoir utilis√© Pip pour installer les d√©pendances, nous sommes pr√™ts √† d√©marrer l'application en ex√©cutant la commande suivante :

```bash
python sentiment_analysis.py
* Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
```

Cela signifie que notre application est en cours d'ex√©cution et √©coute les requ√™tes HTTP sur le port 5000 sur localhost.

#### Inspection du code

Investiguons le code pour comprendre ce qui se passe dans l'application Python **SA Logic**.

```py
from textblob import TextBlob
from flask import Flask, request, jsonify

app = Flask(__name__)                                   #1

@app.route("/analyse/sentiment", methods=['POST'])      #2
def analyse_sentiment():
    sentence = request.get_json()['sentence']           #3
    polarity = TextBlob(sentence).sentences[0].polarity #4
    return jsonify(                                     #5
        sentence=sentence,
        polarity=polarity
    )
    
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)                #6
```

1. Instancie un objet Flask.
2. D√©finit le chemin auquel une requ√™te POST peut √™tre faite.
3. Extrait la propri√©t√© "sentence" du corps de la requ√™te.
4. Instancie un objet TextBlob anonyme et obtient la polarit√© de la premi√®re phrase. (Nous n'en avons qu'une seule).
5. Retourne la r√©ponse avec le corps contenant la phrase et la polarit√© √† l'appelant.
6. Ex√©cute l'objet flask **app** pour √©couter les requ√™tes sur 0.0.0.0:5000 (les appels √† localhost:5000 atteindront √©galement cette application).

**Les services sont configur√©s pour communiquer entre eux. R√©ouvrez le frontend sur localhost:80 et essayez-les avant de continuer !**

![Image](https://cdn-media-1.freecodecamp.org/images/Wfr68VDVe8eOlB0Z9sM8sunj60L7UZD1Hu9v)
_Fig. 6. Architecture de microservices compl√©t√©e_

Dans la section suivante, nous verrons comment d√©marrer les services dans des conteneurs Docker, car c'est un pr√©alable pour pouvoir les ex√©cuter dans un cluster Kubernetes.

### 2. Construction d'images de conteneurs pour chaque service

Kubernetes est un orchestrateur de conteneurs. Compr√©hensiblement, nous avons besoin de conteneurs pour pouvoir les orchestrer. Mais qu'est-ce que les conteneurs ? Cela est mieux r√©pondu par la documentation de Docker.

> _Une image de conteneur est un package l√©ger, autonome et ex√©cutable d'un logiciel qui inclut tout ce dont il a besoin pour fonctionner : code, runtime, outils syst√®me, biblioth√®ques syst√®me, param√®tres. Disponible pour les applications bas√©es sur Linux et Windows, un logiciel conteneuris√© fonctionnera toujours de la m√™me mani√®re, ind√©pendamment de l'environnement._

Cela signifie que les conteneurs peuvent fonctionner sur n'importe quel ordinateur ‚Äî m√™me sur le serveur de production ‚Äî **sans aucune diff√©rence**.

√Ä des fins d'illustration, comparons comment notre application React serait servie en utilisant une machine virtuelle par rapport √† un conteneur.

#### Servir des fichiers statiques React depuis une VM

Les inconv√©nients de l'utilisation d'une machine virtuelle :

1. Inefficace en ressources, chaque VM a le surco√ªt d'un syst√®me d'exploitation complet.
2. Elle est d√©pendante de la plateforme. Ce qui fonctionnait sur votre ordinateur pourrait ne pas fonctionner sur le serveur de production.
3. Lourd et lent √† mettre √† l'√©chelle par rapport aux conteneurs.

![Image](https://cdn-media-1.freecodecamp.org/images/vP3JZyOygXDzTh7I650wZHtHWkv56ioduUJS)
_Fig. 7. Serveur web Nginx avec des fichiers statiques sur une VM_

#### Servir des fichiers statiques React depuis un conteneur

Les avantages de l'utilisation d'un conteneur.

1. Efficace en ressources, utilise le syst√®me d'exploitation h√¥te avec l'aide de Docker.
2. Ind√©pendant de la plateforme. Le conteneur que vous ex√©cutez sur votre ordinateur fonctionnera partout.
3. L√©ger en utilisant des couches d'images.

![Image](https://cdn-media-1.freecodecamp.org/images/6I9ZEnnQNMqeTCK8kRWoOjDucfLCJqjAUGWd)
_Fig. 8. Serveur web Nginx servant des fichiers statiques dans un conteneur_

Ce sont les caract√©ristiques et avantages les plus importants de l'utilisation de conteneurs. Pour plus d'informations, continuez √† lire la [documentation Docker](https://www.docker.com/what-container).

#### Construction de l'image de conteneur pour l'application React (Introduction √† Docker)

Le bloc de construction de base pour un conteneur Docker est le .dockerfile. Le **Dockerfile** commence avec une image de conteneur de base et suit avec une s√©quence d'instructions sur la fa√ßon de construire une nouvelle image de conteneur qui r√©pond aux besoins de votre application.

Avant de commencer √† d√©finir le Dockerfile, rappelons les √©tapes que nous avons suivies pour servir les fichiers statiques React en utilisant Nginx :

1. Construire les fichiers statiques (npm run build)
2. D√©marrer le serveur Nginx
3. Copier le contenu du dossier **build** de votre projet sa-frontend vers nginx**/**html.

Dans la section suivante, vous remarquerez des parall√®les sur la fa√ßon dont la cr√©ation d'un conteneur est similaire √† ce que nous avons fait pendant la configuration locale de React.

#### D√©finition du Dockerfile pour SA-Frontend

Les instructions dans le Dockerfile pour le SA-Frontend ne sont qu'une t√¢che en deux √©tapes. C'est parce que l'√©quipe Nginx nous a fourni [une image de base](https://hub.docker.com/_/nginx/) pour Nginx, que nous allons utiliser pour construire par-dessus. Les deux √©tapes sont :

1. Commencer par l'image de base **Nginx**
2. Copier le r√©pertoire **sa-frontend/build** vers le r√©pertoire nginx**/**html du conteneur.

Converti en un Dockerfile, cela ressemble √† :

```docker
FROM nginx
COPY build /usr/share/nginx/html
```

N'est-ce pas incroyable, c'est m√™me lisible par un humain, faisons un r√©capitulatif :

Commencez par l'image nginx. (Quoi que les gars aient fait l√†-bas). Copiez le r√©pertoire **build** vers le r√©pertoire **nginx/html** dans l'image. C'est tout !

Vous vous demandez peut-√™tre comment j'ai su o√π copier les fichiers de construction ? c'est-√†-dire `/usr/share/nginx/html`. Tr√®s simple : C'√©tait document√© dans l'image [nginx](https://hub.docker.com/_/nginx/) dans Docker Hub.

#### Construction et envoi du conteneur

Avant de pouvoir envoyer notre image, nous avons besoin d'un registre de conteneurs pour h√©berger nos images. Docker Hub est un service cloud de conteneurs gratuit que nous utiliserons pour cette d√©monstration. Vous avez trois t√¢ches √† accomplir avant de continuer :

1. [Installer Docker CE](https://www.docker.com/community-edition)
2. Vous inscrire sur Docker Hub.
3. Vous connecter en ex√©cutant la commande suivante dans votre terminal :

```bash
docker login -u="$DOCKER_USERNAME" -p="$DOCKER_PASSWORD"
```

Apr√®s avoir termin√© les t√¢ches ci-dessus, naviguez vers le r√©pertoire **sa-frontend**. Ensuite, ex√©cutez la commande suivante (remplacez $DOCKER_USER_ID par votre nom d'utilisateur Docker Hub. Par exemple, rinormaloku/sentiment-analysis-frontend)

```
docker build -f Dockerfile -t $DOCKER_USER_ID/sentiment-analysis-frontend .
```

Nous pouvons supprimer `-f Dockerfile` car nous sommes d√©j√† dans le r√©pertoire contenant le Dockerfile.

Pour envoyer l'image, utilisez la commande docker push :

```
docker push $DOCKER_USER_ID/sentiment-analysis-frontend
```

V√©rifiez dans votre d√©p√¥t Docker Hub que l'image a √©t√© envoy√©e avec succ√®s.

#### Ex√©cution du conteneur

Maintenant, l'image dans `$DOCKER_USER_ID/sentiment-analysis-frontend` peut √™tre t√©l√©charg√©e et ex√©cut√©e par n'importe qui :

```bash
docker pull $DOCKER_USER_ID/sentiment-analysis-frontend
docker run -d -p 80:80 $DOCKER_USER_ID/sentiment-analysis-frontend
```

Notre conteneur Docker est en cours d'ex√©cution !

Avant de continuer, expliquons le 80:80 que je trouve d√©routant :

* Le premier 80 est le port de l'h√¥te (c'est-√†-dire mon ordinateur)
* Le second 80 repr√©sente le port du conteneur vers lequel les appels doivent √™tre transf√©r√©s.

![Image](https://cdn-media-1.freecodecamp.org/images/uUv5pZc6QErqJVcacC0vU-QEvjDjVF1VlQ9l)
_Fig. 9. Mappage de port de l'h√¥te vers le conteneur_

Il mappe de <hostPort> vers <containerPort>. Cela signifie que les appels au port 80 de l'h√¥te doivent √™tre mapp√©s au port 80 du conteneur, comme le montre la figure 9.

Parce que le port a √©t√© ex√©cut√© sur l'h√¥te (votre ordinateur) sur le port 80, il doit √™tre accessible sur localhost:80. Si vous n'avez pas de support natif pour Docker, vous pouvez ouvrir l'application sur <ip de la machine docker>:80. Pour trouver l'ip de votre machine docker, ex√©cutez docker-machine ip

Essayez-le ! Vous devriez pouvoir acc√©der √† l'application React √† cette adresse.

#### Le Dockerignore

Nous avons vu pr√©c√©demment que la construction de l'image pour SA-Frontend √©tait lente, pardonnez-moi, **extr√™mement lente**. C'√©tait le cas √† cause du **contexte de construction** qui devait √™tre envoy√© au d√©mon Docker. Plus en d√©tail, le r√©pertoire **contexte de construction** est d√©fini par le dernier argument dans la commande docker build (le point final), qui sp√©cifie le contexte de construction. Et dans notre cas, il incluait les dossiers suivants :

```bash
sa-frontend:
|   .dockerignore
|   Dockerfile
|   package.json
|   README.md
+---build
+---node_modules
+---public
\---src
```

Mais les seules donn√©es dont nous avons besoin se trouvent dans le dossier **build**. T√©l√©charger autre chose serait une perte de temps. Nous pouvons am√©liorer notre temps de construction en supprimant les autres r√©pertoires. C'est l√† que `.dockerignore` entre en jeu. Pour vous, cela sera familier car c'est comme `.gitignore`, c'est-√†-dire ajouter tous les r√©pertoires que vous souhaitez ignorer dans le fichier `.dockerignore`, comme montr√© ci-dessous :

```bash
node_modules
src
public
```

Le fichier `.dockerignore` doit √™tre dans le m√™me dossier que le Dockerfile. Maintenant, la construction de l'image ne prend que quelques secondes.

Continuons avec l'application Java.

#### Construction de l'image de conteneur pour l'application Java

Devinez quoi ! Vous avez appris presque tout sur la cr√©ation d'images de conteneurs ! C'est pourquoi cette partie est extr√™mement courte.

Ouvrez le Dockerfile dans **sa-webapp**, et vous trouverez seulement deux nouveaux mots-cl√©s :

```docker
ENV SA_LOGIC_API_URL http://localhost:5000

EXPOSE 8080
```

Le mot-cl√© **ENV** d√©clare une variable d'environnement √† l'int√©rieur du conteneur Docker. Cela nous permettra de fournir l'URL pour l'API d'analyse de sentiment lors du d√©marrage du conteneur.

De plus, le mot-cl√© **EXPOSE** expose un port que nous voulons acc√©der plus tard. **Mais attendez !!!** Nous ne l'avons pas fait dans le Dockerfile de SA-Frontend, bonne prise ! Cela sert uniquement √† des fins de documentation, en d'autres termes, cela servira d'information √† la personne lisant le Dockerfile.

Vous devriez √™tre familier avec la construction et l'envoi de l'image du conteneur. Si des difficult√©s surviennent, lisez le fichier README.md dans le r√©pertoire **sa-webapp**.

#### Construction de l'image de conteneur pour l'application Python

Dans le Dockerfile dans **sa-logic**, il n'y a pas de nouveaux mots-cl√©s. Maintenant, vous pouvez vous appeler un Docker-Master ?.

Pour construire et envoyer l'image de conteneur, lisez le README.md dans le r√©pertoire **sa-logic**.

#### Test de l'application conteneuris√©e

Pouvez-vous faire confiance √† quelque chose que vous n'avez pas test√© ? Moi non plus. Testons ces conteneurs.

1. Ex√©cutez le conteneur **sa-logic** et configurez-le pour √©couter sur le port 5050 :

```
docker run -d -p 5050:5000 $DOCKER_USER_ID/sentiment-analysis-logic
```

2. Ex√©cutez le conteneur **sa-webapp** et configurez-le pour √©couter sur le port 8080, et en plus, nous devons changer le port sur lequel l'application Python √©coute en rempla√ßant la variable d'environnement SA_LOGIC_API_URL.

```
$ docker run -d -p 8080:8080 -e SA_LOGIC_API_URL='http://<container_ip or docker machine ip>:5000' $DOCKER_USER_ID/sentiment-analysis-web-app
```

Consultez le [README](https://github.com/rinormaloku/k8s-mastery/blob/master/sa-webapp/README.md) pour savoir comment obtenir l'ip du conteneur ou l'ip de la machine docker.

3. Ex√©cutez le conteneur **sa-frontend** :

```bash
docker run -d -p 80:80 $DOCKER_USER_ID/sentiment-analysis-frontend
```

Nous avons termin√©. Ouvrez votre navigateur sur **localhost:80**.

**Attention** : Si vous avez chang√© le port pour le sa-webapp, ou si vous utilisez l'ip de la machine docker, vous devez mettre √† jour le fichier App.js dans **sa-frontend** dans la m√©thode analyzeSentence pour r√©cup√©rer depuis la nouvelle IP ou le nouveau port. Ensuite, vous devez construire et utiliser l'image mise √† jour.

![Image](https://cdn-media-1.freecodecamp.org/images/gdDm95hkRv-AnNmuHUFDIONucxEWcvXN1p34)
_Fig. 10. Microservices s'ex√©cutant dans des conteneurs_

#### Casse-t√™te üß† ‚Äî Pourquoi Kubernetes ?

Dans cette section, nous avons appris √† conna√Ætre le Dockerfile, comment l'utiliser pour construire une image, et les commandes pour la pousser vers le registre Docker. De plus, nous avons √©tudi√© comment r√©duire le nombre de fichiers envoy√©s au contexte de construction en ignorant les fichiers inutiles. Et √† la fin, nous avons fait fonctionner l'application √† partir de conteneurs. Alors pourquoi Kubernetes ? Nous approfondirons cela dans le prochain article, mais je veux vous laisser un casse-t√™te.

* Notre application web d'analyse de sentiment est devenue un succ√®s mondial et nous avons soudainement un million de requ√™tes par minute pour analyser les sentiments et nous subissons une √©norme charge sur **sa-webapp** et **sa-logic**. Comment pouvons-nous mettre √† l'√©chelle les conteneurs ?

### Introduction √† Kubernetes

Je promets et je n'exag√®re pas qu'√† la fin de l'article vous vous demanderez ¬´ Pourquoi ne l'appelons-nous pas Supernetes ? ¬ª.

![Image](https://cdn-media-1.freecodecamp.org/images/6z5-sOpVzRF1YeB2kQzrXakp2kBiGDBlMx4t)
_Fig. 11. Supernetes_

Si vous avez suivi cet article depuis le d√©but, nous avons couvert beaucoup de terrain et beaucoup de connaissances. Vous pourriez vous inqui√©ter que ce sera la partie la plus difficile, mais c'est la plus simple. La seule raison pour laquelle l'apprentissage de Kubernetes est intimidant est √† cause du ¬´ tout le reste ¬ª et nous avons couvert cela si bien.

### Qu'est-ce que Kubernetes

Apr√®s avoir d√©marr√© nos microservices √† partir de conteneurs, nous avions une question, √©laborons-la davantage dans un format Q&R :  
**Q :** Comment mettons-nous √† l'√©chelle les conteneurs ?  
**A :** Nous en d√©marrons un autre.  
**Q :** Comment partageons-nous la charge entre eux ? Que faire si le serveur est d√©j√† utilis√© au maximum et que nous avons besoin d'un autre serveur pour notre conteneur ? Comment calculons-nous la meilleure utilisation du mat√©riel ?  
**A :** Ahm‚Ä¶ Ermm‚Ä¶ (Laissez-moi chercher sur Google).  
**Q :** D√©ployer des mises √† jour sans rien casser ? Et si nous le faisons, comment pouvons-nous revenir √† la version fonctionnelle.

Kubernetes r√©sout toutes ces questions (et plus encore !). Ma tentative de r√©duire Kubernetes en une phrase serait : ¬´ Kubernetes est un orchestrateur de conteneurs, qui abstrait l'infrastructure sous-jacente. (O√π les conteneurs sont ex√©cut√©s) ¬ª.

Nous avons une vague id√©e de l'orchestration de conteneurs. Nous allons la voir en pratique dans la suite de cet article, mais c'est la premi√®re fois que nous lisons sur ¬´ l'abstraction de l'infrastructure sous-jacente ¬ª. Alors prenons un gros plan, sur celui-ci.

#### Abstraction de l'infrastructure sous-jacente

Kubernetes abstrait l'infrastructure sous-jacente en nous fournissant une API simple √† laquelle nous pouvons envoyer des requ√™tes. Ces requ√™tes incitent Kubernetes √† les satisfaire au mieux de ses capacit√©s. Par exemple, c'est aussi simple que de demander ¬´ Kubernetes, d√©marrez 4 conteneurs de l'image x ¬ª. Ensuite, Kubernetes trouvera des n≈ìuds sous-utilis√©s dans lesquels il d√©marrera les nouveaux conteneurs (voir Fig. 12.).

![Image](https://cdn-media-1.freecodecamp.org/images/oRhjNBu9XyT74V6dxJVs1YJhgoC2eMU8TsCX)
_Fig. 12. Requ√™te au serveur API_

Qu'est-ce que cela signifie pour le d√©veloppeur ? Qu'il n'a pas √† se soucier du nombre de n≈ìuds, de l'endroit o√π les conteneurs sont d√©marr√©s et de la mani√®re dont ils communiquent. Il ne traite pas de l'optimisation du mat√©riel ou ne s'inqui√®te pas de la panne des n≈ìuds (et ils tomberont en panne, _loi de Murphy_), car de nouveaux n≈ìuds peuvent √™tre ajout√©s au cluster Kubernetes. Pendant ce temps, Kubernetes d√©marrera les conteneurs dans les autres n≈ìuds qui sont encore en cours d'ex√©cution. Il le fait au mieux de ses capacit√©s.

Dans la figure 12, nous pouvons voir quelques nouvelles choses :

* **Serveur API** : Notre seule fa√ßon d'interagir avec le cluster. Que ce soit pour d√©marrer ou arr√™ter un autre conteneur (err *pods) ou v√©rifier l'√©tat actuel, les logs, etc.
* **Kubelet** : surveille les conteneurs (err *pods) √† l'int√©rieur d'un n≈ìud et communique avec le n≈ìud ma√Ætre.
* ***Pods** : Au d√©but, pensez simplement aux pods comme des conteneurs.

Et nous nous arr√™terons ici, car plonger plus profond√©ment ne ferait que rel√¢cher notre concentration et nous pouvons toujours le faire plus tard, il y a des ressources utiles pour apprendre, comme la documentation officielle (la mani√®re difficile) ou lire le livre incroyable [Kubernetes in Action](https://www.amazon.com/Kubernetes-Action-Marko-Luksa/dp/1617293725), de [Marko Luk≈°a](https://twitter.com/markoluksa).

#### Standardisation des fournisseurs de services cloud

Un autre point fort que Kubernetes met en avant, c'est qu'il standardise les fournisseurs de services cloud (CSP). C'est une d√©claration audacieuse, mais √©laborons avec un exemple :

‚Äî Un expert en Azure, Google Cloud Platform ou un autre CSP se retrouve √† travailler sur un projet dans un tout nouveau CSP, et il n'a aucune exp√©rience de travail avec celui-ci. Cela peut avoir de nombreuses cons√©quences, pour en nommer quelques-unes : il peut manquer la date limite ; l'entreprise pourrait avoir besoin d'embaucher plus de ressources, et ainsi de suite.

En revanche, avec Kubernetes, ce n'est pas un probl√®me du tout. Parce que vous ex√©cuterez les m√™mes commandes vers le serveur API, quel que soit le CSP. Vous demandez de mani√®re d√©clarative au serveur API **ce que vous voulez**. Kubernetes abstrait et impl√©mente le **comment** pour le CSP en question.

Prenez un instant pour r√©fl√©chir ‚Äî c'est une fonctionnalit√© extr√™mement puissante. Pour l'entreprise, cela signifie qu'elles ne sont pas li√©es √† un CSP. Elles calculent leurs d√©penses sur un autre CSP, et elles passent √† autre chose. Elles auront toujours l'expertise, elles auront toujours les ressources, et elles peuvent le faire pour _moins cher !_

Tout cela dit, dans la section suivante, nous mettrons Kubernetes en pratique.

### Kubernetes en pratique ‚Äî Pods

Nous avons configur√© les microservices pour qu'ils s'ex√©cutent dans des conteneurs et c'√©tait un processus fastidieux, mais cela a fonctionn√©. Nous avons √©galement mentionn√© que cette solution n'est pas √©volutive ou r√©siliente et que Kubernetes r√©sout ces probl√®mes. Dans la suite de cet article, nous migrerons nos services vers le r√©sultat final comme le montre la figure 13, o√π les conteneurs sont orchestr√©s par Kubernetes.

![Image](https://cdn-media-1.freecodecamp.org/images/mrA3VBYh2pbG7qH9wnsMj-QxRxZ2MAqA5oTt)
_Fig. 13. Microservices s'ex√©cutant dans un cluster g√©r√© par Kubernetes_

Dans cet article, nous utiliserons Minikube pour le d√©bogage local, bien que tout ce qui sera pr√©sent√© fonctionne √©galement dans Azure et dans Google Cloud Platform.

### Installation et d√©marrage de Minikube

Suivez la documentation officielle pour installer [Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/). Lors de l'installation de Minikube, vous installerez √©galement **Kubectl**. Il s'agit d'un client pour faire des requ√™tes au serveur API Kubernetes.

Pour d√©marrer Minikube, ex√©cutez la commande `minikube start` et apr√®s son ex√©cution, ex√©cutez kubectl get nodes et vous devriez obtenir la sortie suivante

```
kubectl get nodes
NAME       STATUS    ROLES     AGE       VERSION
minikube   Ready     <none>    11m       v1.9.0
```

Minikube nous fournit un cluster Kubernetes qui n'a qu'un seul n≈ìud, mais souvenez-vous que nous ne nous soucions pas du nombre de n≈ìuds, Kubernetes abstrait cela, et pour nous apprendre Kubernetes, cela n'a pas d'importance. Dans la section suivante, nous commencerons avec notre premi√®re ressource Kubernetes [ROULEMENTS DE TAMBOUR] **le Pod**.

#### Pods

J'adore les conteneurs, et maintenant vous aussi. Alors pourquoi Kubernetes a-t-il d√©cid√© de nous donner des Pods comme la plus petite unit√© de calcul d√©ployable ? Que fait un pod ? Les pods peuvent √™tre compos√©s d'un ou m√™me d'un groupe de conteneurs qui partagent le m√™me environnement d'ex√©cution.

Mais devons-nous vraiment ex√©cuter deux conteneurs dans un seul pod ? Erm.. Habituellement, vous n'ex√©cutez qu'un seul conteneur et c'est ce que nous ferons dans nos exemples. Mais pour les cas o√π, par exemple, deux conteneurs doivent partager des volumes, ou communiquent entre eux en utilisant la communication inter-processus ou sont autrement √©troitement coupl√©s, alors cela est rendu possible en utilisant des **Pods**. Une autre fonctionnalit√© que les Pods rendent possible est que nous ne sommes pas li√©s aux conteneurs Docker, si nous le souhaitons, nous pouvons utiliser d'autres technologies comme [Rkt](https://coreos.com/rkt/).

![Image](https://cdn-media-1.freecodecamp.org/images/DiiFgshSEsYe9Rj2AHAUtJUI90CVH53VdioW)
_**Fig. 14. Propri√©t√©s des Pods**_

Pour r√©sumer, les principales propri√©t√©s des Pods sont (√©galement montr√©es dans la figure 14) :

1. Chaque pod a une adresse IP unique dans le cluster Kubernetes
2. Un pod peut avoir plusieurs conteneurs. Les conteneurs partagent le m√™me espace de port, ils peuvent donc communiquer via localhost (compr√©hensiblement, ils ne peuvent pas utiliser le m√™me port), et la communication avec les conteneurs des autres pods doit √™tre faite en conjonction avec l'ip du pod.
3. Les conteneurs dans un pod partagent le m√™me volume*, la m√™me ip, l'espace de port, l'espace de noms IPC.

*Les conteneurs ont leurs propres syst√®mes de fichiers isol√©s, bien qu'ils soient capables de partager des donn√©es en utilisant la ressource Kubernetes **Volumes.**

Cela est plus que suffisant pour que nous continuions, mais pour satisfaire votre curiosit√©, consultez la [documentation officielle](https://kubernetes.io/docs/concepts/workloads/pods/pod/).

### D√©finition du Pod

Ci-dessous, nous avons le fichier manifeste pour notre premier pod **sa-frontend**, puis nous expliquons tous les points.

```bash
apiVersion: v1
kind: Pod                                            # 1
metadata:
  name: sa-frontend                                  # 2
spec:                                                # 3
  containers:
    - image: rinormaloku/sentiment-analysis-frontend # 4
      name: sa-frontend                              # 5
      ports:
        - containerPort: 80                          # 6
```

1. **Kind** : sp√©cifie le type de ressource Kubernetes que nous voulons cr√©er. Dans notre cas, un **Pod**.
2. **Name** : d√©finit le nom de la ressource. Nous l'avons nomm√©e **sa-frontend**.
3. **Spec** est l'objet qui d√©finit l'√©tat souhait√© pour la ressource. La propri√©t√© la plus importante d'un Spec de Pod est le tableau de conteneurs.
4. **Image** est l'image du conteneur que nous voulons d√©marrer dans ce pod.
5. **Name** est le nom unique d'un conteneur dans un pod.
6. **Container Port** : est le port auquel le conteneur √©coute. Ce n'est qu'un indicateur pour le lecteur (supprimer le port n'emp√™che pas l'acc√®s).

### Cr√©ation du pod SA Frontend

Vous pouvez trouver le fichier pour la d√©finition du pod ci-dessus dans `resource-manifests/**sa-frontend-pod.yaml.** Vous pouvez soit naviguer dans votre terminal vers ce dossier, soit vous devrez fournir l'emplacement complet dans la ligne de commande. Ensuite, ex√©cutez la commande :

```yaml
kubectl create -f sa-frontend-pod.yaml
pod "sa-frontend" created
```

Pour v√©rifier si le Pod est en cours d'ex√©cution, ex√©cutez la commande suivante :

```bash
kubectl get pods
NAME                          READY     STATUS    RESTARTS   AGE
sa-frontend                   1/1       Running   0          7s
```

S'il est encore en **ContainerCreating**, vous pouvez ex√©cuter la commande ci-dessus avec l'argument `--watch` pour mettre √† jour les informations lorsque le Pod est en √©tat de fonctionnement.

#### Acc√®s √† l'application depuis l'ext√©rieur

Pour acc√©der √† l'application depuis l'ext√©rieur, nous cr√©ons une ressource Kubernetes de type **Service**, qui sera notre prochain article, qui est l'impl√©mentation appropri√©e, mais pour un d√©bogage rapide, nous avons une autre option, et c'est le transfert de port :

```bash
kubectl port-forward sa-frontend 88:80
Forwarding from 127.0.0.1:88 -> 80
```

Ouvrez votre navigateur sur **127.0.0.1:88** et vous acc√©derez √† l'application React.

#### La mauvaise fa√ßon de mettre √† l'√©chelle

Nous avons dit que l'une des principales caract√©ristiques de Kubernetes √©tait l'√©volutivit√©, pour le prouver, faisons fonctionner un autre pod. Pour ce faire, cr√©ez une autre ressource de pod, avec la d√©finition suivante :

```yaml
apiVersion: v1
kind: Pod                                            
metadata:
  name: sa-frontend2      # Le seul changement
spec:                                                
  containers:
    - image: rinormaloku/sentiment-analysis-frontend 
      name: sa-frontend                              
      ports:
        - containerPort: 80
```

Cr√©ez le nouveau pod en ex√©cutant la commande suivante :

```bash
kubectl create -f sa-frontend-pod2.yaml
pod "sa-frontend2" created
```

V√©rifiez que le deuxi√®me pod est en cours d'ex√©cution en ex√©cutant :

```bash
kubectl get pods
NAME                          READY     STATUS    RESTARTS   AGE
sa-frontend                   1/1       Running   0          7s
sa-frontend2                  1/1       Running   0          7s
```

Maintenant, nous avons deux pods en cours d'ex√©cution !

**Attention** : ce n'est pas la solution finale, et elle pr√©sente de nombreux d√©fauts. Nous am√©liorerons cela dans la section pour une autre ressource Kubernetes **Deployments**.

#### R√©sum√© des Pods

Le serveur web Nginx avec les fichiers statiques s'ex√©cute dans deux pods diff√©rents. Maintenant, nous avons deux questions :

* Comment l'exposons-nous √† l'ext√©rieur pour le rendre accessible via une URL, et
* Comment √©quilibrons-nous la charge entre eux ?

![Image](https://cdn-media-1.freecodecamp.org/images/I4Xjozhym548e8iBKMcPJ5DnUXZojwrnmQpT)
_Fig. 15. √âquilibrage de charge entre les pods_

Kubernetes nous fournit la ressource **Services**. Passons directement √† cela, dans la section suivante.

### Kubernetes en pratique ‚Äî Services

La ressource **Service** de Kubernetes agit comme point d'entr√©e pour un ensemble de pods qui fournissent le m√™me service fonctionnel. Cette ressource effectue le travail lourd, de d√©couverte des services et d'√©quilibrage de charge entre eux comme le montre la figure 16.

![Image](https://cdn-media-1.freecodecamp.org/images/vUV2hIHJnOtiiMKgw9GiExUShzlYB3hwUeWu)
_Fig. 16. Service Kubernetes maintenant les adresses IP_

Dans notre cluster Kubernetes, nous aurons des pods avec diff√©rents services fonctionnels. (Le frontend, l'application Spring WebApp et l'application Python Flask). La question se pose donc de savoir comment un service sait quels pods cibler ? C'est-√†-dire comment g√©n√®re-t-il la liste des endpoints pour les pods ?

Cela se fait en utilisant des **Labels**, et c'est un processus en deux √©tapes :

1. Appliquer un label √† tous les pods que nous voulons que notre Service cible et
2. Appliquer un ¬´ s√©lecteur ¬ª √† notre service afin de d√©finir quels pods √©tiquet√©s cibler.

Cela est beaucoup plus simple visuellement :

![Image](https://cdn-media-1.freecodecamp.org/images/q-Eg301b9pZA7xpZ1hc2Tqj59cDQ2H18iRKp)
_Fig. 17. Pods avec labels et leurs manifestes_

Nous pouvons voir que les pods sont √©tiquet√©s avec ¬´ app: sa-frontend ¬ª et que le service cible les pods avec ce label.

#### Labels

Les labels fournissent une m√©thode simple pour organiser vos ressources Kubernetes. Ils repr√©sentent une paire cl√©-valeur et peuvent √™tre appliqu√©s √† chaque ressource. Modifiez les manifestes pour les pods afin qu'ils correspondent √† l'exemple montr√© pr√©c√©demment dans la figure 17.

Enregistrez les fichiers apr√®s avoir termin√© les modifications, et appliquez-les avec la commande suivante :

```bash
kubectl apply -f sa-frontend-pod.yaml
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
pod "sa-frontend" configured
kubectl apply -f sa-frontend-pod2.yaml 
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
pod "sa-frontend2" configured
```

Nous avons obtenu un avertissement (apply au lieu de create, bien re√ßu). Dans la deuxi√®me ligne, nous voyons que les pods ¬´ sa-frontend ¬ª et ¬´ sa-frontend2 ¬ª sont configur√©s. Nous pouvons v√©rifier que les pods ont √©t√© √©tiquet√©s en filtrant les pods que nous voulons afficher :

```bash
kubectl get pod -l app=sa-frontend
NAME           READY     STATUS    RESTARTS   AGE
sa-frontend    1/1       Running   0          2h
sa-frontend2   1/1       Running   0          2h
```

Une autre fa√ßon de v√©rifier que nos pods sont √©tiquet√©s est d'ajouter le drapeau `--show-labels` √† la commande ci-dessus. Cela affichera tous les labels pour chaque pod.  
Super ! Nos pods sont √©tiquet√©s et nous sommes pr√™ts √† les cibler avec notre Service. Commen√ßons par d√©finir le Service de type LoadBalancer montr√© dans la Fig. 18.

![Image](https://cdn-media-1.freecodecamp.org/images/xXXbN86FdMJitJZ0ueRT1DwBecqO4u681uVY)
_Fig. 18. √âquilibrage de charge avec le Service LoadBalancer_

### D√©finition du Service

La d√©finition YAML du Service Loadbalancer est montr√©e ci-dessous :

```yaml
apiVersion: v1
kind: Service              # 1
metadata:
  name: sa-frontend-lb
spec:
  type: LoadBalancer       # 2
  ports:
  - port: 80               # 3
    protocol: TCP          # 4
    targetPort: 80         # 5
  selector:                # 6
    app: sa-frontend       # 7
```

1. **Kind** : Un service.
2. **Type** : Type de sp√©cification, nous choisissons LoadBalancer parce que nous voulons √©quilibrer la charge entre les pods.
3. **Port** : Sp√©cifie le port auquel le service re√ßoit les requ√™tes.
4. **Protocol** : D√©finit la communication.
5. **TargetPort** : Le port auquel les requ√™tes entrantes sont transf√©r√©es.
6. **Selector** : Objet qui contient des propri√©t√©s pour s√©lectionner les pods.
7. **app** : sa-frontend D√©finit quels pods cibler, uniquement les pods qui sont √©tiquet√©s avec ¬´ app: sa-frontend ¬ª

Pour cr√©er le service, ex√©cutez la commande suivante :

```
kubectl create -f service-sa-frontend-lb.yaml
service "sa-frontend-lb" created
```

Vous pouvez v√©rifier l'√©tat du service en ex√©cutant la commande suivante :

```
kubectl get svc
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
sa-frontend-lb   LoadBalancer   10.101.244.40   <pending>     80:30708/TCP   7m
```

L'**External-IP** est en √©tat d'attente (et n'attendez pas, car cela ne va pas changer). Cela est uniquement d√ª au fait que nous utilisons **Minikube**. Si nous avions ex√©cut√© cela dans un fournisseur de cloud comme Azure ou GCP, nous aurions obtenu une IP publique, ce qui rend nos services accessibles dans le monde entier.

Malgr√© cela, Minikube ne nous laisse pas tomber, il fournit une commande utile pour le d√©bogage local, ex√©cutez la commande suivante :

```bash
minikube service sa-frontend-lb
Opening kubernetes service default/sa-frontend-lb in default browser...
```

Cela ouvre votre navigateur en pointant vers l'IP du service. Apr√®s que le Service re√ßoit la requ√™te, il transf√©rera l'appel √† l'un des pods (peu importe lequel). Cette abstraction nous permet de voir et d'agir avec les nombreux pods comme une seule unit√©, en utilisant le Service comme point d'entr√©e.

#### R√©sum√© du Service

Dans cette section, nous avons couvert l'√©tiquetage des ressources, l'utilisation de celles-ci comme s√©lecteurs dans les Services, et nous avons d√©fini et cr√©√© un service LoadBalancer. Cela remplit nos exigences pour mettre √† l'√©chelle l'application (il suffit d'ajouter de nouveaux pods √©tiquet√©s) et pour √©quilibrer la charge entre les pods, en utilisant le service comme point d'entr√©e.

### Kubernetes en pratique ‚Äî D√©ploiements

Les d√©ploiements Kubernetes nous aident avec une constante dans la vie de chaque application, et c'est le **changement**. De plus, les seules applications qui ne changent pas sont celles qui sont d√©j√† mortes, et tant qu'elles ne le sont pas, de nouvelles exigences arriveront, plus de code sera livr√©, il sera emball√© et d√©ploy√©. Et √† chaque √©tape de ce processus, des erreurs peuvent √™tre commises.

La ressource D√©ploiement automatise le processus de passage d'une version de l'application √† la suivante, avec un temps d'arr√™t nul et en cas d'√©checs, elle nous permet de revenir rapidement √† la version pr√©c√©dente.

#### D√©ploiements en pratique

Actuellement, nous avons **deux pods** et **un service** qui les expose et √©quilibre la charge entre eux (voir Fig. 19.). Nous avons mentionn√© que le d√©ploiement des pods s√©par√©ment est loin d'√™tre parfait. Cela n√©cessite de g√©rer s√©par√©ment chacun (cr√©er, mettre √† jour, supprimer et surveiller leur sant√©). Les mises √† jour rapides et les retours en arri√®re rapides sont hors de question ! Cela n'est pas acceptable et la ressource Kubernetes **D√©ploiements** r√©sout chacun de ces probl√®mes.

![Image](https://cdn-media-1.freecodecamp.org/images/81V1N8qcLyWZi4t69mWSgYbQWjQrqRD2Ye3W)
_Fig. 19. √âtat actuel_

Avant de continuer, √©non√ßons ce que nous voulons accomplir, car cela nous fournira l'aper√ßu qui nous permet de comprendre la d√©finition du manifeste pour la ressource de d√©ploiement. Ce que nous voulons est :

1. Deux pods de l'image rinormaloku/sentiment-analysis-frontend
2. D√©ploiements sans temps d'arr√™t,
3. Pods √©tiquet√©s avec `**app:** sa-frontend` afin que les services soient d√©couverts par le Service **sa-frontend-lb.**

Dans la section suivante, nous traduirons les exigences en une d√©finition de d√©ploiement.

### D√©finition du d√©ploiement

La d√©finition de la ressource YAML qui r√©alise tous les points mentionn√©s ci-dessus :

```yaml
apiVersion: apps/v1
kind: Deployment                                          # 1
metadata:
  name: sa-frontend
spec:
  selector:                                               # 2
    matchLabels:
      app: sa-frontend                                    
  replicas: 2                                             # 3
  minReadySeconds: 15
  strategy:
    type: RollingUpdate                                   # 4
    rollingUpdate: 
      maxUnavailable: 1                                   # 5
      maxSurge: 1                                         # 6
  template:                                               # 7
    metadata:
      labels:
        app: sa-frontend                                  # 8
    spec:
      containers:
        - image: rinormaloku/sentiment-analysis-frontend
          imagePullPolicy: Always                         # 9
          name: sa-frontend
          ports:
            - containerPort: 80
```

1. **Kind** : Un d√©ploiement.
2. **Selector** : Les pods correspondant au s√©lecteur seront pris sous la gestion de ce d√©ploiement.
3. **Replicas** est une propri√©t√© de l'objet Spec des d√©ploiements qui d√©finit combien de pods nous voulons ex√©cuter. Donc seulement 2.
4. **Type** sp√©cifie la strat√©gie utilis√©e dans ce d√©ploiement lors du passage de la version actuelle √† la suivante. La strat√©gie **RollingUpdate** garantit des d√©ploiements sans temps d'arr√™t.
5. **MaxUnavailable** est une propri√©t√© de l'objet RollingUpdate qui sp√©cifie le nombre maximum de pods indisponibles autoris√©s (par rapport √† l'√©tat souhait√©) lors d'une mise √† jour progressive. Pour notre d√©ploiement qui a 2 r√©pliques, cela signifie qu'apr√®s avoir termin√© un pod, nous aurions encore un pod en cours d'ex√©cution, maintenant ainsi notre application accessible.
6. **MaxSurge** est une autre propri√©t√© de l'objet RollingUpdate qui d√©finit la quantit√© maximale de pods ajout√©s √† un d√©ploiement (par rapport √† l'√©tat souhait√©). Pour notre d√©ploiement, cela signifie que lors du passage √† une nouvelle version, nous pouvons ajouter un pod, ce qui fait un total de 3 pods en m√™me temps.
7. **Template** : sp√©cifie le mod√®le de pod que le d√©ploiement utilisera pour cr√©er de nouveaux pods. Tr√®s probablement, la ressemblance avec les pods vous a imm√©diatement frapp√©.
8. `**app:** sa-frontend` l'√©tiquette √† utiliser pour les pods cr√©√©s par ce mod√®le.
9. **ImagePullPolicy** lorsqu'elle est d√©finie sur **Always**, elle tirera les images de conteneur √† chaque red√©ploiement.

Honn√™tement, ce mur de texte m'a m√™me confus, commen√ßons simplement avec l'exemple :

```bash
kubectl apply -f sa-frontend-deployment.yaml
deployment "sa-frontend" created
```

Comme toujours, v√©rifions que tout s'est pass√© comme pr√©vu :

```bash
kubectl get pods
NAME                           READY     STATUS    RESTARTS   AGE
sa-frontend                    1/1       Running   0          2d
sa-frontend-5d5987746c-ml6m4   1/1       Running   0          1m
sa-frontend-5d5987746c-mzsgg   1/1       Running   0          1m
sa-frontend2                   1/1       Running   0          2d
```

Nous avons obtenu 4 pods en cours d'ex√©cution, deux pods cr√©√©s par le d√©ploiement et les deux autres sont ceux que nous avons cr√©√©s manuellement. Supprimez ceux que nous avons cr√©√©s manuellement en utilisant la commande `kubectl delete pod <pod-name>`.

**Exercice** : Supprimez √©galement l'un des pods du d√©ploiement et voyez ce qui se passe. R√©fl√©chissez √† la raison avant de lire l'explication ci-dessous.

**Explication** : La suppression d'un pod a fait remarquer au d√©ploiement que l'√©tat actuel (1 pod en cours d'ex√©cution) est diff√©rent de l'√©tat souhait√© (2 pods en cours d'ex√©cution), donc il a d√©marr√© un autre pod.

Alors, qu'est-ce qui √©tait si bien avec les d√©ploiements, en plus de maintenir l'√©tat souhait√© ? Commen√ßons avec les avantages.

#### Avantages #1 : D√©ploiement sans temps d'arr√™t

Notre chef de produit est venu vers nous avec une nouvelle exigence, nos clients veulent avoir un bouton vert dans le frontend. Les d√©veloppeurs ont livr√© leur code et nous ont fourni la seule chose dont nous avons besoin, l'image du conteneur `rinormaloku/sentiment-analysis-frontend:green`. Maintenant, c'est √† notre tour, nous, les DevOps, devons d√©ployer sans temps d'arr√™t, le travail acharn√© portera-t-il ses fruits ? Voyons cela !

Modifiez le fichier `sa-frontend-deployment.yaml` en changeant l'image du conteneur pour qu'elle pointe vers la nouvelle image : `rinormaloku/sentiment-analysis-frontend:green`. Enregistrez les modifications sous `sa-frontend-deployment-green.yaml` et ex√©cutez la commande suivante :

```bash
kubectl apply -f sa-frontend-deployment-green.yaml --record
deployment "sa-frontend" configured
```

Nous pouvons v√©rifier l'√©tat du d√©ploiement en utilisant la commande suivante :

```bash
kubectl rollout status deployment sa-frontend
Waiting for rollout to finish: 1 old replicas are pending termination...
Waiting for rollout to finish: 1 old replicas are pending termination...
Waiting for rollout to finish: 1 old replicas are pending termination...
Waiting for rollout to finish: 1 old replicas are pending termination...
Waiting for rollout to finish: 1 old replicas are pending termination...
Waiting for rollout to finish: 1 of 2 updated replicas are available...
deployment "sa-frontend" successfully rolled out
```

Selon la sortie, le d√©ploiement a √©t√© effectu√©. Cela a √©t√© fait de telle mani√®re que les r√©pliques ont √©t√© remplac√©es une par une. Ce qui signifie que notre application √©tait toujours en ligne. Avant de continuer, v√©rifions que la mise √† jour est en direct.

#### V√©rification du d√©ploiement

Voyons la mise √† jour en direct sur nos navigateurs. Ex√©cutez la m√™me commande que nous avons utilis√©e auparavant `minikube service sa-frontend-lb`, qui ouvre le navigateur. Nous pouvons voir que le bouton a √©t√© mis √† jour.

![Image](https://cdn-media-1.freecodecamp.org/images/aRxOGkn2bSeCWdsuMPFAPRgbR7ZTQ59RX3uw)
_Fig. 20. Le bouton vert_

#### Derri√®re les sc√®nes de ¬´ The RollingUpdate ¬ª

Apr√®s avoir appliqu√© le nouveau d√©ploiement, Kubernetes compare le nouvel √©tat avec l'ancien. Dans notre cas, le nouvel √©tat demande deux pods avec l'image `rinormaloku/sentiment-analysis-frontend:green`. Cela est diff√©rent de l'√©tat actuel en cours d'ex√©cution, donc il d√©clenche le **RollingUpdate**.

![Image](https://cdn-media-1.freecodecamp.org/images/I86XgWQFhpFLolvA8v0eHmZSKGilmlTaevTa)
_Fig. 21. RollingUpdate rempla√ßant les pods_

Le RollingUpdate agit selon les r√®gles que nous avons sp√©cifi√©es, √† savoir ¬´ **maxUnavailable:** 1 ¬ª et ¬´ **maxSurge:** 1 ¬ª. Cela signifie que le d√©ploiement ne peut terminer qu'un seul pod et ne peut d√©marrer qu'un seul nouveau pod. Ce processus est r√©p√©t√© jusqu'√† ce que tous les pods soient remplac√©s (voir Fig. 21).

Continuons avec l'avantage num√©ro 2.

**Avertissement** : _√Ä des fins de divertissement, la partie suivante est √©crite sous forme de nouvelle._

#### Avantages #2 : Retour √† un √©tat pr√©c√©dent

Le chef de produit entre en courant dans votre bureau et il est en **crise !**

¬´ L'application a un bug critique, en PRODUCTION !! Revenir imm√©diatement √† la version pr√©c√©dente ¬ª ‚Äî crie le chef de produit.

Il voit le calme en vous, sans un cillement. Vous vous tournez vers votre terminal bien-aim√© et tapez :

```bash
kubectl rollout history deployment sa-frontend
deployments "sa-frontend"
REVISION  CHANGE-CAUSE
1         <none>         
2         kubectl.exe apply --filename=sa-frontend-deployment-green.yaml --record=true
```

Vous jetez un coup d'≈ìil rapide aux d√©ploiements pr√©c√©dents. ¬´ La derni√®re version est bogu√©e, tandis que la version pr√©c√©dente fonctionnait parfaitement ? ¬ª ‚Äî demandez-vous au chef de produit.

¬´ Oui, m'√©coutez-vous m√™me ! ¬ª ‚Äî crie le chef de produit.

Vous l'ignorez, vous savez ce que vous avez √† faire, vous commencez √† taper :

```bash
kubectl rollout undo deployment sa-frontend --to-revision=1
deployment "sa-frontend" rolled back
```

Vous actualisez la page et le changement est annul√© !

La m√¢choire du chef de produit s'ouvre.

Vous avez sauv√© la journ√©e !

_Fin !_

Oui‚Ä¶ c'√©tait une nouvelle ennuyeuse. Avant que Kubernetes n'existe, c'√©tait bien mieux, nous avions plus de drame, une intensit√© plus √©lev√©e, et cela pendant une p√©riode plus longue. Ohh, le bon vieux temps !

La plupart des commandes sont explicites, √† l'exception d'un d√©tail que vous avez d√ª comprendre vous-m√™me. Pourquoi la premi√®re r√©vision a-t-elle une **CHANGE-CAUSE** de <none> tandis que la deuxi√®me r√©vision **a une CHANGE-CAUSE** de ¬´ kubectl.exe apply ‚Äìfilename=sa-frontend-deployment-green.yaml ‚Äìrecord=true ¬ª.

Si vous avez conclu que c'est √† cause du drapeau `--record` que nous avons utilis√© lorsque nous avons appliqu√© la nouvelle image, alors vous avez tout √† fait raison !

Dans la section suivante, nous utiliserons les concepts appris jusqu'√† pr√©sent pour compl√©ter toute l'architecture.

### Kubernetes et tout le reste en pratique

Nous avons appris toutes les ressources dont nous avons besoin pour compl√©ter l'architecture, c'est pourquoi cette partie va √™tre rapide. Dans la figure 22, nous avons gris√© tout ce que nous devons encore faire. Commen√ßons par le bas : **D√©ployer le d√©ploiement sa-logic**.

![Image](https://cdn-media-1.freecodecamp.org/images/CwBGmdNtPUeZwsTSL9inGx8xikkNEejnEeVQ)
_Fig. 22. √âtat actuel de l'application_

#### D√©ploiement SA-Logic

Naviguez dans votre terminal vers le dossier resource-manifests et ex√©cutez la commande suivante :

```bash
kubectl apply -f sa-logic-deployment.yaml --record
deployment "sa-logic" created
```

Le d√©ploiement SA-Logic a cr√©√© trois pods. (Ex√©cutant le conteneur de notre application Python). Il les a √©tiquet√©s avec `**app:** sa-logic`. Cet √©tiquetage nous permet de les cibler en utilisant un s√©lecteur depuis le service SA-Logic. Prenez le temps d'ouvrir le fichier `sa-logic-deployment.yaml` et de v√©rifier le contenu.

Ce sont les m√™mes concepts utilis√©s encore et encore, passons directement √† la ressource suivante : **le service SA-Logic**.

#### Service SA Logic

Expliquons pourquoi nous avons besoin de ce Service. Notre application Java (s'ex√©cutant dans les pods du d√©ploiement SA ‚Äî WebApp) d√©pend de l'analyse de sentiment effectu√©e par l'application Python. Mais maintenant, contrairement √† lorsque nous ex√©cutions tout localement, nous n'avons pas une seule application Python √©coutant sur un port, nous avons 2 pods et si n√©cessaire nous pourrions en avoir plus.

C'est pourquoi nous avons besoin d'un **Service** qui ¬´ agit comme point d'entr√©e pour un ensemble de pods qui fournissent le m√™me service fonctionnel ¬ª. Cela signifie que nous pouvons utiliser le Service SA-Logic comme point d'entr√©e pour tous les pods SA-Logic.

Faisons cela :

```
kubectl apply -f service-sa-logic.yaml
service "sa-logic" created
```

**√âtat de l'application mis √† jour** : Nous avons 2 pods (contenant l'application Python) en cours d'ex√©cution et nous avons le service SA-Logic agissant comme un point d'entr√©e que nous utiliserons dans les pods SA-WebApp.

![Image](https://cdn-media-1.freecodecamp.org/images/fYibPnq4frpa7jf4aq9Htc3sT0OxtgOTZ52x)
_Fig. 23. √âtat de l'application mis √† jour_

Maintenant, nous devons d√©ployer les pods SA-WebApp, en utilisant une ressource de d√©ploiement.

#### D√©ploiement SA-WebApp

Nous commen√ßons √† comprendre les d√©ploiements, bien que celui-ci ait une fonctionnalit√© suppl√©mentaire. Si vous ouvrez le fichier `sa-web-app-deployment.yaml`, vous trouverez cette partie nouvelle :

```yaml
- image: rinormaloku/sentiment-analysis-web-app
  imagePullPolicy: Always
  name: sa-web-app
  env:
    - name: SA_LOGIC_API_URL
      value: "http://sa-logic"
  ports:
    - containerPort: 8080
```

La premi√®re chose qui nous int√©resse est de savoir ce que fait la propri√©t√© **env** ? Et nous supposons qu'elle d√©clare la variable d'environnement SA_LOGIC_API_URL avec la valeur ¬´ [http://sa-logic](http://sa-logic/) ¬ª √† l'int√©rieur de nos pods. Mais pourquoi l'initialisons-nous √† [**http://sa-logic**](http://sa-logic/), qu'est-ce que **sa-logic** ?

Pr√©sentons-nous √† **kube-dns**.

#### KUBE-DNS

Kubernetes a un pod sp√©cial, le **kube-dns**. Et par d√©faut, tous les pods l'utilisent comme serveur DNS. Une propri√©t√© importante de **kube-dns** est qu'il cr√©e un enregistrement DNS pour chaque service cr√©√©.

Cela signifie que lorsque nous avons cr√©√© le service **sa-logic**, il a obtenu une adresse IP. Son nom a √©t√© ajout√© comme un enregistrement (en conjonction avec l'IP) dans kube-dns. Cela permet √† tous les pods de traduire **sa-logic** en l'adresse IP du service SA-Logic.

Bien, maintenant nous pouvons continuer avec :

#### D√©ploiement SA WebApp (suite)

Ex√©cutez la commande :

```bash
kubectl apply -f sa-web-app-deployment.yaml --record
deployment "sa-web-app" created
```

Termin√©. Il nous reste √† exposer les pods SA-WebApp √† l'ext√©rieur en utilisant un Service LoadBalancer. Cela permet √† notre application React de faire des requ√™tes http au service qui agit comme un point d'entr√©e vers les pods SA-WebApp.

#### Service SA-WebApp

Ouvrez le fichier `service-sa-web-app-lb.yaml`, comme vous pouvez le voir, tout vous est familier.  
Alors sans plus attendre, ex√©cutez la commande :

```bash
kubectl apply -f service-sa-web-app-lb.yaml
service "sa-web-app-lb" created
```

L'architecture est compl√®te. Mais nous avons une seule dissonance. Lorsque nous avons d√©ploy√© les pods SA-Frontend, notre image de conteneur pointait vers notre SA-WebApp sur [http://localhost:8080/sentiment](http://localhost:8080/sentiment). Mais maintenant, nous devons la mettre √† jour pour qu'elle pointe vers l'adresse IP du Loadbalancer SA-WebApp. (Qui agit comme un point d'entr√©e vers les pods SA-WebApp).

Corriger cette dissonance nous offre l'opportunit√© de r√©sumer une fois de plus tout ce qui va du code au d√©ploiement. (C'est encore plus efficace si vous le faites seul au lieu de suivre le guide ci-dessous). Commen√ßons :

1. Obtenez l'IP du Loadbalancer SA-WebApp en ex√©cutant la commande suivante :

```bash
minikube service list
|-------------|----------------------|-----------------------------|
|  NAMESPACE  |         NAME         |             URL             |
|-------------|----------------------|-----------------------------|
| default     | kubernetes           | No node port                |
| default     | sa-frontend-lb       | http://192.168.99.100:30708 |
| default     | sa-logic             | No node port                |
| default     | sa-web-app-lb        | http://192.168.99.100:31691 |
| kube-system | kube-dns             | No node port                |
| kube-system | kubernetes-dashboard | http://192.168.99.100:30000 |
|-------------|----------------------|-----------------------------|
```

2. Utilisez l'IP du LoadBalancer SA-WebApp dans le fichier `sa-frontend/src/App.js`, comme montr√© ci-dessous :

```js
analyzeSentence() {
        fetch('http://192.168.99.100:31691/sentiment', { /* raccourci pour plus de concision */})
            .then(response => response.json())
            .then(data => this.setState(data));
    }
```

3. Construisez les fichiers statiques `npm run build` (vous devez naviguer vers le dossier **sa-frontend**)

4. Construisez l'image du conteneur :

```bash
docker build -f Dockerfile -t $DOCKER_USER_ID/sentiment-analysis-frontend:minikube .
```

5. Envoyez l'image vers Docker hub.

```bash
docker push $DOCKER_USER_ID/sentiment-analysis-frontend:minikube
```

6. Modifiez le fichier sa-frontend-deployment.yaml pour utiliser la nouvelle image et

7. Ex√©cutez la commande kubectl apply -f sa-frontend-deployment.yaml

Actualisez le navigateur ou si vous avez ferm√© la fen√™tre, ex√©cutez `minikube service sa-frontend-lb`. Essayez en tapant une phrase !

![Image](https://cdn-media-1.freecodecamp.org/images/GkLNiTbXMvnaTdwnH0DjS-Lhq7mizlAnl9Mm)

### R√©sum√© de l'article

Kubernetes est b√©n√©fique pour l'√©quipe, pour le projet, simplifie les d√©ploiements, l'√©volutivit√©, la r√©silience, il nous permet de consommer n'importe quelle infrastructure sous-jacente et vous savez quoi ? √Ä partir de maintenant, appelons-le Supernetes !

Ce que nous avons couvert dans cette s√©rie :

* Construction / Emballage / Ex√©cution d'applications ReactJS, Java et Python
* Conteneurs Docker ; comment les d√©finir et les construire en utilisant des Dockerfiles,
* Registres de conteneurs ; nous avons utilis√© Docker Hub comme d√©p√¥t pour nos conteneurs.
* Nous avons couvert les parties les plus importantes de Kubernetes.
* Pods
* Services
* D√©ploiements
* Nouveaux concepts comme les d√©ploiements sans temps d'arr√™t
* Cr√©ation d'applications √©volutives
* Et en cours de route, nous avons migr√© toute l'application de microservices vers un cluster Kubernetes.

Je suis Rinor Maloku et je veux vous remercier de m'avoir accompagn√© dans ce voyage. Puisque vous avez lu jusqu'ici, je sais que vous avez aim√© cet article et seriez int√©ress√© par d'autres. J'√©cris des articles qui approfondissent les d√©tails des nouvelles technologies tous les 3 mois. Vous pouvez toujours vous attendre √† une application d'exemple, une pratique pratique et un guide qui vous fournit les bons outils et connaissances pour aborder n'importe quel projet r√©el.

Pour rester en contact et ne manquer aucun de mes articles, abonnez-vous √† ma [newsletter](https://tinyletter.com/rinormaloku), suivez-moi sur [Twitter](https://twitter.com/rinormaloku), et consultez ma page [rinormaloku.com](https://rinormaloku.com/).