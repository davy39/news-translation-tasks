---
title: Cours gratuit de 10 heures sur le Machine Learning
subtitle: ''
author: Beau Carnes
co_authors: []
series: null
date: '2021-08-30T13:36:04.000Z'
originalURL: https://freecodecamp.org/news/free-machine-learning-course-10-hourse
coverImage: https://www.freecodecamp.org/news/content/images/2021/08/machinelearning.png
tags:
- name: Machine Learning
  slug: machine-learning
- name: youtube
  slug: youtube
seo_title: Cours gratuit de 10 heures sur le Machine Learning
seo_desc: 'Every day more and more use cases are found for machine learning. It is
  a great field to get into.

  We just released a 10-hour machine learning course for beginners on the freeCodeCamp.org
  YouTube channel.

  Ayush Singh developed this course. He is a yo...'
---

Chaque jour, de plus en plus de cas d'utilisation sont trouvés pour le machine learning. C'est un domaine passionnant à explorer.

Nous venons de publier un cours de 10 heures sur le machine learning pour débutants sur la chaîne YouTube de freeCodeCamp.org.

Ayush Singh a développé ce cours. Il est un jeune data scientist et ingénieur en machine learning.

Voici les sections couvertes dans ce cours :

**Section 1 : Les bases du Machine Learning**

* Qu'est-ce que le Machine Learning ? La façon dont j'aime le concevoir !
* Applications passionnantes du Machine Learning
* Types de ML et leurs catégories
* Workflow d'un problème de ML de base
* Principaux défis du Machine Learning
* Division des données
* Deux problèmes célèbres du Machine Learning : Sous-apprentissage et Surapprentissage
* Solutions pour le Surapprentissage et le Sous-apprentissage
* Apprentissage supervisé et non supervisé en profondeur

**Section 2 : Régression linéaire et régularisation**

* Qu'est-ce que la régression linéaire ? Compréhension visuelle
* Fonction d'hypothèse ou fonction de prédiction
* Solution sous forme fermée aka Équation normale
* Codage de l'équation normale
* Fonction de coût
* Descente de gradient
* Hypothèses et avantages/inconvénients de la régression linéaire
* Modèles linéaires régularisés
* Régression Ridge
* Régression Lasso

**Section 3 : Régression logistique et métriques de performance**

* Régression logistique
* Fonction d'hypothèse
* Fonction de coût
* Descente de gradient
* Hypothèses et avantages/inconvénients

**Section 4 : Machines à vecteurs de support (SVM)**

* Machines à vecteurs de support
* Classification SVM linéaire
* Classification à marge dure/douce
* Classification SVM non linéaire
* Noyau polynomial [Homogène et non homogène]
* Noyau RBF
* Calcul du classificateur SVM
* Problème primal et dual
* Descente de sous-gradient
* Descente de coordonnées
* SVM transductif
* SVR

**Section 5 : ACP (Analyse en Composantes Principales)**

* Révision de la transformation linéaire et des vecteurs propres et valeurs propres
* Besoin de réduction de dimensionnalité
* Intuition de base derrière l'ACP
* Prétraitement des données [Standardisation des données]
* Calcul de la matrice de covariance
* Calcul de l'énergie cumulative pour chaque vecteur propre
* Sélection d'un sous-ensemble de vecteurs propres comme vecteurs de base
* Projection en arrière

**Section 6 : Théorie de l'apprentissage**

* Compromis entre biais et variance
* Erreur d'estimation approximative
* Minimisation du risque empirique
* Ensembles de problèmes publiés

**Section 7 : Arbres de décision et Forêts aléatoires**

* Arbres de décision
* Entraînement des arbres de décision
* Prédiction dans les arbres de décision
* Entropie
* Gain d'information
* Impureté de Gini
* Réglage des hyperparamètres
* Proposition de projet
* Devoir sur les arbres de décision
* Apprentissage d'ensemble
* Apprentissage d'ensemble
* Bagging
* Forêt aléatoire
* Boosting
* Gradient Boosting
* Adaboost
* XGboost
* Stacking
* Cascading

**Section 7.5 : Apprendre plus d'algorithmes et construire plus de projets**

* Naive Bayes
* K plus proches voisins

**Section 8 : Algorithmes d'apprentissage non supervisé**

* Introduction et types d'apprentissage non supervisé et de clustering
* Analyse de clusters
* Algorithmes d'apprentissage non supervisé
* K-Means avec K-Means ++
* Techniques de clustering hiérarchique
* Ensemble de problèmes d'apprentissage non supervisé et publication de projets
* Devoir de programmation K-Means

**Section 9 : Construction d'applications**

* Construction d'un système de détection d'insuffisance cardiaque avec déploiement
* Construction d'un système de détection de fausses nouvelles
* Construction d'un système de détection de spam par email


Regardez le cours complet ci-dessous ou [sur la chaîne YouTube de freeCodeCamp.org](https://youtu.be/NWONeJKn6kc) (10 heures de visionnage).

%[https://youtu.be/NWONeJKn6kc]