---
title: Tutoriel NLP ‚Äì Techniques de pr√©traitement de texte pour d√©butants
subtitle: ''
author: Crypt(iq)
co_authors: []
series: null
date: '2023-07-12T14:31:24.000Z'
originalURL: https://freecodecamp.org/news/natural-language-processing-techniques-for-beginners
coverImage: https://www.freecodecamp.org/news/content/images/2023/07/NLP-6.png
tags:
- name: Machine Learning
  slug: machine-learning
- name: nlp
  slug: nlp
seo_title: Tutoriel NLP ‚Äì Techniques de pr√©traitement de texte pour d√©butants
seo_desc: Natural Language Processing (NLP) is a branch of Machine learning (ML) that
  is focused on making computers understand the human language. It is used to create
  language models, language translation apps like Google translate, and virtual assistants,
  a...
---

Le traitement du langage naturel (NLP) est une branche de l'apprentissage automatique (ML) qui se concentre sur la compr√©hension du langage humain par les ordinateurs. Il est utilis√© pour cr√©er des mod√®les de langage, des applications de traduction comme Google Translate et des assistants virtuels, entre autres.

Cet article vous guide √† travers l'une des √©tapes les plus basiques du NLP, qui est le pr√©traitement de texte. C'est un sujet incontournable pour toute personne int√©ress√©e par les mod√®les de langage et le NLP en g√©n√©ral, qui est une partie centrale du domaine de l'intelligence artificielle (IA) et du ML.

## Qu'est-ce que le pr√©traitement de texte ?

Le pr√©traitement de texte est le processus de transformation de texte non structur√© en texte structur√© pour le pr√©parer √† l'analyse.

Lorsque vous pr√©traitez le texte avant de le fournir aux algorithmes, vous augmentez la pr√©cision et l'efficacit√© de ces algorithmes en supprimant le bruit et d'autres incoh√©rences dans le texte qui peuvent rendre difficile la compr√©hension par l'ordinateur.

Rendre le texte plus facile √† comprendre aide √©galement √† r√©duire le temps et les ressources n√©cessaires pour que l'ordinateur pr√©traite les donn√©es.

## Processus impliqu√©s dans le pr√©traitement de texte

Pour pr√©traiter correctement votre texte et le mettre dans le bon √©tat pour effectuer des analyses et des actions suppl√©mentaires, il y a plusieurs op√©rations √† effectuer sur le texte et quelques √©tapes √† suivre pour obtenir un texte bien structur√©.

Passons en revue ces processus dans les sous-sections suivantes.

### Tokenisation

La tokenisation est la premi√®re √©tape du processus.

Ici, votre texte est analys√© puis divis√© en morceaux appel√©s ¬´ tokens ¬ª qui peuvent √™tre des mots ou des phrases. Cela permet √† l'ordinateur de travailler sur votre texte token par token plut√¥t que sur l'ensemble du texte dans les √©tapes suivantes.

Les deux principaux types de tokenisation sont la tokenisation de mots et la tokenisation de phrases.

La **tokenisation de mots** est le type de tokenisation le plus courant.

Ici, chaque token est un mot, ce qui signifie que l'algorithme d√©compose l'ensemble du texte en mots individuels :

```python
text = 'Wisdoms daughter walks alone. The mark of Athena burns through rome'

words = text.split()
print(words)

#le r√©sultat de ceci est donn√© ci-dessous
>>>> ['Wisdoms', 'daughter', 'walks', 'alone.', 'The', 'mark', 'of', 'Athena', 'burns', 'through', 'rome']
```

D'autre part, la **tokenisation de phrases** d√©compose le texte en phrases au lieu de mots. C'est un type de tokenisation moins courant, utilis√© uniquement dans quelques t√¢ches de traitement du langage naturel (NLP).

Il existe divers algorithmes de tokenisation tels que la tokenisation par espaces blancs, la tokenisation par expressions r√©guli√®res (√©galement appel√©e Regex) et la tokenisation statistique.

Le type d'algorithme que vous utilisez d√©pendra de la t√¢che particuli√®re sur laquelle vous travaillez et de ce que vous visez √† accomplir avec celle-ci.

### Normalisation

Dans la normalisation, votre texte est converti en une forme standard.

Un exemple de cela est la conversion de tout le texte en minuscules, la suppression des nombres ou la suppression des ponctuations. La normalisation aide √† rendre le texte plus coh√©rent.

Il existe plusieurs techniques de normalisation diff√©rentes, mais je vais vous donner une explication de certaines des techniques de normalisation les plus couramment employ√©es ci-dessous.

#### Normalisation de casse

Cette technique convertit toutes les lettres de votre texte en une seule casse, soit en majuscules, soit en minuscules.

La normalisation de casse garantit que vos donn√©es sont stock√©es dans un format coh√©rent et facilite le travail avec les donn√©es.

Un exemple serait de rechercher toutes les instances d'un mot et de le rechercher dans votre texte. Sans normalisation de casse, le r√©sultat de la recherche du mot ¬´ Boy ¬ª serait diff√©rent du r√©sultat de la recherche de ¬´ boy ¬ª.

Vous pouvez utiliser le code suivant pour effectuer une normalisation de casse :

```python
text = "'To Sleep Or NOT to SLEep, THAT is THe Question'"

def lower_case(text):
    text = text.lower()
    return text

lower_case = lower_case(text)#convertit tout en minuscules
print(lower_case)

#le r√©sultat de ceci est donn√© ci-dessous
>>>> to sleep or not to sleep, that is the question
```


#### Racinisation

Des mots comme coding, coder et coded ont tous le m√™me mot de base qui est *code*.

Les mod√®les de ML comprennent le plus souvent que ces mots sont tous d√©riv√©s d'un seul mot de base. Ils peuvent travailler avec votre texte sans les temps, pr√©fixes et suffixes dont nous, en tant qu'humains, aurions normalement besoin pour en comprendre le sens.

La racination de vos textes aide non seulement √† r√©duire le nombre de mots avec lesquels le mod√®le doit travailler, et par extension am√©liore l'efficacit√© du mod√®le.

Bien que l'efficacit√© d'un mod√®le soit augment√©e avec cette technique, elle supprime √©galement des informations importantes de votre texte et pourrait amener certains mots √† √™tre mal cat√©goris√©s par le mod√®le.

Un exemple de cela serait la diff√©rence entre *writing* et *write* dans les phrases ci-dessous :

```

üì° Writing makes me happy.

üì° He writes regularly.

```

Dans la premi√®re phrase, le mot *writing* repr√©sente un nom, tandis que *writes* dans la deuxi√®me phrase repr√©sente un verbe.

Si votre mod√®le de ML racine √† la fois *writing* et *writes* √† la base *write*, la diff√©rence dans leurs parties de discours respectives est n√©glig√©e, ce qui entra√Æne une perte d'informations dans le processus d'analyse du texte.

#### Lemmatisation

Cette m√©thode est tr√®s similaire √† la racination en ce sens qu'elle est √©galement utilis√©e pour identifier la base des mots. Cependant, c'est une technique plus complexe et plus pr√©cise que la racination.

Contrairement √† la racination, la lemmatisation prend en compte la structure des mots avant d'identifier un mot de base.

En raison de la complexit√© de cette technique, elle a des exigences computationnelles √©lev√©es et est donc plus co√ªteuse que la racination.


#### Suppression de la ponctuation

Lors des conversations humaines, les marques de ponctuation comme `‚Äò‚Äô`, ` !` , `[`, `}`, `*`, ` #`, ` /`, ` ?`, et `‚Äò‚Äô` sont incroyablement pertinentes et n√©cessaires pour avoir une conversation appropri√©e. Elles aident √† transmettre pleinement le message de l'auteur.

Les mod√®les de ML, en revanche, trouvent les ponctuations distrayantes.

Leur pr√©sence pourrait interf√©rer avec l'analyse de texte et le processus de traitement du langage naturel (NLP).

En supprimant les marques de ponctuation de notre texte, nous permettons au mod√®le de se concentrer sur le texte seul plut√¥t que de le distraire avec des symboles. Cela facilite l'analyse du texte.

Pour effectuer la suppression de la ponctuation sur du texte, le code suivant peut √™tre utilis√© :

```python
import re

text = ' (to love is to destroy, and to be loved, is to be "the" one <destroyed>} '

def remove_punctuations(text):
    punctuation = re.compile(r'[{};():,."/<>-]')
    text = punctuation.sub(' ', text)
    return text

clean_text = remove_punctuations(text)
print(clean_text)

#le r√©sultat de ceci est donn√© ci-dessous
>>>> to love is to destroy  and to be loved  is to be  the  one  destroyed
```

#### Suppression des accents


Ce processus consiste √† supprimer les symboles de caract√®res sp√©cifiques √† une langue du texte.

Certains caract√®res sont √©crits avec des accents ou des symboles sp√©cifiques pour impliquer une prononciation diff√©rente ou pour signifier que les mots contenant de tels textes accentu√©s ont une signification diff√©rente.

Un exemple de cela serait la diff√©rence de signification et de prononciation entre les mots *r√©sum√©* et *resume*.

Le premier fait r√©f√©rence √† un document qui met en avant vos comp√©tences professionnelles et vos r√©alisations, tandis que le second signifie ¬´ reprendre quelque chose, ou continuer une t√¢che ou une action pr√©c√©dente ¬ª.

Vous pouvez utiliser le code ci-dessous pour effectuer la suppression des accents sur votre texte :

```python
import re

text = "her fianc√©'s r√©sum√© is beautiful"

def remove_accents(text):
    accents = re.compile(u"[\u0300-\u036F]|\u00e9|\u00e8")
    text = accents.sub(u"e", text)
    return text

cleaned_text = remove_accents(text)
print(cleaned_text)

#le r√©sultat de ceci est donn√© ci-dessous
>>>> her fiance's resume is beautiful
```


#### Suppression des mots vides

Les mots vides sont des mots sans signification. Ils n'ajoutent aucune valeur suppl√©mentaire aux donn√©es.

Des mots comme *A, the, and, of* et ainsi de suite sont appel√©s mots vides.

Comme tous les processus pr√©c√©dents, la suppression des mots vides aide √©galement √† augmenter l'efficacit√© de votre mod√®le.

Puisqu'elle r√©duit la taille de notre ensemble de donn√©es, elle le rend plus g√©rable et augmente la pr√©cision des t√¢ches de NLP.

## Conclusion

Dans cet article, vous avez appris les bases du NLP.

Vous √™tes maintenant familiaris√© avec la proc√©dure appropri√©e √† suivre lors du pr√©traitement de votre texte pour les t√¢ches de NLP. N'h√©sitez pas √† pratiquer cela par vous-m√™me et √† travailler sur quelques projets de NLP.

Notez que le choix de la ou des techniques de pr√©traitement √† utiliser sur votre texte d√©pendra largement du type de texte avec lequel vous travaillez, de la source de vos donn√©es et de l'objectif que vous visez √† atteindre avec celles-ci.

Pour en savoir plus sur le NLP, vous pouvez consulter [FreeCodeCamp](https://www.freecodecamp.org/news/tag/nlp/) pour plus d'articles et de cours sur le NLP et le ML en g√©n√©ral.


Connectez-vous avec moi sur Twitter [@Iqma](https://twitter.com/Iqma__) et suivez [mon blog hashnode](https://iqmacodes.hashnode.dev/) pour lire plus de contenu comme celui-ci et pour en apprendre davantage sur tout ce qui concerne l'IA et l'apprentissage automatique.

Bon apprentissage !