---
title: Comment cr√©er un bot Discord aliment√© par LangGraph et Composio
subtitle: ''
author: Shrijal Acharya
co_authors: []
series: null
date: '2025-06-24T21:03:03.788Z'
originalURL: https://freecodecamp.org/news/build-a-langgraph-composio-powered-discord-bot
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1750798930964/65dd7078-e4e7-42d0-a797-1e7d72690513.png
tags:
- name: AI
  slug: ai
- name: agentic AI
  slug: agentic-ai
- name: langgraph
  slug: langgraph
- name: bot
  slug: bot
seo_title: Comment cr√©er un bot Discord aliment√© par LangGraph et Composio
seo_desc: 'With the rise of AI tools over the past couple years, most of us are learning
  how to use them in our projects. And in this article, I‚Äôll teach you how to build
  a quick Discord bot with LangGraph and Composio.

  You‚Äôll use LangGraph nodes to build a bra...'
---

Avec l'essor des outils d'IA au cours des derni√®res ann√©es, la plupart d'entre nous apprenons √† les utiliser dans nos projets. Et dans cet article, je vais vous apprendre √† cr√©er rapidement un bot Discord avec LangGraph et Composio.

Vous utiliserez les n≈ìuds LangGraph pour cr√©er un flux de branchement qui traite les messages entrants et d√©tecte l'intention comme le chat, le support ou l'utilisation d'outils. Il les acheminera ensuite vers la logique appropri√©e en fonction de ce que dit l'utilisateur.

Je sais que cela peut sembler un peu √©trange d'utiliser LangGraph pour un bot Discord, mais vous verrez bient√¥t que ce projet est une mani√®re assez amusante de visualiser comment les flux de travail d'IA bas√©s sur des n≈ìuds fonctionnent r√©ellement.

Pour l'instant, le flux de travail est simple : vous d√©terminerez si l'utilisateur discute simplement, pose une question de support ou demande au bot d'effectuer une action, et vous r√©pondrez en cons√©quence.

**Ce que vous allez apprendre :** üëÄ

* Comment utiliser LangGraph pour cr√©er un flux de travail pilot√© par l'IA qui alimente la logique de votre bot.

* Comment vous pouvez int√©grer Composio pour permettre √† votre bot d'effectuer des actions r√©elles en utilisant des outils externes.

* Comment vous pouvez utiliser Discord.js et g√©rer diff√©rents types de messages comme les r√©ponses, les fils de discussion et les embeds.

* Comment vous pouvez maintenir un contexte par canal en utilisant l'historique des messages et le transmettre √† l'IA.

√Ä la fin de cet article, vous aurez un bot Discord assez d√©cent et fonctionnel que vous pourrez ajouter √† votre serveur. Il r√©pond aux utilisateurs en fonction du contexte des messages et dispose m√™me d'une assistance pour les appels d'outils ! (Et il y a un petit d√©fi pour vous afin d'impl√©menter quelque chose vous-m√™me.) üòâ

## Pr√©requis

Assurez-vous d'avoir Discord install√© sur votre machine afin de pouvoir tester facilement le bot.

Ce projet est con√ßu pour d√©montrer comment vous pouvez cr√©er un bot aliment√© par LangGraph et Composio. Avant de continuer, il est utile d'avoir une compr√©hension de base de :

* Comment travailler avec Node.js

* Une id√©e approximative de ce qu'est LangGraph et de son fonctionnement

* Comment travailler avec Discord.js

* Ce que sont les agents IA

Si vous n'√™tes pas s√ªr de l'un de ces points, essayez de suivre quand m√™me. Vous pourriez tr√®s bien comprendre les choses. Et si cela devient confus, vous pouvez toujours consulter le code source complet [ici](https://github.com/shricodev/discord-bot-langgraph-composio).

## Table des mati√®res

* [Comment configurer l'environnement](#heading-installation)

  * [Initialiser le projet](#heading-initialiser-le-projet)

  * [Installer les d√©pendances](#heading-installer-les-dependances)

  * [Configurer Composio](#heading-configurer-composio)

  * [Configurer l'int√©gration Discord](#heading-configurer-lintegration-discord)

  * [Ajouter les variables d'environnement](#heading-ajouter-les-variables-denvironnement)

* [Construire la logique de l'application](#heading-construire-la-logique-de-lapplication)

  * [D√©finir les types et les helpers utilitaires](#heading-definir-les-types-et-les-helpers-utilitaires)

  * [Impl√©menter le flux de travail LangGraph](#heading-implementer-le-flux-de-travail-langgraph)

  * [Configurer le client Discord.js](#heading-configurer-le-client-discordjs)

* [Conclusion](#heading-conclusion)

## Comment configurer l'environnement

Dans cette section, nous allons tout configurer pour construire le projet.

### Initialiser le projet

Initialisez une application Node.js avec la commande suivante :

üíÅ Ici, j'utilise Bun, mais vous pouvez choisir n'importe quel gestionnaire de paquets de votre choix.

```bash
mkdir discord-bot-langgraph && cd discord-bot-langgraph \
&& bun init -y
```

Maintenant que notre application Node.js est pr√™te, installons quelques d√©pendances.

### Installer les d√©pendances

Nous allons utiliser les principaux packages suivants et quelques autres packages d'assistance :

* [discord.js](https://discord.js.org) : Interagit avec l'API Discord

* [composio](https://composio.dev) : Ajoute la prise en charge de l'int√©gration des outils au bot

* [openai](https://platform.openai.com) : Permet des r√©ponses aliment√©es par l'IA

* [langchain](https://www.langchain.com) : G√®re les flux de travail LLM

* [zod](https://zod.dev) : Valide et analyse les donn√©es en toute s√©curit√©

```bash
bun add discord.js openai @langchain/core @langchain/langgraph \
langchain composio-core dotenv zod uuid
```

### Configurer Composio

üíÅ Vous utiliserez Composio pour ajouter des int√©grations √† votre application. Vous pouvez choisir l'int√©gration de votre choix, mais ici j'utilise Google Sheets.

Tout d'abord, avant de continuer, vous devez obtenir un acc√®s √† une cl√© API Composio.

Allez-y et cr√©ez un compte sur Composio, obtenez votre cl√© API et collez-la dans le fichier `.env` √† la racine du projet :

![Tableau de bord Composio](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/lkr1pys0txedp9vam4tt.png align="left")

```ini
COMPOSIO_API_KEY=<votre_cl√©_api_composio>
```

Authentifiez-vous avec la commande suivante :

```bash
composio login
```

Une fois cela fait, ex√©cutez la commande `composio whoami`, et si vous voyez quelque chose comme ci-dessous, vous √™tes connect√© avec succ√®s.

![R√©sultat de la commande `composio whoami`](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ifzbkw6u6bwnj68lwqxt.png align="left")

Vous y √™tes presque : maintenant, vous devez simplement configurer les int√©grations. Ici, j'utiliserai Google Sheets, mais encore une fois, vous pouvez configurer n'importe quelle int√©gration que vous souhaitez.

Ex√©cutez la commande suivante pour configurer l'int√©gration Google Sheets :

```bash
composio add googlesheets
```

Vous devriez voir un r√©sultat similaire √† ceci :

![Ajouter l'int√©gration Google Sheets de Composio](https://cdn.hashnode.com/res/hashnode/image/upload/v1750336813743/9079ef2b-dc2a-4b10-b001-50e4cf98f3c5.png align="center")

Rendez-vous √† l'URL qui est affich√©e, et vous devriez √™tre authentifi√© comme suit :

![Succ√®s de l'authentification Composio](https://cdn.hashnode.com/res/hashnode/image/upload/v1750325571006/b0864445-7471-471f-88eb-f2ec8d832b39.png align="center")

C'est tout. Vous avez ajout√© avec succ√®s l'int√©gration Google Sheets et pouvez acc√©der √† tous ses outils dans votre application.

Une fois termin√©, ex√©cutez la commande `composio integrations` pour v√©rifier si cela a fonctionn√©. Vous devriez voir une liste de toutes vos int√©grations :

![Liste des int√©grations Composio](https://cdn.hashnode.com/res/hashnode/image/upload/v1750325653419/4585b63a-5581-4102-92e4-a55dca018063.png align="center")

### Configurer l'int√©gration Discord

Cela est un peu hors sujet pour ce tutoriel, mais en gros, vous allez cr√©er une application/bot sur Discord et l'ajouter √† votre serveur.

Vous pouvez trouver un guide sur la fa√ßon de cr√©er et d'ajouter un bot √† votre serveur dans la [documentation Discord.js](https://discordjs.guide/preparations/adding-your-bot-to-servers.html#bot-invite-links).

Et oui, c'est gratuit si vous vous demandez si une √©tape ici n√©cessite un compte pro ou autre chose. üòâ

Assurez-vous de remplir ces trois variables d'environnement :

```ini
DISCORD_BOT_TOKEN=<VOTRE_TOKEN_DISCORD_BOT>
DISCORD_BOT_GUILD_ID=<VOTRE_ID_GUILD_DISCORD_BOT>
DISCORD_BOT_CHANNEL_ID=<VOTRE_ID_CHAINE_DISCORD_BOT>
```

### Ajouter les variables d'environnement

Vous aurez besoin de quelques autres variables d'environnement, y compris la cl√© API OpenAI, pour que le bot fonctionne.

Votre fichier `.env` final devrait ressembler √† ceci :

```ini
OPENAI_API_KEY=<VOTRE_CL√â_API_OPENAI>

COMPOSIO_API_KEY=<VOTRE_CL√â_API_COMPOSIO>

DISCORD_BOT_TOKEN=<VOTRE_TOKEN_DISCORD_BOT>
DISCORD_BOT_GUILD_ID=<VOTRE_ID_GUILD_DISCORD_BOT>
DISCORD_BOT_CHANNEL_ID=<VOTRE_ID_CHAINE_DISCORD_BOT>
```

## Construire la logique de l'application

Maintenant que vous avez pos√© toutes les bases, vous pouvez enfin commencer √† coder le projet.

### D√©finir les types et les helpers utilitaires

Commen√ßons par √©crire quelques fonctions d'assistance et d√©finir les types de donn√©es avec lesquels vous allez travailler.

Il est important dans toute application, surtout dans celles comme celle que nous construisons - qui est sujette aux erreurs en raison de multiples appels API - que nous configurions une journalisation d√©cente afin de savoir quand et comment les choses tournent mal.

Cr√©ez un nouveau fichier nomm√© `logger.ts` √† l'int√©rieur du r√©pertoire `utils` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/utils/logger.ts

export const DEBUG = "DEBUG";
export const INFO = "INFO";
export const WARN = "WARN";
export const ERROR = "ERROR";

export type LogLevel = typeof DEBUG | typeof INFO | typeof WARN | typeof ERROR;

// eslint-disable-next-line  @typescript-eslint/no-explicit-any
export function log(level: LogLevel, message: string, ...data: any[]) {
  const timestamp = new Date().toLocaleString();
  const prefix = `[${timestamp}] [${level}]`;

  switch (level) {
    case ERROR:
      console.error(prefix, message, ...data);
      break;
    case WARN:
      console.warn(prefix, message, ...data);
      break;
    default:
      console.log(prefix, message, ...data);
  }
}
```

Cela commence d√©j√† √† bien se pr√©senter. Pourquoi ne pas √©crire un petit validateur de variables d'environnement ? Ex√©cutez cela lors du d√©marrage initial du programme, et si quelque chose ne va pas, l'application quittera avec des logs clairs afin que les utilisateurs sachent si des variables d'environnement sont manquantes.

Cr√©ez un nouveau fichier nomm√© `env-validator.ts` dans le r√©pertoire `utils` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/utils/env-validator.ts

import { log, ERROR } from "./logger.js";

export const OPENAI_API_KEY = "OPENAI_API_KEY";

export const DISCORD_BOT_TOKEN = "DISCORD_BOT_TOKEN";
export const DISCORD_BOT_GUILD_ID = "DISCORD_BOT_GUILD_ID";
export const DISCORD_BOT_CLIENT_ID = "DISCORD_BOT_CLIENT_ID";

export const COMPOSIO_API_KEY = "COMPOSIO_API_KEY";

export const validateEnvVars = (requiredEnvVars: string[]): void => {
  const missingVars: string[] = [];

  for (const envVar of requiredEnvVars) {
    if (!process.env[envVar]) {
      missingVars.push(envVar);
    }
  }

  if (missingVars.length > 0) {
    log(
      ERROR,
      "variables d'environnement requises manquantes. veuillez cr√©er un fichier .env et ajouter les √©l√©ments suivants :",
    );
    missingVars.forEach((envVar) => console.error(`- ${envVar}`));
    process.exit(1);
  }
};
```

Maintenant, d√©finissons √©galement le type de donn√©es avec lesquelles vous allez travailler :

Cr√©ez un nouveau fichier nomm√© `types.ts` √† l'int√©rieur du r√©pertoire `types` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/types/types.ts

export const QUESTION = "QUESTION";
export const HELP = "HELP";
export const SUPPORT = "SUPPORT";
export const OTHER = "OTHER";
export const TOOL_CALL_REQUEST = "TOOL_CALL_REQUEST";

export type FinalAction =
  | { type: "REPLY"; content: string }
  | { type: "REPLY_IN_THREAD"; content: string }
  | {
      type: "CREATE_EMBED";
      title: string;
      description: string;
      roleToPing?: string;
    };

export type MessageChoice =
  | typeof SUPPORT
  | typeof OTHER
  | typeof TOOL_CALL_REQUEST;

export type SupportTicketType = typeof QUESTION | typeof HELP;

export type Message = {
  author: string;
  content: string;
};

export type SupportTicketQuestion = {
  description: string;
  answer: string;
};

export type SupportTicket = {
  type?: SupportTicketType;
  question?: SupportTicketQuestion;
};

export type ToolCallRequestAction = {
  // actionLog n'est pas destin√© √† √™tre montr√© √† l'utilisateur final.
  // Ceci est uniquement √† des fins de journalisation.
  actionLog: string;
  status: "success" | "failed" | "acknowledged";
};
```

Les types sont assez explicites, mais voici un bref aper√ßu.

`Message` contient l'entr√©e de l'utilisateur et l'auteur. Chaque message peut √™tre marqu√© comme support, une demande d'appel d'outil, ou simplement autre, comme du spam ou une conversation anodine.

Les messages de support sont √©galement √©tiquet√©s comme aide ou question en utilisant `SupportTicketType`.

Le graphique retourne une `FinalAction`, qui peut √™tre une r√©ponse directe, une r√©ponse dans un fil de discussion, ou un embed. Si c'est `CREATE_EMBED` et que `roleToPing` est d√©fini, cela indique une aide de support, donc nous pouvons mentionner le mod√©rateur.

Pour les r√©ponses bas√©es sur des outils, `ToolCallRequestAction` stocke le statut et un journal interne utilis√© pour le d√©bogage.

Maintenant, vous avez besoin d'une derni√®re fonction d'assistance √† utiliser dans vos n≈ìuds pour extraire la r√©ponse du LLM. Cr√©ez un nouveau fichier nomm√© `helpers.ts` et ajoutez le code suivant :

```typescript
// üëá discord-bot-langgraph/utils/helpers.ts

import type { AIMessage } from "@langchain/core/messages";

export function extractStringFromAIMessage(
  message: AIMessage,
  fallback: string = "Aucune r√©ponse valide g√©n√©r√©e par le LLM.",
): string {
  if (typeof message.content === "string") {
    return message.content;
  }

  if (Array.isArray(message.content)) {
    const textContent = message.content
      .map((item) => (typeof item === "string" ? item : ""))
      .join(" ");
    return textContent.trim() || fallback;
  }

  return fallback;
}
```

Vous √™tes pr√™t pour l'instant avec ces fonctions d'assistance en place. Maintenant, vous pouvez commencer √† coder la logique.

### Impl√©menter le flux de travail LangGraph

Maintenant que vous avez d√©fini les types, structurez votre graphique et connectez-le avec quelques ar√™tes.

Cr√©ez un nouveau fichier nomm√© `graph.ts` √† l'int√©rieur du r√©pertoire `src` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/src/graph.ts

import { Annotation, END, START, StateGraph } from "@langchain/langgraph";
import {
  type FinalAction,
  type ToolCallRequestAction,
  type Message,
  type MessageChoice,
  type SupportTicket,
} from "../types/types.js";
import {
  processToolCall,
  processMessage,
  processOther,
  processSupport,
  processSupportHelp,
  processSupportQuestion,
} from "./nodes.js";
import { processMessageEdges, processSupportEdges } from "./edges.js";

const state = Annotation.Root({
  message: Annotation<Message>(),
  previousMessages: Annotation<Message[]>(),
  messageChoice: Annotation<MessageChoice>(),
  supportTicket: Annotation<SupportTicket>(),
  toolCallRequest: Annotation<ToolCallRequestAction>(),
  finalAction: Annotation<FinalAction>(),
});

export type State = typeof state.State;
export type Update = typeof state.Update;

export function initializeGraph() {
  const workflow = new StateGraph(state);

  workflow
    .addNode("process-message", processMessage)
    .addNode("process-support", processSupport)
    .addNode("process-other", processOther)

    .addNode("process-support-question", processSupportQuestion)
    .addNode("process-support-help", processSupportHelp)
    .addNode("process-tool-call", processToolCall)

    // Configuration des ar√™tes commence ici....
    .addEdge(START, "process-message")

    .addConditionalEdges("process-message", processMessageEdges)
    .addConditionalEdges("process-support", processSupportEdges)

    .addEdge("process-other", END)
    .addEdge("process-support-question", END)
    .addEdge("process-support-help", END)
    .addEdge("process-tool-call", END);

  const graph = workflow.compile();

  // Pour obtenir le graphique en png
  // getGraph() est d√©pr√©ci√© cependant
  // Bun.write("graph/graph.png", await graph.getGraph().drawMermaidPng());

  return graph;
}
```

La fonction `initializeGraph`, comme son nom l'indique, retourne le graphique que vous pouvez utiliser pour ex√©cuter le flux de travail.

Le n≈ìud `process-message` est le point de d√©part du graphique. Il prend le message de l'utilisateur, le traite et le route vers le n≈ìud suivant appropri√© : `process-support`, `process-tool-call` ou `process-other`.

Le n≈ìud `process-support` classe davantage le message de support et d√©cide s'il doit aller √† `process-support-help` ou `process-support-question`.

Le n≈ìud `process-tool-call` g√®re les messages lorsque l'utilisateur essaie de d√©clencher un outil ou une action.

Le n≈ìud `process-other` g√®re tout ce qui ne rel√®ve pas des cat√©gories de support ou d'appel d'outil. Ce sont des r√©ponses g√©n√©rales ou de secours.

Pour vous aider √† visualiser comment les choses vont se structurer, voici √† quoi ressemble le graphique avec tous les diff√©rents n≈ìuds (√† travailler !) :

![N≈ìuds LangGraph pour le flux de travail du bot Discord](https://cdn.hashnode.com/res/hashnode/image/upload/v1750327093884/fa8e6b4e-ca61-4900-9b3b-7b3a2863c296.png align="center")

Pour tout connecter, vous devez d√©finir des ar√™tes entre les n≈ìuds, y compris des ar√™tes conditionnelles qui d√©cident dynamiquement de l'√©tape suivante en fonction de l'√©tat.

Cr√©ez un nouveau fichier nomm√© `edges.ts` √† l'int√©rieur du r√©pertoire `src` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/src/edges.ts

import { END } from "@langchain/langgraph";
import { type State } from "./graph.js";
import { QUESTION, OTHER, SUPPORT, TOOL_CALL_REQUEST } from "../types/types.js";
import { log, WARN } from "../utils/logger.js";

export const processMessageEdges = (
  state: State,
): "process-support" | "process-other" | "process-tool-call" | "__end__" => {
  if (!state.messageChoice) {
    log(WARN, "state.messageChoice est ind√©fini. Retour...");
    return END;
  }

  switch (state.messageChoice) {
    case SUPPORT:
      return "process-support";
    case TOOL_CALL_REQUEST:
      return "process-tool-call";
    case OTHER:
      return "process-other";
    default:
      log(WARN, "choix de message inconnu. Retour...");
      return END;
  }
};

export const processSupportEdges = (
  state: State,
): "process-support-question" | "process-support-help" | "__end__" => {
  if (!state.supportTicket?.type) {
    log(WARN, "state.supportTicket.type est ind√©fini. Retour...");
    return END;
  }

  return state.supportTicket.type === QUESTION
    ? "process-support-question"
    : "process-support-help";
};
```

Ce sont les ar√™tes qui connectent diff√©rents n≈ìuds dans votre application. Elles dirigent le flux dans votre graphique.

Les choses se mettent vraiment en place - alors terminons la logique principale en impl√©mentant tous les n≈ìuds pour votre application.

Cr√©ez un nouveau fichier nomm√© `nodes.ts` √† l'int√©rieur du r√©pertoire `src` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/src/nodes.ts

import { type State, type Update } from "./graph.js";
import { ChatOpenAI } from "@langchain/openai";
import { z } from "zod";
import {
  HELP,
  TOOL_CALL_REQUEST,
  OTHER,
  QUESTION,
  SUPPORT,
} from "../types/types.js";
import { extractStringFromAIMessage } from "../utils/helpers.js";
import { OpenAIToolSet } from "composio-core";
import type { ChatCompletionMessageToolCall } from "openai/resources/chat/completions.mjs";
import { v4 as uuidv4 } from "uuid";
import { DEBUG, ERROR, INFO, log, WARN } from "../utils/logger.js";
import {
  SystemMessage,
  HumanMessage,
  ToolMessage,
  BaseMessage,
} from "@langchain/core/messages";

// n'h√©sitez pas √† utiliser n'importe quel mod√®le. Ici, j'utilise gpt-4o-mini
const model = "gpt-4o-mini";

const toolset = new OpenAIToolSet();
const llm = new ChatOpenAI({
  model,
  apiKey: process.env.OPENAI_API_KEY,
  temperature: 0,
});

export const processMessage = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans le traitement du message :", state.message);

  const llm = new ChatOpenAI({
    model,
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
  });

  const structuredLlm = llm.withStructuredOutput(
    z.object({
      type: z.enum([SUPPORT, OTHER, TOOL_CALL_REQUEST]).describe(`
Cat√©goriser le message de l'utilisateur :
- ${SUPPORT} : Support technique, aide pour les probl√®mes ou questions sur l'IA.
- ${TOOL_CALL_REQUEST} : L'utilisateur demande au bot d'effectuer une action d'outil (par exemple, "envoyer un email", "r√©sumer le chat", "r√©sumer les feuilles Google").
- ${OTHER} : Conversation g√©n√©rale, spam ou messages hors sujet.
`),
    }),
  );

  const res = await structuredLlm.invoke([
    [
      "system",
      `Vous √™tes un expert en analyse de messages IA. Vous devez cat√©goriser le message dans
l'une de ces cat√©gories :

- ${SUPPORT} : Si le message demande un support technique, de l'aide pour un probl√®me ou des questions sur les IA et les LLM.
- ${TOOL_CALL_REQUEST} : Si le message est une commande directe ou une demande pour que le bot effectue une action en utilisant des outils/services externes. Exemples : "R√©sum√© d'un document ou d'une feuille Google", "R√©sum√© de la derni√®re heure de chat", "Envoyer un email √† l'√©quipe de d√©veloppement concernant ce bug", "Cr√©er une carte Trello pour cette demande de fonctionnalit√©". Priorisez cela si l'utilisateur demande au bot de *faire* quelque chose au-del√† de simplement r√©pondre.
- ${OTHER} : Pour les discussions g√©n√©rales, le spam, les messages hors sujet ou tout ce qui ne correspond pas √† ${SUPPORT} ou ${TOOL_CALL_REQUEST}.
`,
    ],
    ["human", state.message.content],
  ]);

  return {
    messageChoice: res.type,
  };
};

export const processSupport = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans le support :", state.message);

  const llm = new ChatOpenAI({
    model,
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
  });

  const structuredLlm = llm.withStructuredOutput(
    z.object({
      type: z.enum([QUESTION, HELP]).describe(`
Type de support n√©cessaire :
- ${QUESTION} : L'utilisateur pose une question sp√©cifique en qu√™te d'informations ou d'une r√©ponse.
- ${HELP} : L'utilisateur a besoin d'une assistance plus large, de conseils ou signale un probl√®me n√©cessitant une intervention/d√©pannage.
`),
    }),
  );

  const res = await structuredLlm.invoke([
    [
      "system",
      `
Vous √™tes un analyseur de tickets de support. √âtant donn√© un message de support, cat√©gorisez-le comme ${QUESTION} ou ${HELP}.
- ${QUESTION} : Pour les questions sp√©cifiques.
- ${HELP} : Pour les demandes d'assistance, de d√©pannage ou de rapports de probl√®mes.
`,
    ],
    ["human", state.message.content],
  ]);

  return {
    supportTicket: {
      ...state.supportTicket,
      type: res.type,
    },
  };
};

export const processSupportHelp = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans l'aide de support :", state.message);

  return {
    supportTicket: {
      ...state.supportTicket,
    },
    finalAction: {
      type: "CREATE_EMBED",
      title: "üö® Aide n√©cessaire !",
      description: `Une nouvelle demande d'aide a √©t√© soulev√©e par **@${state.message.author}**.\n\n**Requ√™te :**\n> ${state.message.content}`,
      roleToPing: process.env.DISCORD_SUPPORT_MOD_ID,
    },
  };
};

export const processSupportQuestion = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans la cat√©gorie de question de support :", state.message);

  const llm = new ChatOpenAI({
    model,
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
  });

  const systemPrompt = `
Vous √™tes un assistant IA utile sp√©cialis√© dans l'IA et les LLM. R√©pondez
√† la question de l'utilisateur de mani√®re concise et pr√©cise en fonction des connaissances g√©n√©rales dans
ces domaines. Si la question est en dehors de ce cadre (par exemple, des conseils personnels,
sujets non techniques), indiquez poliment que vous ne pouvez pas r√©pondre. Question de l'utilisateur :
`;

  const res = await llm.invoke([
    ["system", systemPrompt],
    ["human", state.message.content],
  ]);

  const llmResponse = extractStringFromAIMessage(res);
  return {
    supportTicket: {
      ...state.supportTicket,
      question: {
        description: state.message.content,
        answer: llmResponse,
      },
    },
    finalAction: {
      type: "REPLY",
      content: llmResponse,
    },
  };
};

export const processOther = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans la cat√©gorie autre :", state.message);

  const response =
    "Cela semble √™tre un message g√©n√©ral. Je suis l√† pour aider avec le support technique ou effectuer des actions sp√©cifiques si vous le demandez. Comment puis-je vous aider avec cela ?";

  return {
    finalAction: {
      type: "REPLY_IN_THREAD",
      content: response,
    },
  };
};
```

Il n'y a pas grand-chose √† expliquer pour ces n≈ìuds. Chaque n≈ìud dans le flux fonctionne comme un classificateur de messages. Il lance une instance de Chat LLM et utilise une sortie structur√©e pour s'assurer que le mod√®le retourne une √©tiquette sp√©cifique parmi un ensemble pr√©d√©fini comme `QUESTION` ou `HELP` pour les messages de support. L'invite syst√®me d√©finit clairement ce que signifie chaque √©tiquette, et votre message utilisateur est transmis pour classification.

Vous y √™tes presque. Mais il manque une pi√®ce. Pouvez-vous la rep√©rer ?

Le n≈ìud `process-tool-call` qui est cens√© g√©rer le flux de travail lorsque l'utilisateur demande √† utiliser un outil. C'est une grande partie du flux de travail.

C'est un peu plus long, alors je vais l'expliquer s√©par√©ment.

Modifiez le fichier `nodes.ts` ci-dessus pour ajouter le n≈ìud manquant :

```typescript
// üëá discord-bot-langgraph/src/nodes.ts

// Reste du code...
export const processToolCall = async (state: State): Promise<Update> => {
  log(DEBUG, "message dans la cat√©gorie de demande d'appel d'outil :", state.message);

  const structuredOutputType = z.object({
    service: z
      .string()
      .describe("Le service cible (par exemple, 'email', 'discord')."),
    task: z
      .string()
      .describe(
        "Une description concise de la t√¢che (par exemple, 'envoyer un email √† X', 'r√©sumer le chat r√©cent', 'cr√©er la t√¢che Y').",
      ),
    details: z
      .string()
      .optional()
      .describe(
        "Tous les d√©tails ou param√®tres sp√©cifiques extraits du message pertinents pour la t√¢che.",
      ),
  });

  const structuredLlm = llm.withStructuredOutput(structuredOutputType);

  let parsedActionDetails: z.infer<typeof structuredOutputType> = {
    service: "unknown",
    task: "perform a requested action",
  };

  try {
    const res = await structuredLlm.invoke([
      [
        "system",
        `Analyser la demande de l'utilisateur pour identifier une action. Extraire le service cible, une description de la t√¢che et tous les d√©tails ou param√®tres pertinents.
      Exemples :
      - "Rappelle-moi de v√©rifier les emails √† 17h" : service : calendrier/rappel, t√¢che : d√©finir un rappel, d√©tails : v√©rifier les emails √† 17h
      - "Envoyer un r√©sum√© de cette conversation au canal #general" : service : discord, t√¢che : envoyer un r√©sum√© au canal, d√©tails : canal #general
      - "Cr√©er un rapport de bug pour 'l'√©chec de la connexion sur mobile'" : service : gestionnaire de projet, t√¢che : cr√©er un rapport de bug, d√©tails : titre 'l'√©chec de la connexion sur mobile'`,
      ],
      ["human", state.message.content],
    ]);

    parsedActionDetails = res;
    log(INFO, "d√©tails de l'action d'analyse initiale :", parsedActionDetails);
  } catch (error) {
    log(ERROR, "erreur d'analyse initiale :", error);
    return {
      toolCallRequest: {
        actionLog: `√âchec de l'analyse de la demande de l'utilisateur : ${state.message.content}`,
        status: "failed",
      },
      finalAction: {
        type: "REPLY_IN_THREAD",
        content:
          "Je suis d√©sol√©, j'ai eu du mal √† comprendre cette action. Pourriez-vous la reformuler, s'il vous pla√Æt ?",
      },
    };
  }

  try {
    log(INFO, "r√©cup√©ration des outils composio");
    const tools = await toolset.getTools({
      apps: ["GOOGLESHEETS"],
    });

    log(INFO, `r√©cup√©r√© ${tools.length} outils. Erreurs si > 128 pour OpenAI :`);

    if (tools.length === 0) {
      log(WARN, "aucun outil r√©cup√©r√© depuis Composio. passage...");
      return {
        toolCallRequest: {
          actionLog: `Service : ${parsedActionDetails.service}, T√¢che : ${parsedActionDetails.task}. Aucun outil composio trouv√©`,
          status: "failed",
        },
        finalAction: {
          type: "REPLY_IN_THREAD",
          content: "Je n'ai pas trouv√© d'outils pour effectuer votre action.",
        },
      };
    }

    log(DEBUG, "d√©but de la boucle d'ex√©cution d'outil it√©rative");

    const conversationHistory: BaseMessage[] = [
      new SystemMessage(
        "Vous √™tes un assistant utile qui effectue des appels d'outils. Votre t√¢che est de comprendre la demande de l'utilisateur et d'utiliser les outils disponibles pour r√©pondre compl√®tement √† la demande. Vous pouvez utiliser plusieurs outils en s√©quence pour accomplir des t√¢ches complexes. Fournissez toujours un r√©sum√© bref et conversationnel de ce que vous avez accompli apr√®s avoir utilis√© les outils.",
      ),
      new HumanMessage(state.message.content),
    ];

    let totalToolsUsed = 0;
    let finalResponse: string | null = null;

    const maxIterations = 5;
    let iteration = 0;

    while (iteration < maxIterations) {
      iteration++;
      log(
        DEBUG,
        `It√©ration ${iteration} : appel du LLM avec ${tools.length} outils`,
      );

      const llmResponse = await llm.invoke(conversationHistory, {
        tools: tools,
      });

      log(DEBUG, `R√©ponse du LLM √† l'it√©ration ${iteration} :`, llmResponse);

      const toolCalls = llmResponse.tool_calls;

      if ((!toolCalls || toolCalls.length === 0) && llmResponse.content) {
        finalResponse =
          typeof llmResponse.content === "string"
            ? llmResponse.content
            : JSON.stringify(llmResponse.content);
        log(
          INFO,
          `R√©ponse finale re√ßue apr√®s ${iteration} it√©rations :`,
          finalResponse,
        );
        break;
      }

      if (toolCalls && toolCalls.length > 0) {
        log(
          INFO,
          `It√©ration ${iteration} : ex√©cution de ${toolCalls.length} outil(s)`,
        );
        totalToolsUsed += toolCalls.length;

        conversationHistory.push(llmResponse);

        for (const toolCall of toolCalls) {
          log(
            INFO,
            `Ex√©cution de l'outil : ${toolCall.name} avec les arguments :`,
            toolCall.args,
          );

          const composioCompatibleToolCall: ChatCompletionMessageToolCall = {
            id: toolCall.id || uuidv4(),
            type: "function",
            function: {
              name: toolCall.name,
              arguments: JSON.stringify(toolCall.args),
            },
          };

          let toolOutputContent: string;
          try {
            const executionResult = await toolset.executeToolCall(
              composioCompatibleToolCall,
            );
            log(
              INFO,
              `R√©sultat de l'ex√©cution de l'outil ${toolCall.name} :`,
              executionResult,
            );
            toolOutputContent = JSON.stringify(executionResult);
          } catch (toolError) {
            log(ERROR, `Erreur d'ex√©cution de l'outil ${toolCall.name} :`, toolError);
            const errorMessage =
              toolError instanceof Error
                ? toolError.message
                : String(toolError);

            toolOutputContent = `Erreur : ${errorMessage}`;
          }

          conversationHistory.push(
            new ToolMessage({
              content: toolOutputContent,
              tool_call_id: toolCall.id || uuidv4(),
            }),
          );
        }

        continue;
      }

      log(
        WARN,
        `It√©ration ${iteration} : le LLM n'a fourni aucun appel d'outil ou contenu`,
      );
      break;
    }

    let userFriendlyResponse: string;

    if (totalToolsUsed > 0) {
      log(DEBUG, "G√©n√©ration d'un r√©sum√© convivial pour l'utilisateur √† l'aide du LLM");

      try {
        const summaryResponse = await llm.invoke([
          new SystemMessage(
            "Vous √™tes charg√© de cr√©er un r√©sum√© bref et convivial pour un utilisateur Discord concernant les actions qui viennent d'√™tre effectu√©es. Gardez-le conversationnel, en moins de 2-3 phrases, et concentrez-vous sur ce qui a √©t√© accompli plut√¥t que sur les d√©tails techniques. Commencez par des phrases comme 'Termin√© !', 'R√©ussi', 'Tout est pr√™t !', etc.",
          ),
          new HumanMessage(
            `L'utilisateur a demand√© : "${state.message.content}"

J'ai utilis√© ${totalToolsUsed} outils sur ${iteration} it√©rations pour compl√©ter sa demande. ${finalResponse ? `Ma r√©ponse finale √©tait : ${finalResponse}` : "La t√¢che a √©t√© compl√©t√©e avec succ√®s."}

G√©n√©rez un r√©sum√© bref et convivial de ce qui a √©t√© accompli.`,
          ),
        ]);

        userFriendlyResponse =
          typeof summaryResponse.content === "string"
            ? summaryResponse.content
            : `Termin√© ! J'ai compl√©t√© votre demande en utilisant ${totalToolsUsed} action${totalToolsUsed > 1 ? "s" : ""}.`;

        log(INFO, "R√©sum√© convivial g√©n√©r√© :", userFriendlyResponse);
      } catch (summaryError) {
        log(ERROR, "√âchec de la g√©n√©ration du r√©sum√© :", summaryError);
        userFriendlyResponse = `Tout est pr√™t ! J'ai compl√©t√© votre demande en utilisant ${totalToolsUsed} action${totalToolsUsed > 1 ? "s" : ""}.`;
      }
    } else {
      userFriendlyResponse =
        finalResponse ||
        `J'ai compris votre demande concernant '${parsedActionDetails.task}' mais je n'ai pas trouv√© les bons outils pour la compl√©ter.`;
    }

    const actionLog = `Service : ${parsedActionDetails.service}, T√¢che : ${parsedActionDetails.task}. Utilis√© ${totalToolsUsed} outils sur ${iteration} it√©rations.`;

    return {
      toolCallRequest: {
        actionLog,
        status: totalToolsUsed > 0 ? "success" : "acknowledged",
      },
      finalAction: {
        type: "REPLY_IN_THREAD",
        content: userFriendlyResponse,
      },
    };
  } catch (error) {
    log(ERROR, "traitement de l'appel d'outil avec Composio :", error);
    const errorMessage = error instanceof Error ? error.message : String(error);

    return {
      toolCallRequest: {
        actionLog: `Erreur lors de l'appel d'outil (Service : ${parsedActionDetails.service}, T√¢che : ${parsedActionDetails.task}). Erreur : ${errorMessage}`,
        status: "failed",
      },
      finalAction: {
        type: "REPLY_IN_THREAD",
        content: "D√©sol√©, j'ai rencontr√© une erreur lors du traitement de votre demande.",
      },
    };
  }
};
```

La partie jusqu'au premier bloc try-catch est la m√™me. Jusqu'√† ce point, vous essayez de d√©terminer l'outil que l'utilisateur essaie d'appeler. Voici la partie int√©ressante : g√©rer r√©ellement les appels d'outils.

√Ä ce stade, vous devez r√©cup√©rer les outils de Composio. Ici, je passe simplement Google Sheets comme option √† des fins de d√©monstration, mais vous pourriez utiliser litt√©ralement n'importe quoi une fois que vous vous √™tes authentifi√© comme montr√© ci-dessus.

Apr√®s avoir r√©cup√©r√© les outils, vous entrez dans une boucle o√π le LLM peut les utiliser. Il examine l'historique de la conversation et d√©cide quels outils appeler. Vous ex√©cutez ces appels, vous alimentez les r√©sultats et vous r√©p√©tez jusqu'√† 5 it√©rations ou jusqu'√† ce que le LLM donne une r√©ponse finale.

Cette boucle s'ex√©cute jusqu'√† 5 fois comme mesure de s√©curit√© pour que le LLM ne se retrouve pas dans un √©change sans fin.

Si des outils ont √©t√© utilis√©s, vous demandez au LLM d'√©crire un r√©sum√© convivial pour l'utilisateur au lieu de d√©verser la r√©ponse JSON brute. Si aucun outil n'a fonctionn√© ou n'a correspondu, informez simplement l'utilisateur que vous n'avez pas pu effectuer l'action.

Maintenant, avec cela, vous avez termin√© la partie difficile (je veux dire, c'√©tait assez facile, non ?). √Ä partir de l√†, vous devez simplement configurer et travailler avec l'API Discord en utilisant Discord.js.

### Configurer le client Discord.js

Dans cette application, vous utilisez des commandes slash. Pour utiliser des commandes slash dans Discord, vous devez d'abord les enregistrer. Vous pouvez le faire manuellement, mais pourquoi ne pas l'automatiser √©galement ? üòâ

Cr√©ez un nouveau fichier nomm√© `slash-deploy.ts` √† l'int√©rieur du r√©pertoire `utils` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/utils/slash-deploy.ts

import { REST, Routes } from "discord.js";
import dotenv from "dotenv";
import { log, INFO, ERROR } from "./logger.js";
import {
  DISCORD_BOT_TOKEN,
  DISCORD_BOT_GUILD_ID,
  OPENAI_API_KEY,
  DISCORD_BOT_CLIENT_ID,
  validateEnvVars,
} from "./env-validator.js";

dotenv.config();

const requiredEnvVars = [
  DISCORD_BOT_TOKEN,
  DISCORD_BOT_GUILD_ID,
  DISCORD_BOT_CLIENT_ID,
  OPENAI_API_KEY,
];
validateEnvVars(requiredEnvVars);

const commands = [
  {
    name: "ask",
    description: "Posez une question √† l'assistant IA ou donnez-lui une commande.",
    options: [
      {
        name: "prompt",
        type: 3,
        description: "Votre question ou commande pour le bot",
        required: true,
      },
    ],
  },
];

const rest = new REST({ version: "10" }).setToken(
  process.env.DISCORD_BOT_TOKEN!,
);

(async () => {
  try {
    log(INFO, "d√©ploiement des commandes slash(/)");
    await rest.put(
      Routes.applicationGuildCommands(
        process.env.DISCORD_BOT_CLIENT_ID!,
        process.env.DISCORD_BOT_GUILD_ID!,
      ),
      {
        body: commands,
      },
    );

    log(INFO, "commandes slash(/) d√©ploy√©es");
  } catch (error) {
    log(ERROR, "d√©ploiement des commandes slash(/) :", error);
  }
})();
```

Voyez votre fonction `validateEnvVars` en action ? Ici, vous sp√©cifiez les variables d'environnement qui doivent √™tre d√©finies avant d'ex√©cuter le programme. Si certaines sont manquantes et que vous essayez d'ex√©cuter le programme, vous obtiendrez une erreur.

![Sortie de la commande √©chou√©e pour le d√©ploiement de la commande slash vers Discord](https://cdn.hashnode.com/res/hashnode/image/upload/v1750340614800/ce0b37bc-647c-4b94-9099-2e396b0ffa93.png align="center")

La mani√®re dont vous d√©ployez les commandes slash vers Discord est en utilisant l'API `REST` fournie par `discord.js`, sp√©cifiquement en appelant `rest.put` avec vos donn√©es de commande et la guilde cible.

Maintenant, ex√©cutez simplement le script bun `commands:deploy` et vous devriez avoir `/ask` enregistr√© comme une commande slash dans votre Discord.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1750340646555/2d5b22df-cd43-4e54-b985-b64576831316.png align="center")

√Ä ce stade, vous devriez voir la commande slash `/ask` disponible dans votre serveur. Il ne reste plus qu'√† cr√©er le fichier `index.ts`, qui sera le point d'entr√©e de votre bot Discord.

Cr√©ez un nouveau fichier nomm√© `index.ts` √† l'int√©rieur du r√©pertoire `src` et ajoutez les lignes de code suivantes :

```typescript
// üëá discord-bot-langgraph/src/index.ts

import dotenv from "dotenv";
import {
  Client,
  Events,
  GatewayIntentBits,
  EmbedBuilder,
  type Interaction,
} from "discord.js";
import { initializeGraph } from "./graph.js";
import { type Message as ChatMessage } from "../types/types.js";
import { ERROR, INFO, log } from "../utils/logger.js";
import {
  DISCORD_BOT_TOKEN,
  DISCORD_BOT_GUILD_ID,
  OPENAI_API_KEY,
  validateEnvVars,
  DISCORD_BOT_CLIENT_ID,
  COMPOSIO_API_KEY,
} from "../utils/env-validator.js";

dotenv.config();

const requiredEnvVars = [
  DISCORD_BOT_CLIENT_ID,
  DISCORD_BOT_TOKEN,
  DISCORD_BOT_GUILD_ID,

  OPENAI_API_KEY,

  COMPOSIO_API_KEY,
];
validateEnvVars(requiredEnvVars);

const graph = initializeGraph();

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent,
  ],
});

// utilisez une map pour stocker l'historique par canal afin que cela fonctionne correctement avec tous les
// canaux et non pour un canal sp√©cifique.
const channelHistories = new Map<string, ChatMessage[]>();

client.on(Events.ClientReady, async (readyClient) => {
  log(INFO, `connect√© en tant que ${readyClient.user.tag}. pr√™t √† traiter les commandes !`);
});

client.on(Events.InteractionCreate, async (interaction: Interaction) => {
  if (!interaction.isChatInputCommand()) return;
  if (interaction.commandName !== "ask") return;

  const userPrompt = interaction.options.getString("prompt", true);
  const user = interaction.user;
  const channelId = interaction.channelId;

  if (!channelHistories.has(channelId)) channelHistories.set(channelId, []);

  const messageHistory = channelHistories.get(channelId)!;

  const currentUserMessage: ChatMessage = {
    author: user.username,
    content: userPrompt,
  };

  const graphInput = {
    message: currentUserMessage,
    previousMessages: [...messageHistory],
  };

  messageHistory.push(currentUserMessage);
  if (messageHistory.length > 20) messageHistory.shift();

  try {
    await interaction.reply({
      content: "Hmm... traitement de votre demande ! üêÄ",
    });

    const finalState = await graph.invoke(graphInput);

    if (!finalState.finalAction) {
      log(ERROR, "aucune action finale trouv√©e");
      await interaction.editReply({
        content: "Je suis d√©sol√©, je n'ai pas pu traiter votre demande.",
      });
      return;
    }

    const userPing = `<@${user.id}>`;
    const action = finalState.finalAction;

    const quotedPrompt = `üó£üòÄ "${userPrompt}"`;

    switch (action.type) {
      case "REPLY":
        await interaction.editReply({
          content: `${userPing}\n\n${quotedPrompt}\n\n${action.content}`,
        });
        break;

      case "REPLY_IN_THREAD":
        if (!interaction.channel || !("threads" in interaction.channel)) {
          await interaction.editReply({
            content: "Impossible de cr√©er un fil dans ce canal",
          });
          return;
        }

        try {
          const thread = await interaction.channel.threads.create({
            name: `Action : ${userPrompt.substring(0, 50)}...`,
            autoArchiveDuration: 60,
          });

          await thread.send(
            `${userPing}\n\n${quotedPrompt}\n\n${action.content}`,
          );
          await interaction.editReply({
            content: `J'ai cr√©√© un fil pour vous : ${thread.url}`,
          });
        } catch (threadError) {
          log(ERROR, "√©chec de la cr√©ation ou de la r√©ponse dans le fil :", threadError);
          await interaction.editReply({
            content: `${userPing}\n\n${quotedPrompt}\n\nJ'ai essay√© de cr√©er un fil mais j'ai √©chou√©. Voici votre r√©ponse :\n\n${action.content}`,
          });
        }
        break;

      case "CREATE_EMBED": {
        const embed = new EmbedBuilder()
          .setColor(0xffa500)
          .setTitle(action.title)
          .setDescription(action.description)
          .setTimestamp()
          .setFooter({ text: "Syst√®me de support" });

        const rolePing = action.roleToPing ? `<@${action.roleToPing}>` : "";

        await interaction.editReply({
          content: `${userPing} ${rolePing}`,
          embeds: [embed],
        });
        break;
      }
    }
  } catch (error) {
    log(ERROR, "g√©n√©ration de la r√©ponse IA ou traitement du graphique :", error);
    const errorMessage =
      "d√©sol√©, j'ai rencontr√© une erreur lors du traitement de votre demande.";
    if (interaction.replied || interaction.deferred) {
      await interaction.followUp({ content: errorMessage, ephemeral: true });
    } else {
      await interaction.reply({ content: errorMessage, ephemeral: true });
    }
  }
});

const token = process.env.DISCORD_BOT_TOKEN!;
client.login(token);
```

Au c≈ìur de notre bot se trouve l'objet `Client` de `discord.js`. Cela repr√©sente votre bot et g√®re tout, de la connexion √† l'API de Discord √† l'√©coute d'√©v√©nements comme les messages des utilisateurs ou les interactions.

Qu'en est-il de cette intention ? Discord utilise les intentions comme un moyen pour les bots de d√©clarer √† quel type de donn√©es ils veulent acc√©der. Dans notre cas :

* `Guilds` permet au bot de se connecter aux serveurs

* `GuildMessages` lui permet de voir les messages

* `MessageContent` donne acc√®s au contenu r√©el des messages

Ce sont des intentions assez standard, et il en existe beaucoup d'autres en fonction des diff√©rents cas d'utilisation. Vous pouvez toujours les consulter tous [ici](https://discordjs.guide/popular-topics/intents.html#privileged-intents).

Vous conservez √©galement une `Map` pour stocker l'historique des messages par canal afin que le bot puisse r√©pondre avec un contexte sur plusieurs canaux :

```ts
const channelHistories = new Map<string, ChatMessage[]>();
```

Discord.js fournit l'acc√®s √† quelques √©v√©nements auxquels vous pouvez √©couter. Lorsque vous travaillez avec des commandes slash, il enregistre un `Events.InteractionCreate`, que vous √©coutez.

Avec chaque commande `/ask`, vous prenez l'invite de l'utilisateur et les messages pr√©c√©dents. Si `channelHistories` n'a pas de cl√© avec cet `channelId` sp√©cifique, ce qui signifie qu'il est utilis√© pour la premi√®re fois, vous l'initialisez avec un tableau vide et vous les alimentez dans l'√©tat de l'IA.

```ts
const finalState = await graph.invoke({
  message: currentUserMessage,
  previousMessages: [...messageHistory],
});
```

Selon ce que le graphique `finalAction.type` retourne, vous :

* r√©pondez directement,

* cr√©ez un fil et r√©pondez l√†-bas,

* ou envoyez un embed (pour les r√©ponses de type support).

Si un fil ne peut pas √™tre cr√©√©, vous revenez √† r√©pondre dans le canal principal. L'historique des messages est limit√© √† 20 pour garder les choses l√©g√®res.

Notez que nous n'utilisons pas vraiment `previousMessages` pour l'instant dans l'application, mais j'ai pr√©par√© tout ce dont vous avez besoin pour g√©rer l'interrogation des conversations pr√©c√©dentes. Vous pourriez facilement cr√©er un nouveau n≈ìud LangGraph qui interroge ou raisonne sur l'historique si le bot doit se r√©f√©rer aux conversations pass√©es. (Prenez cela comme votre d√©fi !)

Ce projet devrait vous donner une id√©e de base de la mani√®re dont vous pouvez utiliser LangGraph + Composio pour construire un bot quelque peu utile qui peut d√©j√† g√©rer des choses d√©centes. Il y a beaucoup plus que vous pourriez am√©liorer. Je vous laisse le soin de le faire. üëåüòÄ

Voici une rapide d√©monstration de ce que nous avons construit jusqu'√† pr√©sent :

%[https://youtu.be/aeQKN0nMGRg] 

---

## Conclusion

√Ä ce stade, vous devriez avoir une bonne id√©e de la mani√®re dont LangGraph fonctionne et aussi comment alimenter le bot avec des int√©grations en utilisant Composio.

Ce n'est qu'une fraction de ce que vous pouvez faire. Essayez d'ajouter plus de fonctionnalit√©s et de support d'int√©gration au bot pour l'adapter √† votre flux de travail. Cela peut vraiment √™tre utile.

Si vous vous √™tes perdu quelque part en codant, vous pouvez trouver le code source [ici](https://github.com/shricodev/discord-bot-langgraph-composio).

Alors, c'est tout pour cet article. Merci beaucoup d'avoir lu ! √Ä la prochaine. üß°

Aimez construire des choses cool comme √ßa ? Je construis r√©guli√®rement ce genre de choses toutes les quelques semaines. N'h√©sitez pas √† me contacter ici :

* GitHub : [github.com/shricodev](http://github.com/shricodev)

* Portfolio : [techwithshrijal.com](http://techwithshrijal.com)

* LinkedIn : [linkedin.com/in/iamshrijal](http://linkedin.com/in/iamshrijal)