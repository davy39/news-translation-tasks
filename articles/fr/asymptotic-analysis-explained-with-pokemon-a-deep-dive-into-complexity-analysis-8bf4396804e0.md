---
title: 'Analyse Asymptotique Expliqu√©e avec Pok√©mon : Une Plong√©e Profonde dans l''Analyse
  de Complexit√©'
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2019-03-11T17:38:04.000Z'
originalURL: https://freecodecamp.org/news/asymptotic-analysis-explained-with-pokemon-a-deep-dive-into-complexity-analysis-8bf4396804e0
coverImage: https://cdn-media-1.freecodecamp.org/images/1*iWO7juZ8Nb--nnMGUKvKcA.jpeg
tags: []
seo_title: 'Analyse Asymptotique Expliqu√©e avec Pok√©mon : Une Plong√©e Profonde dans
  l''Analyse de Complexit√©'
seo_desc: 'By Divya Godayal

  by Sachin Malhotra and Divya Godayal



  Let‚Äôs admit that we are either still stuck on the nuances of how to write a good
  algorithm or we dread the term itself.


  An algorithm is nothing fancy. It is just the method of doing something. ...'
---

Par Divya Godayal

par [Sachin Malhotra](https://medium.com/@sachinmalhotra) et [Divya Godayal](https://medium.com/@divyagodayal)

![Image](https://cdn-media-1.freecodecamp.org/images/1*iWO7juZ8Nb--nnMGUKvKcA.jpeg)

> Admettons que nous sommes soit toujours bloqu√©s sur les nuances de l'√©criture d'un bon algorithme, soit que nous redoutons le terme lui-m√™me.

Un algorithme n'est rien de fancy. Ce n'est que la m√©thode pour faire quelque chose. Par exemple, disons que Pikachu doit rendre visite √† son ami ce soir. Il peut le faire de nombreuses mani√®res diff√©rentes. Ce qui compte, c'est la m√©thode qu'il choisit.

La m√©thode qu'il choisit d√©terminera le temps qu'il mettra pour atteindre son ami. Nous traitons de tels sc√©narios au quotidien. Nous ne pensons peut-√™tre pas √† chaque d√©cision comme √† une d√©cision algorithmique, mais elle pourrait en √™tre une.

![Image](https://cdn-media-1.freecodecamp.org/images/1*RcDh9k3wXyrTeeCEXJNlhg.png)
_Ceci est un algorithme. Mais peut-√™tre que m√™me cela n'est pas suffisant pour un itin√©raire efficace!!_

Les programmeurs doivent faire un choix √©clair√© √† chaque fois. Cela compte encore plus lorsque vous construisez une application hautement scalable et r√©active.

![Image](https://cdn-media-1.freecodecamp.org/images/1*luh16KeQqc7tSiTaYGsw_A.png)
_**Est-ce vrai ? Mmmm peut-√™tre.**_

Vous √™tes responsable de chaque morceau de code que vous √©crivez, m√™me si cela ne fonctionne pas. ?

## Table des Mati√®res ‚úß

* [Pourquoi analyser un algorithme ? üß†](https://medium.com/p/8bf4396804e0#845b)
* [Complexit√© et Comportement Asymptotique üèÉ‚Äç‚ôÄÔ∏è](https://medium.com/p/8bf4396804e0#e744)
* [Degr√©s de Complexit√© ‚èπ‚è∏‚è∫‚èè‚ãÜ](https://medium.com/p/8bf4396804e0#267c)
* [Outils pour l'Analyse de Complexit√© üîß](https://medium.com/p/8bf4396804e0#ee13)
* [Complexit√© Spatiale üåç](https://medium.com/p/8bf4396804e0#ec3c)
* [Le Compromis Temps et Espace üå≥](https://medium.com/p/8bf4396804e0#b336)
* [Tri √† Bulles üç∏](https://medium.com/p/8bf4396804e0#889a)
* [Tri par Insertion üìñüìïü¶ß](https://medium.com/p/8bf4396804e0#f4cd)
* [Tri Fusion üë´](https://medium.com/p/8bf4396804e0#4ead)
* [Analyse de l'Arbre de R√©cursivit√© üå≥](https://medium.com/p/8bf4396804e0#3bdd)
* [Analyse par la M√©thode Ma√Ætre ü§†üë∂](https://medium.com/p/8bf4396804e0#f99f)
* [Recherche Binaire üß† üëã üëà](https://medium.com/p/8bf4396804e0#d256)

## Pourquoi analyser un algorithme ? üß†

![Image](https://cdn-media-1.freecodecamp.org/images/1*jeBCn1BrA07hRR_oIrodlQ.png)
_**Application des Algorithmes** ‚Äî Basiquement tout, vous pouvez penser √† tout !!!_

Les algorithmes sont partout. Litt√©ralement, partout. En fait, pour √©crire cet article, nous avons compil√© une liste de 1200 √©tapes.

Ne prenez pas cela au s√©rieux maintenant. Je plaisante, bien s√ªr ! ü§≠

Ce que je veux dire, c'est qu'il n'y a pas d'√©chappatoire aux algorithmes dans aucun domaine de la vie. Mieux vaut apprendre l'art de choisir le bon !

Disons que nos Pok√©mon bien-aim√©s ont organis√© un championnat. Chaque fois qu'un Pok√©mon gagne un combat, son rang est mis √† jour. Pour d√©partager les √©galit√©s, le prochain combat est avec le Pok√©mon qui partage le m√™me score.

On vous demande de construire un site web, qui est rapide pour indiquer le prochain match. Le ninja du codage en vous s'est excit√© et s'est lanc√©. Vous avez construit un site web chic, avec des graphiques cool. On vous avait initialement dit qu'il y avait 50 Pok√©mon qui feraient partie du combat.

Pour trouver le prochain jeu du Pok√©mon gagnant, vous avez d√©cid√© de comparer son score avec le score de chaque Pok√©mon dans le championnat, ce qui est essentiellement une recherche lin√©aire. Et cela a fonctionn√© comme un charme !

Mais le jour du premier match, **1000 nouveaux** Pok√©mon (assumons simplement üòú) se sont inscrits !! Aaaah, dommage. Vous ne vous y attendiez pas, n'est-ce pas ?

![Image](https://cdn-media-1.freecodecamp.org/images/1*6AYCwrz4Xkdjhu7EHYFJuw.gif)
_**Scalabilit√© : Vous ne pouvez pas l'ignorer.**_

L'analyse asymptotique est **l'√©valuation de la performance d'un algorithme en termes de taille d'entr√©e (N), o√π N est tr√®s grand**. Elle vous donne une id√©e du comportement limite d'une application, et est donc tr√®s importante pour mesurer la performance de votre code.

Par exemple, si le nombre de Pok√©mon participant au combat est **N**, alors la complexit√© asymptotique de votre algorithme de [recherche lin√©aire](https://guide.freecodecamp.org/algorithms/search-algorithms/linear-search/) est **O(N)**. Si vous ne savez pas ce que cette notation signifie, ne vous inqui√©tez pas. Nous allons l'aborder bient√¥t.

En termes simples, c'est comme demander √† tous les **N** Pok√©mon quel est leur rang et puis prendre une d√©cision. Imaginez demander √† tous les 1000 Pok√©mon. Fatigant ! n'est-ce pas ?

Pour une machine, **O(N)** n'est peut-√™tre pas mauvais, mais sur un site web o√π l'accent est mis sur la r√©activit√© et la vitesse, ce n'est peut-√™tre pas le meilleur choix.

La raison pour laquelle 1000 nouveaux Pok√©mon deviennent un √©norme probl√®me est que vous n'avez pas pens√© √† l'aspect de la scalabilit√© de l'application d√®s le d√©part et avez utilis√© une approche na√Øve pour r√©soudre le probl√®me. Rencontrer de tels probl√®mes de scalabilit√© n'√©tait qu'une question de temps.

L'analyse des algorithmes est comme cela, elle est toujours pr√©sente. Mais vous ne vous en souciez vraiment que lorsqu'elle est vraiment n√©cessaire. Et puis vous tournez simplement autour de la queue... uh oh, je veux dire autour du buisson üò∏

![Image](https://cdn-media-1.freecodecamp.org/images/1*csi_6eFs6SnTeaXyezrUkw.gif)
_Oh Ma Queue ! Que diable fais-tu ici ??_

> Analyser un algorithme aide √† mesurer l'efficacit√© de votre programme et n√©cessite votre attention d√®s le moment o√π vous commencez √† penser √† une solution.

Vous auriez simplement pu utiliser un [dictionnaire](https://guide.freecodecamp.org/computer-science/data-structures/dictionaries/) ou une [table de hachage](https://guide.freecodecamp.org/computer-science/data-structures/hash-tables/) pour trouver tous les Pok√©mon avec le m√™me rang et r√©duire la complexit√© temporelle algorithmique √† **O(1)**. C'est comme aller voir un seul Pok√©mon manager qui a la r√©ponse √† votre requ√™te.

Une r√©duction folle de la complexit√© temporelle, de **O(N) √† O(1)**. Analyser un algorithme rend possible la comparaison de diff√©rentes approches et la d√©cision de la meilleure.

### Qu'est-ce que N, au fait ? ü§î

N d√©finit l'entr√©e. Ici, N est le nombre de Pok√©mon. Pour les besoins de l'analyse algorithmique, nous consid√©rons que N est tr√®s grand.

### Complexit√© et Comportement Asymptotique üèÉ‚Äç‚ôÄÔ∏è

Disons que [Pikachu](https://www.pokemon.com/us/pokedex/pikachu) est √† la recherche d'un co-Pok√©mon qui a un certain type de pouvoir sp√©cial. Pikachu commence par demander √† tous les Pok√©mon leurs pouvoirs un par un. Une telle approche est connue sous le nom de **recherche lin√©aire** puisque elle est faite lin√©airement, un par un. Mais pour notre r√©f√©rence, appelons-la **Recherche de Pikachu**.

```
1. Pikachu_Search(pokemon):              # Liste de pokemon
2.     for p in pokemon_list:           # Nombre d'it√©rations -  N 
3.         if p a un pouvoir sp√©cial:  # Op√©ration en temps constant
4.           return p               # Op√©ration en temps constant
    
5.   return "Aucun Pok√©mon Trouv√©"            # Op√©ration en temps constant
```

Dans l'extrait de code ci-dessus, `pokemon_list` est la liste de tous les Pok√©mon participant au championnat. Par cons√©quent, la taille de cette liste est N.

**Analyse du Temps d'Ex√©cution pour la Recherche de Pikachu :**

1. `√âtape 2` est une boucle for, ainsi les op√©rations √† l'int√©rieur seront r√©p√©t√©es N fois. `√âtape 4` n'est ex√©cut√©e que si la condition √† l'`√©tape 3` est vraie. Une fois que l'`√©tape 4` est ex√©cut√©e, la boucle se rompt et le r√©sultat est retourn√©.
2. Si l'`√âtape 3` prend un temps constant, disons `C1`, alors le temps total pris dans la boucle for serait `**C1.N.**`
3. Toutes les autres op√©rations sont des op√©rations en temps constant non affect√©es par la boucle, donc nous pouvons prendre une constante cumulative pour toutes, `**C2**`.

> _Temps d'Ex√©cution Total f(N) =_ `**_C1.N + C2_**` **_,_** _une fonction de N._

**Rendons-le grand.** Que se passe-t-il si la valeur de N est tr√®s, tr√®s grande. Pensez-vous que les constantes auraient une quelconque signification alors ?

![Image](https://cdn-media-1.freecodecamp.org/images/1*1mx8dpF1xhICxc-z-ae9aQ.jpeg)

**Dans l'analyse algorithmique, une id√©e importante est de supprimer la partie moins importante.**

Par exemple, si le temps d'ex√©cution d'un algorithme est exprim√© comme `10N¬≤ + 2N + 5`, alors asymptotiquement, seul le terme d'ordre sup√©rieur **N¬≤** est significatif. Cela rend la comparaison entre les algorithmes beaucoup plus facile.

### Degr√©s de Complexit√© ‚èπ‚è∏‚è∫‚èè‚ãÜ

Un algorithme montre diff√©rents comportements lorsqu'il est expos√© √† diff√©rents types d'entr√©es. Cela nous am√®ne √† la discussion de la mani√®re dont nous pouvons d√©finir ce comportement ou la complexit√© de l'algorithme. Puisque la recherche de Pikachu est toujours en cours, voyons ce qu'il se passe avec lui.

1. **Meilleur Cas ~** _Optimisme Pur_. Il a eu beaucoup de chance puisque le tout premier Pok√©mon qu'il a approch√© avait le pouvoir sp√©cial que Pikachu recherchait.
2. **Pire Cas ~** _Pessimisme Pur_. Il a d√ª aller voir tous les Pok√©mon et, √† son grand dam, le tout dernier Pok√©mon avait le super pouvoir qu'il voulait.
3. **Cas Moyen ~** _√ätre Pratique._ Pikachu est un Pok√©mon adulte maintenant. L'exp√©rience lui a beaucoup appris et il sait que c'est une question de temps et de chance. Il a estim√© de grandes chances de trouver le super Pok√©mon dans les 500 premiers Pok√©mon qu'il visite et il avait raison.

L'analyse d'un algorithme pourrait √™tre faite de trois mani√®res mentionn√©es ci-dessus.

La `complexit√© du meilleur cas` ne donne pas grand-chose. Elle agit comme la borne inf√©rieure pour la complexit√© d'un algorithme. Si vous l'utilisez, vous vous pr√©parez simplement pour le meilleur. Vous devez √™tre tr√®s chanceux pour que votre algorithme atteigne les bornes du meilleur cas de toute fa√ßon. Dans un sens pratique, cela n'aide pas beaucoup.

Toujours bon √† savoir, la `complexit√© du cas moyen` est g√©n√©ralement difficile √† calculer car elle n√©cessite d'analyser la performance de votre algorithme sur diff√©rentes variations de l'entr√©e et n'est donc pas largement utilis√©e.

La `complexit√© du pire cas` vous aide √† vous pr√©parer au pire. Dans les algorithmes, ce type de pessimisme est consid√©r√© comme bon car il donne une borne sup√©rieure sur la complexit√©. Ainsi, vous connaissez toujours les limites de votre algorithme !

### Outils pour l'Analyse de Complexit√© üîß

Nous avons vu pr√©c√©demment que le temps d'ex√©cution total pour la Recherche de Pikachu est `f(N)= **_C1.N + C2_**` **,** une fonction de N. Connaissons mieux les outils que nous avons, pour repr√©senter le temps d'ex√©cution, afin de rendre possible la comparaison entre les algorithmes.

**Big O** üòÆ: Oh oui ! C'est prononc√© comme √ßa. `Big ‚Äî Oh` ! C'est la borne sup√©rieure de la complexit√© d'un algorithme. Par cons√©quent, il est utilis√© pour d√©signer le pire comportement d'un algorithme.

**Essentiellement, cela d√©signe le temps d'ex√©cution maximum pour un algorithme quel que soit l'entr√©e.**

C'est la notation la plus largement utilis√©e en raison de sa facilit√© d'analyse d'un algorithme en apprenant son pire comportement.

![Image](https://cdn-media-1.freecodecamp.org/images/1*riGmrXn3x7j87Lw8chswPA.png)
_C est une constante. **f(N)** est la fonction de temps d'ex√©cution pour laquelle la borne sup√©rieure est **g(N)**._

Pour la recherche de Pikachu, nous pouvons dire que f(N) ou le temps d'ex√©cution est born√© _par le haut_ par `**C.g(N)**` pour un N tr√®s grand, o√π c est une constante et `g(N) = N`. Ainsi, `O(N)` repr√©sente la borne sup√©rieure asymptotique pour la recherche de Pikachu.

**Big Omega(Œ©):** Similaire √† la notation Big O, la notation Œ© est utilis√©e pour d√©finir une borne inf√©rieure asymptotique sur la performance d'un algorithme. Par cons√©quent, cela est utilis√© pour repr√©senter les sc√©narios du meilleur cas.

La borne omega signifie essentiellement **la quantit√© minimale de temps que notre algorithme prendra pour s'ex√©cuter**, ind√©pendamment de l'entr√©e.

Cette notation n'est pas souvent utilis√©e dans les sc√©narios pratiques, puisque l'√©tude du meilleur comportement ne peut pas √™tre une mesure correcte pour la comparaison.

![Image](https://cdn-media-1.freecodecamp.org/images/1*CG_56UCl0vZ678ocCI7urA.png)
_C est une constante. **f(N)** est la fonction de temps d'ex√©cution pour laquelle la borne inf√©rieure est **g(N)**._

Pour la recherche de Pikachu, nous pouvons dire que f(N) ou le temps d'ex√©cution est born√© _par le bas_ par `**C.g(N)**` pour un N tr√®s grand, o√π c est une constante et `g(N) = 1`. Ainsi, `**Œ©**(1)` repr√©sente la borne inf√©rieure asymptotique pour la Recherche de Pikachu.

**Big Theta**(**Œò**): Une borne serr√©e sur le comportement d'un algorithme, cette notation d√©finit les bornes sup√©rieure et inf√©rieure pour une fonction. Cela est appel√© une `borne serr√©e` car nous fixons le temps d'ex√©cution √† un facteur constant pr√®s au-dessus et en dessous. Quelque chose comme ceci:

![Image](https://cdn-media-1.freecodecamp.org/images/1*XrZtO7deNDuZvWP4SwDO8A.png)
_C1 et C2 sont des constantes. **f(N)** est le temps d'ex√©cution pour lequel la fonction de borne serr√©e serait **g(N)**_

Un algorithme peut pr√©senter diff√©rents comportements dans les meilleurs et pires cas. Lorsque les deux sont identiques, nous avons tendance √† utiliser la notation theta. Sinon, les meilleurs et pires cas sont appel√©s **s√©par√©ment** comme:

(a) Pour le `**pire cas**`, f(N) est born√© par la fonction `g(N) = N`, pour de grandes valeurs de N. Ainsi, la complexit√© de la borne serr√©e serait not√©e comme `Œò(N)`. Cela signifie que le temps d'ex√©cution du pire cas pour la recherche de Pikachu est **au moins** `C_1‚ãÖN_` et **au plus** `C_2‚ãÖN._`

(b) De m√™me, sa complexit√© de borne serr√©e pour le `**meilleur cas**` est `Œò(1)`.

![Image](https://cdn-media-1.freecodecamp.org/images/1*6wtt9IcNS3eBzGQlDDGrtw.png)

Prenons un autre exemple o√π `f(N) = 10N¬≤ + 2N + 5`, pour cette fonction, les complexit√©s des meilleurs et pires cas seraient Œ©(N¬≤) et O(N¬≤) respectivement. Ainsi, la complexit√© moyenne ou de la borne serr√©e serait Œò(N¬≤).

Puisque la complexit√© du pire cas agit comme une meilleure m√©trique de comparaison, √† partir de maintenant, nous utiliserons Big-O pour l'analyse de complexit√©.

### Complexit√© Spatiale üåç

Nous avons discut√© de la complexit√© temporelle jusqu'√† pr√©sent. Un concept important dans l'analyse de complexit√© est la _Complexit√© Spatiale_. Comme le sugg√®re le nom, cela signifie combien d'_espace ou de m√©moire_ l'algorithme prendra en termes de N, o√π N est tr√®s grand.

Chaque fois que nous comparons diff√©rents algorithmes pour r√©soudre un probl√®me particulier, nous ne nous concentrons pas uniquement sur les complexit√©s temporelles. La complexit√© spatiale est √©galement un aspect important pour comparer diff√©rents algorithmes. Oui, il est vrai que nous avons beaucoup de m√©moire disponible de nos jours et donc, l'espace est quelque chose qui peut √™tre compromis. Cependant, ce n'est pas quelque chose que nous devrions ignorer tout le temps.

Il y a un dilemme int√©ressant auquel les d√©veloppeurs sont confront√©s tout le temps lorsqu'ils trouvent des solutions pour des probl√®mes de programmation. Discutons un peu de ce que c'est.

### Le Compromis Temps et Espace üå≥

Plus souvent qu'autrement, vous voulez rendre votre algorithme extr√™mement rapide. Parfois, en faisant cela, vous finissez par compromettre la complexit√© spatiale.

> Cependant, parfois nous √©changeons un peu de **temps** pour optimiser l'**espace**.

Dans les applications pratiques, une chose ou une autre est compromise et cela est famously appel√© le compromis temps-espace dans le monde de l'analyse algorithmique.

![Image](https://cdn-media-1.freecodecamp.org/images/1*TxlQ9MDoOIqB1H-rTA5CnQ.gif)
_Balan√ßoire. Nous parlons d'un type de jeu similaire entre **Temps et Espace**_

Pikachu a r√©alis√© qu'il cherchait un Pok√©mon tous les deux jours. Cela signifie essentiellement ex√©cuter la Recherche de Pikachu encore et encore. Huh ! üò∞ Naturellement, il s'est tellement fatigu√© de la quantit√© √©puisante de travail qu'il devait fournir chaque jour.

Pour l'aider et acc√©l√©rer son processus de recherche, nous avons d√©cid√© d'utiliser une table de hachage. Nous pouvons utiliser le _type de pouvoir_ d'un Pok√©mon comme _cl√©_ dans la table de hachage.

Si nous devons trouver le Pok√©mon avec un pouvoir sp√©cial, la complexit√© du pire cas serait `O(1)`, puisque la recherche dans une table de hachage est une op√©ration en temps constant.

Sans utiliser cette table de hachage, le pauvre petit Pikachu aurait d√ª aller voir chaque Pok√©mon individuellement et demander leurs pouvoirs. Et r√©p√©ter cela est insens√©.

Tout ce qu'il a fallu, c'est cr√©er une table de hachage une fois et, √† partir de l√†, l'utiliser pour les recherches afin de r√©duire le temps d'ex√©cution global !

![Image](https://cdn-media-1.freecodecamp.org/images/1*0A9yDB0qZ88wnzw13V_Cng.gif)
_Whaaaaaaaaatttttttttt?_

Mais ce n'est pas tout, comme vous l'avez vu, cela s'accompagne d'un co√ªt d'espace. La table de hachage aurait besoin d'une entr√©e pour chaque Pok√©mon. Par cons√©quent, la complexit√© spatiale serait `O(N)`.

`_O(N) Temps, O(1) Espace_` ‚Äî **Choisissez entre** ‚Äî `_O(1) Temps, O(N) Espace_`

![Image](https://cdn-media-1.freecodecamp.org/images/1*V84IpE3a3TPslY53nSEVyA.gif)
_Ne vous inqui√©tez pas, ce n'est pas si grave. ?_

Ce choix d√©pend des besoins de l'application. Si nous avons une application orient√©e client, elle ne doit pas √™tre lente. La priorit√© dans une telle situation serait de rendre l'application aussi r√©active que possible, peu importe la quantit√© d'espace utilis√©e. Cependant, si nous sommes vraiment limit√©s par l'espace disponible, nous devons sacrifier le temps pour compenser cela.

> Choisir votre algorithme judicieusement aide √† optimiser √† la fois le temps et l'espace.

La complexit√© temporelle et spatiale vont toujours de pair. Nous devons faire les calculs et opter pour la meilleure approche. Il existe une r√®gle d'or pour vous aider √† d√©cider laquelle compromettre. Tout d√©pend de l'application.

C'est beaucoup de concepts th√©oriques √† assimiler. Nous savons, m√™me le pauvre Pikachu s'est un peu ennuy√©. Mais ne vous inqui√©tez pas, nous allons maintenant mettre tous ces concepts en pratique et les utiliser pour analyser la complexit√© de certains algorithmes. Cela aidera √† clarifier les diff√©rences minimes entre les diff√©rents types de complexit√©s, l'importance de la complexit√© Big-Oh, le compromis temps-espace et plus encore.

Pour commencer, Pikachu veut analyser toutes les techniques de tri. Trier tous les Pok√©mon par leurs rangs l'aide √† garder le tableau des rangs organis√©.

![Image](https://cdn-media-1.freecodecamp.org/images/1*CEyd9iHvnZkyuWVcabHQHA.gif)

Examinons les algorithmes de tri de base mais cruciaux. Le tableau d'entr√©e `pk_rank` √† trier est de taille N.

Au cas o√π vous ne seriez pas familier avec l'un des algorithmes de tri mentionn√©s ci-dessous, nous vous conseillons de les lire avant de passer aux sections suivantes. L'intention des exemples suivants est **de ne pas** expliquer les diff√©rents algorithmes mais d'expliquer comment vous pouvez d√©river leur complexit√© temporelle et spatiale.

### Tri √† Bulles üç∏

Le [**tri √† bulles**](https://guide.freecodecamp.org/algorithms/sorting-algorithms/bubble-sort)**,** l'un des algorithmes de tri les plus simples, compare r√©p√©titivement les √©l√©ments adjacents d'un tableau et les √©change s'ils sont dans le mauvais ordre. L'analogie est tir√©e des bulles qui finissent par remonter √† la surface. √Ä mesure que les √©l√©ments d'un tableau sont tri√©s, ils **remontent** progressivement √† leur position correcte dans le tableau.

![Image](https://cdn-media-1.freecodecamp.org/images/1*Hinlmu41uBcmnbO0kmypyw.gif)
_Exactement comme les bulles dans le verre de Pikachu. ?_

![Image](https://cdn-media-1.freecodecamp.org/images/1*uKKrhrU6C1ZV67WacLcwCQ.png)
_Algorithme de Tri √† Bulles_

**Complexit√© Temporelle :** Maintenant que nous avons l'algorithme en place, analysons sa complexit√© temporelle et spatiale. Nous pouvons clairement voir √† partir des `√©tapes 2 et 3` qu'il y a une structure de _boucle imbriqu√©e_ dans l'algorithme. De plus, la plage de la deuxi√®me boucle for est `N ‚Äî 1 ‚Äî i`, ce qui indique clairement qu'elle d√©pend de la boucle pr√©c√©dente.

```
si i = 0, la deuxi√®me boucle for s'ex√©cuterait N-1 fois
si i = 1, la deuxi√®me boucle for s'ex√©cuterait N-2 fois
si i = 2, la deuxi√®me boucle for s'ex√©cuterait N-3 fois
.
.
si i = N-1, la deuxi√®me boucle for s'ex√©cuterait 0 fois
```

Maintenant, nous savons la quantit√© de temps (it√©rations) que notre algorithme de tri √† bulles prend √† chaque √©tape. Nous avons mentionn√© pr√©c√©demment qu'il y a une boucle imbriqu√©e dans l'algorithme. Pour chaque valeur de la variable dans la premi√®re boucle, nous connaissons la quantit√© de temps prise dans la deuxi√®me boucle. Il ne reste plus qu'√† les additionner. Faisons cela.

```
S = N-1 + N-2 + N-3 + ... + 3 + 2 + 1
~ N * (N+1) / 2 
~ N¬≤ + N, en ignorant tous les coefficients
```

Si vous regardez les `√©tapes 4` et `5`, ce sont des op√©rations en temps constant. Elles n'ajoutent vraiment rien √† la complexit√© temporelle (ou spatiale d'ailleurs). Cela implique que nous avons **N¬≤ + N** it√©rations et dans chaque it√©ration, nous avons des op√©rations en temps constant qui sont effectu√©es.

Par cons√©quent, la complexit√© temporelle de l'algorithme de tri √† bulles serait **C.(N¬≤ + N)** o√π `C` est une constante. Asymptotiquement, nous pouvons dire que la complexit√© temporelle du pire cas pour le Tri √† Bulles est `**O(N¬≤)**`.

Est-ce un bon algorithme de tri ? Nous n'avons pas regard√© d'autres algorithmes pour comparer. Cependant, voyons combien de temps il faudra √† cet algorithme pour trier un milliard de Pok√©mon (reproduction, surpopulation, vous voyez üòõ).

Nous vous laissons faire le calcul, mais le tri √† bulles prendra environ **31 709 ans** pour trier un milliard de Pok√©mon (en supposant que chaque instruction prend 1 ms pour s'ex√©cuter). Pikachu est-il immortel ou quelque chose ü§î

![Image](https://cdn-media-1.freecodecamp.org/images/1*xKTLPvG81Zik6oeBScok3g.gif)
_tic-tac 1, tic-tac 2._

**Complexit√© Spatiale :** L'analyse de la complexit√© spatiale est comparativement plus simple que celle de la complexit√© temporelle pour cet algorithme. L'algorithme de tri √† bulles n'effectue qu'une seule op√©ration de mani√®re r√©p√©t√©e. L'√©change de nombres. En faisant cela, il n'utilise aucune m√©moire externe. Il r√©arrange simplement les nombres dans le tableau original et donc, la complexit√© spatiale est constante, ou `O(1)` ou m√™me `Œò(1)`.

### Tri par Insertion üìñüìïü¶ß

Aimez-vous jouer aux cartes ?

Eh bien, m√™me si vous ne le faites pas, vous devez savoir qu'une bonne strat√©gie initiale dans de nombreux jeux est de ranger les cartes dans un ordre sp√©cifique, c'est-√†-dire **trier le jeu de cartes**. L'id√©e du tri par insertion est tr√®s similaire √† celle de ranger le jeu de cartes.

Disons que vous avez quelques cartes tri√©es dans l'ordre croissant. Si on vous donne une autre carte √† `ins√©rer` √† la bonne position afin que les cartes dans votre main soient toujours tri√©es. _Que ferez-vous ?_

> _Vous commenceriez par l'une ou l'autre des extr√©mit√©s gauche ou droite des cartes en main et compareriez la nouvelle carte avec chaque carte du jeu pour trouver la bonne place._

![Image](https://cdn-media-1.freecodecamp.org/images/1*VHkmGYcdX6nsWrmZCSp_ig.gif)
_Une fois que vous avez trouv√© la bonne position, vous `ins√©rerez` la carte l√†._

De m√™me, si d'autres nouvelles cartes sont fournies, vous r√©p√©tez le m√™me processus pour chaque nouvelle carte et gardez les cartes dans votre main tri√©es.

Le [**tri par insertion**](https://guide.freecodecamp.org/algorithms/sorting-algorithms/insertion-sort/) fonctionne de la m√™me mani√®re. Il commence √† l'index `1` (l'indexation du tableau commence √† `0`) et traite chaque √©l√©ment comme une nouvelle carte. Chacun des nouveaux √©l√©ments peut alors √™tre plac√© √† la position correcte dans le _sous-tableau de gauche d√©j√† tri√©_.

La chose importante √† noter ici est que, √©tant donn√© une nouvelle carte (ou un √©l√©ment dans notre cas √† un index `j`), toutes les cartes en main (ou tous les √©l√©ments avant cet index) sont _d√©j√† tri√©es_.

Regardons un algorithme formel pour le tri par insertion suivi d'une animation qui ex√©cute l'algorithme sur une entr√©e de test.

![Image](https://cdn-media-1.freecodecamp.org/images/1*NeNYxh_69LXhnTJ3Ni160A.png)

![Image](https://cdn-media-1.freecodecamp.org/images/1*UpB6EEJZB8HihhERZWxC-A.gif)

**Complexit√© Temporelle :** √Ä partir des `√©tapes 1 et 4`, il y a une structure `while` _imbriqu√©e_ dans une boucle `for`. La boucle while s'ex√©cute `j+1` fois et `j` d√©pend clairement de `i`. Voyons comment la valeur de `j` change avec les valeurs changeantes de `i`.

```
si i = 1, alors j = 0 donc la boucle while s'ex√©cuterait 1 fois
si i = 2, alors j = 1 donc la boucle while s'ex√©cuterait 2 fois
si i = 3, alors j = 2 donc la boucle while s'ex√©cuterait 3 fois
.
.
si i = N-1, alors j = N-2 donc la boucle while s'ex√©cuterait N-1 fois
```

Maintenant, nous savons la quantit√© de temps (it√©rations) que notre algorithme de tri par insertion prend √† chaque √©tape. Le temps total est :

```
S = 1 + 2 + 3 + .... + N-2 + N-1
~ N * (N+1) / 2 
~ N¬≤ + N, en ignorant tous les coefficients
```

Les `√©tapes 2 √† 7` sont des op√©rations en temps constant. Elles n'ajoutent vraiment rien √† la complexit√© temporelle (ou spatiale d'ailleurs). Cela implique que nous avons **N¬≤ + N** it√©rations et dans chaque it√©ration, nous avons des op√©rations en temps constant qui sont effectu√©es.

Par cons√©quent, la complexit√© temporelle de l'algorithme de tri par insertion serait **C.(N¬≤ + N)** o√π `C` est une constante. Asymptotiquement, nous pouvons dire que la complexit√© temporelle du pire cas pour le Tri par Insertion est la m√™me que celle du tri √† bulles, c'est-√†-dire `**O(N¬≤)**`.

**Complexit√© Spatiale :** L'analyse de la complexit√© spatiale est comparativement plus simple que celle de la complexit√© temporelle pour cet algorithme. L'algorithme de tri par insertion ne r√©arrange que les nombres dans le tableau original. En faisant cela, il n'utilise aucune m√©moire externe. Par cons√©quent, la complexit√© spatiale est constante, ou `O(1)` ou m√™me `Œò(1)`.

**Note :** Comparer les algorithmes sur la base de la complexit√© asymptotique est facile et rapide. De plus, √† un niveau sup√©rieur, c'est une bonne mesure. Mais d'un point de vue pratique, si deux algorithmes ont la m√™me complexit√©, cela ne signifie pas n√©cessairement qu'ils ont la m√™me performance dans des sc√©narios pratiques.

Lors du calcul de la complexit√© asymptotique d'un algorithme, nous ignorons tous les _facteurs constants_ et les termes d'ordre inf√©rieur.

> _Mais ces valeurs ignor√©es finissent par s'ajouter au temps d'ex√©cution d'un algorithme._

Le tri par insertion est beaucoup plus rapide que le tri √† bulles lorsque le tableau est _presque_ tri√©. Pour chaque passage dans le tableau, le tri √† bulles doit aller jusqu'√† la fin du tableau et comparer les paires adjacentes, tandis que le tri par insertion, en revanche, s'arr√™terait t√¥t s'il trouve que le tableau est tri√©. Essayez d'ex√©cuter les deux algorithmes sur un tableau tri√© et regardez le nombre d'it√©rations qu'il faut √† chacun pour terminer l'ex√©cution.

Ainsi, chaque fois que vous cherchez le meilleur algorithme pour votre application, il doit √™tre analys√© sous de nombreux aspects diff√©rents. L'analyse asymptotique aide d√©finitivement √† √©liminer les algorithmes plus lents, mais l'observation et des insights plus profonds aident √† trouver l'algorithme le mieux adapt√© √† votre application.

![Image](https://cdn-media-1.freecodecamp.org/images/1*XrDxuuZzmbrTDXWWGv9s7w.gif)
_Faites attention √† cela !_

### Tri Fusion üë´

Jusqu'√† pr√©sent, nous avons analys√© deux des algorithmes de tri les plus basiques. Ce sont des algorithmes de tri introductifs mais ne sont pas ceux g√©n√©ralement utilis√©s en pratique en raison de leur complexit√© asymptotique √©lev√©e.

Passons √† un algorithme de tri plus rapide et plus pratique. L'algorithme de tri fusion s'√©carte de la structure de tri √† _boucle imbriqu√©e_ que nous avons vue dans les deux algorithmes pr√©c√©dents et adopte un nouveau paradigme que nous allons discuter ci-dessous.

L'algorithme de [**Tri Fusion**](https://guide.freecodecamp.org/algorithms/sorting-algorithms/merge-sort) est bas√© sur quelque chose connu sous le nom de paradigme de programmation _Diviser pour R√©gner_. Ce paradigme de programmation est bas√© sur une id√©e tr√®s simple et trouve son utilit√© dans de nombreux algorithmes diff√©rents, y compris le tri fusion. Diviser pour R√©gner est divis√© en trois √©tapes de base :

> _**Diviser**_ : Diviser un grand probl√®me en sous-probl√®mes plus petits.  
> _**Conqu√©rir**_ : R√©soudre de mani√®re optimale les sous-probl√®mes plus petits  
> _**Combiner**_ : Enfin, combiner les r√©sultats des sous-probl√®mes pour trouver la solution du grand probl√®me original.

![Image](https://cdn-media-1.freecodecamp.org/images/1*l-BZTiXtFs3jCYehwzsy6A.png)
_Lequel semble **plus facile**?_

Regardons un aper√ßu de la mani√®re dont l'algorithme de tri fusion utilise le paradigme diviser pour r√©gner.

1. _Diviser_ ~ La premi√®re √©tape du processus est de _diviser_ le tableau donn√© en deux sous-tableaux de taille √©gale. Cela aide puisque nous avons maintenant 2 sous-tableaux plus petits √† trier, chacun avec la moiti√© du nombre d'√©l√©ments d'origine.
2. _Conqu√©rir ~_ L'√©tape suivante consiste √† trier les sous-tableaux plus petits. Cette partie est appel√©e l'√©tape de _conqu√™te_ puisque nous r√©solvons les sous-probl√®mes de mani√®re optimale.
3. _Combiner ~_ Enfin, nous avons deux moiti√©s tri√©es du tableau original et nous devons les combiner de mani√®re optimale pour obtenir un seul tableau tri√©. C'est l'√©tape de _combinaison_ du paradigme expliqu√© ci-dessus.

Mais attendez. Est-ce tout ?

√âtant donn√© un tableau de 1000 √©l√©ments, si nous le divisons en 2 moiti√©s √©gales de 500 chacune, nous avons encore beaucoup d'√©l√©ments √† trier dans un tableau (ou sous-tableau).

Ne devrions-nous pas diviser les deux moiti√©s en 4 pour obtenir des sous-tableaux encore plus courts ?

Oui ! En effet, nous devrions !

**Nous** [**divisons r√©cursivement**](https://medium.freecodecamp.org/recursion-demystified-99a2105cb871) **le tableau en moiti√©s plus petites et trions et fusionnons les moiti√©s plus petites pour obtenir le tableau original.**

Cela signifie essentiellement que nous divisons, par exemple, un tableau de taille 1000 en 2 moiti√©s de 500 chacune. Ensuite, nous divisons ces deux moiti√©s en 4 portions de 250 chacune et ainsi de suite. Ne vous inqui√©tez pas si vous n'arrivez pas √† contempler tout cela intuitivement en termes d'analyse de complexit√©. Nous y viendrons tr√®s bient√¥t.

Regardons l'algorithme pour le tri fusion. L'algorithme est divis√© en deux fonctions, l'une qui trie r√©cursivement les deux moiti√©s √©gales d'un tableau donn√© et une autre qui fusionne les deux moiti√©s tri√©es ensemble.

Nous allons d'abord analyser la complexit√© de la fonction _fusion_ puis passer √† l'analyse de la fonction _tri_fusion_.

![Image](https://cdn-media-1.freecodecamp.org/images/1*ZVMhC2h0ndre_brfB2cEHg.png)
_**Fusionner** deux tableaux **tri√©s**_

La fonction ci-dessus prend simplement deux moiti√©s tri√©es du tableau et les fusionne en une seule moiti√© tri√©e. Les deux moiti√©s sont d√©finies √† l'aide d'indices. La moiti√© gauche est de `[gauche, milieu]` et la moiti√© droite est de `[milieu + 1, droite]`.

Les `√©tapes 2-3` copient les √©l√©ments du tableau original vers un tampon temporaire et nous utilisons ce tampon √† des fins de fusion. Les √©l√©ments tri√©s sont copi√©s dans le tableau original. Puisque nous it√©rons sur une certaine portion du tableau, la complexit√© temporelle pour cette op√©ration est `O(N)` en consid√©rant qu'il y a `N` √©l√©ments dans le tableau.

L'`√©tape 5` est une boucle while qui it√®re sur la plus courte des deux sous-tableaux. Cette boucle while et celles qui suivent, aux `√©tapes 13 et 14`, couvrent tous les √©l√©ments des deux sous-tableaux. Ainsi, leur complexit√© temporelle combin√©e est `O(N)`.

Cela signifie que l'√©tape de fusion est un algorithme en temps lin√©aire.

> _La complexit√© globale du tri fusion est d√©cid√©e par le nombre de fois o√π la fonction de fusion est appel√©e._

Passons √† la fonction _tri_fusion_ originale. Elle est extr√™mement simple.

![Image](https://cdn-media-1.freecodecamp.org/images/1*O84DDNcLEbGcQKZs5oFNLg.png)
_Algorithme de Tri Fusion_

L'`√©tape 4` appelle la fonction `tri_fusion` sur la moiti√© gauche du tableau.

L'`√©tape 5` appelle la fonction `tri_fusion` sur la moiti√© droite du tableau.

et ensuite l'`√©tape 6` appelle enfin la fonction `fusion` pour combiner les deux moiti√©s.

Oh. Une fonction qui s'appelle elle-m√™me ? ü§®ü§®

Comment calcule-t-on sa complexit√© ?

Jusqu'√† pr√©sent, nous avons discut√© de l'analyse des boucles. Cependant, de nombreux algorithmes, comme le Tri Fusion, sont r√©cursifs par nature. Lorsque nous les analysons, nous obtenons une relation de r√©currence pour la complexit√© temporelle. Nous obtenons le temps d'ex√©cution sur une entr√©e de taille `N` en fonction de `N` et du temps d'ex√©cution sur des entr√©es de tailles plus petites.

Principalement, il existe deux fa√ßons importantes d'analyser la complexit√© d'une relation de r√©currence :

1. En utilisant un Arbre de R√©cursivit√© et
2. En utilisant la M√©thode Ma√Ætre.

### Analyse de l'Arbre de R√©cursivit√© üå≥

C'est la mani√®re la plus intuitive pour analyser la complexit√© des relations de r√©currence. Essentiellement, nous pouvons visualiser une relation de r√©currence sous la forme d'un arbre de r√©cursivit√©.

La visualisation aide √† conna√Ætre la quantit√© de travail effectu√©e par l'algorithme √† chaque √©tape (lire niveau) le long du chemin et la somme du travail effectu√© √† chaque niveau nous indique la complexit√© globale de l'algorithme.

Avant de regarder l'arbre de r√©cursivit√© pour l'algorithme de Tri Fusion, regardons d'abord la relation de r√©currence pour celui-ci.

```
T(N) = 2T(N / 2) + O(N)
```

![Image](https://cdn-media-1.freecodecamp.org/images/1*gAesvFZFJT3uSq0tR1e3Kg.png)

Soit `T(N)` la quantit√© de travail effectu√©e (ou le temps pris pour) trier un tableau compos√© de `N` √©l√©ments. La relation ci-dessus stipule que le temps total pris est √©gal au temps pris pour trier les deux moiti√©s du tableau `+` le temps pris pour fusionner les deux moiti√©s. Nous avons d√©j√† vu le temps pris pour fusionner les deux moiti√©s auparavant et cela est `O(N)`.

Nous pouvons √©crire la relation de r√©currence comme suit :

```
T(N) = 2T(N / 2) + O(N)
T(N / 2) = 2T(N / 4) + O(N / 2)
T(N / 4) = 2T(N / 8) + O(N / 4)
...
```

Il est beaucoup plus facile de visualiser cela sous la forme d'un arbre. Chaque n≈ìud de l'arbre consisterait en deux branches puisque nous avons deux sous-probl√®mes diff√©rents √©tant donn√© un seul probl√®me. Regardons l'arbre de r√©cursivit√© pour le tri fusion.

![Image](https://cdn-media-1.freecodecamp.org/images/1*JQhExzK_FA8UlKgnHPHM6g.png)
_Arbre de R√©cursivit√© pour le Tri Fusion_

Chaque n≈ìud de l'arbre repr√©sente un sous-probl√®me et la valeur √† chaque n≈ìud repr√©sente la quantit√© de travail d√©pens√©e √† chaque sous-probl√®me. Le n≈ìud racine repr√©sente le probl√®me original.

Dans notre arbre de r√©cursivit√©, chaque n≈ìud non-feuille a 2 enfants, repr√©sentant le nombre de sous-probl√®mes en lesquels il se divise. Nous avons vu √† partir de l'algorithme pour le Tri Fusion que, √† chaque √©tape de la r√©cursivit√©, le tableau donn√© est divis√© en deux moiti√©s √©gales.

Ainsi, il y a deux choses importantes que nous devons d√©terminer afin d'analyser la complexit√© de l'algorithme de tri fusion.

1. Nous devons conna√Ætre la quantit√© de _travail_ effectu√© √† chaque _niveau_ de l'arbre et
2. Nous devons conna√Ætre le nombre total de _niveaux_ dans l'arbre, ou, comme on l'appelle plus commun√©ment, la _hauteur de l'arbre._

Tout d'abord, nous allons calculer la hauteur de notre arbre de r√©cursivit√©. Nous pouvons voir √† partir de l'arbre de r√©cursivit√© ci-dessus que chaque n≈ìud non-feuille se divise en deux n≈ìuds. Par cons√©quent, ce que nous avons ci-dessus est un _arbre binaire complet_.

Intuitivement, nous continuerons √† diviser le tableau jusqu'√† ce qu'il ne reste qu'un seul √©l√©ment dans un sous-tableau, moment auquel nous n'avons besoin d'aucun tri (c'est le cas de base) et nous retournons simplement.

Au premier niveau de notre arbre de r√©cursivit√© binaire, il y a un seul sous-probl√®me compos√© de `N` √©l√©ments. Le niveau suivant de l'arbre se compose de `2` sous-probl√®mes (sous-tableaux √† trier) avec `N / 2` √©l√©ments chacun.

Pour l'instant, nous ne nous pr√©occupons pas vraiment du _nombre de sous-probl√®mes_. Nous voulons simplement conna√Ætre la taille de chaque sous-probl√®me puisque nous pouvons voir que **tous les sous-probl√®mes √† un niveau particulier de l'arbre sont de la m√™me taille.**

```
Au Niveau 0, nous avons des sous-probl√®me(s) chacun compos√© de N    √©l√©ments
Au Niveau 1, nous avons des sous-probl√®me(s) chacun compos√© de N/2  √©l√©ments
Au Niveau 2, nous avons des sous-probl√®me(s) chacun compos√© de N/4  √©l√©ments
Au Niveau 3, nous avons des sous-probl√®me(s) chacun compos√© de N/8  √©l√©ments
Au Niveau 4, nous avons des sous-probl√®me(s) chacun compos√© de N/16 √©l√©ments
.
.
.
Au Niveau X, nous avons des sous-probl√®me(s) chacun compos√© de 1 √©l√©ment.
```

Le nombre d'√©l√©ments semble diminuer en _puissances de 2_. D'apr√®s le motif ci-dessus, il semble que :

```
N = 2^X 
X = log_2(N)
```

Cela signifie que la hauteur de notre arbre est `log_2(N)` (logarithme en base 2 de N). Maintenant, regardons la _quantit√© de travail effectu√©e par l'algorithme √† chaque √©tape._

`T(N)` est d√©fini comme la quantit√© de travail n√©cessaire pour trier un tableau de `N` √©l√©ments. Nous avons examin√© la relation de r√©currence pour cela plus t√¥t et elle √©tait :

```
T(N) = 2T(N / 2) + O(N)
```

Cela implique que la quantit√© de travail effectu√©e au premier niveau de l'arbre est `O(N)` et le reste du travail est effectu√© au niveau suivant. Cela est d√ª √† l'appel de r√©cursion sous la forme `2T(N / 2)`. Au niveau suivant, comme nous pouvons le voir sur la figure ci-dessus, la quantit√© de travail effectu√©e est `2 * O(N / 2) = O(N)`. De m√™me, la quantit√© de travail effectu√©e au troisi√®me niveau est `4 * O(N / 4) = O(N)`.

√âtonnamment, l'algorithme doit effectuer la m√™me quantit√© de travail √† chaque niveau et cette quantit√© de travail s'√©l√®ve √† `O(N)` qui est le temps consomm√© par la proc√©dure de _fusion_. Ainsi, le nombre de niveaux d√©finira la complexit√© temporelle globale.

Comme nous l'avons calcul√© pr√©c√©demment, le nombre de niveaux dans notre arbre de r√©cursivit√© est `log(N)` et donc, la complexit√© temporelle pour le Tri Fusion est `O(Nlog(N))`.

Hourra ! Nous avons appris une nouvelle m√©thodologie pour l'analyse asymptotique sous la forme d'arbres de r√©cursivit√©. C'est une mani√®re amusante de construire une intuition sur la complexit√© de toute relation de r√©currence. Il n'est peut-√™tre pas toujours faisable de dessiner l'arbre de r√©cursivit√© complet, mais cela aide d√©finitivement √† construire une compr√©hension.

### Analyse par la M√©thode Ma√Ætre ü§†üë∂

Nous avons examin√© la m√©thode bas√©e sur l'arbre de r√©cursivit√© pour l'analyse asymptotique des r√©currences. Cependant, comme mentionn√© pr√©c√©demment, il n'est peut-√™tre pas faisable de dessiner l'arbre de r√©cursivit√© √† chaque fois pour calculer la complexit√©.

La r√©cursivit√© du tri fusion divise un probl√®me donn√© (tableau) en deux sous-probl√®mes plus petits (sous-tableaux). Et si nous obtenons un algorithme o√π un probl√®me est divis√© en, disons, 100 sous-probl√®mes ? Nous ne pourrons pas dessiner l'arbre de r√©cursivit√© pour l'analyse.

Ainsi, nous avons besoin d'une m√©thode plus directe pour analyser la complexit√© d'une relation de r√©currence. Nous avons besoin d'une m√©thode qui ne n√©cessite pas de _dessiner r√©ellement_ l'arbre de r√©cursivit√© mais qui s'appuie sur les m√™mes concepts que l'arbre de r√©cursivit√©.

C'est l√† que la **M√©thode Ma√Ætre** entre en jeu. Cette m√©thode est bas√©e sur la m√©thode de l'arbre de r√©cursivit√©. Il existe trois sc√©narios diff√©rents qui sont couverts par la m√©thode ma√Ætre et qui couvrent essentiellement la plupart des relations de r√©currence. Avant de regarder ces cas, cependant, regardons l'arbre de r√©cursivit√© pour la relation de r√©currence g√©n√©rale suivante :

```
T(n) = a T(n / b) + f(n)
```

* `n` est la taille du probl√®me.
* `a` est le nombre de sous-probl√®mes dans la r√©cursion.
* `n / b` est la taille de chaque sous-probl√®me. (Ici, il est suppos√© que tous les sous-probl√®mes sont essentiellement de la m√™me taille.)
* `f(n)` est le co√ªt du travail effectu√© en dehors des appels r√©cursifs, qui inclut le co√ªt de la division du probl√®me en sous-probl√®mes plus petits et le co√ªt de la fusion des solutions aux sous-probl√®mes.

![Image](https://cdn-media-1.freecodecamp.org/images/1*pyIKd1wW3vVXw3MF_Ssv_g.png)

Les deux choses les plus importantes √† conna√Ætre pour comprendre la m√©thode ma√Ætre sont la quantit√© de travail effectu√©e par l'algorithme √† la racine et la quantit√© de travail effectu√©e aux feuilles.

Le travail effectu√© √† la racine est simplement `f(n)`. La quantit√© de travail effectu√©e aux feuilles d√©pend de la hauteur de l'arbre.

La hauteur de cet arbre serait `log_b(n)` c'est-√†-dire le logarithme en base `b` de `n`. Cela suit de l'arbre de r√©cursivit√© que nous avons vu pour le tri fusion. `b` dans le cas du tri fusion est `2`. Le nombre de n≈ìuds √† n'importe quel niveau, `l` sont `a^l` et donc, le nombre de n≈ìuds feuilles au dernier niveau serait :

```
a^{log_b(n)} = n ^ log_b(a) n≈ìuds.
```

Puisque la quantit√© de travail effectu√©e sur chaque sous-probl√®me au niveau final est `Œò(1)`, la quantit√© totale de travail effectu√©e aux n≈ìuds feuilles est `n ^ log_b(a)`.

Si vous vous concentrez sur la relation de r√©currence g√©n√©rique ci-dessus, vous remarquerez qu'il y a deux forces principales en jeu :

1. _L'√©tape de Division_ ~ le terme ùíá(ùíè/ùíÉ) essaie d√©sesp√©r√©ment de se reproduire, multipliant des copies de plus en plus petites de lui-m√™me.
2. _L'√©tape de Conqu√™te_ ~ le terme ùíá(ùíè) repr√©sente la fusion puisqu'il essaie d√©sesp√©r√©ment de fusionner ces mini-portions ensemble.

Les deux forces essaient de s'opposer l'une √† l'autre et, en faisant cela, elles veulent contr√¥ler la quantit√© totale de travail effectu√©e par l'algorithme et donc la complexit√© temporelle globale.

Qui va gagner ?

#### Cas 1 (L'√©tape de Division gagne)

Si `f(n) = Œò(n^c)` tel que `c < log_b(a)`, alors `T(n) = Œò(n^log_b(a)`. `f(n)` est la quantit√© de travail effectu√©e √† la racine de l'arbre et `n ^ log_b(a)` est la quantit√© de travail effectu√©e aux feuilles.

Si le travail effectu√© aux feuilles est polynomialement plus important, alors les feuilles sont la partie dominante, et notre r√©sultat devient le travail effectu√© aux feuilles.

```
ex. T(n) = 8 T(n / 2) + 1000 n^2
```

![Image](https://cdn-media-1.freecodecamp.org/images/1*3oZQZ-MzHZX0GC91IIT_Dg.png)

Si nous adaptons cette relation de r√©currence √† la M√©thode Ma√Ætre, nous obtenons :

```
a = 8, b = 2, et f(n) = O(n^2)
D'o√π, c = 2 et log_b(a) = log_2(8) = 3
Clairement, 2 < 3 et cela correspond au Cas 1 de la M√©thode Ma√Ætre. Cela implique que la quantit√© de travail effectu√©e aux feuilles de l'arbre est asymptotiquement plus √©lev√©e que le travail effectu√© √† la racine. Par cons√©quent, la complexit√© de cette relation de r√©currence est Œò(n^log_2(8)) = Œò(n^3).
```

### Cas 2 (L'√©tape de Conqu√™te gagne)

Si `f(n) = Œò(n^c)` tel que `c > log_b(a)`, alors `T(n) = Œò(f(n))`. Si le travail effectu√© √† la racine est asymptotiquement plus important, alors notre complexit√© finale devient le travail effectu√© √† la racine.

Nous ne nous pr√©occupons pas de la quantit√© de travail effectu√©e aux niveaux inf√©rieurs ici, puisque le terme polynomial le plus grand d√©pendant de `n` est celui qui contr√¥le la complexit√© de l'algorithme. Par cons√©quent, le travail effectu√© √† tous les niveaux inf√©rieurs peut √™tre ignor√© en toute s√©curit√©.

```
ex. T(n) = 2 T(n / 2) + n^2
```

![Image](https://cdn-media-1.freecodecamp.org/images/1*gQdAJIqbC87o0Ct1dD9ySQ.png)

Si nous adaptons cette relation de r√©currence √† la M√©thode Ma√Ætre, nous obtenons :

```
a = 2, b = 2, et f(n) = O(n^2)
D'o√π, c = 2 et log_b(a) = log_2(2) = 1
Clairement, 2 > 1 et donc cela correspond au Cas 2 de la M√©thode Ma√Ætre o√π la majorit√© du travail est effectu√©e √† la racine de l'arbre de r√©cursivit√© et c'est pourquoi Œò(f(n)) contr√¥le la complexit√© de l'algorithme. Ainsi, la complexit√© temporelle de cette relation de r√©currence est Œò(n^2).
```

#### Cas 3 [C'est une √©galit√© !]

Si `f(n) = Œò(n^c)` tel que `c = log_b(a)`, alors `T(n) = Œò(n^c log(n))`. Le dernier cas est lorsque le travail effectu√© aux feuilles et le travail effectu√© √† la racine de l'arbre sont √©gaux.

Dans ce cas, les √©tapes de conqu√™te et de division sont √©galement dominantes et donc, la quantit√© totale de travail effectu√©e est √©gale au travail effectu√© √† _n'importe quel niveau * la hauteur de l'arbre._

```
ex. T(n) = 2T(n / 2) + O(n)
```

![Image](https://cdn-media-1.freecodecamp.org/images/1*JQhExzK_FA8UlKgnHPHM6g.png)
_Attendez, n'est-ce pas le Tri Fusion ?_

Oui ! C'est la complexit√© de l'algorithme de Tri Fusion. Si nous adaptons la relation de r√©currence pour le tri fusion dans la M√©thode Ma√Ætre, nous obtenons :

```
a = 2, b = 2, et f(n) = O(n^1)
D'o√π, c = 1 = log_2(2)
Cela correspond au crit√®re du Cas 3 d√©crit ci-dessus. La quantit√© de travail effectu√©e est la m√™me √† tous les niveaux comme on peut le v√©rifier sur la figure ci-dessus. Ainsi, la complexit√© temporelle est le travail effectu√© √† n'importe quel niveau * le nombre total de niveaux (ou la hauteur de l'arbre).
```

Nous avons analys√© la complexit√© temporelle de l'algorithme de Tri Fusion en utilisant deux m√©thodes diff√©rentes, √† savoir l'Arbre de R√©cursivit√© et la M√©thode Ma√Ætre. Nous avons d√ª utiliser ces diff√©rentes techniques car l'algorithme de tri fusion est un algorithme **r√©cursif** et les approches classiques d'analyse asymptotique que nous avons vues pr√©c√©demment pour les **boucles** n'√©taient d'aucune utilit√© ici.

**Complexit√© Spatiale :** En ce qui concerne la complexit√© spatiale, nous n'avons pas √† utiliser de techniques compliqu√©es et donc, l'analyse est beaucoup plus simple. Une structure de donn√©es principale occupant de l'espace dans l'algorithme de Tri Fusion est le tableau `tampon temporaire` qui est utilis√© pendant la proc√©dure de `fusion`.

Ce tableau est initialis√© une fois et la taille de ce tableau est `N`. Une autre structure de donn√©es qui occupe de l'espace est la [_pile de r√©cursion_](https://www.hackerearth.com/practice/notes/demystifying-recursion-by-stack-tracing/). Essentiellement, le nombre total d'appels r√©cursifs d√©termine la taille de la pile de r√©cursion. Comme nous l'avons vu dans la repr√©sentation de l'arbre de r√©cursivit√©, **le nombre d'appels effectu√©s par le tri fusion est essentiellement la hauteur de l'arbre de r√©cursivit√©.**

La hauteur de l'arbre de r√©cursivit√© √©tait `log_2(N)` et donc, la taille de la pile de r√©cursion sera √©galement `log_2(N)` au maximum.

![Image](https://cdn-media-1.freecodecamp.org/images/1*OQ4SghHM5aB1_e41KARnbA.png)

Par cons√©quent, la complexit√© spatiale totale pour le tri fusion serait `N + log_2(N) = O(N)`.

### Recherche Binaire üß† üëã üëà

Souvenez-vous de notre ami Pikachu et de sa recherche d'un Pok√©mon avec un pouvoir sp√©cifique. Le pauvre petit Pikachu avait 1000 Pok√©mon √† sa disposition et il devait trouver celui avec un pouvoir sp√©cifique. Oui, Pikachu est tr√®s s√©lectif quant √† ses adversaires.

Ses exigences changent jour apr√®s jour et il ne peut certainement pas aller v√©rifier aupr√®s de chaque Pok√©mon, chaque fois que ses exigences changent, c'est-√†-dire qu'il ne peut pas effectuer une **Recherche Lin√©aire** dans la liste des Pok√©mon pour trouver celui qu'il cherche.

Nous avons mentionn√© pr√©c√©demment l'utilisation d'une **Table de Hachage** pour stocker les Pok√©mon en utilisant leur valeur de pouvoir unique comme cl√© et le Pok√©mon lui-m√™me comme valeur. Cela r√©duirait la complexit√© de la recherche √† `O(1)`, c'est-√†-dire un temps constant.

Cependant, cela utilise un espace suppl√©mentaire qui augmente la complexit√© spatiale de l'op√©ration de recherche √† `O(N)` en consid√©rant qu'il y a `N` Pok√©mon disponibles. `N` dans ce cas serait `1000`. Et si Pikachu n'avait pas tout cet espace suppl√©mentaire disponible et qu'il voulait toujours acc√©l√©rer le processus de recherche ?

![Image](https://cdn-media-1.freecodecamp.org/images/1*zPvLZixp2h7khcIzBBXI6w.jpeg)
_Puis-je faire cela ?_

Oui ! Bien s√ªr, Pikachu peut utiliser ses connaissances profondes sur les **algorithmes de tri** pour trouver une strat√©gie de recherche qui serait plus rapide que la lente recherche lin√©aire.

Pikachu a d√©cid√© de demander de l'aide √† son bon ami Deoxys. Deoxys, √©tant le Pok√©mon le plus rapide, aide Pikachu √† **trier** la liste des Pok√©mon selon leur pouvoir.

Au lieu de s'appuyer sur les algorithmes de tri traditionnels, Deoxys utilise l'algorithme de [**Tri Rapide**](https://guide.freecodecamp.org/algorithms/sorting-algorithms/quick-sort/) (bien s√ªr qu'il le fait !) pour trier les Pok√©mon.

En faisant cela, il n'utilise aucun espace suppl√©mentaire et le temps pris pour trier les `N` Pok√©mon est le m√™me que celui de l'algorithme de **Tri Fusion**. Donc, Pikachu est heureux que son ami l'aide au moment opportun.

Pikachu, √©tant extr√™mement intelligent, invente une strat√©gie de recherche qui utilise la nature tri√©e de la liste des Pok√©mon. Ce nouvel algorithme est connu sous le nom d'algorithme de [**Recherche Binaire**](https://guide.freecodecamp.org/miscellaneous/freecodecamp-algorithm-binary-search-guide/) (**Note** : Le tri est une condition pr√©alable pour ex√©cuter une recherche binaire, une fois la liste tri√©e, Pikachu peut ex√©cuter une recherche binaire autant de fois qu'il le souhaite sur cette liste tri√©e).

Regardons le code de cet algorithme puis analysons sa complexit√©.

![Image](https://cdn-media-1.freecodecamp.org/images/1*d3K7llJtj5gl2RjITp0WAw.png)

Clairement, l'algorithme est r√©cursif par nature. Voyons si nous pouvons utiliser nos nouveaux trucs pour analyser la complexit√© temporelle de l'algorithme de recherche binaire. Les deux variables `l` et `r` d√©finissent essentiellement la portion du tableau dans laquelle nous devons rechercher l'√©l√©ment donn√©, `x`.

Si nous regardons l'algorithme, tout ce qu'il fait vraiment est de diviser la portion de recherche du tableau d'entr√©e en deux. En plus de faire un appel r√©cursif bas√© sur une certaine condition, il ne fait pas grand-chose. Donc, regardons rapidement la relation de r√©currence pour l'algorithme de recherche binaire.

```
T(n) = T(n / 2) + O(1)
```

Cela semble √™tre une relation de r√©currence assez simple √† analyser. D'abord, essayons d'analyser l'arbre de r√©cursivit√© et d'en d√©duire la complexit√©, puis nous regarderons le th√©or√®me Ma√Ætre et verrons lequel des trois cas correspond √† cette r√©cursion.

![Image](https://cdn-media-1.freecodecamp.org/images/1*U9jFamdwwGALXvS6eW2XNg.png)

Waouh ! Cet algorithme de recherche binaire est super rapide. Il est beaucoup plus rapide que la recherche lin√©aire. Ce que cela implique pour notre petit ami mignon Pikachu, c'est que pour 1000 Pok√©mon, il devrait simplement aller et ¬´ demander ¬ª **10** d'entre eux au maximum pour trouver le Pok√©mon sp√©cial qu'il cherche (comment ? ü§ì).

Maintenant, voyons comment la m√©thode plus ¬´ formulaire ¬ª d'approche de l'analyse de complexit√© r√©cursive, c'est-√†-dire la m√©thode Ma√Ætre, peut nous aider dans ce cas. La relation r√©cursive g√©n√©rique de la m√©thode Ma√Ætre est

```
T(n) = a T(n / b) + f(n)
```

et pour notre algorithme de recherche binaire, nous avons

```
T(n) = T(n / 2) + O(1)
f(n) = O(n^0), donc c = 0
a = 1
b = 2
c = 0
```

Il y a 3 cas diff√©rents pour le th√©or√®me Ma√Ætre et `c ? log_b(a)` d√©cide lequel des trois cas est utilis√© pour une analyse particuli√®re. Dans notre cas, `0 < log_2(1)` c'est-√†-dire `0 = 0`. Cela implique que notre algorithme de recherche binaire correspond au **cas-3** du th√©or√®me Ma√Ætre, donc `T(n) = Œò(n^0 log(n)) = Œò(log(n)`

### Comment choisir le meilleur algorithme ? ü§®

Dans cet article, nous avons introduit l'id√©e de l'analyse de complexit√© qui est une partie importante de la conception et du d√©veloppement d'algorithmes. Nous avons vu pourquoi l'analyse de la complexit√© d'un algorithme est importante et comment elle affecte directement nos d√©cisions de scalabilit√©. Nous avons m√™me vu quelques techniques g√©niales pour analyser cette complexit√© de mani√®re efficace et correcte afin de prendre des d√©cisions √©clair√©es en temps opportun. La question se pose cependant,

**√âtant donn√© tout ce que je sais sur les complexit√©s temporelle et spatiale de deux algorithmes, comment choisir celui √† utiliser finalement ? Y a-t-il une r√®gle d'or ?**

La r√©ponse √† cette question, malheureusement, est **Non !**

Il n'y a pas de r√®gle d'or pour vous aider √† d√©cider quel algorithme utiliser. Cela d√©pend totalement de nombreux facteurs externes. Essayons de regarder quelques-uns de ces sc√©narios dans lesquels vous pourriez vous trouver et voyons aussi le type de d√©cisions que vous voudriez prendre.

#### Aucune contrainte sur l'espace !

Eh bien, si vous avez deux algorithmes A et B et que vous voulez d√©cider lequel utiliser, en plus de la complexit√© temporelle, la complexit√© spatiale devient √©galement un facteur important.

Cependant, √©tant donn√© que l'espace n'est pas un probl√®me qui vous pr√©occupe, il est pr√©f√©rable d'opter pour l'algorithme qui a la capacit√© de r√©duire davantage la complexit√© temporelle, m√™me avec plus d'espace.

Par exemple, le [Tri par Comptage](https://guide.freecodecamp.org/algorithms/sorting-algorithms/counting-sort) est un algorithme de tri en temps lin√©aire, mais il d√©pend fortement de la quantit√© d'espace disponible. Pr√©cis√©ment, la _plage_ de nombres qu'il peut traiter d√©pend de la quantit√© d'espace disponible. Avec un espace illimit√©, vous √™tes mieux loti en utilisant l'algorithme de tri par comptage pour trier une grande plage de nombres.

#### Exigence de latence sous-seconde et espace limit√© disponible

Si vous vous trouvez dans un tel sc√©nario, il devient vraiment important de comprendre profond√©ment la performance de l'algorithme sur de nombreuses entr√©es vari√©es, surtout le type d'entr√©es que vous attendez de l'algorithme pour travailler dans votre application.

Par exemple, nous avons deux algorithmes de tri : le tri √† bulles et le tri par insertion, et vous voulez d√©cider lequel utiliser pour trier une liste d'utilisateurs en fonction de leur √¢ge. Vous avez analys√© le type d'entr√©e attendu et vous avez trouv√© que le tableau d'entr√©e est **presque tri√©**. Dans un tel sc√©nario, il est pr√©f√©rable d'utiliser le tri par insertion plut√¥t que le tri √† bulles en raison de sa capacit√© inh√©rente √† g√©rer de mani√®re amazone les entr√©es presque tri√©es.

#### Attendez, pourquoi quelqu'un utiliserait-il le tri √† bulles ou le tri par insertion dans des sc√©narios r√©els ?

Si vous pensez que ces algorithmes sont juste √† des fins √©ducatives et ne sont pas utilis√©s dans des sc√©narios r√©els, vous n'√™tes pas seul ! Cependant, cela ne pourrait pas √™tre plus √©loign√© de la v√©rit√©. Je suis s√ªr que vous avez tous utilis√© la fonctionnalit√© `sort()` en Python √† un moment donn√© dans votre carri√®re.

Eh bien, si vous l'avez utilis√©e et que vous avez √©t√© √©merveill√© par ses performances, vous avez utilis√© un algorithme hybride bas√© sur le tri par insertion et le tri fusion appel√© l'algorithme Tim Sort. Pour en savoir plus, rendez-vous ici :

[**Timsort ‚Äî le plus rapide algorithme de tri que vous n'avez jamais entendu**](https://skerritt.blog/timsort-the-fastest-sorting-algorithm-youve-never-heard-of/)  
[_Timsort : Un algorithme de tri tr√®s rapide, O(n log n), stable, construit pour le monde r√©el ‚Äî pas construit dans le milieu universitaire‚Ä¶_skerritt.blog](https://skerritt.blog/timsort-the-fastest-sorting-algorithm-youve-never-heard-of/)

Il est vrai que le tri par insertion peut ne pas √™tre utile pour des entr√©es tr√®s grandes comme nous l'avons tous vu avec sa complexit√© temporelle polynomiale. Cependant, sa capacit√© inh√©rente √† trier rapidement une plage de nombres _presque_ tri√©e est ce qui le rend si sp√©cial et c'est pr√©cis√©ment la raison pour laquelle il est utilis√© dans l'algorithme Timsort.

En bref, vous n'aurez jamais une division claire en noir et blanc entre les algorithmes parmi lesquels vous avez du mal √† choisir. Vous devez analyser toutes les propri√©t√©s des algorithmes, y compris leur complexit√© temporelle et spatiale. Vous devez consid√©rer la taille des entr√©es que vous attendez que votre algorithme traite et toute autre contrainte qui pourrait exister. En tenant compte de tous ces facteurs, vous devez prendre une d√©cision √©clair√©e !

> _Si vous avez pass√© un bon moment √† comprendre les subtilit√©s de l'analyse de complexit√© et √† jouer avec notre ami Pikachu, n'oubliez pas de d√©truire ce bouton like et de r√©pandre un peu d'amour. _‚ù§Ô∏è__  
>   
> _Si vous voulez plus de probl√®mes de programmation avec une analyse de complexit√© d√©taill√©e, rendez-vous dans notre [cuisine](https://github.com/DivyaGodayal/CoderChef-Kitchen)! _üç≥__  
>   
> _Analyser un algorithme est une partie importante de l'ensemble des comp√©tences de tout d√©veloppeur et si vous pensez qu'il y a d'autres personnes qui pourraient b√©n√©ficier de cet article, alors partagez-le autant que possible!_