---
title: Comment extraire facilement des informations de sites web en utilisant Standard
  Library et Node.js
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2018-07-12T07:14:10.000Z'
originalURL: https://freecodecamp.org/news/scrape-websites-for-information-easily-using-code-xyz-and-node-js-8be3e2f938ab
coverImage: https://cdn-media-1.freecodecamp.org/images/1*owqsessjwq39-cbYI5glLw.png
tags:
- name: JavaScript
  slug: javascript
- name: Node.js
  slug: nodejs
- name: General Programming
  slug: programming
- name: 'tech '
  slug: tech
- name: Web Development
  slug: web-development
seo_title: Comment extraire facilement des informations de sites web en utilisant
  Standard Library et Node.js
seo_desc: 'By Janeth Ledezma

  A web scraper is a tool that allows us to select and transform a website‚Äôs unstructured
  data into a structured database. So where would a web scraper come in handy? I have
  listed my favorite use cases to get you excited about launch...'
---

Par Janeth Ledezma

Un scraper web est un outil qui permet de s√©lectionner et transformer les donn√©es non structur√©es d'un site web en une base de donn√©es structur√©e. Alors, dans quels cas un scraper web peut-il √™tre utile ? J'ai list√© mes cas d'utilisation pr√©f√©r√©s pour vous donner envie de lancer le v√¥tre !

![Image](https://cdn-media-1.freecodecamp.org/images/sjGtkAW7bu3T6pLz1Vv4oXLwUmpk8IZUiObt)
_[Cette question sur Quora](https://www.quora.com/What-are-examples-of-how-real-businesses-use-web-scraping-Are-there-any-types-of-businesses-which-use-this-more-than-others" rel="noopener" target="_blank" title=") m'a encourag√©e √† cr√©er mon propre scraper web._

* Extraire des annonces immobili√®res ‚Äî les entreprises utilisent le web scraping pour collecter des propri√©t√©s d√©j√† list√©es
* Extraire des produits/avis de produits depuis des sites de d√©taillants ou de fabricants pour les afficher sur votre site, fournir des comparatifs de sp√©cifications/prix
* Extraire des sites d'actualit√©s pour appliquer une analyse et une curation personnalis√©es (manuelle ou automatique), fournir des nouvelles mieux cibl√©es √† votre audience
* Collecter des adresses e-mail pour la g√©n√©ration de leads

Vous pouvez lire d'autres cas d'utilisation pratiques pour un [scraper web ici](https://www.quora.com/What-are-examples-of-how-real-businesses-use-web-scraping-Are-there-any-types-of-businesses-which-use-this-more-than-others).

Maintenant, commen√ßons ! Comme exemple simple ‚Äî [nous allons extraire la page d'accueil de Hacker News](https://news.ycombinator.com/) pour r√©cup√©rer les titres des liens.

_Si vous n'√™tes pas encore familier avec [Standard Library](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service), vous allez √™tre agr√©ablement surpris ! [Standard Library](https://www.freecodecamp.org/news/scrape-websites-for-information-easily-using-code-xyz-and-node-js-8be3e2f938ab/undefined) est une plateforme de d√©veloppement et de publication d'API qui peut vous aider √† construire et d√©ployer du code en un temps record en utilisant l'√©diteur d'API en navigateur ‚Äî [Code on Standard Library.](https://code.stdlib.com)_

### √âtape Une : Connectez-vous √† Code on Standard Library

La premi√®re √©tape consiste √† vous rendre sur [https://code.stdlib.com](https://code.stdlib.com)/ et √† cr√©er un compte gratuit. [Code on Standard Library](https://code.stdlib.com) est un √©diteur d'API en ligne d√©velopp√© par l'√©quipe de [Standard Library](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service) ‚Äî un environnement de d√©veloppement int√©grable pour construire rapidement des API, des webhooks et des t√¢ches d'automatisation de workflow.

Dans le coin inf√©rieur gauche, cliquez sur **(se connecter)**. Si vous avez un compte [Standard](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service) [Library](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service), cliquez sur **D√©j√† inscrit**, et connectez-vous en utilisant vos identifiants [Standard Library](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service). Une fen√™tre modale appara√Ætra vous demandant de choisir un espace de noms (c'est votre nom d'utilisateur). Entrez votre e-mail et choisissez un mot de passe.

Apr√®s avoir cr√©√© votre compte, un module diff√©rent appara√Ætra listant les plans d'abonnement. Un compte gratuit est tout ce dont vous avez besoin pour commencer, mais vous [pouvez en savoir plus sur les forfaits de prix de Standard Library ici](https://stdlib.com/pricing).

Une fois que vous cliquez sur **S'abonner + Gagner des cr√©dits**, vous devriez voir un message de confirmation appara√Ætre.

Cliquez sur **Continuer** pour revenir √† la page d'accueil.

### √âtape Deux : S√©lectionnez le code source du Web Scraper

S√©lectionnez le bouton **API √† partir du code source**. Les [Standard Library](https://stdlib.com/?utm_source=content&utm_medium=blog&utm_campaign=scrape_service) Sourcecodes sont con√ßus pour rationaliser la cr√©ation de diff√©rents types de projets. Les Sourcecodes fournissent des valeurs par d√©faut pour des √©l√©ments comme le code de base et la configuration des r√©pertoires afin que vous puissiez vous concentrer directement sur le d√©veloppement et la mise en ≈ìuvre de fonctionnalit√©s plus complexes.

Vous devriez voir une liste de codes sources publi√©s. Faites d√©filer vers le bas et s√©lectionnez **@nemo/web-scraper**. Assurez-vous d'entrer le nom souhait√© pour votre API et cliquez sur **Okay** (ou appuyez sur entr√©e)

Vous verrez alors le code de votre endpoint sous : `functions/__main__.js`

![Image](https://cdn-media-1.freecodecamp.org/images/fxvrAQ16nO2vIJyREwOXiFJjiJFiboO2JW5V)

Sur le c√¥t√© droit, vous remarquerez une bo√Æte de param√®tres.

Dans le param√®tre URL requis, tapez :

`[https://news.ycombinator.com/](https://news.ycombinator.com/)`

Dans les requ√™tes, tapez :

`[[".storylink", "text"]]`

S√©lectionnez le bouton vert ¬´ **Ex√©cuter** ¬ª.

En quelques secondes, vous devriez avoir une liste de titres de liens de la page d'accueil de [Hacker News](https://news.ycombinator.com/) sous la section **R√©sultats** de [Code on Standard Library](https://code.stdlib.com). Vous remarquerez un portail de documentation ‚Äî copiez et collez l'URL de la documentation dans un nouvel onglet de votre navigateur pour voir les informations de votre API sur Standard Library.

![Image](https://cdn-media-1.freecodecamp.org/images/FWTfuTNbvtcxKG0f7g14zuDLZBsYAkvfEuKN)

### Comment √ßa marche ?

Le scraper web effectue une simple requ√™te GET vers une URL, ex√©cute une s√©rie de requ√™tes sur la page r√©sultante et vous la retourne. Il utilise le puissant processeur DOM (Document Object Model) [cheerio](https://github.com/cheeriojs/cheerio), ce qui nous permet d'utiliser des [s√©lecteurs CSS](https://www.w3schools.com/cssref/css_selectors.asp) pour extraire des donn√©es de la page ! Les s√©lecteurs CSS sont des motifs utilis√©s pour s√©lectionner le ou les √©l√©ments que vous souhaitez organiser.

### **Comment interroger en utilisant des s√©lecteurs CSS**

Les pages web sont √©crites en [langages de balisage](https://en.wikipedia.org/wiki/Markup_language) tels que HTML. [Un √©l√©ment HTML](https://www.w3schools.com/Html/html_elements.asp) est un composant d'un document HTML ou d'une page web. Les √©l√©ments d√©finissent la mani√®re dont les informations sont affich√©es √† l'≈ìil humain sur le navigateur ‚Äî des informations telles que des images, des multim√©dias, du texte, des feuilles de style, des scripts, etc.

Pour cet exemple, nous avons utilis√© le s√©lecteur de ¬´ [.class](https://www.w3schools.com/cssref/css_selectors.asp) ¬ª (class = ¬´ storylink ¬ª) pour r√©cup√©rer les titres de tous les hyperliens de tous les √©l√©ments de la page d'accueil de Hacker News.

Si vous vous demandez comment trouver les noms des √©l√©ments qui composent un site web ‚Äî permettez-moi de vous montrer !

Lancez [Google Chrome](https://www.google.com/chrome/?brand=CHBD&gclid=EAIaIQobChMI87WK1Iya3AIVh_hkCh1hMgIIEAAYASAAEgKilfD_BwE&gclsrc=aw.ds&dclid=CLuW3dWMmtwCFcq5ZAodXTwHBA) et tapez notre URL [Hacker News](https://news.ycombinator.com/) `[https://news.ycombinator.com/](https://news.ycombinator.com/)`. Ensuite, faites un clic droit sur le titre de n'importe quel article et s√©lectionnez ¬´ **inspecter** ¬ª. Cela ouvrira la console web sur Google Chrome. Ou vous pouvez utiliser la **touche commande** (**‚åò**) + **touche option** (**‚å•**) + **touche J**.

![Image](https://cdn-media-1.freecodecamp.org/images/aI2tVsJLANFpuOdChy0O6gZHFN1HBe4Am4gF)
_Clic droit et s√©lectionnez Inspecter_

La console de d√©veloppement web s'ouvrira √† droite de votre √©cran. Remarquez que lorsque vous avez s√©lectionn√© le titre d'un lien, une section de la console est √©galement mise en surbrillance. L'√©l√©ment mis en surbrillance a une ¬´ classe ¬ª d√©finie comme ¬´ storylink ¬ª. Et maintenant, vous savez comment trouver les noms des √©l√©ments sur n'importe quel site !

![Image](https://cdn-media-1.freecodecamp.org/images/b9U1cj2dENdmS6zTP3jrYIkdfngZm33Zh10Y)

Si vous souhaitez interroger diff√©rentes m√©tadonn√©es sur [Hacker News](https://news.ycombinator.com/), survolez-les avec votre curseur. Ci-dessous, vous pouvez voir comment j'ai trouv√© le s√©lecteur .class = ¬´ sitestr ¬ª pour interroger l'URL d'un lien en survolant cet √©l√©ment sur Hacker News avec ma souris.

![Image](https://cdn-media-1.freecodecamp.org/images/Ntst2lyUgnwM93vP819Xi0VDsrKNuR7IPi2W)

![Image](https://cdn-media-1.freecodecamp.org/images/rFtJJhAOLDauqHKw2565vXMGI4OGPxZ-6AKt)

### C'est tout, et merci !

Merci d'avoir lu ! J'adorerais que vous **commentiez ici**, **m'envoyiez un e-mail √† Janeth [at] stdlib [dot] com**, ou suiviez [Standard Library](http://www.stdlib.com?utm_source=content&utm_medium=blog&utm_campaign=scrape_service) sur Twitter, [@StdLibHQ](https://twitter.com/StdLibHQ). Faites-moi savoir si vous avez construit quelque chose d'excitant que vous aimeriez que l'√©quipe de Standard Library mette en avant ou partage ‚Äî j'adorerais aider !

_Janeth Ledezma est une Developer Advocate pour Standard Library et dipl√¥m√©e de Berkeley ‚Äî allez les ours ! üêª Quand elle n'apprend pas la langue arabe ou ne fait pas de sport, vous pouvez la trouver en train de conduire sa CBR500R. üèç Suivez son parcours avec Standard Library sur Twitter @ms[s_ledezma.](https://twitter.com/mss_ledezma)_