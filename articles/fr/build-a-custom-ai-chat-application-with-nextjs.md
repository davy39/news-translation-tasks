---
title: 'Comment cr√©er une application de chat IA personnalis√©e avec Next.js : Fine-tuner
  GPT avec vos propres donn√©es'
subtitle: ''
author: Sharvin Shah
co_authors: []
series: null
date: '2025-10-07T11:11:07.070Z'
originalURL: https://freecodecamp.org/news/build-a-custom-ai-chat-application-with-nextjs
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1759834368425/fc26010c-077e-4af9-86cd-e16f1c218560.png
tags:
- name: Next.js
  slug: nextjs
- name: AI
  slug: ai
- name: Chat
  slug: chat
seo_title: 'Comment cr√©er une application de chat IA personnalis√©e avec Next.js :
  Fine-tuner GPT avec vos propres donn√©es'
seo_desc: In 2025, AI-powered applications have advanced from generic chatbots to
  highly specialised assistants that understand your specific field, communicate in
  your style, and give contextually relevant answers. While Large Language Models
  (LLMs) like GPT-...
---

En 2025, les applications aliment√©es par l'IA sont pass√©es de simples chatbots g√©n√©riques √† des assistants hautement sp√©cialis√©s qui comprennent votre domaine sp√©cifique, communiquent selon votre style et fournissent des r√©ponses pertinentes au contexte. Bien que les grands mod√®les de langage (LLM) comme GPT-5 poss√®dent des capacit√©s g√©n√©rales impressionnantes, il existe une demande croissante pour une IA qui comprenne profond√©ment des entreprises particuli√®res, des marques personnelles ou des domaines de connaissances sp√©cialis√©s.

Imaginez avoir un assistant IA qui ne conna√Æt pas seulement le d√©veloppement web en g√©n√©ral, mais qui comprend √©galement votre style de codage sp√©cifique, conna√Æt l'historique de vos projets et peut r√©pondre aux questions avec votre propre voix. Ce n'est pas de la science-fiction : c'est ce que le fine-tuning rend possible aujourd'hui.

Dans ce tutoriel, vous apprendrez √† affiner les derniers mod√®les GPT-4.1 d'OpenAI et √† cr√©er une application de chat pr√™te pour la production en utilisant Next.js 15. Je vous guiderai tout au long du processus : de la pr√©paration de votre jeu de donn√©es et de sa soumission pour le fine-tuning, √† la construction d'une interface de chat √©l√©gante utilisant votre mod√®le personnalis√©.

Je vous montrerai ce processus en utilisant le contenu du site web de mon agence, mtechzilla.com, comme exemple de donn√©es. Vous apprendrez √† scraper, nettoyer et formater du contenu r√©el pour l'entra√Ænement. Naturellement, vous voudrez utiliser vos propres donn√©es ‚Äî qu'il s'agisse de documentation, d'articles de blog, de transcriptions de support client ou de tout autre texte refl√©tant les connaissances et le style que vous souhaitez donner √† votre IA.

Ce tutoriel s'adresse aux d√©veloppeurs familiers avec React et Node.js mais novices dans le fine-tuning de mod√®les d'IA. √Ä la fin, vous disposerez d'une application de chat IA personnalis√©e enti√®rement fonctionnelle et pr√™te √† √™tre d√©ploy√©e.

En septembre 2025, le fine-tuning de GPT-5 n'est pas encore pris en charge. Ce tutoriel utilise GPT-4.1. Lorsque le fine-tuning de GPT-5 sera disponible, il vous suffira principalement de changer le nom du mod√®le de base.

## Table des mati√®res :

* [Comprendre le Fine-Tuning](#heading-comprendre-le-fine-tuning)
    
* [Pr√©requis](#heading-prerequis)
    
* [√âtape 1 : Pr√©paration du jeu de donn√©es](#heading-etape-1-preparation-du-jeu-de-donnees)
    
* [√âtape 2 : Soumission du Fine-Tuning](#heading-etape-2-soumission-du-fine-tuning)
    
* [√âtape 3 : Configuration de l'application Next.js](#heading-etape-3-configuration-de-l-application-nextjs)
    
* [√âtape 4 : Construction de l'interface de chat](#heading-etape-4-construction-de-l-interface-de-chat)
    
* [√âtape 5 : Int√©gration de la route API](#heading-etape-5-integration-de-la-route-api)
    
* [√âtape 6 : Tester votre application](#heading-etape-6-tester-votre-application)
    
* [Conclusion](#heading-conclusion)
    

## Comprendre le Fine-Tuning

Avant de plonger dans le code, expliquons ce que signifie r√©ellement le fine-tuning et quand c'est la meilleure option pour votre projet.

Le fine-tuning consiste √† prendre un mod√®le de langage pr√©-entra√Æn√© et √† l'entra√Æner davantage avec votre jeu de donn√©es sp√©cifique. C'est comme enseigner √† un √©tudiant brillant votre domaine d'expertise particulier et votre style de communication. Le mod√®le conserve ses connaissances g√©n√©rales mais devient sp√©cialis√© dans votre domaine.

C'est assez diff√©rent des autres m√©thodes de personnalisation du comportement de l'IA. La g√©n√©ration augment√©e par r√©cup√©ration (RAG) consiste √† fournir un contexte pertinent au mod√®le lors d'une requ√™te, un peu comme si l'on donnait √† quelqu'un des documents de r√©f√©rence √† utiliser pour r√©pondre √† des questions. Le Prompt Engineering, quant √† lui, consiste √† cr√©er des instructions intelligentes pour diriger le comportement du mod√®le sans entra√Ænement suppl√©mentaire. Le fine-tuning, cependant, aboutit √† un mod√®le qui a profond√©ment appris et internalis√© vos donn√©es.

Les compromis en 2025 sont plus clairs que jamais. Le fine-tuning n√©cessite un investissement initial dans la pr√©paration des donn√©es et des co√ªts d'entra√Ænement, mais il permet une inf√©rence plus rapide, √©limine le besoin d'injection de contexte et offre une personnalit√© plus coh√©rente. Les syst√®mes RAG sont moins chers √† mettre en place et plus faciles √† mettre √† jour, mais ils n√©cessitent des bases de donn√©es vectorielles et peuvent avoir du mal √† √©galer des styles nuanc√©s. Le Prompt Engineering est gratuit et imm√©diat, mais il limite le degr√© de personnalisation que vous pouvez atteindre.

En septembre 2025, OpenAI prend en charge le fine-tuning supervis√© pour trois nouveaux mod√®les : GPT-4.1, GPT-4.1-mini et GPT-4.1-nano. Chaque mod√®le a des capacit√©s et des co√ªts diff√©rents. GPT-4.1-nano est l'option la plus abordable, id√©ale pour les t√¢ches simples. GPT-4.1-mini √©quilibre performance et co√ªt, tandis que GPT-4.1 offre l'intelligence la plus √©lev√©e pour les applications complexes et sp√©cifiques √† un domaine.

Le fine-tuning est pr√©f√©rable lorsque vous avez besoin d'une voix et d'un style coh√©rents, que vous poss√©dez des connaissances sp√©cialis√©es mal couvertes par le mod√®le de base, que vous souhaitez r√©duire le d√©lai en supprimant l'injection de contexte, ou que vous devez garantir des comportements sp√©cifiques sans prompts compliqu√©s. Si vos besoins impliquent des informations changeant fr√©quemment, des recherches factuelles simples ou seulement une personnalisation occasionnelle, envisagez plut√¥t d'utiliser le RAG ou le Prompt Engineering.

## Pr√©requis

Avant de commencer, assurez-vous d'avoir configur√© les outils et comptes suivants :

1. Node.js v22+ et npm (v√©rifiez avec `node --version`)
    
2. Connaissances de base en JavaScript pour les scripts
    
3. Familiarit√© avec React et TypeScript pour l'application web
    
4. Une cl√© API OpenAI avec facturation activ√©e (obtenez-en une sur [https://platform.openai.com/docs/overview](https://platform.openai.com/docs/overview))
    
5. Un √©diteur de code
    

Vous aurez √©galement besoin de contenu pour entra√Æner votre mod√®le. Il peut s'agir d'articles de blog, de documentation, de transcriptions ou de tout texte repr√©sentant les connaissances et le style que vous souhaitez transmettre √† votre IA.

Si vous √™tes bloqu√©, vous pouvez consulter le d√©p√¥t GitHub pour obtenir de l'aide ou me contacter (je suis ravi d'aider mes coll√®gues d√©veloppeurs).

**Lien du d√©p√¥t :** [https://github.com/Sharvin26/ai-fine-tuning-project](https://github.com/Sharvin26/ai-fine-tuning-project)

## √âtape 1 : Pr√©paration du jeu de donn√©es

La cl√© d'un projet de fine-tuning r√©ussi est d'avoir un jeu de donn√©es bien pr√©par√©. OpenAI n√©cessite des donn√©es d'entra√Ænement au format JSONL (JSON Lines), o√π chaque ligne est un objet JSON complet repr√©sentant une conversation. Le JSONL est un format o√π chaque ligne est un objet JSON distinct, ce qui est id√©al pour g√©rer efficacement de grands jeux de donn√©es. Il permet un streaming et une manipulation faciles des donn√©es, ce qui le rend id√©al pour les t√¢ches d'apprentissage automatique.

La structure JSONL requise par OpenAI pour le fine-tuning est la suivante :

```json
{
   "messages":[
      {
         "role":"system",
         "content":"You are a helpful assistant."
      },
      {
         "role":"user",
         "content":"What is React?"
      },
      {
         "role":"assistant",
         "content":"React is a JavaScript library..."
      }
   ]
}
```

Chaque ligne repr√©sente une conversation compl√®te. Pour que le fine-tuning soit efficace, vous avez besoin d'au moins 10 exemples, bien que 50 √† 100 donnent g√©n√©ralement de meilleurs r√©sultats.

Construisons un scraper Node.js qui extrait le contenu d'un site web et le convertit au format appropri√©.

Tout d'abord, configurons la structure de notre dossier de scripts :

```bash
mkdir ai-fine-tuning-project
cd ai-fine-tuning-project
mkdir scripts
cd scripts
npm init -y
npm install cheerio axios dotenv openai
touch scraper.js fine-tune.js .gitignore .env
```

Ouvrez `ai-fine-tuning-project` dans un √©diteur de code et copiez les valeurs suivantes dans un fichier `.env` dans le dossier scripts.

```bash
OPENAI_API_KEY=sk-...votre-cle-api-ici...
OPENAI_ORG_ID=org-...votre-id-organisation...
```

Mettez √† jour les variables d'environnement avec une cl√© API et un ID d'organisation valides d'OpenAI.

1. G√©n√©rez une cl√© API en suivant ce guide : [O√π trouver ma cl√© API OpenAI ?](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key). Voici les meilleures pratiques pour s√©curiser votre cl√© API : [Meilleures pratiques pour la s√©curit√© des cl√©s API](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).
    
2. Vous pouvez trouver votre ID d'organisation OpenAI ici : [Param√®tres de l'organisation OpenAI](https://platform.openai.com/settings/organization/general).
    

Ajoutez le code suivant au fichier `.gitignore` :

```plaintext
# Environment variables
.env
.env.local
.env.*.local

# Dependencies
node_modules/

# Logs
*.log
logs/

# Cache and temporary files
.cache/
temp/
tmp/

# OS files
.DS_Store
Thumbs.db

# IDE files
.vscode/
.idea/
*.swp
*.swo
```

Mettez √† jour le script du scraper (`scraper.js`) avec le code suivant :

```javascript
const cheerio = require("cheerio");
const axios = require("axios");
const fs = require("fs");
const OpenAI = require("openai");
require("dotenv").config();

const config = {
    urls: [
        {
            url: "https://www.mtechzilla.com/",
            contentType: "general",
        },
        {
            url: "https://www.mtechzilla.com/company/about-us",
            contentType: "about",
        },
        {
            url: "https://www.mtechzilla.com/services",
            contentType: "services",
        },
    ],
    openai: {
        apiKey: process.env.OPENAI_API_KEY,
        model: "gpt-5",
        trainingExamples: 50,
    },
    outputFile: "training_data.jsonl",
};

class AIScraper {
    constructor(config) {
        this.urls = config.urls;
        this.openaiConfig = config.openai;
        this.outputFile = config.outputFile;
        this.scrapedContent = [];
        this.trainingData = [];
        this.openai = new OpenAI({
            apiKey: this.openaiConfig.apiKey,
        });
        this.totalCost = 0;
    }

    async fetchPage(url) {
        try {
            const response = await axios.get(url, {
                timeout: 30000,
                headers: {
                    'User-Agent': 'Mozilla/5.0 (compatible; AI-Training-Data-Scraper/1.0)'
                }
            });
            return response.data;
        } catch (error) {
            console.error(`Failed to fetch ${url}: ${error.message}`);
            return null;
        }
    }

    extractContent(html, urlConfig) {
        const $ = cheerio.load(html);
        
        $('script, style, nav, header, footer').remove();
        $('[class*="cookie"], [class*="popup"], [class*="ad"]').remove();
        $('button, .btn').remove();
        
        const headings = [];
        $('h1, h2, h3, h4').each((_, elem) => {
            const text = $(elem).text().trim();
            if (text.length > 3 && text.length < 200) {
                headings.push(text);
            }
        });
        
        const paragraphs = [];
        $('p').each((_, elem) => {
            const text = $(elem).text().trim();
            if (text.length > 20) {
                paragraphs.push(text);
            }
        });
        
        const listItems = [];
        $('ul li, ol li').each((_, elem) => {
            const text = $(elem).text().trim();
            if (text.length > 5 && text.length < 200) {
                listItems.push(text);
            }
        });
        
        return {
            url: urlConfig.url,
            contentType: urlConfig.contentType,
            title: $('title').text().trim(),
            metaDescription: $('meta[name="description"]').attr('content') || '',
            headings: headings.slice(0, 10),
            paragraphs: paragraphs.slice(0, 15),
            listItems: listItems.slice(0, 20)
        };
    }

    formatContentForPrompt(content) {
        let formattedContent = `URL: ${content.url}\n`;
        formattedContent += `Content Type: ${content.contentType}\n`;
        formattedContent += `Title: ${content.title}\n\n`;
        
        if (content.metaDescription) {
            formattedContent += `Description: ${content.metaDescription}\n\n`;
        }
        
        if (content.headings.length > 0) {
            formattedContent += `Headings:\n${content.headings.map(h => `- ${h}`).join('\n')}\n\n`;
        }
        
        if (content.paragraphs.length > 0) {
            formattedContent += `Content:\n${content.paragraphs.join('\n\n')}\n\n`;
        }
        
        if (content.listItems.length > 0) {
            formattedContent += `Features/Services:\n${content.listItems.map(item => `- ${item}`).join('\n')}\n\n`;
        }
        
        return formattedContent;
    }

    async generateTrainingDataWithAI() {
        const allContent = this.scrapedContent.map(content => 
            this.formatContentForPrompt(content)
        ).join('\n' + '='.repeat(50) + '\n');
        
        const prompt = `Based on the website content below, generate ${this.openaiConfig.trainingExamples} diverse, natural Q&A pairs for training a customer service chatbot.

Website Content:
${allContent}

Create varied questions a real customer might ask, including:
- Company/business information
- Services or products offered  
- Contact and support questions
- General greetings and conversational questions
- FAQ-style questions

Make questions natural and human-like. Generate accurate answers based ONLY on the provided website content. Keep answers concise but informative.

Return a JSON object with a "training_data" array containing the Q&A pairs.`;

        try {
            const response = await this.openai.chat.completions.create({
                model: this.openaiConfig.model,
                messages: [
                    {
                        role: "system",
                        content: "You are an expert at creating training data for AI chatbots. Always return valid JSON. Output your final JSON response directly without any reasoning or explanation."
                    },
                    {
                        role: "user",
                        content: prompt,
                    },
                ],
                response_format: { 
                    type: "json_schema",
                    json_schema: {
                        name: "training_data_generation",
                        schema: {
                            type: "object",
                            properties: {
                                training_data: {
                                    type: "array",
                                    items: {
                                        type: "object",
                                        properties: {
                                            question: {
                                                type: "string",
                                                description: "A natural question a customer might ask"
                                            },
                                            answer: {
                                                type: "string", 
                                                description: "An accurate answer based on the website content"
                                            }
                                        },
                                        required: ["question", "answer"]
                                    }
                                }
                            },
                            required: ["training_data"]
                        }
                    }
                }
            });
            
            const generatedContent = response.choices[0].message.content?.trim();
            
            const actualInputTokens = response.usage.prompt_tokens;
            const actualOutputTokens = response.usage.completion_tokens;
            const actualCost = (actualInputTokens * 1.25 / 1000000) + (actualOutputTokens * 10 / 1000000);
            this.totalCost += actualCost;
            
            if (!generatedContent) {
                throw new Error("No content generated in response");
            }
            
            const structuredData = JSON.parse(generatedContent);
            const validTrainingData = [];
            
            if (structuredData.training_data && Array.isArray(structuredData.training_data)) {
                structuredData.training_data.forEach(item => {
                    if (item.question && item.answer) {
                        validTrainingData.push({
                            messages: [
                                {
                                    role: "system",
                                    content: "You are a helpful assistant. Answer questions accurately based on the website content."
                                },
                                {
                                    role: "user", 
                                    content: item.question
                                },
                                {
                                    role: "assistant",
                                    content: item.answer
                                }
                            ]
                        });
                    }
                });
            }
            
            this.trainingData = validTrainingData;
            console.log(`Generated ${validTrainingData.length} training examples`);
            
        } catch (error) {
            console.error(`OpenAI API error: ${error.message}`);
            throw error;
        }
    }

    async scrape() {
        console.log(`Starting scraper for ${this.urls.length} URLs`);
        
        for (const urlConfig of this.urls) {
            const html = await this.fetchPage(urlConfig.url);
            
            if (html) {
                const content = this.extractContent(html, urlConfig);
                this.scrapedContent.push(content);
                console.log(`Scraped: ${content.title || urlConfig.url}`);
            }
            
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
        
        if (this.scrapedContent.length === 0) {
            throw new Error("No content scraped successfully");
        }
        
        await this.generateTrainingDataWithAI();
        
        console.log(`Scraped ${this.scrapedContent.length} pages, generated ${this.trainingData.length} examples`);
        console.log(`Total cost: $${this.totalCost.toFixed(4)}`);
    }

    saveToFile() {
        if (this.trainingData.length === 0) {
            console.error("No training data to save!");
            return;
        }
        
        const jsonl = this.trainingData
            .map(example => JSON.stringify(example))
            .join('\n');
        
        fs.writeFileSync(this.outputFile, jsonl);
        console.log(`Saved ${this.trainingData.length} examples to ${this.outputFile}`);
    }
}

async function main() {
    try {
        if (!config.openai.apiKey) {
            console.error("Please set your OpenAI API key in .env file");
            return;
        }
        
        const scraper = new AIScraper(config);
        await scraper.scrape();
        scraper.saveToFile();
        
        console.log("Scraping complete!");
        
    } catch (error) {
        console.error("Error:", error.message);
    }
}

main();
```

Si vous utilisez une version de Node.js ant√©rieure √† 22, vous pourriez rencontrer des probl√®mes lors de l'ex√©cution du script. La version recommand√©e est `v22.18.0`.

Ce code met en place un syst√®me automatis√© pour le web scraping et la cr√©ation de donn√©es d'entra√Ænement aliment√©es par l'IA. Il g√©n√®re des jeux de donn√©es d'entra√Ænement √† partir du contenu d'un site web. Le script utilise Cheerio pour analyser le HTML des URL fournies, extrayant des informations utiles telles que les titres, les paragraphes et les √©l√©ments de liste tout en ignorant les parties inutiles comme les scripts, les menus de navigation et les publicit√©s. Apr√®s avoir rassembl√© le contenu, il utilise l'API d'OpenAI (configur√©e pour utiliser GPT-4.1 avec une sortie JSON structur√©e) pour cr√©er intelligemment des paires de questions-r√©ponses naturelles √† des fins de fine-tuning.

Les paires Q&R g√©n√©r√©es sont format√©es dans des fichiers JSONL selon le format de fine-tuning d'OpenAI. Chaque entr√©e comprend un message syst√®me, une question utilisateur et une r√©ponse de l'assistant. Le scraper dispose √©galement de fonctionnalit√©s utiles telles que la limitation du d√©bit entre les requ√™tes, la gestion des erreurs et le suivi des co√ªts bas√© sur l'utilisation des tokens (1,25 $ par million de tokens d'entr√©e et 10 $ par million de tokens de sortie). Cela vous permet de suivre vos d√©penses tout en g√©n√©rant des donn√©es d'entra√Ænement.

Cependant, il s'agit d'un script de base qui peut √™tre am√©lior√© en fonction de la conception de votre site web, de votre public et de vos objectifs. Bien qu'il extraie diverses sections de contenu et cr√©e des paires de questions-r√©ponses diversifi√©es, vous devrez v√©rifier manuellement la sortie pour garantir la qualit√© et le formatage correct, car OpenAI rejettera les donn√©es mal format√©es. Dans les environnements de production, ce processus de v√©rification peut √™tre automatis√© en mettant √† jour le script avec une logique de validation suppl√©mentaire et des contr√¥les de qualit√©.

Maintenant, cr√©ons notre fichier `training_data.jsonl` en lan√ßant notre scraper :

```bash
node scraper.js
```

Vous devriez voir la sortie suivante :

```bash
Starting scraper for 3 URLs
Scraped: MTechZilla: Custom Software and App Development Company
Scraped: About MTechZilla | Custom Software Development Agency
Scraped: Expert App & Web Development Services | MTechZilla
Generated 50 training examples
Scraped 3 pages, generated 50 examples
Total cost: $0.0632
Saved 50 examples to training_data.jsonl
Scraping complete!
```

**Conseil de pro** : La qualit√© est plus importante que la quantit√©. Examinez le fichier `training_data.jsonl` g√©n√©r√© et affinez tous les exemples qui ne refl√®tent pas fid√®lement le contenu ou le ton que vous souhaitez que votre IA adopte.

## √âtape 2 : Soumission du Fine-Tuning

Avec notre jeu de donn√©es pr√©par√©, cr√©ons un script pour le soumettre √† OpenAI pour le fine-tuning. Nous utiliserons les mod√®les GPT-4.1 et g√©rerons l'ensemble du processus, du t√©l√©chargement √† la finalisation.

Mettez √† jour le script de fine-tuning (`fine-tune.js`) :

```javascript
const OpenAI = require("openai");
const fs = require("fs");
require("dotenv").config();

const CONFIG = {
    // Choose your base model for fine-tuning
    MODEL: "gpt-4.1-nano-2025-04-14", // Options: gpt-4.1-nano-2025-04-14, gpt-4.1-mini-2025-04-14, gpt-4.1-2025-04-14

    // Training file path
    TRAINING_FILE: "training_data.jsonl",

    // Polling interval for job status (in milliseconds)
    POLL_INTERVAL: 30000, // 30 seconds
};

class FineTuningManager {
    constructor() {
        if (!process.env.OPENAI_API_KEY) {
            throw new Error("OPENAI_API_KEY environment variable is required");
        }
        
        this.openai = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY,
            organization: process.env.OPENAI_ORG_ID,
        });
    }

    // Step 1: Validate training data format
    validateTrainingData() {
        console.log("üîç Validating training data format...");
        
        if (!fs.existsSync(CONFIG.TRAINING_FILE)) {
            throw new Error(`Training file not found: ${CONFIG.TRAINING_FILE}`);
        }

        const content = fs.readFileSync(CONFIG.TRAINING_FILE, "utf-8");
        const lines = content.split("\n").filter(line => line.trim());
        
        if (lines.length < 10) {
            throw new Error(`Need at least 10 examples. Found: ${lines.length}`);
        }

        let validExamples = 0;
        lines.forEach((line, index) => {
            try {
                const data = JSON.parse(line);
                
                // Validate JSONL structure as per OpenAI documentation
                if (!data.messages || !Array.isArray(data.messages) || data.messages.length < 2) {
                    throw new Error(`Invalid structure at line ${index + 1}`);
                }
                
                // Check for required roles
                const hasUser = data.messages.some(m => m.role === 'user');
                const hasAssistant = data.messages.some(m => m.role === 'assistant');
                
                if (!hasUser || !hasAssistant) {
                    throw new Error(`Missing user or assistant message at line ${index + 1}`);
                }
                
                validExamples++;
            } catch (e) {
                console.warn(`‚ö†Ô∏è Skipping line ${index + 1}: ${e.message}`);
            }
        });

        if (validExamples < 10) {
            throw new Error(`Need at least 10 valid examples. Found: ${validExamples}`);
        }

        console.log(`‚úÖ Validation passed: ${validExamples} valid examples`);
        return validExamples;
    }

    // Step 2: Upload training file to OpenAI
    async uploadTrainingFile() {
        console.log("üì§ Uploading training file...");

        const file = await this.openai.files.create({
            file: fs.createReadStream(CONFIG.TRAINING_FILE),
            purpose: "fine-tune",
        });

        console.log(`‚úÖ File uploaded: ${file.id}`);
        return file.id;
    }

    // Step 3: Create fine-tuning job
    async createFineTuningJob(fileId) {
        console.log(`üöÄ Creating fine-tuning job with model: ${CONFIG.MODEL}`);

        const job = await this.openai.fineTuning.jobs.create({
            training_file: fileId,
            model: CONFIG.MODEL,
            method: {
                type: "supervised"
            }
        });

        console.log(`‚úÖ Fine-tuning job created: ${job.id}`);
        return job.id;
    }

    // Step 4: Monitor job until completion
    async monitorJob(jobId) {
        console.log("‚è≥ Monitoring fine-tuning job...");
        console.log("This typically takes 10-30 minutes...\n");

        while (true) {
            const job = await this.openai.fineTuning.jobs.retrieve(jobId);
            
            console.log(`Status: ${job.status}`);

            if (job.status === "succeeded") {
                console.log("\nüéâ Fine-tuning completed successfully!");
                console.log(`üéÜ Your fine-tuned model ID: ${job.fine_tuned_model}`);
                return job.fine_tuned_model;
            } 
            
            if (job.status === "failed") {
                throw new Error(`Fine-tuning failed: ${job.error?.message || 'Unknown error'}`);
            }
            
            if (job.status === "cancelled") {
                throw new Error("Fine-tuning was cancelled");
            }

            // Wait before checking again
            await new Promise(resolve => setTimeout(resolve, CONFIG.POLL_INTERVAL));
        }
    }

    // Complete supervised fine-tuning workflow
    async runFineTuning() {
        try {
            console.log("ü§ñ Starting OpenAI Supervised Fine-Tuning\n");
            console.log(`üìã Using model: ${CONFIG.MODEL}`);
            console.log(`üìÑ Training file: ${CONFIG.TRAINING_FILE}\n`);
            
            // Step 1: Validate data
            const validExamples = this.validateTrainingData();
            
            // Step 2: Upload file
            const fileId = await this.uploadTrainingFile();
            
            // Step 3: Create job
            const jobId = await this.createFineTuningJob(fileId);
            
            // Step 4: Monitor completion
            const modelId = await this.monitorJob(jobId);
            
            console.log("\n" + "=".repeat(60));
            console.log("SUCCESS! Your fine-tuned model is ready!");
            console.log("=".repeat(60));
            console.log(`\n Model ID: ${modelId}`);
            console.log(`Trained on ${validExamples} examples`);
            console.log("\n Next steps:");
            console.log("1. Copy the Model ID above");
            console.log("2. Use it in your application to access your custom model");
            
            return modelId;
            
        } catch (error) {
            console.error(`\n‚ùå Fine-tuning failed: ${error.message}`);
            
            if (error.message.includes("not found")) {
                console.log("üí° Tip: Make sure training_data.jsonl exists in the current directory");
            } else if (error.message.includes("API_KEY")) {
                console.log("üí° Tip: Set OPENAI_API_KEY in your .env file");
            }
            
            throw error;
        }
    }
}

// Main execution
async function main() {
    const manager = new FineTuningManager();
    await manager.runFineTuning();
}

if (require.main === module) {
    main().catch(console.error);
}

module.exports = FineTuningManager;
```

Ce script g√®re l'ensemble du processus de fine-tuning une fois que vos donn√©es d'entra√Ænement sont pr√™tes via le scraper. Il fonctionne comme un gestionnaire automatis√©, prenant votre fichier d'entra√Ænement JSONL et le transformant en un mod√®le OpenAI personnalis√© con√ßu pour vos besoins sp√©cifiques. Le processus commence par une validation approfondie, garantissant que votre fichier d'entra√Ænement existe, contient au moins 10 exemples valides et suit le format requis par OpenAI avec les r√¥les de message corrects (utilisateur et assistant). Cette √©tape de validation est importante car OpenAI rejettera les donn√©es qui ne sont pas format√©es correctement, donc identifier les probl√®mes t√¥t vous fait gagner du temps et √©conomise des co√ªts d'API.

Ce script fournit un flux de travail complet de fine-tuning avec les nouveaux mod√®les GPT-4.1. Vous pouvez choisir entre les mod√®les nano (le moins cher), mini (√©quilibr√©) ou complet (le plus performant), selon vos besoins et votre budget. Une fois la validation r√©ussie, le script t√©l√©charge votre fichier d'entra√Ænement sur les serveurs d'OpenAI et lance un travail de fine-tuning en utilisant le mod√®le de base s√©lectionn√©. Le script utilise le fine-tuning supervis√©, ce qui signifie que votre mod√®le apprend directement des paires questions-r√©ponses que vous avez fournies, ajustant ses r√©ponses pour correspondre aux informations et au ton de votre site web.

La partie la plus simple est la phase de surveillance, o√π le script v√©rifie automatiquement l'√©tat du travail de fine-tuning toutes les 30 secondes jusqu'√† ce qu'il soit termin√©. Le fine-tuning prend g√©n√©ralement de 10 √† 30 minutes, selon la taille de votre jeu de donn√©es et le mod√®le de base choisi. Pendant le processus, vous recevrez des mises √† jour d'√©tat claires dans la console. Une fois termin√©, le script vous donne votre ID de mod√®le personnalis√©, que vous pouvez utiliser imm√©diatement dans vos applications. Il fournit √©galement des messages d'erreur utiles et des conseils si quelque chose ne va pas, comme vous rappeler de v√©rifier votre cl√© API ou de v√©rifier que votre fichier d'entra√Ænement existe.

Maintenant, soumettons notre fichier `training_data.jsonl` pour le fine-tuning avec la commande suivante :

```bash
node fine-tune.js
```

Vous devriez voir la sortie suivante :

```bash
üéâ Fine-tuning completed successfully!
üéÜ Your fine-tuned model ID: ft:gpt-4.1-nano-2025-04-14:...

============================================================
SUCCESS! Your fine-tuned model is ready!
============================================================

 Model ID: ft:ft:gpt-4.1-nano-2025-04-14:...
Trained on 50 examples

 Next steps:
1. Copy the Model ID above
2. Use it in your application to access your custom model
```

**Conseil de pro** : Commencez par le mod√®le nano pour tester votre jeu de donn√©es et votre flux de travail. C'est l'option la plus rentable et elle est souvent suffisante pour des connaissances sp√©cifiques √† un domaine. Vous pourrez toujours vous entra√Æner avec un mod√®le plus grand plus tard en mettant √† jour la configuration dans `fine-tune.js`.

## √âtape 3 : Configuration de l'application Next.js

Maintenant que notre mod√®le est entra√Æn√©, construisons une application de chat moderne. Nous allons configurer un dossier web s√©par√© avec une application Next.js utilisant TypeScript et shadcn/ui pour les composants.

Tout d'abord, revenez √† la racine du projet :

```bash
cd ..
```

Puis cr√©ez l'application web :

```bash
npx create-next-app@latest web
```

Choisissez les options suivantes lors de la configuration :

```bash
‚úî Would you like to use TypeScript? ‚Ä∫ Yes
‚úî Which linter would you like to use? ‚Ä∫ ESLint
‚úî Would you like to use Tailwind CSS? ‚Ä∫ Yes
‚úî Would you like your code inside a `src/` directory? ‚Ä∫ Yes
‚úî Would you like to use App Router? (recommended) ‚Ä∫ Yes
‚úî Would you like to use Turbopack? (recommended) ‚Ä∫ No
‚úî Would you like to customize the import alias (`@/*` by default)? ‚Ä∫ No
```

Allez dans le r√©pertoire web :

```bash
cd web
```

Installez les paquets requis en utilisant la commande suivante :

```bash
npm install ai @ai-sdk/openai @ai-sdk/react openai lucide-react
```

Maintenant, configurons shadcn/ui pour de beaux composants :

```bash
npx shadcn@latest init
```

Choisissez l'option suivante lors de la configuration :

```bash
‚úî Which color would you like to use as the base color? ‚Ä∫ Slate
```

Et ajoutez les composants shadcn suivants :

```bash
npx shadcn@latest add button
npx shadcn@latest add card
npx shadcn@latest add scroll-area
npx shadcn@latest add avatar
```

Cr√©ez le fichier `.env.local` en utilisant la commande suivante :

```json
touch .env.local
```

Ajoutez vos variables d'environnement dans `web/.env.local` :

```bash
OPENAI_API_KEY=sk-...votre-cle-api...
OPENAI_ORG_ID=org-...votre-id-organisation...
FINE_TUNED_MODEL=ft:gpt-4.1-nano-2025-04-14:... # Votre ID de mod√®le issu du fine-tuning
```

Dans le r√©pertoire `src`, cr√©ez un nouveau dossier nomm√© `types`. √Ä l'int√©rieur de ce dossier, cr√©ez un fichier appel√© `chat.ts` et copiez-y le code suivant :

```typescript
// web/src/types/chat.ts
export interface Message {
    id: string;
    role: "user" | "assistant" | "system";
    content: string;
    createdAt?: Date;
}

export interface ChatRequest {
    messages: Message[];
    model?: string;
}

export interface ChatResponse {
    message: Message;
    usage?: {
        prompt_tokens: number;
        completion_tokens: number;
        total_tokens: number;
    };
}
```

Ce code TypeScript d√©finit les structures de donn√©es (interfaces) pour une application de chat, √©tablissant une norme sur la mani√®re dont les messages et les interactions API doivent √™tre format√©s dans votre application. L'interface `Message` sp√©cifie ce que chaque message de chat doit inclure : un ID unique, un r√¥le indiquant s'il provient de l'utilisateur, de l'assistant ou du syst√®me, le contenu du message et un horodatage optionnel. L'interface `ChatRequest` organise les donn√©es que vous envoyez √† votre mod√®le affin√©, y compris un tableau de messages (l'historique de la conversation) et un param√®tre de mod√®le optionnel pour sp√©cifier quel mod√®le affin√© utiliser.

Enfin, l'interface `ChatResponse` d√©finit ce que vous recevrez de l'API : le message de r√©ponse de l'assistant et des statistiques d'utilisation optionnelles indiquant combien de tokens ont √©t√© utilis√©s pour les prompts et les compl√©tions. Cela vous aide √† suivre les co√ªts. En d√©finissant ces interfaces, TypeScript garantit la s√©curit√© des types dans toute votre application, capturant les erreurs pendant le d√©veloppement et fournissant des suggestions d'autocompl√©tion dans votre √©diteur de code. Cela rend votre application de chat plus robuste et plus facile √† maintenir.

Mettez √† jour `app/layout.tsx` avec les m√©ta-informations et la mise en page du chat :

```typescript
// web/app/layout.tsx
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";

const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
    title: "AI Chat - Powered by Custom Fine-Tuned Model",
    description: "Chat with an AI trained on custom content",
};

export default function RootLayout({
    children,
}: {
    children: React.ReactNode;
}) {
    return (
        <html lang="en" className="h-full">
            <body
                className={`${inter.className} h-full bg-gradient-to-br from-slate-50 to-slate-100 dark:from-slate-950 dark:to-slate-900`}
                suppressHydrationWarning={true}
            >
                {children}
            </body>
        </html>
    );
}
```

Ce code configure la mise en page racine (root layout) d'une application Next.js, agissant comme une enveloppe autour de chaque page de votre application de chat. Il commence par importer la police Inter de Google Fonts et la configure pour utiliser des caract√®res latins, donnant √† votre application une apparence propre et moderne.

L'objet `metadata` d√©finit le titre et la description de la page qui apparaissent dans les onglets du navigateur et les r√©sultats des moteurs de recherche, ce qui est important pour le SEO et l'exp√©rience utilisateur. Le composant `RootLayout` rassemble tout : il enveloppe toutes les pages de votre application (en utilisant la prop `children`) dans une structure HTML coh√©rente avec un style pleine hauteur (`h-full`) et un arri√®re-plan en d√©grad√© agr√©able. Cet arri√®re-plan passe de tons ardoise clairs en mode clair √† de l'ardoise fonc√©e en mode sombre, s'adaptant automatiquement aux param√®tres syst√®me de l'utilisateur. L'attribut `suppressHydrationWarning` r√©sout un probl√®me courant de Next.js o√π le HTML rendu par le serveur peut l√©g√®rement diff√©rer du HTML rendu par le client (souvent d√ª √† des √©l√©ments comme les horodatages ou la d√©tection de th√®me), emp√™chant ainsi les avertissements dans la console.

Cette mise en page garantit que chaque page de votre application de chat partage le m√™me style de base, la m√™me typographie et les m√™mes m√©tadonn√©es, de sorte que vous n'avez pas besoin de r√©p√©ter le code sur chaque page. Elle nous donne une base solide avec TypeScript pour la s√©curit√© des types, shadcn/ui pour les composants standard, une gestion efficace des variables d'environnement et une structure de projet propre, facile √† maintenir et √† √©tendre.

## √âtape 4 : Construction de l'interface de chat

Construisons une interface de chat magnifique et r√©active en utilisant les composants shadcn et les puissantes fonctionnalit√©s de streaming du SDK AI de Vercel.

Tout d'abord, cr√©ez le composant de chat principal dans `src/components/chat.tsx` :

```typescript
// web/src/components/chat.tsx
"use client";

import { useChat } from "@ai-sdk/react";
import { useRef, useEffect, useState } from "react";
import { Send, Bot, User, Loader2, AlertCircle } from "lucide-react";
import { Button } from "@/components/ui/button";
import {
    Card,
    CardContent,
    CardHeader,
    CardTitle,
    CardDescription,
} from "@/components/ui/card";
import { ScrollArea } from "@/components/ui/scroll-area";
import { Avatar, AvatarFallback } from "@/components/ui/avatar";
import { cn } from "@/lib/utils";

export default function Chat() {
    const scrollAreaRef = useRef<HTMLDivElement>(null);
    const inputRef = useRef<HTMLInputElement>(null);
    const [input, setInput] = useState("");

    const {
        messages,
        sendMessage,
        status,
        error,
        regenerate,
        stop,
        setMessages,
    } = useChat({
        onError: (error) => {
            console.error("Chat error:", error);
        },
        onFinish: () => {
            inputRef.current?.focus();
        },
    });

    const isLoading = status === "streaming" || status === "submitted";

    // Add welcome message on mount
    useEffect(() => {
        if (messages.length === 0) {
            setMessages((prev) => [
                ...prev,
                {
                    id: "welcome",
                    role: "assistant" as const,
                    parts: [
                        {
                            type: "text" as const,
                            text: "Hello! I'm your custom AI assistant, trained on specific content. How can I help you today?",
                        },
                    ],
                },
            ]);
        }
    }, [messages.length, setMessages]);

    const handleSubmit = (e: React.FormEvent) => {
        e.preventDefault();
        if (!input.trim() || isLoading) return;
        
        sendMessage({
            role: "user",
            parts: [{ type: "text", text: input }],
        });
        setInput("");
    };

    const handleInputChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        setInput(e.target.value);
    };

    // Auto-scroll to bottom when new messages arrive
    useEffect(() => {
        if (scrollAreaRef.current) {
            const scrollContainer = scrollAreaRef.current.querySelector(
                "[data-radix-scroll-area-viewport]"
            );
            if (scrollContainer) {
                scrollContainer.scrollTop = scrollContainer.scrollHeight;
            }
        }
    }, [messages]);


    return (
        <div className="flex h-screen max-w-5xl mx-auto p-4">
            <Card className="flex-1 flex flex-col shadow-xl overflow-hidden">
                {/* Header */}
                <CardHeader className="border-b flex-shrink-0">
                    <div className="flex items-center space-x-4">
                        <div className="relative">
                            <Avatar className="h-10 w-10">
                                <AvatarFallback className="bg-primary text-primary-foreground">
                                    <Bot className="h-6 w-6" />
                                </AvatarFallback>
                            </Avatar>
                            <div className="absolute -bottom-0.5 -right-0.5 w-3 h-3 bg-green-500 rounded-full border-2 border-background animate-pulse" />
                        </div>
                        <div className="flex-1">
                            <CardTitle>Custom AI Assistant</CardTitle>
                            <CardDescription>
                                Powered by your fine-tuned model
                            </CardDescription>
                        </div>
                    </div>
                </CardHeader>

                {/* Messages Area */}
                <ScrollArea ref={scrollAreaRef} className="flex-1 min-h-0">
                    <div className="p-4 space-y-4 pb-4">
                        {messages.map((message) => {
                            const isUser = (message.role as string) === "user";
                            return (
                                <div
                                    key={message.id}
                                    className={cn(
                                        "flex",
                                        isUser ? "justify-end" : "justify-start"
                                    )}
                                >
                                    <div
                                        className={cn(
                                            "flex items-start gap-3 max-w-[85%] min-w-0",
                                            isUser && "flex-row-reverse"
                                        )}
                                    >
                                        {/* Avatar */}
                                        <Avatar className="h-8 w-8 shrink-0">
                                            <AvatarFallback
                                                className={cn(
                                                    isUser
                                                        ? "bg-primary text-primary-foreground"
                                                        : "bg-muted"
                                                )}
                                            >
                                                {isUser ? (
                                                    <User className="h-4 w-4" />
                                                ) : (
                                                    <Bot className="h-4 w-4" />
                                                )}
                                            </AvatarFallback>
                                        </Avatar>

                                        {/* Message Content */}
                                        <div className="space-y-1 min-w-0 flex-1">
                                            <div
                                                className={cn(
                                                    "rounded-lg px-4 py-2.5 text-sm max-w-full",
                                                    isUser
                                                        ? "bg-primary text-primary-foreground"
                                                        : "bg-muted"
                                                )}
                                            >
                                                <div className="whitespace-pre-wrap break-words leading-relaxed overflow-wrap-anywhere">
                                                    {message.parts?.map((part, index) => {
                                                        if (part.type === "text") {
                                                            return <p key={index}>{part.text}</p>;
                                                        }
                                                        return null;
                                                    })}
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            );
                        })}

                        {/* Loading Indicator */}
                        {isLoading && (
                            <div className="flex justify-start">
                                <div className="flex items-center gap-3 max-w-[85%]">
                                    <Avatar className="h-8 w-8">
                                        <AvatarFallback className="bg-muted">
                                            <Bot className="h-4 w-4" />
                                        </AvatarFallback>
                                    </Avatar>
                                    <div className="bg-muted rounded-lg px-4 py-2.5">
                                        <div className="flex items-center gap-2">
                                            <Loader2 className="h-3 w-3 animate-spin" />
                                            <span className="text-sm text-muted-foreground">
                                                Thinking...
                                            </span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        )}

                        {/* Error Message */}
                        {error && (
                            <div className="flex justify-center px-4">
                                <div className="bg-destructive/10 border border-destructive/20 rounded-lg p-3 max-w-md">
                                    <div className="flex items-start gap-2">
                                        <AlertCircle className="h-4 w-4 text-destructive mt-0.5" />
                                        <div className="space-y-1">
                                            <p className="text-sm text-destructive">
                                                {error.message ||
                                                    "Something went wrong. Please try again."}
                                            </p>
                                            <Button
                                                onClick={() => regenerate()}
                                                variant="ghost"
                                                size="sm"
                                                className="h-7 px-2 text-xs"
                                            >
                                                Retry last message
                                            </Button>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        )}
                    </div>
                </ScrollArea>

                {/* Input Area */}
                <CardContent className="border-t p-4 flex-shrink-0">
                    <form onSubmit={handleSubmit} className="flex gap-2">
                        <input
                            ref={inputRef}
                            type="text"
                            value={input}
                            onChange={handleInputChange}
                            placeholder="Type your message..."
                            disabled={isLoading}
                            className={cn(
                                "flex-1 px-3 py-2 text-sm rounded-md border border-input bg-background",
                                "placeholder:text-muted-foreground",
                                "focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",
                                "disabled:cursor-not-allowed disabled:opacity-50"
                            )}
                            autoFocus
                        />

                        {isLoading ? (
                            <Button
                                type="button"
                                onClick={stop}
                                variant="destructive"
                                size="sm"
                            >
                                Stop
                            </Button>
                        ) : (
                            <Button
                                type="submit"
                                disabled={!input.trim()}
                                size="sm"
                            >
                                <Send className="h-4 w-4" />
                                <span className="ml-2 hidden sm:inline">
                                    Send
                                </span>
                            </Button>
                        )}
                    </form>

                    {/* Character Counter */}
                    {input.length > 0 && (
                        <div className="mt-2 text-xs text-muted-foreground text-right">
                            {input.length} / 4000
                        </div>
                    )}
                </CardContent>
            </Card>
        </div>
    );
}
```

Ce code cr√©e le composant principal de l'interface de chat o√π les utilisateurs interagissent avec votre mod√®le d'IA affin√©. Il utilise principalement le hook `useChat` du SDK AI de Vercel, qui g√®re toutes les t√¢ches complexes de messagerie, telles que l'envoi de messages, la r√©ception de r√©ponses en streaming, la gestion de l'√©tat de la conversation et la gestion des erreurs. Le composant configure plusieurs hooks React : `useRef` pour g√©rer les √©l√©ments du DOM comme la zone de d√©filement et le champ de saisie, `useState` pour le texte de saisie, et `useEffect` pour les effets secondaires comme le d√©filement automatique et l'affichage d'un message de bienvenue lors du premier chargement du chat.

L'interface utilisateur est construite √† l'aide de composants shadcn/ui pour cr√©er un aspect poli et professionnel avec un effort minimal. La mise en page comporte trois sections principales : un en-t√™te affichant l'√©tat de l'assistant IA (avec un point vert clignotant pour indiquer qu'il est en ligne), une zone de messages d√©filante au milieu et un formulaire de saisie en bas. Chaque message est affich√© avec un avatar (une ic√¥ne utilisateur pour les messages humains et une ic√¥ne robot pour les r√©ponses de l'IA) et stylis√© diff√©remment selon l'exp√©diteur. Les messages de l'utilisateur apparaissent √† droite avec un arri√®re-plan de couleur primaire, tandis que les messages de l'assistant apparaissent √† gauche avec un arri√®re-plan discret. Le composant inclut des d√©tails d'exp√©rience utilisateur (UX) r√©fl√©chis comme le d√©filement automatique vers le dernier message, la gestion du focus qui revient au champ de saisie apr√®s l'envoi, et un compteur de caract√®res indiquant √† quel point vous √™tes proche de la limite de 4000 caract√®res.

Le composant g√®re √©galement diff√©rents √©tats de mani√®re fluide : il affiche une animation "Thinking..." avec un chargeur rotatif pendant que l'IA g√©n√®re une r√©ponse, affiche des messages d'erreur avec un bouton de r√©essai si quelque chose ne va pas, et permet m√™me aux utilisateurs d'arr√™ter la r√©ponse en cours si elle prend trop de temps. Lors du chargement, le bouton d'envoi se transforme en bouton "Stop", donnant aux utilisateurs un contr√¥le total sur la conversation. Tout est envelopp√© dans un style r√©actif qui s'adapte aux diff√©rentes tailles d'√©cran, garantissant que votre interface de chat est superbe, que les utilisateurs soient sur ordinateur ou sur mobile.

Maintenant, mettez √† jour la page principale pour utiliser le composant de chat :

```typescript
// web/app/page.tsx
import Chat from "@/components/chat";

export default function Home() {
    return (
        <main className="h-screen">
            <Chat />
        </main>
    );
}
```

Cette interface de chat utilise les composants shadcn/ui pour cr√©er un aspect poli et professionnel. Elle comprend des fonctionnalit√©s telles que le streaming de messages en temps r√©el, des √©tats de chargement anim√©s, la gestion des erreurs avec options de r√©essai, le d√©filement automatique vers les derniers messages, un design r√©actif pour tous les appareils, des raccourcis clavier, des fonctionnalit√©s d'accessibilit√© et un compteur de caract√®res pour tenir les utilisateurs inform√©s.

## √âtape 5 : Int√©gration de la route API

Cr√©ons maintenant la route API backend qui connecte notre interface de chat au mod√®le OpenAI affin√© avec un support de streaming appropri√©.

```typescript
// web/app/api/chat/route.ts
import { openai } from "@ai-sdk/openai";
import { streamText, convertToModelMessages } from "ai";
import { NextRequest, NextResponse } from "next/server";

export async function POST(req: NextRequest) {
    try {
        // Parse request body
        const body = await req.json();
        const { messages } = body;

        // Validate messages
        if (!messages || !Array.isArray(messages)) {
            return NextResponse.json(
                { error: "Invalid request format" },
                { status: 400 }
            );
        }

        // Convert UI messages to model messages using AI SDK utility
        const modelMessages = convertToModelMessages(messages);

        // Check if we have any valid messages
        if (modelMessages.length === 0) {
            return NextResponse.json(
                { error: "No valid messages provided" },
                { status: 400 }
            );
        }

        // Add system prompt to prevent hallucination and guide the model
        const systemPrompt = {
            role: "system" as const,
            content: `You are a helpful assistant answering questions about MTechZilla, a software development company. 

IMPORTANT INSTRUCTIONS:
- Only answer questions based on information you were specifically trained on about MTechZilla
- If you don't know something or weren't trained on specific information, say "I don't have that specific information in my training data"
- Never make up or guess information about MTechZilla
- Be accurate and only provide information you're confident about

Answer questions accurately based on your training data about MTechZilla's services, technologies, and approach.`
        };

        // Prepend system message if not already present
        const hasSystemMessage = modelMessages.some(msg => msg.role === 'system');
        if (!hasSystemMessage) {
            modelMessages.unshift(systemPrompt);
        }

        // Load fine-tuned model ID from environment variable
        const fineTunedModelId = process.env.FINE_TUNED_MODEL;

        // Ensure we have a valid model ID
        if (!fineTunedModelId) {
            throw new Error("No fine-tuned model ID available");
        }

        // Call OpenAI with streaming using the new AI SDK
        const result = streamText({
            model: openai(fineTunedModelId),
            messages: modelMessages,
            temperature: 0.1, // Lower temperature for more deterministic, factual responses
        });

        // Log stream start
        console.log(`Stream started`);

        // Return UI message stream response for useChat compatibility
        return result.toUIMessageStreamResponse({
            headers: {
                "Cache-Control": "no-cache, no-transform",
                "X-Accel-Buffering": "no",
            },
        });
    } catch (error: unknown) {
        console.error("Chat API Error:", error);

        // Handle specific errors
        if (error && typeof error === "object" && "status" in error) {
            const errorWithStatus = error as { status: number };

            if (errorWithStatus.status === 401) {
                return NextResponse.json(
                    {
                        error: "Authentication failed. Check API key configuration.",
                    },
                    { status: 401 }
                );
            }

            if (errorWithStatus.status === 404) {
                return NextResponse.json(
                    {
                        error: "Model not found. Check your fine-tuned model ID.",
                    },
                    { status: 404 }
                );
            }

            if (errorWithStatus.status === 429) {
                return NextResponse.json(
                    {
                        error: "OpenAI rate limit reached. Please try again later.",
                    },
                    { status: 429 }
                );
            }
        }

        // Generic error
        return NextResponse.json(
            { error: "An error occurred. Please try again." },
            { status: 500 }
        );
    }
}
```

Ce code configure le point de terminaison de l'API backend qui connecte votre interface de chat √† votre mod√®le OpenAI affin√©. Lorsqu'un utilisateur envoie un message, cette route API Next.js re√ßoit la requ√™te, v√©rifie si les messages sont correctement format√©s et les convertit du format UI vers la structure requise par l'API d'OpenAI √† l'aide de l'outil `convertToModelMessages` du SDK AI. Une fonctionnalit√© cl√© est l'injection d'un prompt syst√®me avant d'envoyer les messages √† votre mod√®le. Le code ajoute automatiquement des instructions sp√©cifiques, demandant √† l'IA de ne r√©pondre qu'en fonction de ses donn√©es d'entra√Ænement sur MTechZilla (dans cet exemple) et de dire clairement "Je n'ai pas cette information sp√©cifique" au lieu d'inventer des choses. C'est crucial pour pr√©venir les erreurs et garantir que le chatbot reste pr√©cis et fiable.

La route charge votre ID de mod√®le affin√© √† partir des variables d'environnement pour s√©curiser les param√®tres sensibles. Elle utilise le SDK AI de Vercel pour appeler OpenAI avec le streaming activ√©, de sorte que les r√©ponses apparaissent mot par mot en temps r√©el au lieu d'attendre la r√©ponse compl√®te. La temp√©rature est r√©gl√©e sur 0,1, ce qui rend le mod√®le plus pr√©visible et factuel ‚Äî parfait pour un chatbot de service client o√π la pr√©cision est plus importante que la cr√©ativit√©. La fonction `streamText` g√®re tous les d√©tails du streaming, et la r√©ponse est renvoy√©e dans un format qui fonctionne directement avec le hook `useChat` de votre composant frontend.

Le code inclut une gestion approfondie des erreurs pour les probl√®mes courants : √©checs d'authentification (cl√©s API invalides), erreurs de mod√®le non trouv√© (ID de mod√®le incorrect), limitation du d√©bit (trop de requ√™tes) et erreurs g√©n√©rales du serveur. Chaque type d'erreur renvoie un message sp√©cifique et utile pour faciliter le d√©bogage pendant le d√©veloppement et fournir un retour clair aux utilisateurs en cas de probl√®me. Les en-t√™tes de r√©ponse incluent des directives de contr√¥le du cache pour garantir des donn√©es fra√Æches et √©viter les probl√®mes de mise en m√©moire tampon pendant le streaming, garantissant ainsi une exp√©rience de chat fluide et en temps r√©el pour vos utilisateurs.

## √âtape 6 : Tester votre application

Une fois que tout est configur√©, testons l'application compl√®te et assurons-nous qu'elle fonctionne correctement.

Tout d'abord, assurez-vous d'avoir ajout√© votre ID de mod√®le affin√© au fichier d'environnement :

```bash
OPENAI_API_KEY=sk-...votre-cle-api...
OPENAI_ORG_ID=org-...votre-id-organisation...
FINE_TUNED_MODEL=ft:gpt-4.1-nano-2025-04-14:... # Copiez depuis scripts/model_info.json
```

Lancez le serveur de d√©veloppement :

```bash
npm run dev
```

Ouvrez [http://localhost:3000](http://localhost:3000) dans votre navigateur, et vous verrez l'interface suivante :

![Capture d'√©cran d'une fen√™tre de chat avec "Custom AI Assistant" en haut. L'IA salue l'utilisateur en disant : "Bonjour ! Je suis votre assistant IA personnalis√©, entra√Æn√© sur un contenu sp√©cifique. Comment puis-je vous aider aujourd'hui ?" Un champ de saisie de message et un bouton d'envoi se trouvent en bas.](https://cdn.hashnode.com/res/hashnode/image/upload/v1757941475393/692f92ff-11bc-451d-a9fa-a288c87f7d78.png align="center")

Testez divers sc√©narios :

1. **Test de connaissances du domaine** : Posez des questions li√©es √† vos donn√©es d'entra√Ænement
    
2. **Flux de conversation** : Ayez une conversation √† plusieurs tours
    
3. **Cas limites** : Essayez des entr√©es tr√®s longues, des messages rapides, des interruptions de r√©seau
    
4. **Tests mobiles** : Testez sur diff√©rentes tailles d'√©cran
    

## Conclusion

F√©licitations ! Vous avez r√©ussi √† affiner un mod√®le GPT-4.1 et √† cr√©er une application de chat pr√™te pour la production, d√©montrant ainsi la puissance de l'IA personnalis√©e. Nous avons transform√© le contenu brut d'un site web en donn√©es d'entra√Ænement structur√©es, utilis√© les derniers mod√®les d'OpenAI pour le fine-tuning et construit une application Next.js moderne avec streaming en temps r√©el et une interface soign√©e. La cl√© d'un fine-tuning r√©ussi est de savoir quand c'est le bon choix ‚Äî utilisez-le pour une voix de marque coh√©rente, des connaissances sp√©cialis√©es du domaine et pour r√©duire la complexit√© du RAG, mais envisagez l'option RAG pour les informations qui changent souvent. Notre structure de projet modulaire s√©pare les scripts d'entra√Ænement de l'application web, ce qui facilite le r√©entra√Ænement des mod√®les et l'ajout de nouvelles fonctionnalit√©s.

En continuant, n'oubliez pas que le fine-tuning est un processus √©tape par √©tape. Observez comment les utilisateurs interagissent, recueillez des commentaires et continuez √† am√©liorer votre mod√®le avec de nouveaux exemples d'entra√Ænement. √âvitez les erreurs courantes comme l'utilisation de trop peu de donn√©es (visez plus de 50 bons exemples), l'ignorance des erreurs de validation et l'absence de limites de d√©bit et de gestion des erreurs appropri√©es. En 2025, la personnalisation de l'IA √©volue rapidement, avec des tendances vers des mod√®les plus efficaces, l'apprentissage continu et des m√©thodes hybrides m√©langeant diff√©rentes techniques. Ce qui n√©cessitait auparavant une √©quipe d'ing√©nieurs ML peut d√©sormais √™tre r√©alis√© par quelques d√©veloppeurs poss√©dant les bonnes comp√©tences. Vous disposez maintenant des outils et des connaissances n√©cessaires pour cr√©er des applications d'IA sp√©cialis√©es qui comprennent et servent v√©ritablement votre domaine sp√©cifique.

*Pour les fondateurs envisageant l'adoption de l'IA, j'ai cr√©√© un guide gratuit :* [*AI or No AI? The 2025 Founder's Decision Playbook*](https://www.notion.so/AI-or-No-AI-The-2025-Founder-s-Decision-Playbook-25ec9ed724ec80668a8fc42bb804515a) *‚Äî un cadre pour aider √† d√©cider quand l'IA apporte r√©ellement de la valeur.*

*N'h√©sitez pas √† me contacter sur* [*LinkedIn*](https://www.linkedin.com/in/sharvinshah/) *et* [*Twitter*](https://twitter.com/sharvinshah26)*.*