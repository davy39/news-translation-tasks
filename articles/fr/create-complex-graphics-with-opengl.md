---
title: Créer des graphiques complexes avec OpenGL
subtitle: ''
author: Beau Carnes
co_authors: []
series: null
date: '2021-08-11T12:40:12.000Z'
originalURL: https://freecodecamp.org/news/create-complex-graphics-with-opengl
coverImage: https://www.freecodecamp.org/news/content/images/2021/08/opengladvanced.png
tags:
- name: openGL
  slug: opengl
- name: youtube
  slug: youtube
seo_title: Créer des graphiques complexes avec OpenGL
seo_desc: "OpenGL can be used to create complex 2D and 3D graphics effects. \nWe just\
  \ released an advanced OpenGL course on the freeCodeCamp.org YouTube channel.\n\
  Victor Gordan created this course. Before this course he created one of the most\
  \ popular OpenGL cour..."
---

OpenGL peut être utilisé pour créer des effets graphiques 2D et 3D complexes. 

Nous venons de publier un cours avancé sur OpenGL sur la chaîne YouTube freeCodeCamp.org.

Victor Gordan a créé ce cours. Avant ce cours, il a créé l'un des cours OpenGL les plus populaires sur YouTube. Maintenant, il vous aidera à faire passer vos compétences au niveau supérieur.

Voici les sujets abordés dans ce cours :

* Le tampon de profondeur
* Le tampon de pochoir
* Le culling de faces
* La transparence et le mélange
* Le framebuffer
* Les cubemaps et la skybox
* Le geometry shader
* L'instanciation
* L'anti-aliasing

Regardez le cours ci-dessous ou sur [la chaîne YouTube freeCodeCamp.org](https://youtu.be/GJFHqK_-ARA) (1 heure de visionnage).

%[https://youtu.be/GJFHqK_-ARA]

## Transcription

OpenGL peut être utilisé pour créer des effets graphiques complexes. Ce cours avancé sur OpenGL de Victor Gordan vous aidera à faire passer vos compétences au niveau supérieur.

Salut à tous ! Dans ce cours, je vais vous enseigner différents sujets avancés en OpenGL qui vous aideront à réaliser des effets plus complexes, des rendus plus beaux et des scènes plus optimisées. Si vous ne savez pas ce qu'est OpenGL ou si vous n'êtes pas familier avec celui-ci, alors vous devriez d'abord regarder le cours pour débutants sur OpenGL que vous pouvez trouver sur cette chaîne. Et cela devrait être tout ce que vous devez savoir sur ce cours, profitez-en !

Dans ce tutoriel, nous allons examiner les tampons de profondeur dans OpenGL et voir également comment nous pouvons les utiliser pour un petit effet graphique.

Vous vous souvenez peut-être que nous avons déjà utilisé le tampon de profondeur dans le tutoriel "Passage en 3D" afin de corriger un problème étrange que nous avions. Comme le tampon est désactivé par défaut, nous voulons nous assurer qu'il est activé et que nous le nettoyons à chaque frame, tout comme le tampon de couleur. Maintenant, ce que fait ce tampon, c'est qu'il stocke des valeurs de "profondeur" qui représentent à quelle distance du plan proche de la matrice de projection se trouve un certain fragment. Une valeur de profondeur de 0 signifie qu'il est exactement sur le plan proche, et une valeur de 1 signifie qu'il est sur le plan éloigné.

En utilisant ces informations de profondeur, nous pouvons évaluer quel objet doit être devant quel autre objet. Nous pouvons le faire en utilisant la fonction glDepthFunc et en insérant l'une des entrées suivantes. Par défaut, OpenGL choisit GL_LESS, ce qui signifie que si la valeur de profondeur d'un objet est inférieure à celle de la valeur de profondeur actuelle, alors la première valeur remplace la seconde. Dans la plupart des circonstances, vous devriez utiliser GL_LESS, mais je suppose que vous pourriez également choisir l'une des autres si vous voulez que votre jeu ou application soit déroutant.

Maintenant, la partie intéressante. Visualisons le tampon de profondeur. Nous pouvons facilement le faire en allant dans le fragment shader et en sortant gl_FragCoord.z comme FragColor. Le problème est que dès que nous appuyons sur exécuter, vous remarquerez que l'écran est principalement purement blanc. La seule façon de voir un peu d'obscurité est de se rapprocher très près d'un objet. Cela est dû au fait que la profondeur dans OpenGL n'est pas linéaire. Si la profondeur était linéaire, alors nous aurions la même quantité de précision pour la profondeur à une distance proche que nous aurions à une distance éloignée. Comme nous nous concentrons presque toujours sur les choses qui sont proches de nous, nous voulons que la précision soit très élevée près de nous et faible loin de nous. Cela est réalisé en utilisant cette formule. Ne vous inquiétez pas, nous n'avons pas à l'implémenter puisque OpenGL le fait automatiquement.

Parfois, cependant, vous voulez utiliser une autre formule, donc pour cela, nous devons d'abord obtenir la valeur z en linéarisant la fonction de profondeur, ce qui peut être fait en utilisant cette fonction. Maintenant, en utilisant cette fonction, nous obtenons la valeur z qui, gardez à l'esprit, n'est pas normalisée. Cette valeur est simplement la distance par rapport au plan proche. Donc, déclarons les constantes near et far de notre frustum, et divisons la profondeur linéaire par la longueur far pour la normaliser rapidement juste pour voir à quoi ressemblent les résultats. Maintenant, regardons un problème rapide que vous pouvez rencontrer, puis je vous montrerai l'effet intéressant que nous pouvons obtenir avec les tampons de profondeur.

Donc, le problème principal qui survient avec les tampons de profondeur est appelé Z-fighting, et il se produit parce que deux triangles ou plus ont le même tampon de profondeur et ainsi la fonction de profondeur ne peut pas décider lequel est plus proche que l'autre, et ainsi il change constamment entre eux. Une solution facile à cela est généralement de s'assurer que vous n'avez pas de triangles qui sont trop proches les uns des autres et parallèles. Si le Z-fighting apparaît à une distance éloignée, alors vous pourriez également envisager de modifier la fonction du tampon de profondeur afin d'avoir plus de précision à cette distance. Et le dernier truc est d'utiliser un entier plus grand pour le tampon de profondeur. Habituellement, par défaut, il utilise 24 bits, mais vous pourriez le changer en 32 bits si votre carte le supporte. Cela augmentera la précision et ainsi diminuera le changement de Z-fighting.

Maintenant, pour l'effet intéressant. Nous pouvons prendre la valeur z et la brancher dans une fonction logistique pour laquelle nous avons un paramètre de raideur et un paramètre de décalage. La raideur contrôlera la rapidité avec laquelle la valeur de profondeur passe de proche de 0 à proche de 1, et le décalage déterminera à quelle valeur z ce changement est à moitié fait. Le truc intéressant à propos de cela est que cela peut vous donner des bords lisses pour la fin de votre frustum si vous le souhaitez, mais le truc encore plus intéressant est que cela peut quelque peu simuler un effet de brouillard. Donc, changeons notre couleur de fond en gris et calculons la valeur de profondeur en utilisant notre fonction. Ensuite, multiplions notre direcLight() habituel par l'inverse de notre valeur de profondeur, et ajoutons également la valeur de profondeur fois la couleur grise d'avant. Maintenant, nous devrions avoir un bel effet de brouillard simple. Gardez à l'esprit que vous devrez peut-être ajuster un peu la raideur et le décalage pour obtenir le bon résultat.

Amusez-vous à jouer avec différents effets !

Dans ce tutoriel, nous allons examiner le tampon de pochoir et comment nous pouvons l'utiliser pour créer des effets utiles tels que le contour d'un modèle.

Donc, le tampon de pochoir, tout comme le tampon de profondeur, contient une valeur pour chaque pixel que vous pouvez voir, ces valeurs étant utilisées pour le masquage d'image en général. Contrairement au tampon de profondeur, où chaque pixel contient entre 2 et 4 octets de données, pour le tampon de pochoir, chaque pixel ne contient qu'un seul octet de données, donc des valeurs de 0 à 255. Mais vous n'utiliserez principalement que les valeurs 0 et 1.

Donc, voyons comment nous pouvons travailler avec ce nouveau tampon. Tout d'abord, nous avons la fonction glStencilMask qui nous permet de choisir quelles parties du tampon de pochoir nous voulons pouvoir modifier. Elle prend simplement un pixel du masque et un pixel correspondant du tampon de pochoir, et applique une comparaison bit à bit "ET" sur eux. Gardez à l'esprit que chaque pixel a un octet de données, donc 8 bits. Une opération bit à bit "ET" compare chaque bit avec son homologue correspondant et ne sort 1 que s'ils sont tous les deux à 1. Par conséquent, si nous entrons 0x00 dans glStencilMask, ce qui signifie que nous avons 8 bits égaux à 0, alors toutes les comparaisons échoueront et le tampon de pochoir ne changera pas du tout. Mais si nous entrons 0xFF dans glStencilMask, alors tous les bits du masque seront à 1 puisque 0xFF est égal à huit uns, et ainsi nous pourrons modifier n'importe quelle partie du tampon de pochoir.

Maintenant, regardons deux autres fonctions que nous pouvons utiliser : glStencilFunc et glStencilOp. glStencilFunc nous permet de contrôler comment le tampon de pochoir passe un test ou échoue un test, tandis que glStencilOp nous permet de dicter ce qui se passe lorsque le test de pochoir échoue, lorsque le test de pochoir passe mais que le test de profondeur échoue, et lorsque les deux passent.

Prenons un regard plus approfondi sur glStencilFunc. Elle prend trois arguments : une fonction, une valeur de référence et un masque. La fonction peut être l'une de celles-ci, par défaut étant définie sur GL_ALWAYS pour que le test passe toujours. La valeur de référence est simplement la valeur que nous utilisons pour comparer dans la fonction. Remarquez comment avant de comparer la valeur de pochoir avec la valeur de référence, nous appliquons une opération bit à bit ET aux deux en utilisant le masque. Cela signifie que si vous voulez comparer la valeur numérique des deux avec précision, vous voudrez que votre masque soit 0xFF afin que rien ne change.

Maintenant, pour glStencilOp, elle a quatre arguments : sfail, dpfail et dppass. Ceux-ci signifient échec de pochoir, échec de profondeur et passage de profondeur. Pour tous ceux-ci, vous pouvez choisir entre les options suivantes. Par défaut, ils ont tous GL_KEEP, ce qui signifie essentiellement que rien ne change. Il n'y a pas vraiment grand-chose à dire de plus sur ces fonctions, donc si vous voulez en savoir plus à leur sujet, consultez la documentation.

Le tampon de pochoir peut être utilisé pour de nombreuses choses telles que les portails, les miroirs et plus encore, mais une fonctionnalité facile à implémenter est le contour des modèles, alors examinons cela. Nous voulons d'abord rendre notre objet comme nous le faisons normalement et mettre à jour le tampon de pochoir avec des 1 partout où nous avons un fragment de notre objet, et des 0 partout où nous n'avons pas de fragment de notre objet. Cela créera essentiellement une figure comme celle-ci. Ensuite, nous voulons désactiver l'écriture dans le tampon de pochoir pour ne pas le modifier accidentellement, et également désactiver le test de profondeur afin de pouvoir nous assurer que le prochain objet que nous dessinons sera complètement devant le précédent. Maintenant, nous voulons rendre une version agrandie de l'objet que nous avions avant, mais cette fois en une couleur unie, et avec la condition suivante : nous ne dessinons ses fragments que là où la valeur de pochoir n'est pas 1, donc essentiellement pas là où se trouvait la silhouette de l'objet précédent. Ensuite, nous restaurons simplement l'écriture dans le pochoir et réactivons le tampon de profondeur. C'est tout ce que nous avons à faire.

Maintenant, implémentons cela en code. Nous commençons par activer notre tampon de pochoir en utilisant glEnable(GL_STENCIL_TEST), et nous nous assurons également que notre tampon de profondeur est activé. Ensuite, nous utilisons glStencilOp en y insérant GL_KEEP, GL_KEEP et GL_REPLACE. Cela fera en sorte que lorsque les tests de profondeur et de pochoir passent tous les deux, nous utiliserons la valeur de référence spécifiée par glStencilFunc. Maintenant, assurons-nous de nettoyer tous les tampons avant chaque frame, et passons à la partie où la magie opère.

Tout d'abord, nous spécifions que notre test de pochoir passe toujours, et nous définissons la valeur de référence à 1. Ensuite, nous activons l'écriture dans tout notre tampon de pochoir avec un masque de pochoir de tous les 1. Et maintenant, nous dessinons simplement notre objet. À ce stade, notre tampon de pochoir ressemble à ceci, et notre tampon de couleur à ceci. Rappelez-vous que toutes ces valeurs sont 1 car nous avons spécifié dans la fonction glStencilOp que si les tests de pochoir et de profondeur passent tous les deux, alors rendre le pixel du tampon de pochoir égal à 1. Maintenant, pour le contour, nous voulons que notre test de pochoir ne passe que lorsqu'il n'est pas égal à 1 et que le test de profondeur passe. Ensuite, nous désactivons notre tampon de profondeur pour des raisons mentionnées précédemment, et désactivons l'écriture dans le masque de pochoir afin de pouvoir conserver notre silhouette originale.

Maintenant, comme nous voulons que le contour soit d'une couleur unie, nous devrons créer deux nouveaux shaders et un programme de shader. Donc, créons d'abord le programme de shader comme ceci. Ensuite, pour "outlining.frag", nous voulons simplement retourner une couleur, tandis que pour "outlining.vert", nous voulons obtenir la position et toutes les uniformes liées aux transformations, plus une nouvelle uniforme float appelée outlining, que nous multiplierons avec la matrice d'échelle. Maintenant, de retour dans la fonction principale, nous voulons envoyer cette uniforme outlining au shader avec une valeur de quelque chose comme 1.08. Ensuite, nous dessinons simplement le même objet à nouveau, mais cette fois en utilisant les autres shaders. La dernière étape que nous devons faire est d'activer l'écriture dans tout le pochoir, de le nettoyer en faisant toujours passer le test et en remplaçant les valeurs par 0, et d'activer le tampon de profondeur. Maintenant, si vous exécutez le programme, vous devriez voir un contour autour de votre objet. Si votre objet a son origine à son centre géométrique et s'il n'a pas de formes très complexes, alors le contour a probablement l'air bien. Dans mon cas, cependant, vous pouvez voir que l'origine n'est pas au centre puisque le contour est décalé vers le haut, et que les formes sont assez complexes, avec de nombreuses courbes, donc cette méthode ne fonctionnera pas très bien.

Une meilleure méthode qui ne prend pas beaucoup de temps serait d'importer les normales dans le vertex shader et de les ajouter au vecteur de position, en les multipliant par l'outlining, que nous retirerons de la matrice d'échelle, et que nous abaisserons maintenant de 1.08 à 0.08. Maintenant, lors de la mise à l'échelle des vecteurs, au lieu de les mettre à l'échelle à partir de leur origine, nous les mettons à l'échelle vers l'extérieur à partir du modèle en utilisant la normale comme référence pour ce que signifie "vers l'extérieur". Cela vous donnera de bien meilleurs résultats, avec une exception. Si vous avez des arêtes vives, alors vos normales seront proches de la perpendiculaire les unes par rapport aux autres et créeront ainsi un petit espace lors de l'expansion du modèle.

Par conséquent, une troisième solution à cela serait de simplement avoir un autre modèle qui est plus grand que le premier. Pour être plus précis, il doit être plus épais, pas nécessairement plus grand. Vous pouvez obtenir quelque chose comme cela en utilisant le modificateur solidify de Blender. Ici, vous pouvez voir que j'ai le modèle initial et la version plus grande de celui-ci. Maintenant, j'ai déjà exporté les deux en tant que modèles différents, et je n'ai qu'à les importer dans mon programme comme ceci. Ensuite, au lieu de dessiner l'objet une deuxième fois, je dessine simplement la version plus grande de celui-ci, cette fois sans même avoir besoin d'une uniforme pour le mettre à l'échelle. Et comme vous pouvez le voir, cela donne les meilleurs résultats, bien qu'au coût de doubler le coût de stockage... Vous pourriez bien sûr faire une fonction similaire à la fonction solidify que Blender a, mais cela serait légèrement plus compliqué pour ce tutoriel.

Aujourd'hui, je vais vous montrer ce qu'est le culling de faces et comment il affecte les performances. Nous allons également mesurer ce changement de performance en créant un compteur FPS.

Donc, le culling de faces est une étape dans le pipeline graphique qui décide si un triangle passera au fragment shader (c'est-à-dire si le triangle sera dessiné ou non). OpenGL décide cela en voyant quel côté du triangle fait actuellement face à la caméra. En général, dans la plupart des programmes graphiques 3D, c'est le côté avant d'un triangle qui est envoyé au fragment shader, et le côté arrière d'un triangle qui est rejeté.

La façon dont OpenGL détermine quel côté est lequel est par une convention d'index, qui peut être soit dans le sens des aiguilles d'une montre, soit dans le sens inverse des aiguilles d'une montre. Dans un cadre dans le sens inverse des aiguilles d'une montre, si l'ordre des indices d'un triangle est dans le sens inverse des aiguilles d'une montre lorsqu'il nous fait face, alors le côté que nous voyons est le côté avant. De même, si l'ordre des indices d'un triangle est dans le sens des aiguilles d'une montre lorsqu'il nous fait face, alors le côté que nous voyons est le côté arrière. Pour un cadre dans le sens des aiguilles d'une montre, c'est exactement l'inverse. La plupart des programmes graphiques utilisent une norme dans le sens inverse des aiguilles d'une montre, mais ne vous attendez pas à ce que tous l'utilisent.

Maintenant, afin de mettre tout cela en code, nous devons simplement activer le culling de faces en utilisant glEnable avec GL_CULL_FACE, spécifier quelle face nous voulons garder, 99% du temps ce sera GL_FRONT, et ensuite spécifier la norme que nous voulons utiliser. Encore une fois, je suggère d'utiliser celle dans le sens inverse des aiguilles d'une montre puisque, d'après ce que j'ai vu, elle est plus courante que celle dans le sens des aiguilles d'une montre.

Maintenant, si nous exécutons le programme, vous remarquerez que lorsque nous entrons dans un objet, nous ne pourrons pas voir son intérieur, puisque celui-ci contient les arrières des triangles, qui sont rejetés. Par conséquent, nous ne voyons que l'arrière-plan.

Donc, voyons si cela fait une différence de performance. Pour cela, nous aurons besoin d'un compteur FPS, que j'afficherai dans le titre de la fenêtre. Commençons par créer trois doubles pour le temps précédent, le temps actuel et la différence entre ces deux. Ensuite, nous voulons également un entier non signé qui servira de compteur pour voir combien de frames nous avons dans un certain laps de temps. Maintenant, le FPS est simplement le nombre de frames que vous obtenez en une seconde. Cela signifie que pour obtenir le FPS, nous pouvons compter le nombre de frames que nous obtenons en une seconde, une frame étant une boucle dans notre boucle principale while. Mais cela signifierait également que notre FPS ne sera mis à jour qu'une fois par seconde. Au lieu de cela, mettons-le à jour toutes les 30 secondes par exemple.

Pour cela, nous devons simplement obtenir le temps actuel en secondes en utilisant glfwGetTime, la différence de temps et incrémenter le compteur. Ensuite, si la différence est supérieure ou égale à un trentième de seconde, nous procédons à la mesure du FPS. Le FPS sera simplement égal à 1 divisé par la différence de temps, ce qui est le nombre de frames en une seconde que cette différence de temps donne, mais la différence de temps contient plusieurs frames, qui sont égales au compteur, donc nous devons également le multiplier par le compteur. Maintenant, nous pourrions nous arrêter ici, mais il est également utile de savoir combien de temps prend une frame en termes de millisecondes. Pour cela, nous divisons simplement la différence de temps par le compteur, ce qui nous donne le nombre de secondes qu'une frame prend, puis nous multiplions cela par 1000 pour le transformer en millisecondes. Ensuite, nous mettons simplement ensemble le nouveau titre et l'appliquons à la fenêtre en utilisant glfwSetWindowTitle. Ensuite, nous voulons définir le temps précédent comme le temps actuel afin de ramener la différence de temps à 0, et également définir le compteur à 0.

Maintenant, si vous démarrez votre programme, vous pourrez voir le nombre de frames que vous avez. S'ils sont bloqués à 60, cela signifie que vous avez le VSync activé, qui essaie de maintenir votre FPS constant à 60 frames par seconde. Si vous souhaitez le désactiver, écrivez glfwSwapInterval(0) dans votre fonction principale. Gardez à l'esprit que cela ne pourra désactiver le VSync que si le VSync n'est pas forcé par votre pilote graphique. Dans tous les cas, je recommande de le garder à 60 frames par seconde. Mais si vous ne voulez pas le faire, assurez-vous au moins que les fonctions qui gèrent les entrées de l'utilisateur sont placées dans une instruction if qui fonctionne périodiquement comme celle-ci, sinon la réactivité de vos entrées variera avec votre FPS, ce que vous ne voulez pas.

Et juste pour vous montrer que le culling de faces améliore votre FPS, voici un modèle de très haute résolution et la différence de FPS. La différence n'est pas grande ici, mais elle est perceptible dans les chiffres. Lorsque vous avez plusieurs modèles et beaucoup de choses qui se passent, la différence deviendra encore plus perceptible.

Dans ce tutoriel, je vais vous montrer comment activer rapidement la transparence et comment utiliser la fonction de mélange dans OpenGL.

Comme vous l'avez peut-être remarqué, toutes les textures que nous avons utilisées jusqu'à présent avaient 4 composants : ROUGE, VERT, BLEU et ALPHA (RGBA). Les trois premiers donnent de la couleur à notre scène, tandis que le dernier contrôle le niveau de transparence des différents objets. Maintenant, si vous regardez ce modèle d'herbe que j'ai importé, vous remarquerez qu'il n'y a aucune transparence. Pour l'activer, nous devons simplement créer un nouveau fragment shader qui sera identique à notre fragment shader normal, mais nous vérifierons si la valeur alpha est inférieure à un certain seuil, et si c'est le cas, nous rejetterons ce fragment. N'oubliez pas de créer également un nouveau programme de shader pour ce nouveau fragment shader. Donc, si vous exécutez le programme, vous devriez voir que l'herbe est maintenant comme elle devrait être.

Maintenant, je vais simplement ajouter un tas de fenêtres transparentes placées aléatoirement. Comme le code ici n'est pas pertinent pour OpenGL, je ne l'expliquerai pas. Le shader que j'utilise pour ceux-ci est un shader très basique qui affiche simplement les textures sans aucun éclairage. Donc maintenant, comme vous pouvez le voir, il y a un tas de FENÊTRES, mais même si dans ma texture elles sont transparentes, ici elles ne le sont pas. Pour obtenir un effet transparent, nous avons besoin de mélange.

Maintenant, un peu de théorie. Voici la formule qu'OpenGL utilise pour mélanger différentes couleurs ensemble. Tous les termes C représentent la couleur, tandis que les termes T représentent la transparence. Au cas où vous ne le sauriez pas ou l'auriez oublié, un niveau alpha de 0 est complètement transparent et un niveau alpha de 1 est complètement opaque. Ensuite, la couleur source est la couleur dans le fragment shader, tandis que la couleur de destination est la couleur dans le tampon de couleur. Ces transparences peuvent avoir différentes formules. La plus courante est celle où la source obtient sa valeur de transparence à partir de la partie alpha de la couleur source, tandis que la transparence de la destination est 1 moins la valeur alpha de la source. Donc maintenant, disons à OpenGL que nous voulons utiliser cette configuration en utilisant glBlendFunc en spécifiant les fonctions source et destination. Voici une liste de certaines fonctions que vous pourriez vouloir utiliser pour une raison ou une autre. Ensuite, si vous le souhaitez, vous pouvez également utiliser glBlendEquation avec l'un de ces arguments afin de spécifier comment vous voulez que les couleurs précédentes interagissent, en changeant essentiellement l'équation par défaut. Et enfin, vous pouvez utiliser la fonction glBlendFuncSeparate pour choisir comment interagir avec le canal RGB et le canal alpha pour la source et la destination. Gardez à l'esprit que vous ne pouvez pas spécifier une fonction pour chaque valeur RGB, seulement pour toutes ensemble.

À ce stade, nous devons simplement activer le mélange en utilisant glEnable(GL_BLEND) juste avant nos fenêtres, puis le désactiver juste après avoir fini de les dessiner afin de ne pas affecter accidentellement autre chose. Vous devriez toujours faire cela avec des objets transparents. Après cela, compilez et vous devriez voir que les fenêtres sont transparentes. Mais il y a un problème... le mélange est tout déréglé. Cela ne semble tout simplement pas correct. Et pour cela, nous avons notre ami le tampon de profondeur à blâmer. Comme les fenêtres sont dessinées dans un ordre aléatoire, les fenêtres qui sont dessinées derrière celles déjà existantes ne sont pas dessinées du tout puisque le test de profondeur échoue. Donc, pour dessiner toutes les fenêtres, nous devrions dessiner la plus éloignée en premier et la plus proche en dernier. Ou vous pourriez bien sûr être paresseux à ce sujet et simplement désactiver le tampon de profondeur lors du dessin des fenêtres, mais cela ne fonctionnera pas dans la plupart des circonstances, et je ne le recommande généralement pas. Une autre option serait de trier les fenêtres par leur distance par rapport à la caméra.

Maintenant, le tri n'a rien à voir avec OpenGL, donc je ne vais pas expliquer cette partie, et je vous encourage même à trouver votre propre solution pour trier les fenêtres. L'important est que je calcule toutes les distances d'une fenêtre à la caméra en soustrayant la position de la fenêtre de la position de la caméra et en obtenant la longueur de ce vecteur. Ensuite, en fonction de cette longueur, je trie toutes mes fenêtres de la plus éloignée à la plus proche et je les dessine. C'est aussi simple que cela ! Vous devez simplement être un peu créatif avec la partie tri et la façon dont vous stockez vos objets. Gardez simplement à l'esprit que cette méthode où vous dessinez simplement les objets dans l'ordre n'est pas garantie de fonctionner 100% du temps. Si différents objets transparents s'intersectent ou font des choses étranges, vous obtiendrez des résultats étranges. Mais les autres méthodes sont assez compliquées, donc pour l'instant, cela devra suffire.

Dans ce tutoriel, je vais vous montrer comment implémenter un framebuffer personnalisé dans votre application OpenGL et comment vous pouvez utiliser le framebuffer pour obtenir des effets de post-traitement.

Tout d'abord, qu'est-ce qu'un framebuffer ? Eh bien, vous pouvez penser à un framebuffer comme une collection de plusieurs tampons qui résultent en l'image finale que vous voyez sur votre écran. Il contient donc un tampon de couleur, un tampon de profondeur et un tampon de pochoir. Maintenant, pourquoi voudriez-vous en utiliser un ? Eh bien, si nous créons notre propre framebuffer, alors nous pouvons l'afficher sur un rectangle qui couvre tout l'écran et ensuite, en utilisant des shaders, modifier les pixels affichés sur le rectangle pour obtenir différents effets. Cela s'appelle le post-traitement car vous traitez les pixels après que tout le rendu a déjà été fait.

D'accord, maintenant implémentons le framebuffer. Tout comme n'importe quel objet OpenGL, nous créons un entier non signé, nous générons le framebuffer en utilisant glGenFramebuffers, et nous le lions. C'était tout pour le framebuffer. Maintenant, nous devons ajouter une texture de couleur pour qu'il soit utile. Donc, nous allons créer une texture comme dans le tutoriel sur les textures, en nous assurant de clamp la texture aux bords, sinon certains effets saigneront d'un côté de l'écran à l'autre en raison de la répétition par défaut de la texture. Ensuite, nous attachons simplement la texture au framebuffer en utilisant glFramebufferTexture2D.

Gardez à l'esprit que nous stockons notre couleur dans une texture, donc nous pouvons y accéder depuis un shader, ce que nous voulons faire. Mais dans le cas du tampon de profondeur, nous ne nous soucions pas vraiment de le lire dans un shader pour ce tutoriel, donc au lieu d'utiliser une texture, nous pouvons utiliser un Render Buffer Object qui est beaucoup plus rapide mais a l'inconvénient que vous ne pouvez pas le lire directement dans un shader. Nous le créons en utilisant glGenRenderbuffers, puis nous configurons son stockage en utilisant glRenderbufferStorage, en y insérant GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, et la largeur et la hauteur. Nous utilisons GL_DEPTH24_STENCIL8 afin de pouvoir y stocker à la fois le tampon de pochoir et le tampon de profondeur. Soyez également très prudent que tous les composants du framebuffer aient la même largeur et la même hauteur, sinon vous pourriez obtenir une erreur. Ensuite, nous l'attachons simplement au framebuffer en utilisant glFramebufferRenderbuffer.

Et pour un peu de vérification d'erreurs, écrivez simplement ceci. Malheureusement, les erreurs ne sont pas très spécifiques, elles vous donnent simplement un nombre. Voici les significations des erreurs que vous pouvez obtenir.

Maintenant que nous avons l'objet framebuffer, nous pouvons créer notre rectangle qui couvrira toujours tout l'écran, et donc nous ne voulons pas appliquer de transformations. Créons maintenant deux shaders très basiques pour le framebuffer, faisons-en un programme de shader, puis envoyons l'unité de notre texture, 0 puisque c'est la seule texture dans ce shader.

Maintenant, gérons la partie dessin. Tout d'abord, assurons-nous de lier le framebuffer avant de dessiner quoi que ce soit, y compris l'arrière-plan. Assurez-vous que vos tampons sont nettoyés et que vous avez activé le test de profondeur après cela. Ensuite, après avoir fini de dessiner tout dans la scène, nous voulons revenir à notre framebuffer par défaut en liant 0, et dessiner le rectangle qui affiche le framebuffer que nous venons de délier. Assurez-vous simplement de désactiver le test de profondeur afin que le rectangle ne échoue pas le test de profondeur.

Maintenant, si vous exécutez le programme, vous devriez voir ce que vous voyiez avant sans aucune différence. Si votre écran est d'une couleur unie, vérifiez d'abord que vous n'avez pas d'erreurs dans votre fenêtre de type cmd, puis assurez-vous que votre culling de faces ne se débarrasse pas du rectangle (donc changez soit l'ordre des sommets, soit désactivez le culling lors du dessin du rectangle). Pour toute autre erreur, vérifiez le code source dans la description et parcourez votre code très soigneusement, il y a beaucoup de choses qui peuvent mal tourner dans ce cas.

D'accord, maintenant rendons cela intéressant. Dans le fragment shader du framebuffer, nous pouvons faire toutes sortes d'effets intéressants. Certains effets faciles seraient d'inverser les couleurs comme ceci, ou de rendre l'image en noir et blanc. Mais ceux-ci ne sont pas très intéressants. Pour obtenir des résultats plus intéressants, nous voulons échantillonner plusieurs pixels lorsque nous choisissons la couleur d'un seul pixel. Pour cela, nous voulons d'abord déclarer un tableau de vec2 qui représentera le décalage du pixel sur lequel nous nous trouvons à ses 8 voisins. Remarquez comment je divise 1 par 800 pour obtenir la largeur et la hauteur d'un pixel pour ma fenêtre de 800 par 800. Après cela, nous voulons créer un tableau de floats qui représentera quelque chose appelé un noyau. C'est essentiellement une matrice qui nous aide à obtenir des effets intéressants en définissant à quel point chaque pixel est important par rapport au pixel sur lequel nous nous trouvons actuellement, celui-ci étant celui du milieu. En général, vous voulez probablement qu'ils soient quelque peu symétriques et qu'ils s'additionnent toujours à 1. S'ils s'additionnent à plus de 1, la couleur finale sera plus claire, et s'ils sont en dessous de 1, la couleur finale sera plus foncée. Ici, cependant, ils s'additionnent à 0, mais c'est intentionnel puisque c'est un noyau de détection de contours et je veux que tout soit vraiment sombre, sauf les contours des choses.

Maintenant, tout ce que nous avons à faire est de multiplier chaque partie du noyau avec chaque pixel à un certain décalage et de les additionner tous dans ce vec3 nommé couleur. Gardez simplement à l'esprit que même si ceux-ci ressemblent à des matrices, nous ne les multiplions pas de la même manière que nous multiplions les matrices. Ensuite, la dernière étape consiste à sortir la couleur comme FragColor, et c'est tout ! Je pense que ce noyau donne un effet assez intéressant. Voici quelques autres noyaux que vous pourriez vouloir essayer. Je suggère que vous jouiez un peu avec cela et que vous créiez vos propres noyaux afin de vous faire une idée de leur fonctionnement.

Dans ce tutoriel, je vais vous montrer ce que sont les cubemaps dans OpenGL et comment vous pouvez les utiliser pour créer des skyboxes.

Alors, qu'est-ce que les cubemaps ? Eh bien, ce sont simplement un autre type de texture, qui contient 6 textures 2D, une pour chaque côté d'un cube. Lors de l'échantillonnage d'une cubemap, vous spécifiez un vecteur 3D au lieu d'un vecteur 2D. Cela vous permet d'échantillonner facilement entre les 6 côtés du cube. Et comme les coordonnées du cube correspondent aux vecteurs d'échantillonnage, il n'est pas nécessaire d'avoir des UV. Les utilisations les plus courantes des cubemaps sont la texturation de la quadrique et les skyboxes.

Alors maintenant, codons cela. La première chose que vous devez faire est d'écrire les sommets et les indices du cube. Ensuite, nous voudrons créer un VAO, VBO et EBO comme dans les premiers tutoriels.

Maintenant, créons un tableau avec 6 chaînes qui contiendront les chemins vers les 6 images que nous utiliserons pour la skybox. Ensuite, nous voulons créer la texture cubemap elle-même comme n'importe quelle autre texture, sauf que là où nous mettons GL_TEXTURE_2D avant, nous mettons maintenant GL_TEXTURE_CUBE_MAP. Assurez-vous de clamp la texture dans les trois directions puisque la texture est un cube, donc 3D. Ce clamp devrait empêcher toute couture de s'afficher.

Et maintenant, nous allons passer en revue les six textures et les lire en utilisant la bibliothèque stb, en les mettant dans la texture cubique une fois que nous les avons lues. Remarquez comment je désactive le retournement vertical. Cela est dû au fait que, contrairement à la plupart des textures dans OpenGL, les cubemaps sont censées commencer dans le coin supérieur gauche, et non dans le coin inférieur gauche. Remarquez également comment j'ajoute i à GL_TEXTURE_CUBE_MAP_POSITIVE_X. Cela représente le côté du cube auquel j'assigne actuellement une texture, et j'ajoute i pour parcourir tous les côtés. Voici l'ordre des côtés que vous pouvez trouver dans la documentation OpenGL, et voici l'ordre dans lequel nous avons écrit les chemins. Remarquez quelque chose de bizarre ? Eh bien, normalement dans OpenGL, l'avant est dans la direction Z négative, mais pour les cubemaps, l'avant est dans la direction Z positive. Cela signifie que les cubemaps fonctionnent dans un système à main gauche, tandis que la plupart d'OpenGL fonctionne dans un système à main droite. Cela peut être très déroutant, et franchement, je ne sais pas pourquoi ils ont choisi de faire cela, mais bon. Gardez à l'esprit que vous obtiendrez probablement de petits bugs à cause de cela si vous n'êtes pas prudent. Dans mon cas, ma texture droite continuait à s'afficher à l'envers pour une raison quelconque. Pour corriger cela, j'ai simplement retourné la texture dans un éditeur d'images. Donc, préparez-vous à ce genre de choses, car d'après ce que j'ai entendu, cela peut arriver assez souvent avec les skyboxes.

D'accord, retour au tutoriel. Nous allons maintenant avoir besoin de deux shaders pour la skybox. Le vertex shader prendra les coordonnées, sortira les coordonnées de texture et prendra également les uniformes pour les transformations de matrice. Dans la fonction principale, créez un vec4 qui contient les coordonnées transformées finales. Maintenant, comme ces coordonnées sont maintenant dans l'espace écran, nous allons faire quelque chose d'un peu étrange. Au lieu de donner à gl_Position les coordonnées telles qu'elles sont, nous allons lui donner les composantes x, y, w et à nouveau w. Cela entraînera la composante z étant toujours 1 après la division de perspective. Et comme le tampon de profondeur prend la composante z comme sa valeur de profondeur, la skybox aura toujours une valeur de profondeur de 1, soit la valeur de profondeur la plus éloignée possible, étant ainsi derrière tous les objets, comme il se doit. Et enfin, nous voulons exporter les coordonnées de texture comme les positions, sauf que nous allons inverser l'axe z pour contrer le changement de système de coordonnées.

Pour le fragment shader, nous voulons simplement importer les coordonnées de texture, la cubemap, puis définir la fragColor pour qu'elle soit égale à la texture. C'est tout.

De retour dans la fonction principale, je vais créer un programme de shader et exporter l'unité de texture de la skybox. Il ne reste plus qu'à gérer la partie dessin.

Nous allons commencer par définir la fonction de profondeur à GL_LEQUAL au lieu du GL_LESS par défaut, car notre skybox est exactement sur le bord, c'est-à-dire 1, donc nous avons besoin de ce signe égal. Ensuite, nous allons activer le shader et créer les matrices de vue et de projection qui sont identiques à celles que nous avons créées dans la classe caméra, sauf pour un petit détail. Pour la matrice de vue, nous la rétrogradons en mat3, puis nous la remettons à l'échelle en mat4. Cela rendra la dernière ligne et colonne de la matrice égales à 0, n'ayant ainsi aucun effet sur les translations. Nous voulons que la skybox tourne, pas qu'elle se déplace. Ensuite, exportez simplement ces matrices vers le vertex shader.

Maintenant, la dernière partie consiste à dessiner la cubemap elle-même comme n'importe quel autre objet, sauf que lorsque nous lions la texture, nous utilisons GL_TEXTURE_CUBE_MAP au lieu du GL_TEXTURE_2D habituel. N'oubliez pas de passer le test de profondeur à son GL_LESS par défaut après avoir terminé avec la skybox.

Si vous démarrez votre programme, vous devriez maintenant avoir une belle skybox tout autour de vous. Si l'une des faces est inversée ou quelque chose de ce genre, jouez avec l'orientation de vos images dans un éditeur d'images. Faites-moi confiance, c'est beaucoup plus facile de faire cela plutôt que d'essayer de trouver un petit bug logique causé par les deux systèmes de coordonnées différents et les origines de lecture de texture différentes. Si vous avez des coutures qui sont clairement des lignes, alors vous pouvez essayer d'ajouter glEnable(GL_TEXTURE_CUBE_MAP_SEAMLESS) quelque part dans votre code. Si vos coutures ne sont pas des lignes, mais simplement des différences claires de couleur entre une face et une autre, alors vous avez probablement une skybox de mauvaise qualité. Si vous ne pouvez rien voir ou seulement des parties de la skybox, alors vous avez probablement le culling des faces arrière activé et vous avez écrit les indices dans le mauvais ordre d'enroulement. Désactivez simplement le culling des faces lors du dessin de la skybox, ou écrivez les indices dans le bon ordre d'enroulement.

Dans ce tutoriel, je vais vous montrer ce qu'est le geometry shader et comment vous pouvez l'utiliser pour créer des choses comme des normales visibles.

Jusqu'à présent, nous n'avons utilisé que le vertex shader et le fragment shader, qui suffisent dans la plupart des situations. Mais parfois, entre le vertex et le fragment shader, vous voulez avoir une étape supplémentaire pour modifier la géométrie de vos maillages. Même si cela peut sembler que vous pouvez le faire dans le vertex shader, vous ne pouvez faire des choses qu'aux vertices individuels. Si vous vouliez modifier un triangle entier, c'est-à-dire un groupe de vertices, alors vous devriez utiliser le geometry shader. Le deuxième avantage du geometry shader est qu'il peut passer d'un type de primitive à un autre, et peut ainsi créer ou supprimer des vertices.

Alors, commençons par ajouter le geometry shader à notre classe de shader. Remarquez comment je fais exactement la même chose que pour les deux autres shaders, sauf que j'utilise GL_GEOMETRY_SHADER. Maintenant que nous supportons les geometry shaders personnalisés, créons un geometry shader qui ne fait rien.

Comme tout autre shader, nous commencerons par la version. Ensuite, nous avons besoin de deux layouts écrits comme ceci. Le premier layout signifie quel type de primitive nous recevons, qui peut être l'un des suivants, tandis que le deuxième layout montre quel type de primitive nous exportons, qui peut être l'un des suivants. Dans ce cas, nous voulons recevoir un triangle et exporter un triangle. Ensuite, nous avons nos sorties vers le fragment shader. Gardez à l'esprit que vous devriez passer les données du vertex shader au geometry shader puis au fragment shader.

Maintenant, pour importer des données dans le geometry shader, nous devons faire quelque chose d'un peu différent. Au lieu d'avoir simplement un "in", nous aurons une sorte de structure C écrite comme ceci. Notez que nous n'avons pas à inclure la position dans celle-ci car elle est déjà intégrée dans une structure par défaut comme celle-ci appelée gl_in. Maintenant, nous devons revenir au vertex shader et remplacer toutes les données sortantes par la structure exactement identique sauf pour cette dernière partie et "out" au lieu de "in". Assurez-vous que tout le reste de la structure est identique à son homologue dans le geometry shader. Remarquez comment j'ai également inclus la matrice de projection. C'est parce que nous voulons appliquer la matrice de projection uniquement APRÈS avoir modifié notre géométrie. Maintenant, pour assigner des données à ces valeurs sortantes, nous écrivons simplement le nom que nous leur avons donné plus un point et le nom de la variable à laquelle nous voulons assigner des données. Très similaire à une structure C ou C++.

Maintenant, dans le geometry shader, nous avons toutes les données dont nous avons besoin, donc tout ce qu'il reste à faire est d'assembler ces données ensemble. Pour cela, nous assignons simplement la position, la normale, la couleur et les coordonnées de texture à leurs données. Remarquez comment ici j'ai également un index à côté du nom de la partie de la structure à laquelle je veux accéder. C'est parce que nous sommes dans le geometry shader et donc nous avons essentiellement un tableau de telles structures, chacune avec différentes valeurs pour un sommet spécifique. Une fois que nous avons fini d'assigner les valeurs d'un sommet, nous devons utiliser EmitVertex() pour déclarer que nous avons terminé avec ce sommet, VertEx veRTeX veRtEx vERTeX. Maintenant, nous pouvons faire la même chose pour les deux autres sommets, et une fois que nous avons terminé avec les trois sommets dont nous avons besoin pour un triangle, nous déclarons que notre primitive est complète en utilisant EndPrimitive(). Et c'était tout pour le geometry shader par défaut. Si vous exécutez votre programme, vous devriez avoir exactement ce que vous aviez avant, génial !

Mais c'est vraiment ennuyeux, alors changeons un peu les choses et rendons le geometry shader plus amusant. Une chose extrêmement facile à faire est de calculer la normale de surface en utilisant un produit vectoriel et ensuite d'ajouter cette normale aux trois positions de la primitive. Cela donnera à vos maillages l'apparence que toutes les primitives ont explosé ou bugué.

Maintenant, faisons quelque chose d'un peu plus sérieux. Créons un nouveau shader qui prendra notre vertex shader par défaut, un nouveau fragment shader et un nouveau geometry shader. Et dessinons notre modèle en utilisant ce shader après l'avoir dessiné en utilisant le shader par défaut. Maintenant, pour le fragment shader, nous allons simplement sortir une couleur unie, rien de fantaisiste.

Mais pour le geometry shader, nous allons prendre un triangle et sortir non pas un triangle, mais plusieurs lignes ! Donc maintenant, nous détruisons et créons effectivement une nouvelle géométrie, car comme vous pouvez le voir, nous allons sortir 6 sommets alors que nous n'en avons reçu que 3. Ensuite, nous utiliserons la structure exactement identique, et dans la fonction principale, nous récupérerons simplement la position du premier sommet et la déclarerons. Mais au lieu de passer au sommet suivant, nous resterons sur celui-ci mais nous ajouterons la normale du sommet et l'émettons ensuite. Cela crée essentiellement une ligne à travers la normale du sommet. Maintenant, nous voulons faire la même chose pour les autres sommets, mais pour ne pas lier toutes les lignes ensemble, nous devons d'abord terminer cette ligne en utilisant EndPrimitive puis passer à la suivante. Après avoir fait cela pour tous les sommets, nous pouvons appuyer sur lecture et voir que nous sommes maintenant capables de visualiser toutes les normales de notre modèle, ce qui peut être assez utile pour le débogage.

Gardez à l'esprit que les geometry shaders peuvent également être très utiles pour des choses comme l'herbe ou la subdivision de modèles. Donc, ils sont en fait assez intéressants.

Dans ce tutoriel, je vais vous montrer ce qu'est l'instanciation et comment vous pouvez l'utiliser pour améliorer massivement les performances et l'apparence de votre projet OpenGL.

Donc, l'instanciation est simplement une fonctionnalité qui vous permet de dessiner un maillage plusieurs fois en un seul appel de dessin. Maintenant, pourquoi voudriez-vous cela ? Eh bien, considérons ces scénarios où j'ai une ceinture d'astéroïdes tous faits à partir d'un seul maillage d'astéroïde qui est déformé dans le vertex shader pour donner un peu de variété. Dans le scénario de gauche, j'ai simplement une boucle qui dessine chaque astéroïde individuellement. Cela signifie que chaque astéroïde a un appel de dessin. Maintenant, dans le scénario de droite, je dessine tous les astéroïdes ensemble. Cela signifie que je n'ai qu'un seul appel de dessin. Si vous regardez la différence de performance, vous verrez qu'elle est massive.

Maintenant, codons cela. Je vais commencer avec le code déjà écrit pour le premier scénario puisque ce n'est rien de nouveau pour cette série. Donc, afin d'activer l'instanciation, tout ce que nous avons à faire est d'utiliser glDrawElementsInstanced au lieu de glDrawElements, et d'ajouter à la fin combien d'instances du maillage nous voulons. Le seul problème est que cela dessine tous les maillages exactement aux mêmes positions, donc c'est inutile.

Il existe plusieurs façons de déplacer chaque maillage vers une position unique. Vous pourriez avoir du code qui fait cela dans le vertex shader par exemple. En utilisant gl_InstanceID, vous obtiendrez l'index de l'instance que vous êtes en train de dessiner, et vous pourrez donc l'utiliser pour la génération de nombres aléatoires contrôlés. Alternativement, vous pourriez avoir une uniforme avec toutes les transformations et récupérer la transformation correcte pour une instance spécifique en utilisant gl_InstanceID. Mais le problème avec cela est que les uniformes ne peuvent pas stocker autant de données. Donc, la meilleure façon d'avoir beaucoup de transformations et de ne pas avoir la génération à l'intérieur du vertex shader est de stocker les transformations à l'intérieur d'un vertex buffer qui est attaché au VAO du maillage.

Alors, commençons par créer un constructeur VBO qui prend un vecteur de mat4. Ensuite, nous voulons ajouter une variable entière non signée publique à la classe Mesh qui signifiera le nombre d'instances que nous désirons. Et bien sûr, nous devons également l'ajouter au constructeur pour le changer facilement. De plus, dans le constructeur, nous devrions ajouter le vecteur de transformations matricielles pour les instances afin de pouvoir le brancher dans le vertex buffer. Maintenant, dans le fichier Mesh.cpp, nous voulons créer un VBO pour les instances puis lier ses attributs au VAO uniquement si nous dessinons plus d'un maillage. Assurez-vous de lier la matrice comme 4 vec4 différents, sinon votre programme ne fonctionnera pas. Et à la fin, utilisez glVertexAttribDivisor en branchant le numéro de layout de chaque vec4 et 1. Ce 1 signifie que le vec4 sera utilisé pour une instance entière. Si c'était 0, alors le vec4 serait utilisé pour un sommet, et ensuite le vec4 suivant serait utilisé pour le sommet suivant, ce que nous ne voulons certainement pas. Et juste pour être clair, si c'était 2, il serait utilisé pour deux instances avant de passer au vec4 suivant. Maintenant, limitons également l'utilisation de glDrawElementsInstanced uniquement pour plusieurs instances.

Pour la classe Model, nous devons faire exactement la même chose que pour la classe Mesh où nous ajoutons instanceMatrix au constructeur et en tant que variable, et instancing en tant que variable encore une fois. Maintenant, dans notre fonction loadMesh, nous voulons inclure l'instancing et instanceMatrix dans le processus de création de Mesh.

Maintenant, nous avons besoin d'un shader légèrement modifié pour le dessin d'instances afin de s'adapter au nouveau layout. Donc, créez un nouveau programme de shader spécifiquement pour les astéroïdes en utilisant un vertex shader spécial et le fragment shader par défaut. Le vertex shader sera identique au shader par défaut sauf que nous aurons un 5ème layout pour instanceMatrix, nous supprimerons les uniformes dont nous n'avons pas besoin, et remplacerons toutes les transformations par celle de instanceMatrix. N'oubliez pas d'exporter les uniformes d'éclairage dans la fonction principale également.

Ensuite, tout ce qu'il reste à faire est de fusionner les matrices de translation, de rotation et de mise à l'échelle ensemble et de les ajouter toutes au vecteur instanceMatrix. Ensuite, ajoutez simplement cela et le nombre d'instanciation au constructeur Model des astéroïdes, et dessinez les astéroïdes une fois. Rappelez-vous que nous devons appeler la fonction de dessin une seule fois. Maintenant, compilez et witness des milliers et des milliers d'astéroïdes avec un impact minimal sur les performances. Bien sûr, gardez à l'esprit que les performances varieront d'un GPU à l'autre, donc cela peut ne pas fonctionner aussi bien sur le vôtre que sur celui de quelqu'un d'autre.

Dans ce tutoriel, je vais vous montrer ce qu'est l'anti-aliasing et comment vous pouvez l'implémenter dans votre projet OpenGL.

Vous avez peut-être remarqué que si les bords horizontaux et verticaux semblent extrêmement nets, les bords diagonaux ont tendance à sembler un peu saccadés, comme un escalier. Cela est dû à la manière dont nous affichons les images sur nos écrans. Comme nos écrans sont constitués d'une série de petits carrés, c'est-à-dire des pixels, il est impossible d'avoir une ligne lisse sur la diagonale. Mais heureusement, nous pouvons simuler la douceur en faisant saigner la couleur d'un bord dans les pixels adjacents comme ceci.

Maintenant, ces bords crénelés sont appelés Aliasing, et une technique d'anti-aliasing est ce qui nous aide à obtenir de meilleurs bords. Il existe plusieurs techniques pour l'anti-aliasing, chacune avec ses avantages et ses inconvénients, mais aujourd'hui je vais me concentrer sur le MSAA qui signifie Multi Sampling Anti-Aliasing. Alors, à quoi fait référence ce Multi Sampling ?

Eh bien, dans la partie rasterisation du pipeline, les primitives sont remplies. La manière dont il est décidé quels pixels doivent être colorés et lesquels ne doivent pas l'être est en vérifiant si le point d'échantillonnage d'un pixel, qui est normalement au centre de celui-ci, est à l'intérieur de la forme de la primitive. Cela signifie que si le point d'échantillonnage est même légèrement à l'extérieur du triangle, il ne sera pas échantillonné, même si vous penseriez qu'il devrait au moins le faire partiellement. Eh bien, c'est là que le MSAA intervient. Comme vous l'avez peut-être deviné, cette technique ajoute simplement plusieurs points d'échantillonnage afin qu'un résultat plus précis puisse être atteint.

Ici, par exemple, deux des quatre points d'échantillonnage sont à l'intérieur du triangle, et donc la couleur de ce pixel sera quelque part entre la couleur de l'arrière-plan et la couleur de la primitive.

Maintenant, implémentons cela. Commençons par créer une variable où nous spécifions combien d'échantillons nous désirons. Maintenant, si vous n'avez pas de framebuffer, alors vous pouvez simplement donner un indice de fenêtre à GLFW en disant que vous voulez GLFW_SAMPLES puis le nombre d'échantillons que vous voulez, et ensuite activer GL_MULTISAMPLE. C'était tout pour ce tutoriel, car... non, je plaisante. Mais pour de vrai, si vous n'avez pas de framebuffer, c'est tout ce que vous avez à faire, vous avez terminé. Si vous avez un framebuffer, alors vous voudrez supprimer la partie GLFW. Au lieu de cela, vous devez aller à votre framebuffer et remplacer tous les GL_TEXTURE_2D par GL_TEXTURE_2D_MULTISAMPLE. Ensuite, remplacez glTexImage2D par glTexImage2DMultisamples, en y insérant le type de texture, le nombre d'échantillons, le format de couleur, la largeur, la hauteur, et si vous voulez que tous les échantillons soient exactement à la même position dans les pixels.

Ensuite, pour l'objet renderbuffer, nous devons passer de glRenderbufferStorage à glRenderbufferStorageMultismaple et ajouter le nombre d'échantillons que nous voulons.

Maintenant, le problème est que nous ne pouvons plus faire de post-traitement sur ce framebuffer puisque le multisampling est activé. Donc, pour contourner cela, nous aurons besoin d'un framebuffer normal que nous pouvons post-traiter. C'est exactement comme celui que j'ai fait dans le tutoriel sur le framebuffer.

Maintenant, dans la fonction principale, nous voulons nous assurer que nous lions d'abord le FBO multisampling, nettoyons l'écran, nettoyons les tampons et activons le test de profondeur. Ensuite, nous dessinons tout ce que nous voulons dessiner. Après cela, nous lions le FBO multisampling en lecture seule et le FBO postprocessing en écriture seule. Maintenant, en utilisant glBlitFramebuffer, nous allons résoudre tout le multisampling et copier le résultat sur le FBO postprocessing.

Maintenant, assurez-vous de lier le framebuffer par défaut et de dessiner le rectangle du framebuffer en utilisant la texture postprocessing. Exécutez le programme et vous verrez que les bords des primitives sont beaucoup plus lisses et plus beaux. Soyez simplement conscient que l'application de noyaux dans le post-traitement écrasera essentiellement l'anti-aliasing et vous pourriez donc vous retrouver avec de l'aliasing à nouveau. En ce qui concerne le nombre d'échantillons que vous devriez utiliser, je suggère d'utiliser soit 2, 4 ou 8. Vous pouvez aller jusqu'à 16 et 32 sur certains GPU, mais le rapport amélioration/performance n'en vaut pas la peine.

C'était tout pour ce tutoriel, comme toujours, le code source et toutes les ressources utilisées sont dans la description. Au revoir !