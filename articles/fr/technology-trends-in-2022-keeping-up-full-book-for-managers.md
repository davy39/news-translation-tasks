---
title: Tendances technologiques en 2022 – Garder le rythme [Livre complet pour les
  gestionnaires]
subtitle: ''
author: David Clinton
co_authors: []
series: null
date: '2022-05-11T23:06:08.000Z'
originalURL: https://freecodecamp.org/news/technology-trends-in-2022-keeping-up-full-book-for-managers
coverImage: https://www.freecodecamp.org/news/content/images/2023/06/Technology-Trends-in-2022-Book-Cover-1.png
tags:
- name: management
  slug: management
- name: technology
  slug: technology
seo_title: Tendances technologiques en 2022 – Garder le rythme [Livre complet pour
  les gestionnaires]
seo_desc: "This post is based on my recently published book, Keeping Up, a quick and\
  \ accessible guide to the current state of the tech industry and the big trends\
  \ you can't afford to ignore. \nIn it, we'll cover everything from digital security,\
  \ privacy, serverl..."
---

Cet article est basé sur mon livre récemment publié, _Garder le rythme_, un guide rapide et accessible sur l'état actuel de l'industrie technologique et les grandes tendances que vous ne pouvez pas ignorer.

Dans ce livre, nous couvrirons tout, de la sécurité numérique, de la confidentialité, des plateformes serverless, de l'internet des objets (IoT), de la recherche technologique, et bien plus encore à un niveau élevé.

Si vous êtes un gestionnaire ou un décideur dans votre entreprise, quelqu'un qui planifie sa carrière ou sa trajectoire éducative, ou simplement une personne curieuse, alors ce livre est pour vous.

[Voici un lien vers le livre physique](https://www.amazon.com/Keeping-Up-backgrounders-technology-trends/dp/B08HGLPZMP) si vous souhaitez vous procurer un exemplaire.

## Table des matières

* [Chapitre 1 : Comprendre la sécurité numérique](#heading-chapitre-1-comprendre-la-securite-numerique)
* [Chapitre 2 : Comprendre la confidentialité numérique](#heading-chapitre-2-comprendre-la-confidentialite-numerique)
* [Chapitre 3 : Comprendre le cloud](#heading-chapitre-3-comprendre-le-cloud)
* [Chapitre 4 : Comprendre la connectivité numérique](#heading-chapitre-4-comprendre-la-connectivite-numerique)
* [Chapitre 5 : Comprendre le business de la recherche technologique](#heading-chapitre-5-comprendre-le-business-de-la-recherche-technologique)
* [Chapitre 6 : Où les tendances chaudes vont mourir](#heading-chapitre-6-ou-les-tendances-chaudes-vont-mourir)
* [Chapitre 7 : Plateformes de calcul](#heading-chapitre-7-plateformes-de-calcul)
* [Chapitre 8 : Sécurité et confidentialité](#heading-chapitre-8-securite-et-confidentialite)

## Chapitre 1 : Comprendre la sécurité numérique

Quelle que soit votre connexion à la technologie, la sécurité devrait jouer un rôle prépondérant dans la façon dont vous pensez et agissez.

La technologie, après tout, amplifie l'impact de tout ce que nous faisons avec elle. Les choses que nous disons et écrivons en utilisant les technologies de communication peuvent être lues et entendues par beaucoup plus de personnes que ce ne serait possible sans elles. La capacité de se connecter facilement avec les gens et de collaborer sur des projets de toutes sortes est bien plus grande.

Les tâches que nous pouvons accomplir, grâce à la magie de l'automatisation, sont presque illimitées. L'étendue des informations auxquelles nous pouvons accéder instantanément grâce aux appareils les plus simples et les moins chers dépasse de loin tout ce que les plus grands érudits auraient pu espérer voir de leur vivant il y a quelques décennies.

Tout cela signifie que les criminels et autres individus non contraints par une conscience morale auront des outils encore plus puissants pour compromettre les données que vous créez et consommez, et voler ou endommager les biens que vous acquérez. Vous avez donc un intérêt marqué à apprendre comment vous protéger, protéger vos biens et ceux des personnes et organisations qui vous entourent.

Ce chapitre présentera un bref aperçu de ce qui est en jeu dans le domaine de la sécurité technologique. Nous définirons les types de menaces auxquelles nous sommes confrontés et discuterons des principaux outils à notre disposition pour repousser ces menaces.

Si vous êtes intéressé à creuser plus profondément le sujet, mon livre LPI Security Essentials est entièrement consacré à vous donner une vue d'ensemble complète.

### Piratage ? Qu'est-ce que le piratage ?

Définir le piratage informatique de manière à ne pas énerver quelqu'un, quelque part, c'est comme parler de politique au travail. Préparez-vous à de longs silences gênants et éventuellement à de la violence.

Vous voyez, les puristes pourraient insister sur le fait que le terme piratage devrait s'appliquer exclusivement aux individus axés sur la réutilisation forcée du matériel informatique à des fins non standard. D'autres réservent le titre aux personnes qui contournent les contrôles d'authentification pour s'introduire dans les réseaux à des fins criminelles ou politiques. Et que dire de ceux qui portent le titre comme signe de leur expertise pratique en toutes choses informatiques ? (Et puis, bien sûr, il y a les crackers.)

Mais c'est mon livre, donc je vais utiliser le terme comme je veux.

Je décrète donc que le piratage concerne tous les plans que les _méchants_ ont pour vos appareils numériques. Plus précisément, leurs plans pour entrer sans autorisation, sortir sans être remarqués, et (parfois) emporter vos affaires avec eux lorsqu'ils partent.

Utiliser le terme de cette manière nous donne un moyen utile d'organiser une discussion sur certaines menaces courantes et particulièrement effrayantes.

#### Comment les pirates entrent-ils ?

Le truc est de trouver un moyen de passer à travers vos défenses (comme les mots de passe, les pare-feu et les barrières physiques). Dans la plupart des cas, les mots de passe offrent probablement la protection la plus faible :

* Les mots de passe sont souvent courts, utilisent une gamme étroite de caractères et sont faciles à deviner.
* Si un appareil était livré avec un mot de passe d'usine simple par défaut (comme "admin" ou "1234") destiné uniquement à vous permettre de vous connecter pour la première fois, alors les chances sont assez bonnes que de nombreux utilisateurs ne prendront jamais la peine de le remplacer par quelque chose de mieux.
* Même les mots de passe forts peuvent être volés par des escroqueries de phishing par e-mail trompeuses ("Cliquez ici pour vous connecter à votre compte bancaire..."); l'ingénierie sociale ("Bonjour, c'est Ed de l'informatique. Nous avons quelques problèmes avec votre compte d'entreprise. Pourriez-vous me donner votre mot de passe par téléphone afin que je puisse le réparer rapidement ?"); et les logiciels de suivi de clavier.

Nous parlerons davantage des pare-feu plus tard dans ce chapitre. Et les barrières physiques ? Je pense que vous savez déjà à quoi ressemble une porte verrouillée. Mais il vaut probablement la peine de passer quelques instants à réfléchir à d'autres types d'attaques numériques.

Le gros lot est généralement d'accéder à vos données et de s'enfuir avec des copies. Mais pour certains, simplement détruire les originaux peut être tout aussi satisfaisant.

Bien sûr, se connecter à vos appareils en utilisant des mots de passe volés est l'approche la plus directe. Mais l'accès peut également être obtenu en interceptant vos données lorsqu'elles voyagent sur un réseau non sécurisé.

Une approche couramment utilisée ici est connue sous le nom d'attaque de l'homme du milieu, où les paquets de données peuvent être interceptés en transit et modifiés sans que les utilisateurs autorisés à chaque extrémité ne sachent qu'il y a un problème.

Le chiffrement correct de vos connexions réseau (et l'évitement des réseaux publics non sécurisés) est une protection efficace contre ce type de menace. Nous parlerons davantage du chiffrement un peu plus tard.

Si le matériel que vous utilisez a une "porte dérobée" non documentée intégrée, alors vous êtes plus ou moins perdu quoi que vous fassiez. Nous parlerons davantage des portes dérobées plus tard dans le livre.

Mais pour l'instant, je noterai simplement qu'il n'a pas manqué de portables, de serveurs en rack et même d'équipements de mise en réseau haut de gamme fournis par les fabricants qui ont été intentionnellement conçus pour inclure de graves vulnérabilités d'accès. Soyez très prudent quant à l'endroit où vous achetez vos appareils informatiques.

Si les attaquants trouvent un moyen d'entrer dans votre bâtiment physique (parfois en se faisant passer pour des employés d'une société de livraison), ils pourraient discrètement brancher un minuscule dispositif d'écoute dans une prise Ethernet inutilisée de votre réseau. Cela leur donnera une belle plateforme pour surveiller et même influencer toutes vos activités de l'intérieur.

Protéger votre infrastructure physique et surveiller attentivement l'activité du réseau est votre meilleur espoir contre ce type d'intrusion.

Même si votre maison ou votre bureau est entièrement fortifié, il n'y a aucune garantie que les données circulant sur les appareils mobiles (comme les smartphones ou les ordinateurs portables) ne finissent pas entre de mauvaises mains.

Et même si vous avez pris soin d'utiliser uniquement les meilleurs mots de passe pour ces appareils, les disques de données eux-mêmes peuvent encore être facilement montés comme des partitions externes sur la machine d'un voleur. Une fois montés, vos fichiers et informations de compte seront maintenant largement ouverts.

La seule façon de protéger vos appareils mobiles contre ce type de menace est de chiffrer l'ensemble du disque en utilisant une phrase de passe forte.

#### Ce que les pirates recherchent

Maintenant que des économies entières sont gérées sur des ordinateurs directement connectés à des réseaux publics, il y a de l'argent et de la valeur à tirer grâce à des efforts d'espionnage corporatif, académique ou politique bien planifiés... et grâce au vol traditionnel à l'ancienne.

Que l'objectif soit de construire un avantage militaire ou commercial concurrentiel, de détruire complètement la concurrence, ou simplement de mettre la main sur de l'argent "gratuit", l'accès illégal aux données d'autres personnes n'a jamais été aussi facile.

Alors, que recherchent probablement les pirates ?

Toutes les informations financières importantes et autres informations sensibles que vous préféreriez qu'ils n'aient pas. Y compris, il faut le noter, le type d'informations que vous utilisez pour vous identifier auprès des banques, des sociétés de cartes de crédit et des agences gouvernementales.

Une fois que les méchants ont obtenu des points de données importants comme votre date de naissance, votre adresse domicile, les numéros d'identification émis par le gouvernement, et quelques détails bancaires de base, il n'est généralement pas difficile de se présenter comme si c'était vous, en prenant complètement le contrôle de votre identité dans le processus.

Les attaques numériques peuvent également être utilisées comme chantage pour forcer les victimes à payer pour annuler les dommages qu'elles ont causés.

C'est l'objectif de la plupart des attaques de _ransomware_, où les pirates chiffrent toutes les données sur les ordinateurs d'une victime et refusent d'envoyer les clés de déchiffrement nécessaires pour restaurer votre accès légitime à moins que vous ne leur envoyiez beaucoup d'argent. De telles attaques ont déjà effectivement mis hors service des infrastructures critiques comme les systèmes informatiques alimentant les hôpitaux et les villes.

La meilleure défense contre les ransomwares est d'avoir des sauvegardes complètes et testées de vos données critiques et un système fiable pour les restaurer rapidement sur votre matériel. Ainsi, si vous êtes un jour victime d'une attaque de ransomware, vous pouvez simplement effacer votre logiciel existant et le remplacer par des copies fraîches, peuplées de vos données sauvegardées.

Mais vous devriez également renforcer vos paramètres de sécurité généraux pour rendre plus difficile l'accès des pirates de ransomware à votre système en premier lieu.

Lorsque leur objectif principal est de vous empêcher, vous ou votre organisation, de vaquer à vos occupations, les pirates peuvent rester à une distance sûre et lancer une attaque par déni de service distribué (DDoS) contre votre infrastructure web.

Les attaques DDoS historiques ont utilisé des essaims massifs de milliers d'appareils connectés au réseau piratés illégalement pour transmettre des nombres paralysants de requêtes contre un seul service cible. Lorsqu'elles sont suffisamment importantes, les attaques DDoS ont réussi à mettre hors service même de grandes entreprises de taille entreprise utilisant des défenses sophistiquées pendant des heures à la fois.

Le site hébergeant l'une de mes collections open source en ligne préférées a été durement touché il y a plus d'un an et ne s'en est toujours pas complètement remis.

### Qu'est-ce que le chiffrement ?

Si vos données sont illisibles, il y a beaucoup moins de mauvaises choses que des individus non autorisés pourront faire avec elles. Mais si elles sont illisibles, il y a probablement peu de choses que vous pourrez faire avec elles également.

Ne serait-il pas agréable s'il existait un moyen de présenter vos données comme illisibles dans tous les scénarios sauf lorsqu'il y a une raison légitime ?

Eh bien, devinez quoi ? Il existe, et cela s'appelle le chiffrement des données.

#### Chiffrement des données en transit

Les algorithmes de chiffrement codent les informations de manière à les rendre difficiles, voire impossibles, à lire.

Un exemple simple (et ancien) est le remplacement de symboles, où chaque lettre "a" dans un message serait remplacée par, disons, la lettre trois positions plus loin dans l'alphabet (ce qui serait "d"). Chaque "b" deviendrait "e" et ainsi de suite. "Hello world" deviendrait "khoor zruog". Ensuite, les personnes qui tombent sur votre message codé seraient incapables de le comprendre d'un coup d'œil.

Bien sûr, il ne faudrait pas longtemps à un ordinateur moderne (ou même à un enfant intelligent de 8 ans) pour décoder celui-ci.

Mais certains cryptologues très intelligents ont travaillé dur pendant la majeure partie du siècle dernier pour produire des algorithmes beaucoup plus efficaces.

Il existe quelques variations significatives de la cryptographie moderne. Mais l'idée générale est que les personnes peuvent appliquer un algorithme de chiffrement à leurs données et transmettre en toute sécurité la copie chiffrée sur des réseaux non sécurisés. Ensuite, le destinataire peut appliquer une clé de déchiffrement de quelque sorte aux données, restaurant la version originale.

Le chiffrement est désormais largement disponible pour de nombreuses activités courantes, y compris l'envoi et la réception d'e-mails. Vous pouvez également vous assurer que les données que vous demandez à un site web sont les mêmes données qui sont finalement affichées dans votre navigateur en vérifiant l'icône de cadenas dans la barre d'adresse de votre navigateur. L'icône confirme que le serveur du site web utilise le chiffrement Transport Layer Security (TLS).

Au cours des dernières années, le projet Let's Encrypt ([letsencrypt.org](https://letsencrypt.org/)) a encouragé des millions de nouveaux sites web à utiliser le chiffrement en fournissant des certificats de chiffrement gratuits et des outils simples à utiliser pour aider les administrateurs de serveurs à les installer.

#### Chiffrement des données au repos

TLS protégera vos données lorsqu'elles sont en déplacement, mais qu'est-ce qui les gardera en sécurité même lorsqu'elles se reposent dans leur disque de stockage confortable ? Le chiffrement de fichiers et de disques, c'est ça.

Tous les systèmes d'exploitation offrent désormais un logiciel intégré pour chiffrer tout ou partie d'un disque de stockage soit au moment de l'installation, soit plus tard. Chaque fois que vous allumez un disque chiffré, vous serez invité à entrer la phrase de passe que vous avez créée lorsque vous avez activé le chiffrement.

Le problème est que si vous oubliez votre phrase de passe, vous êtes plus ou moins définitivement bloqué hors de votre système et les données sont perdues à jamais.

Mais si vous ne chiffrez pas votre système, alors, comme nous l'avons noté précédemment, toute personne qui vole le matériel aura un accès facile et instantané à vos informations privées.

C'est un monde difficile, n'est-ce pas ?

### À quoi sert un pare-feu ?

Vous pouvez penser à un pare-feu comme à un filtre.

Tout comme, par exemple, un filtre à eau est capable de bloquer certaines impuretés, ne laissant passer que de l'eau propre, un pare-feu peut inspecter chaque paquet de données entrant ou sortant de votre infrastructure, bloquant l'accès lorsque cela est approprié.

Outre le fait de ne pas devoir être remplacé toutes les quelques semaines, le grand avantage d'un pare-feu par rapport à un filtre à eau est qu'il peut être configuré de près pour permettre et refuser l'entrée de manière à correspondre exactement à vos besoins de sécurité et fonctionnels, puis mis à jour ultérieurement si vos besoins changent.

#### Pare-feux matériels

Un pare-feu matériel est un dispositif de mise en réseau physique conçu à cet effet, couramment utilisé dans les environnements d'entreprise.

De tels pare-feux sont installés à la périphérie d'un réseau privé et configurés pour bloquer le trafic entrant potentiellement dangereux, rediriger d'autres trafics vers des destinations distantes, ou permettre au trafic d'accéder à des milliers d'hôtes au sein du réseau local.

Les pare-feux matériels sont vendus par des entreprises spécialisées comme Cisco et Juniper, ainsi que par des fabricants d'équipements généraux comme HP et Dell.

Les appareils de pare-feu ont tendance à être très coûteux, coûtant souvent plusieurs milliers de dollars. Ils sont normalement déployés uniquement pour gérer l'infrastructure d'entreprise.

#### Pare-feux logiciels

Un pare-feu logiciel est une application qui s'exécute sur un PC ordinaire et peut effectuer à peu près toutes les fonctions que vous attendriez d'un pare-feu matériel.

Il y a deux différences importantes :

* Le logiciel de pare-feu (comme l'utilitaire iptables de Linux) est souvent gratuit et, bien que compliqué, bénéficie des avantages de vastes ressources de documentation. Le logiciel peut également être installé sur n'importe quel vieux PC qui traîne, réduisant votre coût global à presque rien.
* Vous ne voudrez pas utiliser un tel pare-feu dans un environnement professionnel occupé, cependant, puisque un PC ordinaire n'aura probablement pas la puissance de calcul nécessaire pour gérer de grands volumes de trafic réseau. De plus, dans la plupart de ces cas, il ne sera pas assez fiable pour fournir des services critiques 24/7.

Il existe une autre variante de pare-feu logiciel qui est utilisée dans le cadre des systèmes d'exploitation de qualité grand public. De tels pare-feux vous permettent de mieux sécuriser votre système d'exploitation en définissant des règles pour les types d'activités que vous souhaitez autoriser. Ceux-ci peuvent être particulièrement utiles pour les appareils mobiles qui passent fréquemment d'un réseau à l'autre.

Les plateformes de cloud computing - comme Amazon Web Services (AWS) et Microsoft Azure - fournissent une technologie de type pare-feu pour une utilisation avec les ressources que vous pourriez déployer dans leurs systèmes. Les politiques de pare-feu peuvent exister dans des objets avec des noms comme "groupe de sécurité" ou "liste de contrôle d'accès" qui peuvent être appliqués à toute ressource nécessitant ces politiques.

### Qui fait le mieux la sécurité ?

Il n'y a pas si longtemps, on entendait souvent des professionnels de l'informatique jurer qu'ils ne feraient jamais fonctionner leurs opérations informatiques sur une infrastructure qu'ils ne contrôlaient pas physiquement.

Cela était courant lorsqu'il s'agissait de sous-traiter à des entreprises tierces, hors site, ou à des plateformes de cloud computing.

Que ce soit parce que ces administrateurs ne faisaient pas confiance à la fiabilité et à la sécurité de l'infrastructure informatique gérée par des inconnus, ou parce que des restrictions réglementaires exigeaient que les charges de travail sensibles restent locales, ce sentiment était largement partagé. Et cela avait du sens.

Mais le passé est un pays étranger. Aujourd'hui, il peut être affirmé avec force que les environnements les plus sécurisés et fiables peuvent être trouvés chez les plus grands fournisseurs de cloud public.

Pourquoi ? Ils ont l'argent et l'incitation à embaucher les meilleurs ingénieurs, et l'argent et l'incitation à construire la meilleure infrastructure.

Au-delà de cela, les fournisseurs de cloud maintiennent des centres de données dans des juridictions politiques à travers le monde, et font de grands efforts pour s'assurer que leurs déploiements respectent les normes de l'industrie et du gouvernement.

Permettez-moi d'illustrer. Vous vous souvenez de la menace DDoS dont nous avons parlé un peu plus tôt dans le chapitre ?

Eh bien, à l'été 2020, une organisation non nommée déployant des ressources sur AWS a été frappée par une attaque DDoS culminant à 2,3 Tbps (https://www.zdnet.com/article/aws-said-it-mitigated-a-2-3-tbps-ddos-attack-the-largest-ever). C'est-à-dire que chaque seconde, des requêtes frappaient le service public de l'organisation avec 2,3 téraoctets de données.

Que signifie "2,3 téraoctets" ?

Eh bien, un mégaoctet est (environ) un million d'octets d'information (une version PDF de ce livre prendrait probablement six mégaoctets ou plus). Un gigaoctet est un milliard d'octets d'information. Un téraoctet est un billion d'octets d'information.

Cela équivaudrait à environ 165 000 livres PDF. 2,3 téraoctets équivaudraient à environ 380 000 livres PDF.

Maintenant, essayez d'imaginer tous les caractères de texte utilisés pour remplir 380 000 livres PDF étant lancés sur un service web chaque seconde.

Vous avez cette image en tête ?

Voici ce qui est arrivé à ce service web : Rien. Il a simplement continué à fonctionner comme s'il n'avait pas un souci au monde.

Comment est-ce même possible ?

Le service AWS Shield d'Amazon a simplement atténué l'attaque. Le client n'a rien eu à faire.

_C'est_ pourquoi le déplacement de vos charges de travail vers le cloud public n'implique pas nécessairement de compromettre vos normes.

## Chapitre 2 : Comprendre la confidentialité numérique

Avertissement de service public : vous pourriez trouver ce chapitre un peu déprimant. Si vous préférez vous remonter le moral tout de suite, passez peut-être à "Comprendre le Cloud".

Pour tous les nombreux avantages que nous tirons de la technologie - et particulièrement des technologies qui composent l'internet public - il y a clairement aussi beaucoup de coûts. Trouver comment vous voulez équilibrer les avantages par rapport aux coûts peut nécessiter une réflexion minutieuse.

Voici une manière concise et efficace de décrire l'équation (dont la source, hélas, je ne me souviens plus) :

> "Choisissez deux des trois : confidentialité, sécurité et commodité. Mais vous ne pouvez pas avoir les trois."

En d'autres termes, si la sécurité est une valeur critique pour vous, alors vous devrez renoncer à l'accès instantané 24/7 à votre argent, votre crédit et vos comptes personnels. C'est parce que ce type d'accès nécessite d'exposer vos comptes sur des réseaux publics à un niveau qui ne permettra pas autant de protection des données que vous pourriez souhaiter.

De même, que se passe-t-il si vous ne pouvez tout simplement pas vivre sans la commodité de recevoir des mises à jour d'actualités et de la connectivité sociale via des sites appartenant à des entreprises tierces qui collectent et utilisent vos informations personnelles ? Eh bien, vous devrez "payer pour cela" en renonçant à une certaine mesure de votre confidentialité.

Bien sûr, la plupart d'entre nous choisiront un mélange de ces trois éléments basé sur un compromis pratique entre des valeurs et des besoins concurrents.

Mais prendre une décision raisonnable sur ce mélange nécessitera des informations solides. C'est ce que vous trouverez dans le reste de ce chapitre.

### Comment les entreprises obtiennent vos données

Curieux de savoir quels types de données personnelles et même privées vous pourriez exposer au cours d'une journée normale sur l'internet ?

La réponse est "tous types".

Peut-être que la meilleure façon de comprendre l'ampleur et la nature du problème est de le décomposer par plateforme.

#### Transactions financières

Prenez un moment pour visualiser ce qui est impliqué dans une simple transaction par carte de crédit en ligne.

Vous avez probablement signé sur le site web du marchand en utilisant votre adresse e-mail comme identifiant de compte et un mot de passe (espérons-le) unique.

Après avoir parcouru quelques pages, vous ajouterez un ou plusieurs articles au panier d'achat virtuel du site. Lorsque vous avez tout ce dont vous avez besoin, vous commencerez le processus de paiement, en entrant les informations de livraison, y compris une adresse postale et votre numéro de téléphone. Vous pourriez également entrer le numéro de compte de la carte de fidélité que le marchand vous a envoyée et un code de coupon que vous avez reçu dans un message marketing par e-mail.

Bien sûr, l'étape clé implique d'entrer vos informations de paiement qui, pour une carte de crédit, incluront probablement le nom et l'adresse du propriétaire de la carte, ainsi que le numéro de la carte, la date d'expiration et un code de sécurité.

En supposant que l'infrastructure du marchand soit conforme aux protocoles de la norme de sécurité des données de l'industrie des cartes de paiement (PCI-DSS) pour la gestion des informations financières, il est relativement peu probable que ces informations soient volées et vendues par des criminels.

Mais dans tous les cas, elles existeront toujours dans la base de données du marchand.

Pour approfondir un peu tout cela, comprenez que l'utilisation de votre compte de carte de fidélité et de votre code de coupon peut communiquer beaucoup d'informations sur vos préférences d'achat et de style de vie, ainsi que des enregistrements de certaines de vos activités précédentes.

Votre compte sur le site inclut également vos informations de contact et votre localisation domicile.

Toutes ces informations peuvent, au moins en théorie, être assemblées pour créer un profil robuste de vous en tant que consommateur et citoyen.

C'est pour ces raisons que je préfère personnellement utiliser des systèmes de paiement e-commerce tiers comme PayPal, car de telles transactions ne laissent aucune trace de ma méthode de paiement spécifique dans les bases de données du marchand.

#### Appareils

Les systèmes d'exploitation modernes sont conçus dès le départ pour se connecter à l'internet de multiples façons.

Ils interrogeront souvent automatiquement les dépôts de logiciels en ligne pour les correctifs et mises à jour et "demanderont" de l'aide à distance lorsque quelque chose ne va pas. Certaines données de diagnostic de performance sont envoyées et stockées en ligne, où elles peuvent contribuer à l'analyse statistique ou au diagnostic et à la correction des bugs.

Les logiciels individuels peuvent se connecter à des serveurs distants indépendamment du système d'exploitation pour accomplir leurs propres tâches.

Tout cela est bien.

Sauf que vous pourriez avoir du mal à être sûr que _toutes_ les données allant et venant entre votre appareil et l'internet sont des choses que vous êtes d'accord pour partager.

Pouvez-vous savoir que les fichiers privés et les informations personnelles ne sont pas balayés avec toutes les autres données ? Et êtes-vous confiant que aucune de vos données ne trouvera jamais accidentellement son chemin vers une application inattendue située au-delà de votre contrôle ?

Pour illustrer le problème, je vous renverrais aux appareils alimentés par des assistants numériques comme Alexa d'Amazon (figure 2.1) et l'Assistant Google ("OK Google").

Puisque, par définition, les microphones utilisés par les assistants numériques écoutent constamment leur mot clé ("Alexa..."), tout ce que dit quiconque à portée de l'appareil est enregistré.

Au moins certaines de ces conversations sont également enregistrées et stockées en ligne et, comme il s'est avéré, certaines de _celles-ci_ ont finalement été entendues par des êtres humains travaillant pour le vendeur.

Dans au moins un cas, une conversation enregistrée par inadvertance a été utilisée pour condamner un suspect de meurtre.

![Figure 2.1 : Un appareil avec l'assistant numérique Alexa d'Amazon.](https://www.freecodecamp.org/news/content/images/2022/05/figure-2-1.jpg)
_Figure 2.1 : Un appareil avec l'assistant numérique Alexa d'Amazon._

Amazon, Google et d'autres acteurs de ce domaine sont conscients du problème et tentent de le résoudre. Mais il est peu probable qu'ils le résolvent jamais complètement.

Rappelez-vous, commodité, sécurité et confidentialité ne fonctionnent pas bien ensemble.

Maintenant, si vous pensez que les informations des ordinateurs et des tablettes qui peuvent être suivies et enregistrées sont flippantes, attendez de entendre parler des thermostats et des ampoules.

À mesure que de plus en plus d'appareils ménagers et d'outils sont adoptés dans le cadre des systèmes de "maison intelligente", de plus en plus de flux de données de performance seront générés avec eux.

Et, comme cela a déjà été démontré dans de multiples applications du monde réel, toutes ces données peuvent être interprétées de manière programmatique pour révéler des informations significatives sur ce qui se passe dans une maison et qui le fait.

#### Appareils mobiles

Vous êtes-vous déjà arrêté au milieu d'un voyage, sorti votre smartphone et vérifié une carte numérique pour obtenir des directions ?

Bien sûr que oui.

L'application de carte utilise vos informations de localisation actuelle et vous envoie des informations précieuses, mais en même temps, vous envoyez des informations tout aussi précieuses en retour.

Quelle sorte d'informations pourrait-ce être ?

J'ai lu une fois à propos d'un individu facétieux en Allemagne qui a emprunté quelques dizaines de smartphones, les a chargés sur une remorque pour enfants et a lentement tiré la remorque au milieu d'une rue de ville vide. Il n'a pas fallu longtemps avant que Google Maps ne signale un embouteillage sérieux là où il n'y en avait pas.

Comment l'application Google Maps en sait-elle plus sur les conditions de circulation locales que vous ?

Une classe importante de données qui alimente leur système est obtenue grâce à la surveillance constante de la localisation, de la vitesse et de la direction de mouvement de chaque téléphone Android actif qu'ils peuvent atteindre - y compris votre téléphone Android.

Pour ma part, j'apprécie ce service et cela ne me dérange pas trop la façon dont mes données sont utilisées. Mais je suis également conscient que, un jour, ces données pourraient être utilisées de manière à entrer en conflit avec mes intérêts. Appelez cela un risque calculé.

Bien sûr, ce ne sont pas seulement les informations de mouvement basées sur le GPS que Google et Apple - les créateurs des deux systèmes d'exploitation mobiles les plus populaires - obtiennent. Ils, ainsi que quelques autres acteurs de l'industrie, gèrent également les enregistrements de toutes nos activités sur les moteurs de recherche et les données retournées par les applications de surveillance d'exercice et de santé.

En d'autres termes, s'ils décident de le faire, de nombreuses entreprises technologiques pourraient compiler sans effort des profils décrivant nos mouvements précis, nos plans et notre état de santé. Et de là, il n'y a qu'un petit pas pour imaginer les propriétaires de telles données prédisant ce que nous sommes susceptibles de faire dans les semaines et les mois à venir.

#### Navigateurs Web

La plupart d'entre nous utilisent des navigateurs web pour la plupart de nos interactions quotidiennes avec l'internet. Et, tout bien considéré, les navigateurs web sont des créations assez miraculeuses, agissant souvent comme un concierge incroyablement puissant, nous apportant toutes les richesses de l'humanité sans même transpirer.

Mais, comme je suis sûr que vous pouvez déjà l'anticiper, tout ce pouvoir s'accompagne d'un compromis.

Pour avoir un aperçu des informations que votre navigateur partage librement sur vous, jetez un coup d'œil à la page Google Analytics illustrée à la figure 2.2. Ce tableau de bord affiche un résumé visuel décrivant toutes les visites sur mon propre site bootstrap-it.com au cours des sept derniers jours. Je peux voir :

* D'où dans le monde viennent mes visiteurs
* À quel moment de la journée ils ont tendance à visiter
* Combien de temps ils ont passé sur mon site
* Quelles pages ils visitent
* Quel site ils ont quitté avant de venir sur mon site
* Combien de visiteurs font des visites répétées
* Quels systèmes d'exploitation ils utilisent
* Quel facteur de forme de dispositif ils utilisent (c'est-à-dire, bureau, smartphone ou tablette)
* Les cohortes démographiques auxquelles ils appartiennent (genres, groupes d'âge, groupes de revenus)

![Figure 2.2 : Le tableau de bord d'accueil d'une page Google Analytics affichant des visualisations des visiteurs d'un site web.](https://www.freecodecamp.org/news/content/images/2022/05/figure-2-2.png)
_Figure 2.2 : Le tableau de bord d'accueil d'une page Google Analytics affichant des visualisations des visiteurs d'un site web._

Outre tout cela, les journaux propres d'un serveur web peuvent rapporter des informations détaillées, en particulier, l'adresse IP spécifique et l'heure précise associée à chaque visiteur.

Cela signifie que, chaque fois que votre navigateur se connecte à mon site web (ou à tout autre site web), il donne à mon serveur web une énorme quantité d'informations. Google les collecte simplement et me les présente dans un format élégant et facile à digérer.

Entre nous, je suis parfaitement conscient qu'en laissant Google collecter toutes ces informations sur les utilisateurs de mon site web, je fais partie du problème. Et, pour la record, je me sens un peu coupable à ce sujet.

De plus, les serveurs web sont capables de "surveiller" ce que vous faites en temps réel et de "se souvenir" de ce que vous avez fait lors de votre dernière visite.

Pour expliquer, avez-vous déjà remarqué comment, sur certains sites, juste avant de cliquer pour quitter la page, un message "Attendez ! Avant de partir !" apparaît ? Les serveurs peuvent suivre les mouvements de votre souris et, lorsqu'ils se rapprochent "trop" de la fermeture de l'onglet ou du passage à un autre onglet, ils afficheront cette fenêtre contextuelle.

De même, de nombreux sites enregistrent de petits paquets de données sur votre ordinateur appelés "cookies". Un tel cookie pourrait contenir des informations de session qui pourraient inclure le contenu précédent d'un panier d'achat ou même votre statut d'authentification. L'objectif est de fournir une expérience pratique et cohérente sur plusieurs visites. Mais de tels outils peuvent être mal utilisés.

Enfin, comme les systèmes d'exploitation, les navigateurs communiqueront également silencieusement avec le fournisseur qui les fournit. Obtenir des commentaires sur l'utilisation peut aider les fournisseurs à rester à jour sur les problèmes de sécurité et de performance. Mais des tests indépendants ont montré que, dans de nombreux cas, beaucoup plus de données sont envoyées "à la maison" que ce qui semblerait approprié.

#### Interaction avec le site web

Bien que certaines de ces informations puissent être couvertes par les sections précédentes du chapitre, je devrais souligner au moins quelques problèmes particulièrement pertinents. Par exemple, le fait que les sites web adorent vous faire signer pour des services de valeur ajoutée.

Les newsletters et les mises à jour de produits qu'ils vous enverront pourraient être parfaitement légitimes et, en effet, fournir une grande valeur. Mais elles arrivent toujours en échange de certaines de vos informations de contact privées.

Tant que vous en êtes conscient, j'ai fait mon travail.

Un exemple parfait est les données que vous contribuez aux plateformes de médias sociaux comme Twitter, Facebook et LinkedIn.

Vous pourriez penser que vous communiquez simplement avec vos connexions et abonnés, mais cela va en réalité beaucoup plus loin.

Prenez un logiciel merveilleux - et effrayant - appelé Recon-ng qui est utilisé par les professionnels de la sécurité réseau pour tester la vulnérabilité numérique d'une organisation. Une fois que vous l'avez configuré avec quelques bases sur votre organisation, Recon-ng se rendra sur l'internet et recherchera toute information publique disponible qui pourrait être utilisée pour pénétrer vos défenses ou vous causer du tort.

Par exemple, êtes-vous sûr que des étrangers ne peuvent pas savoir assez sur l'environnement logiciel avec lequel vos développeurs travaillent pour vous causer des dommages ?

Eh bien, peut-être devriez-vous jeter un coup d'œil à la section "qualifications" de certaines de ces annonces d'emploi que vous avez publiées sur LinkedIn. Ou que dire des questions (ou réponses) que vos développeurs pourraient avoir publiées sur Stack Overflow ?

Chaque publication raconte une histoire, et il ne manque pas de personnes intelligentes qui adorent lire des histoires.

Des logiciels comme Recon-ng peuvent vous aider à identifier les menaces potentielles, mais cela ne fait que souligner votre responsabilité d'éviter de laisser vos données exposées en public en premier lieu.

Le message à retenir ? Souriez. Vous êtes surveillé.

### Pourquoi les entreprises veulent vos données

Les données, c'est de l'argent. Certaines des plus grandes et des plus réussies entreprises technologiques des dernières décennies ont fait leurs milliards grâce aux données. Généralement, ce serait grâce à vos données.

Bien sûr, la valeur ne va pas toutes dans une seule direction.

Les grandes entreprises technologiques fournissent, en règle générale, des services utiles. Les applications de suivi de la santé suivent et rapportent effectivement sur votre santé. Les entreprises de médias sociaux offrent (à de rares occasions) des interactions sociales saines. Et les données de performance historiques aident parfois à améliorer le service client et technique.

Mais les entreprises existent pour générer des revenus et, en règle générale, plus elles possèdent de données, plus elles peuvent générer de revenus.

Plus il y a de clients potentiels qui fournissent leur adresse e-mail et leurs coordonnées de compte de médias sociaux, plus il sera facile de se connecter à eux avec de nouvelles offres. Et plus il sera facile pour d'autres entreprises travaillant dans des industries chevauchantes de se connecter aux clients d'une entreprise également. L'incitation pour vous de vendre votre liste de contacts à un tiers intéressé est évidente.

Naturellement, les restrictions légales et les accords d'utilisateur peuvent parfois empêcher de telles ventes de jeux de données. Mais tous les cas d'utilisation ne sont pas nécessairement couverts par de telles lois, et toutes les entreprises ne sont pas nécessairement liées par un fort désir de suivre la loi.

Un cas délicieux en est la liste canadienne Ne pas appeler, qui remonte à 2004. La loi empêchait les télémarketeurs de contacter toute personne ayant ajouté son nom à la liste nationale. La loi exigeait que tous les télémarketeurs retirent toutes les entrées de la liste de leurs propres listes d'appels.

Le problème était que les spammeurs téléchargeaient joyeusement les listes Ne pas appeler et, confiants qu'elles représentaient des comptes actifs confirmés, appelaient spécifiquement ceux-ci. La seule loi qui était efficace dans ce cas était la _loi des conséquences imprévues_.

Vos données peuvent également être utiles pour personnaliser les résultats que vous obtenez des requêtes des moteurs de recherche. Bien sûr, vous pourriez parfois apprécier de voir des résultats liés à votre comportement de navigation précédent, mais ne perdez pas de vue le fait que votre comportement est utilisé dans le cadre d'une campagne pour vous vendre des choses.

Ce ne sont pas seulement les moteurs de recherche : les historiques de navigation sur smartphone sont parfois utilisés par les entreprises à proximité pour pousser des publicités personnalisées dans votre direction - parfois même à travers des affichages numériques automatisés sur des panneaux d'affichage physiques et d'autres signalisations.

Peut-être la plus grande valeur que vos données peuvent offrir est lorsqu'elles sont agrégées avec des données générées par des milliers ou des millions d'autres utilisateurs. Les scientifiques des données peuvent diffuser et analyser d'énormes ensembles de données dynamiques pour extraire des informations significatives sur des tendances subtiles mais significatives. Dans de nombreux cas, ces données sont assainies pour supprimer toute information personnellement identifiable (PII).

Nous pouvons résumer le modèle économique des applications web du 21e siècle avec cette expression populaire - et exacte :

> "Si vous ne payez pas pour le produit, vous êtes le produit."

### Comment protéger vos données

Tout cela semble assez sombre. Après tout, 1984 de George Orwell était censé être un avertissement, pas un guide pratique.

Que pouvez-vous faire pour résister ?

**Soyez conscient de votre environnement.**

Remarquez-vous encore ces déclarations de conditions de service que vous "cliquez pour signer" avant qu'ils ne vous laissent utiliser un service ou un outil ?

Certaines de ces déclarations sont aussi longues que ce chapitre - et, si je peux me permettre, bien moins amusantes. Mais le fait est qu'elles contiennent des informations qui peuvent avoir un impact profond sur vous et vos données.

De nombreux accords décrivent les données qu'ils sont susceptibles de collecter et ce qu'ils prévoient d'en faire. Ils offrent souvent des assurances qu'ils ne vendront jamais vos données à des tiers - une assurance qu'ils pourraient parfois même honorer à la fois dans la lettre et l'esprit de la loi (bien qu'il y ait eu des cas célèbres d'entreprises qui n'ont fait ni l'un ni l'autre).

Je n'ai jamais rencontré quelqu'un qui ait le temps et l'énergie de lire ces déclarations interminables du début à la fin. Mais si une organisation paie un groupe d'avocats pour écrire quelque chose, vous pouvez parier que c'est une affaire sérieuse.

**Soyez conscient de vos droits.**

Au-delà de votre accord spécifique avec un fournisseur de services technologiques, l'utilisation de vos données peut être réglementée par la législation gouvernementale.

Un exemple est le Règlement général sur la protection des données (RGPD) de l'Union européenne, qui contrôle la manière dont les organisations doivent traiter toute donnée personnelle qu'elles rencontrent dans le cadre de leurs opérations.

Un autre exemple est la loi américaine sur la portabilité et la responsabilité de l'assurance maladie (HIPAA), qui réglemente la gestion des informations privées dans les industries de l'assurance maladie et des soins de santé.

**Soyez conscient de vos alternatives.**

Envisagez d'adopter des outils axés sur la confidentialité plutôt que les services plus commerciaux que vous utilisez actuellement.

Par exemple, le moteur de recherche DuckDuckGo.com, dont la page d'accueil est illustrée à la figure 2.3, ne suit pas votre comportement de recherche et retournera les mêmes résultats pour une requête particulière pour vous que pour toute autre personne.

Ils sont une entreprise à but lucratif, mais ils gagnent une grande partie de leurs revenus grâce à des liens d'affiliation qui leur paient une commission pour les ventes générées par les liens de recherche - aucun d'entre eux n'a d'impact sur votre confidentialité.

![Figure 2.3 : La page d'accueil de DuckDuckGo.com.](https://www.freecodecamp.org/news/content/images/2022/05/figure-2-3.png)
_Figure 2.3_

Le navigateur Brave, pour un autre exemple, a été montré pour envoyer beaucoup moins de données non documentées sur l'internet que tout autre navigateur majeur.

Pour être précis, au début de 2020, Douglas Leith de l'École d'informatique et de statistique, Trinity College Dublin, a testé six navigateurs pour leurs risques de révéler des informations d'identification uniques sur leurs ordinateurs hôtes ([scss.tcd.ie/Doug.Leith/pubs/browser_privacy.pdf](https://www.scss.tcd.ie/Doug.Leith/pubs/browser_privacy.pdf)). Il a constaté que Brave offrait clairement la plus grande protection de la confidentialité.

Brave bloque également les publicités des pages web par défaut, ce qui soulève une question. Puisque de nombreuses pages web génèrent des revenus exclusivement grâce aux publicités affichées, Brave s'attend-il à ce que les fournisseurs de contenu offrent leurs services gratuitement ?

Le fournisseur du navigateur a en réalité un modèle économique qui inclut les fournisseurs de contenu : les utilisateurs du navigateur Brave peuvent choisir d'être montrés des publicités simples et extrêmement discrètes de la part d'annonceurs soigneusement sélectionnés en échange de micro-paiements dans une crypto-monnaie.

Les utilisateurs peuvent ensuite choisir d'effectuer des micro-paiements aux fournisseurs de contenu de sites web en utilisant ces fonds comme moyen de payer pour leur contenu via le programme Brave Rewards (illustré à la figure 2.4).

![Figure 2.4 : La page d'accueil du navigateur Brave.](https://www.freecodecamp.org/news/content/images/2022/05/figure-2-4.png)
_Figure 2.4_

Opter pour des applications open source peut également être une stratégie de confidentialité efficace.

OpenStreetMap (openstreetmap.org) est une alternative à Google Maps. Il n'a peut-être pas toutes les clochettes et sifflets et la connectivité intégrée à laquelle vous êtes habitué, mais c'est justement cette connectivité qui alimente nos réserves, n'est-ce pas ?

Si vous n'êtes pas à l'aise avec les grands acteurs des systèmes d'exploitation mobiles (Android et iOS), vous pourriez, à la place, acheter un téléphone et installer l'une des nombreuses variations expérimentales de Linux mobile.

Emprunter cette voie sera probablement mouvementé. Attendez-vous à rencontrer des défis de configuration et de compatibilité inattendus, et ne vous attendez pas à trouver toutes les applications pratiques que vous avez appris à connaître et à aimer en utilisant les grands magasins d'applications.

Voyez un trou qui a besoin d'être comblé ? Pourquoi ne pas contribuer votre propre innovation en participant à des projets open source existants ou en ajoutant vos propres solutions à la communauté ?

## Chapitre 3 : Comprendre le Cloud

Vous n'en êtes peut-être pas toujours conscient, mais vous profitez des nombreux fruits du cloud presque toutes les heures de chaque jour. Beaucoup des joies (et des horreurs) de la vie moderne seraient impossibles sans lui.

Avant de parler de ce qu'il fait et de l'endroit où il nous mène, nous devrions expliquer exactement ce que c'est.

Le "cloud" consiste à utiliser les ordinateurs d'autres personnes plutôt que les vôtres. C'est tout. Non, vraiment.

Les fournisseurs de cloud exécutent de nombreux serveurs de calcul (qui ne sont que des ordinateurs qui existent pour "servir" des applications et des données en réponse à des demandes externes), des dispositifs de stockage et du matériel de mise en réseau. Chaque fois que l'envie vous en prend, vous pouvez provisionner des unités de ces serveurs, dispositifs et capacité de mise en réseau pour vos propres charges de travail. Lorsque vous ajoutez des millions d'autres utilisateurs pris par des impulsions similaires, vous obtenez le cloud moderne.

Pour de nombreuses applications - bien que pas toutes - il y a d'énormes avantages en termes de coût et de performance à réaliser en déployant sur un cloud. Et d'innombrables applications - qu'elles soient petites, grandes ou colossales - ont trouvé des foyers productifs sur une plateforme cloud ou une autre.

Alors, voyons comment tout cela fonctionne et ce que vous pourriez être en mesure de faire avec.

### Modèles de déploiement de serveurs d'applications

Au fil des décennies, nous avons connu plusieurs modèles pour exécuter des charges de travail de serveurs. D'une certaine manière, tous ces changements ont été le produit de seulement deux technologies :

* Les protocoles de mise en réseau qui permettent la communication entre les nœuds connectés
* La virtualisation qui permet une utilisation rapide, efficace et rentable des ressources matérielles pour des utilisations multiples et parallèles

La mise en réseau, largement parce qu'elle est maintenant une technologie si stable et bien établie, n'est pas quelque chose sur lequel nous allons nous concentrer ici. Mais nous reviendrons à la virtualisation un peu plus tard.

#### Centres de données locaux

Dans le temps, si vous vouliez lancer un nouveau serveur pour effectuer une tâche de calcul, vous passiez une semaine ou deux à calculer la quantité de puissance de calcul dont vous auriez besoin pour votre travail. Vous contactiez ensuite les représentants commerciaux de quelques fournisseurs de matériel, attendiez qu'ils vous reviennent avec des offres, compariez les offres et, une fois que vous en aviez sélectionné une, attendiez encore quelques semaines pour que votre nouveau matériel soit livré. Enfin, vous assembliez toutes les pièces, les branchiez et commenciez à charger le logiciel.

La salle où vos serveurs fonctionnaient avait besoin d'une alimentation électrique fiable et robuste et d'un système de refroidissement : comme les enfants en colère, les serveurs génèrent beaucoup de chaleur mais n'aiment pas être chauds. Vous ne voudriez probablement pas faire d'autre travail dans cette salle, puisque le bruit des ventilateurs de refroidissement internes puissants de vos serveurs était difficile à ignorer.

Bien que les serveurs déployés localement vous donnaient tout le contrôle direct et manuel sur votre matériel dont vous pourriez avoir besoin, cela avait un coût.

Pour une chose, les opportunités de redondance de l'infrastructure (et la fiabilité qui l'accompagne) étaient limitées. Après tout, même si vous sauvegardiez régulièrement vos données (et en supposant que vos sauvegardes étaient fiables), elles ne vous protégeraient toujours pas d'un incident à l'échelle de l'installation comme un incendie catastrophique.

Vous devriez également gérer votre propre mise en réseau, ce qui pourrait être particulièrement délicat - et risqué - lorsque des clients distants nécessitaient un accès depuis l'extérieur de votre bâtiment.

Au fait, ne vous laissez pas tromper par mon utilisation trompeuse du passé ici ("étaient limitées", "sauvegardées"). Il y a encore beaucoup de charges de travail de toutes tailles qui tournent joyeusement dans des centres de données sur site.

Mais la tendance est, sans aucun doute, dirigée dans l'autre direction.

#### Co-localisation de serveurs

Une autre option pour les organisations de taille moyenne à grande est de stocker vos propres serveurs dans le centre de données de quelqu'un d'autre, un arrangement connu sous le nom de co-localisation.

L'entreprise d'hébergement fournit les baies de serveurs et l'alimentation, ainsi que tout l'équipement de mise en réseau et de refroidissement dont vous aurez besoin. Chaque fois que vous avez besoin d'un accès physique à vos serveurs, ils seront toujours heureux lorsque vous passerez dire bonjour.

C'est un moyen pratique de maintenir un contrôle direct sur vos serveurs tout en laissant la sécurité physique et les maux de tête de l'infrastructure plus large entre les mains de spécialistes. Les installations de co-localisation sont souvent capables de normes de sécurité et de fiabilité bien plus élevées que celles que les petites opérations pourraient gérer par elles-mêmes.

Pour des raisons de sécurité, les centres de co-localisation ne feront probablement pas de publicité pour leurs services au niveau de la rue.

Mais si vous voulez voir à quoi ils ressemblent, recherchez "hébergement de serveurs en co-localisation" dans votre ville, puis utilisez Google Satellite pour vérifier une ou deux des adresses qui reviennent. Si vous voyez un grand bâtiment non marqué avec des dizaines d'unités de climatisation puissantes sur le toit, ce sera un centre de données.

#### Virtualisation

Comme je l'ai suggéré plus tôt, la virtualisation est la technologie qui, plus que toute autre, définit l'internet moderne et les nombreux services qu'il permet.

Au cœur de la virtualisation se trouve un tour de magie logiciel astucieux qui vous permet de convaincre un système d'exploitation qu'il est seul sur un ordinateur bare metal alors qu'il n'est, en fait, qu'un des nombreux systèmes d'exploitation partageant un seul ensemble de ressources physiques. Un système d'exploitation virtuel se verra attribuer de l'espace sur un disque de stockage virtuel, de la bande passante via une interface réseau virtuelle et de la mémoire à partir d'un module RAM virtuel.

Voici pourquoi c'est une si grande affaire : Supposons que les disques de stockage sur votre hôte serveur aient une capacité totale de deux téraoctets et que vous ayez 64 Go de RAM. Vous pourriez avoir besoin de 10 Go de stockage et de 10 Go de mémoire pour le système d'exploitation hôte (ou, _hyperviseur_ comme on appelle certains hôtes de virtualisation). Cela vous laisse beaucoup de place pour vos instances de systèmes d'exploitation virtuels.

Vous pourriez facilement lancer plusieurs instances virtuelles, chacune allouée avec suffisamment de ressources pour accomplir leurs tâches individuelles. Lorsqu'une instance particulière n'est plus nécessaire, vous pouvez l'éteindre, libérant ses ressources pour qu'elles soient instantanément disponibles pour d'autres instances effectuant d'autres tâches.

Mais les vrais avantages viennent de la manière dont la virtualisation peut être si efficace avec vos ressources. Une instance pourrait, par exemple, se voir attribuer de la RAM et du stockage qui, plus tard, s'avèrent insuffisants. Vous pouvez facilement allouer plus de chaque à partir du pool - souvent sans même éteindre votre instance. De même, vous pouvez réduire l'allocation pour une instance à mesure que ses besoins diminuent.

Cela élimine toute la devinette de la planification des serveurs. Vous n'avez besoin d'acheter (ou de louer) que des ressources matérielles génériques et de les attribuer en unités incrémentielles si nécessaire. Il n'est plus nécessaire de scruter l'avenir lointain en essayant d'anticiper ce que vous ferez dans cinq ans. Cinq _minutes_ suffisent largement pour la planification.

Maintenant, imaginez que tout cela se passe à une échelle beaucoup plus grande : Supposons que vous avez des milliers de serveurs fonctionnant dans un entrepôt quelque part qui hébergent des charges de travail pour des milliers de clients.

Peut-être qu'un client demande soudainement un autre téraoctet d'espace de stockage. Même si le disque que le client utilise actuellement est saturé, vous pouvez facilement ajouter un autre téraoctet à partir d'un autre disque, peut-être un branché à quelques centaines de mètres de l'autre côté de l'entrepôt.

Le client ne remarquera jamais la différence, mais le changement peut être pratiquement instantané.

##### Bétail vs Animaux de compagnie

La virtualisation des serveurs a changé la façon dont nous voyons l'informatique et même le développement de logiciels.

Il n'est plus si important de construire des interfaces de configuration dans vos applications qui permettront de régler et de corriger les choses à la volée. Il est souvent plus efficace pour vos développeurs et administrateurs système de construire une image de système d'exploitation personnalisée (presque toujours basée sur Linux) avec tous les logiciels préconfigurés. Vous pouvez ensuite lancer de nouvelles instances virtuelles basées sur votre image chaque fois qu'une mise à jour est nécessaire.

Si quelque chose ne va pas ou si vous devez appliquer un changement, vous créez simplement une nouvelle image, éteignez votre instance, puis la remplacez par une instance exécutant votre nouvelle image.

Effectivement, vous traitez vos serveurs virtuels de la même manière qu'un agriculteur traite ses vaches : lorsque le moment est venu (comme il le sera inévitablement), vous prenez une vieille ou malade vache et vous la tuez, puis vous en amenez une autre (plus jeune) pour la remplacer.

Quiconque a déjà été impliqué dans l'administration de salles de serveurs héritées serait horrifié par une telle pensée ! Nos anciennes machines physiques étaient traitées comme des animaux de compagnie bien-aimés.

Au moindre signe de détresse, nous serions debout, préoccupés, à ses côtés, essayant de diagnostiquer quel était le problème et comment il pouvait être résolu. Si tout le reste échouait, nous serions forcés de redémarrer le serveur, espérant contre tout espoir qu'il redémarre. Si même _cela_ n'était pas suffisant, nous cédions et remplacions le matériel.

Mais la modularité que nous obtenons grâce à la virtualisation nous donne toutes sortes de nouvelles flexibilités.

Maintenant que les considérations matérielles ont été largement abstraites, notre principal objectif est le logiciel (qu'il s'agisse de systèmes d'exploitation complets ou d'applications individuelles).

Et le logiciel, grâce aux langages de script, peut être automatisé. Ainsi, en utilisant des outils d'orchestration comme Ansible, Terraform et Puppet, vous pouvez automatiser la création, le provisionnement et la gestion complète du cycle de vie des instances de services d'application.

Même la gestion des erreurs peut être intégrée à votre orchestration, de sorte que vos applications pourraient être conçues pour corriger magiquement leurs propres problèmes.

##### Machines virtuelles vs Conteneurs

Les instances virtuelles se présentent sous deux formes. Les machines virtuelles (ou VM) sont des systèmes d'exploitation complets qui s'exécutent sur - mais dans une certaine mesure indépendamment de - la machine hôte.

C'est le type de virtualisation qui utilise un hyperviseur pour administrer l'accès que chaque VM obtient aux ressources matérielles sous-jacentes, mais de telles VM sont généralement laissées à vivre comme elles le choisissent.

Des exemples d'environnements d'hyperviseur incluent le projet open source Xen, VMware ESXi, VirtualBox d'Oracle et Microsoft Hyper-V.

Les conteneurs, en revanche, partageront non seulement le matériel, mais aussi le noyau logiciel du système d'exploitation hôte. Cela rend les instances de conteneurs beaucoup plus rapides et plus légères (puisque leurs images n'ont pas besoin d'inclure un noyau).

Non seulement cela signifie que les conteneurs peuvent se lancer presque instantanément, mais que leurs systèmes de fichiers peuvent être transportés entre les hôtes et partagés. La portabilité signifie que les environnements d'instance peuvent être reproduits de manière fiable n'importe où, rendant la collaboration et le déploiement automatisé non seulement possibles, mais faciles.

Des exemples de technologies de conteneurs incluent LXD et Docker. Et les implémentations de conteneurs d'entreprise incluent le système d'orchestration open source Kubernetes de Google.

#### Clouds publics

Les plateformes de cloud public ont élevé l'abstraction et l'allocation dynamique des ressources de calcul au rang d'art. Les grands fournisseurs de cloud exploitent de vastes réseaux de centaines de milliers de serveurs et des nombres inimaginables de dispositifs de stockage répartis dans des centres de données à travers le monde.

N'importe qui, n'importe où, peut créer un compte utilisateur avec un fournisseur, demander une instance en utilisant une capacité définie sur mesure, et avoir un serveur web entièrement fonctionnel et accessible au public en quelques minutes. Et comme vous ne payez que pour ce que vous utilisez, vos frais refléteront de près vos besoins réels.

Un serveur web que je fais fonctionner sur Amazon Web Services (AWS) pour héberger deux ou trois de mes sites web modérément fréquentés ne me coûte que 50 dollars par an environ et a suffisamment de puissance pour gérer beaucoup plus de trafic.

Les ressources AWS utilisées par l'entreprise de streaming vidéo Netflix coûteront probablement un peu plus - sans aucun doute des millions de dollars par an. Mais ils pensent évidemment qu'ils obtiennent une bonne affaire et préfèrent utiliser AWS plutôt que d'héberger leur infrastructure eux-mêmes.

Justement, qui sont tous ces fournisseurs de cloud public, je suis sûr que vous vous demandez ?

Eh bien, cette conversation doit commencer (et, souvent, se terminer) avec AWS. Ils sont l'éléphant dans chaque pièce.

Les millions de charges de travail fonctionnant dans les centres de données énormes et omniprésents d'Amazon, ainsi que leur rythme frénétique d'innovation, en font le joueur à battre dans cette course. Et cela ne tient même pas compte des milliards de dollars de bénéfices nets qu'ils empochent chaque trimestre.

À ce stade, la seule concurrence sérieuse à AWS est Microsoft Azure, qui fait un assez bon travail pour suivre les catégories de services et, selon tous les comptes, réalise de bons bénéfices dans le processus ; et Alibaba Cloud, qui se concentre principalement sur le marché asiatique pour l'instant.

Google Cloud est dans la course, mais semble se concentrer sur un ensemble plus restreint de services où ils peuvent raisonnablement rivaliser.

Comme la barrière à l'entrée sur le marché est redoutable, il n'y a que quelques autres qui se font remarquer, notamment Oracle Cloud, IBM Cloud et, avec un changement bienvenu dans la convention de nommage, Digital Ocean.

#### Clouds privés

La bonté du cloud peut également être obtenue plus près de chez soi, si c'est ce que vous recherchez. Rien ne vous empêche de construire vos propres environnements cloud sur une infrastructure située dans votre propre centre de données.

En fait, il existe de nombreux logiciels matures qui géreront le processus pour vous. Parmi ceux-ci, les environnements open source OpenStack ([openstack.org](https://www.openstack.org/)) et VMware vSphere ([vmware.com/products/vsphere.html](https://www.vmware.com/products/vsphere.html)) sont particulièrement notables.

Construire et exécuter un cloud est un processus très compliqué et ne convient pas aux amateurs ou aux timides. Et je ne tenterais pas de télécharger et de tester OpenStack - même juste pour expérimenter - à moins que vous n'ayez une station de travail rapide et puissante pour servir d'hôtes cloud et au moins quelques machines pour les nœuds.

Vous pouvez également avoir les deux en maintenant certaines opérations proches de chez vous tout en externalisant d'autres opérations dans le cloud. Cela s'appelle un déploiement de cloud hybride.

Peut-être, par exemple, des restrictions réglementaires vous obligent à garder une base de données backend d'informations sensibles sur la santé des clients dans les quatre murs de votre propre opération, mais vous aimeriez que vos serveurs web accessibles au public fonctionnent dans un cloud public. Il est possible de connecter des ressources d'un domaine (par exemple, AWS) à un autre (votre centre de données) pour créer un tel arrangement.

En fait, il existe des moyens d'intégrer étroitement vos ressources locales et cloud. Le service _VMware Cloud on AWS_ facilite (relativement) l'utilisation de l'infrastructure VMware déployée localement pour gérer de manière transparente les ressources AWS ([aws.amazon.com/vmware](https://aws.amazon.com/vmware/)).

### La valeur de l'externalisation de vos opérations de calcul

Pourquoi pourriez-vous vouloir migrer des charges de travail vers le cloud ? Vous pourriez finir par économiser beaucoup d'argent. Donc, il y a cela.

Bien sûr, cela ne fonctionnera pas de cette manière pour chaque déploiement, mais il semble y avoir beaucoup de cas d'utilisation où c'est le cas.

Pour vous aider à prendre des décisions éclairées, les plateformes cloud offrent souvent des calculateurs sophistiqués pour comparer les coûts d'exécution d'une application localement par rapport à ce que cela coûterait dans le cloud. La version AWS de cela est ici : [aws.amazon.com/tco-calculator](https://calculator.aws/#/)

Une partie du calcul des prix est la _manière_ dont vous payez.

Le modèle traditionnel sur site impliquait des investissements initiaux importants pour du matériel serveur coûteux que vous espériez fournir suffisamment de valeur au cours des cinq à dix prochaines années pour justifier l'achat. Ces investissements sont connus sous le nom de _dépenses en capital_ ("Capex").

Les services cloud, en revanche, sont facturés de manière incrémentielle (à l'heure, ou même à la minute) selon le nombre d'unités de service que vous consommez réellement. Cela est normalement classé comme _dépenses d'exploitation_ (Opex).

En utilisant le modèle Opex, si vous devez exécuter une charge de travail de serveur seulement une fois tous les quelques jours pendant cinq minutes à la fois en réponse à un événement de déclenchement externe, vous pouvez automatiser l'utilisation d'une charge de travail "serverless" (en utilisant un service comme Lambda d'Amazon) pour ne fonctionner que lorsque cela est nécessaire. Coûts totaux : peut-être seulement quelques centimes par mois pour couvrir ces minutes où le service est effectivement en cours d'exécution.

Outre les considérations de coût, il se passe beaucoup plus de choses dans le monde du cloud qui devraient attirer votre attention.

Vous avez déjà vu comment le temps de latence entre la décision de déployer un nouveau serveur sur site et son déploiement effectif (semaines ou mois) se compare à un processus de décision/déploiement similaire dans un cloud public (quelques minutes).

Mais les grands fournisseurs de cloud sont également positionnés pour offrir des environnements significativement plus sécurisés et fiables.

Par exemple, vous vous souvenez peut-être de notre histoire sur l'attaque DDoS du chapitre 2 (Comprendre la sécurité numérique). C'était l'incident où l'équivalent de 380 000 livres PDF de données ont été utilisés pour bombarder un service web hébergé sur AWS chaque seconde... et le service a survécu. Êtes-vous confiant de pouvoir faire cela vous-même ?

Et qu'en est-il de la fiabilité par la redondance ? Votre infrastructure sur site survivrait-elle à une perte catastrophique de vos locaux ? Même si vous avez fait ce qu'il fallait et maintenu des sauvegardes hors site, combien de temps vous faudrait-il pour les appliquer à du matériel reconstruit, connecté au réseau et fonctionnel ?

Les grandes plateformes cloud exécutent des centres de données dans des emplacements physiquement éloignés à travers le monde. Elles facilitent (et dans certains cas rendent inévitable) la réplication de vos données et applications dans plusieurs emplacements afin que, même si un centre de données tombe en panne, les autres seront intacts. Pouvez-vous reproduire cela ?

Les fournisseurs de cloud gèrent également des réseaux de distribution de contenu (CDN) vous permettant d'exposer des copies mises en cache de données fréquemment consultées à des emplacements de périphérie proches de l'endroit où vos clients vivent sur terre. Cela réduit considérablement la latence, améliorant l'expérience utilisateur que vos clients obtiendront. Est-ce quelque chose que vous pouvez faire vous-même ?

Une dernière pensée. La plupart des grands investissements dans les nouvelles technologies de l'information ces jours-ci sont investis dans les écosystèmes cloud.

C'est en partie parce que les grands fournisseurs de cloud génèrent de l'argent beaucoup plus rapidement qu'ils ne peuvent espérer le dépenser. Mais c'est aussi parce qu'ils sont impliqués dans une course à la vie ou à la mort pour capturer de nouveaux segments du marché de l'infrastructure avant que la concurrence ne les revendique.

Le résultat est que le taux d'innovation dans le cloud est stupéfiant.

Je gagne ma vie en gardant un œil attentif sur AWS, et même moi, je manque régulièrement des annonces de nouveaux produits. L'une des raisons pour lesquelles j'évite d'inclure des captures d'écran de la console de gestion AWS dans mes livres et cours vidéo est que leur console est mise à jour si souvent que les images seront souvent obsolètes avant que le livre ne soit publié.

Dans certains cas, cela pourrait signifier que les déploiements locaux fonctionneraient avec un désavantage intégré simplement parce qu'ils n'auraient pas accès aux technologies de pointe équivalentes.

### Les risques de l'externalisation de vos opérations de calcul

Ayant dit tout cela, comme pour la plupart des choses dans la vie, choisir entre le cloud et le local n'est pas toujours aussi évident que je l'ai peut-être fait paraître.

Il peut encore y avoir, par exemple, des lois et des règles vous obligeant à garder vos données locales. Il y aura également des cas où les mathématiques ne fonctionnent tout simplement pas : parfois, il est vraiment moins cher de faire les choses dans votre propre centre de données.

Vous devriez également vous inquiéter de l'enfermement par la plateforme. La courbe d'apprentissage nécessaire avant que vous ne soyez prêt à lancer des déploiements cloud complexes et multi-niveaux n'est pas triviale. Et vous pouvez être sûr que la manière dont cela fonctionne sur AWS ne sera probablement pas tout à fait la même que ce qui se passe sur MS Azure.

L'investissement en connaissances que vous devrez faire une fois que vous aurez fait votre choix sera probablement coûteux.

Mais que se passe-t-il avec cet investissement si les politiques du fournisseur changent soudainement de manière à vous forcer à quitter la plateforme ? Ou s'ils ferment réellement leurs portes (cela pourrait arriver : Kodak, Blockbuster Video et Palm étaient autrefois grands, eux aussi) ?

Et qu'en est-il d'être bloqué hors de votre compte pour une raison quelconque ? À quel point serait-il difficile pour vous de réoutiller et de recharger tout ailleurs ?

Réfléchissez simplement à l'avance et assurez-vous de faire un choix rationnel.

## Chapitre 4 : Comprendre la connectivité numérique

Les téléphones ont changé la façon dont nous parlions tous et faisions notre travail (eh bien, la façon dont nos arrière-grands-parents le faisaient, en tout cas). Les informations pouvaient maintenant être communiquées instantanément, plutôt que d'être envoyées par des routes terrestres lentes.

Mais ce n'est guère une nouvelle pour quiconque de nos jours. Le réseau moderne - mieux connu sous le nom d'internet - a de même stimulé la communication, bien que cette fois-ci, c'est le mouvement des _données_ plutôt que de la _voix_ qui a été stimulé.

Dans les cinquante années ou plus depuis la naissance de l'internet, il a été chargé de la gestion, du stockage et de la gestion de plus en plus de nos données. Ces changements ont apporté des opportunités, des risques et des pressions considérables.

Se connecter est maintenant une nécessité de base.

Gérer tous nos nombreux appareils connectés et tirer parti des moyens par lesquels nous nous authentifions pour étendre nos identités présente également des défis. Nous discuterons de tout cela dans ce chapitre.

### Se connecter à l'internet

De nos jours, après la nourriture et le logement, l'une des ressources les plus basiques est la connectivité internet.

Si vous ne pouvez pas accéder à l'internet, vous aurez du mal à faire vos opérations bancaires, à vous éduquer, à réserver des arrangements de voyage, ou même à déterminer exactement où vous vous trouvez.

Ce n'est pas pour rien qu'un accès internet généralisé, fiable et relativement rapide est crucial pour le développement économique général d'une région.

Même si l'internet a été initialement construit comme un réseau décentralisé et distribué de ressources, vous devez toujours établir une sorte de connexion pour y accéder.

Les meilleures connexions sont gérées par des opérateurs de réseau, connus sous le nom de _réseaux de niveau 1_. Ces réseaux peuvent atteindre tous les autres réseaux grâce à un accord de peering qui ne nécessite pas de paiement pour le transit IP.

Vous pouvez penser à ces réseaux comme l'épine dorsale de l'internet, et leur infrastructure réseau en est la structure.

Des exemples de sociétés gérant des réseaux de niveau 1 incluent AT&T et Verizon aux États-Unis, Tata Communications (Inde) et Deutsche Telekom (Allemagne). Ces opérateurs revendent de la bande passante à des fournisseurs de services internet (FAI) plus petits qui, à leur tour, vendent l'accès aux utilisateurs finaux comme vous et moi.

#### Options de bande passante

Les particuliers à la recherche d'un accès à large bande dans leurs foyers ou petites entreprises peuvent généralement choisir entre l'un des quatre modèles d'accès :

* **Câble**. Puisqu'ils sont déjà dans le secteur de la fourniture de données à des millions de foyers via des connexions physiques existantes, les fournisseurs de télévision par câble peuvent facilement transmettre l'internet via les mêmes fils.
* **Ligne d'abonné numérique (DSL)**. Une famille de technologies qui permettent la transmission de données numériques sur des lignes téléphoniques en cuivre, le DSL peut fournir un niveau de service approximativement similaire à celui du câble, mais sans avoir besoin d'un abonnement câble sous-jacent. En fait, en utilisant une connexion "cuivre sec", vous n'avez même pas besoin d'un compte de ligne téléphonique fixe.
* **Fibre optique**. En raison de certains détails techniques obscurs (y compris les lois de la physique), la transmission de signaux numériques sous forme de lumière infrarouge peut se faire plus rapidement et nécessiter moins de répéteurs que les câbles électriques comparables. Une connexion internet par fibre optique pourrait typiquement offrir des vitesses de transfert de 10-40 Gbit/s - mille fois plus rapides que les taux actuellement standard utilisant le câble ou le DSL.
* **Satellite**. Faire passer de nouveaux câbles dans des villes densément peuplées est coûteux, mais les entreprises peuvent rapidement rentabiliser leur investissement grâce aux nombreux contrats d'accès qu'elles signeront.

Mais les régions rurales peu peuplées sont beaucoup plus difficiles à desservir. En partie pour combler un vide de connectivité rurale, un certain nombre d'entreprises travaillent ambitieusement à lancer des constellations de milliers de satellites en orbite pour fournir une couverture internet universelle.

À l'heure où nous écrivons ces lignes, SpaceX est le plus avancé avec son projet, ayant déjà lancé avec succès plus de 500 satellites dans le cadre du système Starlink.

Outre ces technologies dominantes, il y a eu plus d'une tentative de solutions de connectivité alternatives. Certaines sont expérimentales mais prometteuses, et d'autres sont un peu plus spéculatives.

L'internet par ballon de Google (officiellement connu sous le nom de Loon LLC) est une tentative de faire flotter des flottes de ballons à haute altitude fournissant un signal de 1 Mbps à toute personne à portée sur le sol.

Loon est conçu pour fournir une bande passante bas de gamme dans des régions difficiles d'accès où un service fiable a été difficile ou même impossible. À partir de 2020, le projet semble être en phase expérimentale avancée.

La bande passante sur ligne électrique (BPL) peut tirer parti de tout le réseau électrique qui relie les autorités électriques aux foyers et aux entreprises pour fournir des données internet.

En fin de compte, la technologie offre une bande passante limitée car le bruit de ligne provoque une perte significative du signal de données. Les lignes électriques transportant des données peuvent également causer des interférences avec les communications radio à haute fréquence.

En fin de compte, la qualité relativement faible du signal et la forte concurrence d'autres technologies signifient que le BPL ne sera probablement jamais largement adopté.

Les réseaux utilisant des formes de fournisseur de services internet sans fil (WISP) peuvent desservir des foyers et des bureaux sur de plus grandes zones géographiques sans avoir besoin de câbler physiquement chaque bâtiment.

Des connexions filaires sont installées au centre de la zone et, lorsque nécessaire, des liaisons montantes connectées sont installées dans des zones surélevées pour renforcer les signaux sans fil destinés aux consommateurs. Des tours radio existantes ou d'autres structures hautes peuvent être utilisées pour les répéteurs de liaison montante, rendant un système WISP relativement peu coûteux à installer.

Des coopératives de réseaux sans fil à plus petite échelle peuvent être partagées localement en utilisant un _fournisseur de services internet de quartier (NISP)_ (en utilisant des antennes sur le toit) ou un _réseau maillé sans fil_ (où les appareils connectés au réseau agissent comme des nœuds pairs) pour partager efficacement une seule connexion physique.

Ces systèmes sont principalement conçus pour nous servir là où nous vivons et travaillons. Mais l'accès aux données mobiles est définitivement aussi une chose.

Je suis sûr que vous êtes déjà familier avec les forfaits de données que les compagnies de téléphonie mobile peuvent fournir en plus de leurs services d'appel et de messagerie.

#### Accès aux données des téléphones mobiles

La connectivité cellulaire est distribuée à travers des zones géographiques (connues sous le nom de "cellules") à partir de transmetteurs radio individuels répartis dans la cellule.

Puisque les transmetteurs dans chaque cellule utiliseront des fréquences radio différentes de celles des cellules autour, les technologies sans fil modernes permettent un "transfert" automatique et transparent lorsque l'utilisateur se déplace entre les cellules.

Les technologies utilisées pour la téléphonie sans fil ont changé depuis les années 80, lorsque ce qui est maintenant connu sous le nom de téléphones cellulaires 1G ("Première Génération") ont été introduits. Pour décrire l'évolution des téléphones cellulaires en termes très généraux, nous pourrions dire que :

* Les téléphones **1G** ne transportaient que des communications vocales et avaient une vitesse de transfert maximale de 2,4 Kbps.
* Les téléphones **2G** pouvaient transporter des messages de service de messages courts (SMS) et de service de messagerie multimédia (MMS), qui pouvaient inclure de courtes vidéos et des images.
* Les téléphones **3G** avaient des taux de transfert beaucoup plus élevés (jusqu'à 2 Mbps) que toute variante de 2G et étaient donc appelés "bande passante mobile".
* Les téléphones **4G** pouvaient atteindre des vitesses allant jusqu'à 100 Mbps, ce qui permettait la télévision mobile HD, les jeux en ligne et la visioconférence.
* Les téléphones **5G** - lorsqu'ils sont utilisés sur des réseaux compatibles - devraient atteindre des vitesses de transfert allant jusqu'à 20 Gbps avec une latence très faible, permettant des environnements virtuels entièrement immersifs.

Si le déploiement de la 5G est un succès (et, au moment de la rédaction, cela n'est pas encore clair), l'étendue et les limites des nouvelles catégories de services qui pourraient être déployées ne sont pas encore connues.

En ce qui concerne la planification d'une nouvelle entreprise, il est depuis longtemps admis que rien ne remplace une solide recherche de marché.

Sans savoir qui seront vos clients, où ils vivent et ce qu'ils aiment, comment pouvez-vous les servir correctement ?

Eh bien, vous pouvez maintenant ajouter à cette liste "à quel point leur connectivité internet est fiable et robuste", car sans accès numérique, ils ne vous trouveront peut-être jamais ou ne pourront pas consommer votre service.

### Parler à l'Internet des Objets

Deux changements récents sont, plus que tout autre chose, responsables de l'écosystème de l'Internet des Objets (IoT) : la disponibilité d'ordinateurs embarqués bon marché et à carte unique (comme le Raspberry Pi illustré à la figure 4.1), et une connectivité internet bon marché et toujours active.

![Figure 4.1 : Un ordinateur à carte unique Raspberry Pi](https://www.freecodecamp.org/news/content/images/2022/05/figure4-1.jpg)
_Figure 4.1_

Ces minuscules cartes uniques - souvent plus petites qu'une carte de crédit - sont faciles à incorporer dans à peu près tout ce que vous prévoyez de fabriquer. De tels dispositifs coûtent très peu - parfois seulement quelques dollars chacun - et ils sont généralement conçus pour exécuter des distributions Linux complètes et gratuites.

Et la disponibilité du réseau signifie que les vastes flux de données générés par toutes ces caméras embarquées, capteurs et autres périphériques peuvent être automatiquement envoyés "à la maison" pour traitement et analyse.

#### Le rêve de l'IoT

Voici quelques façons dont les applications IoT changent déjà activement les pratiques commerciales et consommateurs :

* **Contrôle des stocks**. Le tout premier appareil IoT était - du moins selon certains - un distributeur automatique de Coca-Cola à l'Université Carnegie Mellon. Dans les années 80, la machine a été modifiée pour signaler numériquement son inventaire en cours.

L'idée simple selon laquelle les appareils physiques peuvent se surveiller eux-mêmes et leur environnement, fournissant des rapports de statut précis et à la minute aux serveurs distants, est au cœur de nombreuses solutions industrielles modernes.

Le commerce de détail moderne, le commerce de gros, la logistique et les opérations de fabrication ont désormais un accès constant à leurs inventaires, leur permettant de comprendre les tendances et d'anticiper les problèmes.
* **Agriculture**. De plus en plus, l'agriculture moderne intègre des technologies robotisées d'irrigation, de fertilisation, de plantation et même de récolte. Tous ces robots qui se déplacent sur votre propriété génèrent des données et, de temps en temps, se mettent dans des situations difficiles.

Le transfert de ces données "en arrière" vers les serveurs d'administration est crucial pour suivre ce qui se passe, ce qui pourrait nécessiter une réparation et comment votre ferme réelle se comporte.

Vous pouvez donc vous attendre à ce que chacun de ces appareils fasse partie de l'IoT de quelqu'un.
* **Militaire**. La communication est essentielle pour les opérations militaires. Mais si même les armes, les véhicules et autres équipements peuvent communiquer de manière autonome, et s'il existe des serveurs dédiés à l'interprétation et à l'action sur cette communication, alors vous êtes déjà bien en avance dans le jeu.

Les capteurs connectés à chacun des centaines de composants d'un avion de chasse, par exemple, peuvent contribuer à donner aux planificateurs une vue sans précédent de ce qui se passe réellement.
* **Villes intelligentes**. Lorsque les capteurs intégrés dans les bâtiments, les routes, l'éclairage public, les smartphones et les systèmes électriques sont combinés avec les données provenant des caméras de circulation et des départements publics, le potentiel d'informations basées sur les données est énorme.

Des données correctement comprises peuvent aider les villes à gérer leurs ressources, leurs services publics et même leur circulation de manière plus efficace, et à mieux maintenir leur infrastructure physique.
* **Maisons intelligentes**. À une échelle beaucoup plus petite que les villes intelligentes, les appareils domestiques peuvent être connectés, surveillés et contrôlés via des applications pour smartphones ou des serveurs distants.

Les appareils domestiques intelligents incluent déjà les systèmes de chauffage et de climatisation, les ampoules, les aspirateurs robots, les portes de garage et les systèmes de sécurité. Ces appareils peuvent être contrôlés via des applications téléphoniques mais, dans de nombreux cas, également via des appareils contrôlés par la voix comme Amazon Echo (Alexa).

Les conversations sur l'IoT sont toujours à un pas du _buzzwordisme_ - où les mots perdent leur sens et l'exagération devient un choix de style de vie acceptable.

Tous les trucs IoT ne sont pas vraiment de l'IoT. Ou, pour le dire autrement, tout l'IoT ne vaut pas la peine d'en parler.

Mais voici une bonne façon de catégoriser une technologie particulière : si, heure après heure, quelque chose génère plus de données que tout être humain ne pourrait en absorber, alors c'est probablement un appareil IoT.

Traiter efficacement toutes ces données peut être un problème. Et ce n'est pas le seul potentiel de problèmes dans le monde de l'IoT.

#### Le cauchemar de l'IoT

Dans le monde des technologies de l'information, en règle générale, plus vous avez de connexions réseau actives dans votre infrastructure, plus votre risque d'être attaqué avec succès est grand.

C'est parce que les intrusions réussies des pirates proviennent généralement de dispositifs mal configurés ou non corrigés. Plus vous exposez de dispositifs publics, plus la probabilité qu'un d'entre eux ait une vulnérabilité sérieuse est grande.

Quels types de vulnérabilités parlons-nous ?

Eh bien, la base de données des vulnérabilités et expositions courantes du gouvernement américain contient près de 140 000 entrées individuelles, chacune représentant une faiblesse logicielle unique qui pourrait permettre un accès non autorisé et la destruction d'un système informatique.

Il existe des menaces affectant tous les systèmes d'exploitation (Windows, Linux, macOS), tous les formats (serveur, PC, smartphone) et tous les âges (il existe des menaces actives remontant aux années 1990).

Et des centaines de nouvelles entrées sont ajoutées chaque mois.

À cet égard, les dispositifs IoT ne sont pas différents des autres types d'ordinateurs. Mais il y a une façon dont ils sont bien pires.

Parce que vous n'interagissez généralement pas directement avec les dispositifs IoT au niveau du système d'exploitation, et parce qu'ils sont souvent des articles de commodité achetés et déployés par dizaines, voire par milliers, vous ne les traitez pas instinctivement comme des ordinateurs.

La plupart d'entre nous, par exemple, savent que nous devons créer des mots de passe complexes et uniques pour nos ordinateurs portables et nos routeurs WiFi.

Mais votre réfrigérateur ? Il suffit de le brancher et tout ira bien !

Le problème est que de nombreux dispositifs IoT - comme les réfrigérateurs "intelligents" - ont leurs propres systèmes d'exploitation intégrés et, généralement, leurs propres interfaces réseau.

Il y a de fortes chances que quiconque conduisant dans votre rue résidentielle tranquille puisse scanner les réseaux disponibles et identifier rapidement la marque de l'appareil IoT que vous utilisez. Ils peuvent ensuite supposer que vous n'avez pas changé les informations d'authentification par défaut de l'usine et se connecter à votre réseau privé.

Ce qui rend les choses bien pires, c'est que de nombreux fabricants d'appareils expédient encore leurs produits avec des informations d'authentification utilisant une variation de admin/admin.

C'est un gros problème.

### Tirer parti des identités fédérées

Toutes ces discussions sur les dangers présentés par l'authentification et les identifiants devraient vous rendre curieux de savoir comment ils peuvent être utilisés pour générer de bonnes choses en matière de connectivité.

En un seul mot, ce serait la _fédération_.

La fédération d'identité est une technologie permettant de lier l'identité d'une seule personne à travers plusieurs services réseau. La fédération est ce qui vous permet de vous connecter à des sites de jeux en ligne ou d'applications web en utilisant, par exemple, vos identifiants de compte Google.

L'avantage de la fédération est qu'une seule connexion peut être tout ce dont vous aurez besoin lorsque vous passerez d'un service en ligne à l'autre parmi ceux que vous utilisez régulièrement. Cela vous permet de réduire le risque d'exposer votre mot de passe via un site web vulnérable.

Bien sûr, cela augmente également les dommages qui peuvent résulter d'une violation grave des données des serveurs utilisés par votre fournisseur de fédération.

La fédération peut être utilisée pour s'intégrer à des systèmes d'authentification unique (SSO) tiers, comme Kerberos, le protocole Lightweight Directory Access Protocol (LDAP) et Microsoft Active Directory (AD). Lorsque ces systèmes sont utilisés avec des services cloud, ils peuvent permettre un accès automatisé et ponctuel aux ressources de compte privé pour les consommateurs ou les processus.

Outre la commodité, toute cette bonté d'authentification favorise les opportunités de collaboration à distance sécurisée sur des projets vastes et complexes - une tendance en pleine croissance.

## Chapitre 5 : Comprendre le business de la recherche technologique

Faire parvenir une nouvelle technologie aux consommateurs nécessitera généralement de bonnes personnes et des ressources considérables - y compris de l'argent. Généralement, beaucoup d'argent.

Une grande partie de cet argent sera dépensée en recherche et, plus souvent qu'autrement, la recherche difficile nécessaire pour traduire une grande idée en un produit utilisable sera effectuée par quelqu'un dont le titre de poste n'est pas "entrepreneur".

En fait, parfois la recherche sera effectuée par des individus qui sont à peine conscients que leurs innovations ont une quelconque valeur commerciale.

Si vous êtes ici parce que vous voulez prendre de l'avance sur les technologies de pointe, alors vous pourriez vouloir garder un œil sur les organisations connues pour produire des recherches pratiques. Savoir qui est important dans la recherche, qui la finance et où les gros sous sont dépensés peut vous donner des informations utiles sur ce qui pourrait arriver ensuite.

De là, vous n'êtes qu'à un pas de, par exemple, passer du temps à apprendre les outils qui accompagneront la nouvelle technologie ou de vous positionner pour en profiter lorsqu'elle apparaîtra enfin.

### Qui finance la science commerciale et pourquoi ?

Il fut un temps où les grandes avancées dans la recherche scientifique sérieuse étaient les produits de mécénats privés. La famille italienne des Médicis, par exemple, a soutenu de nombreuses personnes dont le travail s'est avéré crucial, y compris Léonard de Vinci et Galilée.

Cependant, les années précédant la Seconde Guerre mondiale ont vu la portée et la complexité des projets de recherche croître bien au-delà de la capacité du soutien privé. La dépendance de la guerre à une complexité technologique sans précédent - exemplifiée par le travail du Projet Manhattan pour construire la bombe atomique - a poussé de plus en plus de recherches sous la responsabilité du gouvernement.

L'implication du gouvernement dans la recherche s'est poursuivie dans les générations qui ont suivi la guerre. Pourtant, il a été estimé que les universités et les gouvernements ne sont responsables que de 30 % du financement de la recherche, la majeure partie du reste étant fournie par l'industrie privée (voir [en.wikipedia.org/wiki/Funding_of_science](https://en.wikipedia.org/wiki/Funding_of_science)).

Voyons comment cela se décompose.

#### Contribuables

Les gouvernements démocratiques, bien sûr, ne dépensent pas leur propre argent, dont ils n'ont traditionnellement aucun.

Leurs nombreux programmes et services sont financés par des revenus prélevés, d'une manière ou d'une autre, sur leurs actifs en capital et sur leurs populations. Dans les États-nations modernes, "populations" signifierait ces individus et entreprises qui paient des impôts.

La recherche et le développement publics peuvent être réalisés au sein des agences gouvernementales. Selon les termes de certains mandats d'agences, les résultats de la recherche doivent immédiatement entrer dans le domaine public.

Mais même ceux qui conservent les droits sur leur recherche orienteront souvent leur travail vers des entreprises et des institutions qui peuvent l'utiliser de manière productive.

La National Science Foundation (NSF) des États-Unis, par exemple, utilise son budget annuel de 8 milliards de dollars pour financer "environ 25 pour cent de toutes les recherches fondamentales soutenues par le gouvernement fédéral menées par les collèges et universités américains" ([https://www.nsf.gov/about/](https://www.nsf.gov/about/)).

D'autres agences américaines effectuent la majeure partie ou la totalité de leurs recherches en interne. Voici quelques exemples :

* Le _National Institute of Standards and Technology (NIST)_ a pour mandat de "promouvoir l'innovation et la compétitivité industrielle".

Une partie très importante de cette mission est la maintenance de la National Vulnerability Database (NVD), qui joue un rôle fondamental dans la gestion des systèmes de détection et d'évaluation des vulnérabilités protégeant notre infrastructure informatique.
* L'Agence de projets de recherche avancée de la défense (DARPA) du ministère américain de la Défense collabore avec des partenaires des secteurs public et privé pour aider au développement des technologies émergentes.

Les travaux des dernières années ont inclus des recherches sur la robotique et les véhicules autonomes, mais vous pourriez être plus familier avec une innovation de la DARPA datant de quelques décennies : l'internet.
* Les National Institutes of Health (NIH) emploient 6 000 scientifiques dans 27 instituts et centres de recherche.

Leur "mission est de rechercher des connaissances fondamentales sur la nature et le comportement des systèmes vivants et l'application de ces connaissances pour améliorer la santé, prolonger la vie et réduire la maladie et le handicap".

La liste complète des agences de recherche du gouvernement américain (disponible sur [en.wikipedia.org/wiki/List_of_United_States_research_and_development_agencies](https://en.wikipedia.org/wiki/List_of_United_States_research_and_development_agencies)) fait une lecture assez intéressante. Jetez un coup d'œil par vous-même.

Naturellement, les gouvernements d'autres pays ont leurs propres agences de recherche. Un exemple est le Conseil national de recherches du Canada (CNRC), qui a évolué de ses origines technologiques militaires à travers les deux guerres mondiales, à son focus actuel sur les partenariats avec des entreprises technologiques des secteurs privé et public.

Le CNRC divise désormais son travail en quatre "lignes d'affaires" :

* Recherche et développement stratégique
* Services techniques
* Gestion de l'infrastructure scientifique et technologique
* Programme d'aide à la recherche industrielle du CNRC (PARI)

Comme nous l'avons mentionné en discutant de la NSF, une proportion significative des fonds des contribuables dirigés vers la recherche et le développement sont accordés aux collèges et universités publics et privés.

Mais, du point de vue des collèges, combien de financement de la R&D académique provient de sources gouvernementales ?

Un examen de 2016 des 20 collèges américains qui ont dépensé le plus en R&D a révélé qu'ils ont chacun dépensé entre 837 000 et 2,4 millions de dollars, et que entre environ 47-87 % de leurs dépenses totales provenaient de sources gouvernementales d'une sorte ou d'une autre (voir [bestcolleges.com/features/colleges-with-highest-research-and-development-expenditures/](https://www.bestcolleges.com/features/colleges-with-highest-research-and-development-expenditures/)).

En revanche, les entreprises n'ont fourni que entre 2 et 22 % de ce financement.

#### Financement caritatif privé

Alors que nous sommes sur le sujet de la recherche académique, nous ne devrions pas ignorer une troisième source de financement : les dotations privées.

Certaines - bien que pas toutes - dotations permanentes étaient ciblées par leurs donateurs sur des activités de recherche. Bien que le capital du fonds ne puisse pas être dépensé chaque année, le revenu que ce capital génère peut l'être.

L'université de Harvard, de manière célèbre - ou peut-être infâme - a une dotation totale supérieure à 40 milliards de dollars. Une partie de cela trouve sans doute son chemin vers la R&D.

Curieusement, selon cette étude de 2016, les dépenses totales de R&D de Harvard cette année-là - y compris les activités financées par les gouvernements (52,1 %), les entreprises (4,7 %) et les dotations - étaient juste un peu plus d'un million de dollars.

Bien sûr, les dons soutiennent également de nombreuses recherches en dehors des milieux académiques. La plupart des maladies graves ont des fondations caritatives associées qui existent pour collecter des fonds à la fois pour les soins aux victimes et la recherche médicale.

Et des milliers de organisations à but non lucratif enregistrées existent à travers le monde soutenant des causes non médicales, y compris de nombreuses impliquant des recherches liées à la technologie. La Fondation Bill & Melinda Gates est un exemple particulièrement bien connu.

#### Entreprises

Les entreprises orientées vers la technologie ont un intérêt marqué à mettre la main sur les innovations avant leurs concurrents. Pour améliorer leurs chances, beaucoup géreront leurs propres laboratoires de recherche en interne.

La Bell Telephone Company, par exemple - et ses successeurs, y compris American Telephone & Telegraph Company (AT&T) - a maintenu les laboratoires Bell actifs et extrêmement créatifs. Les laboratoires Bell, sous divers noms, ont été responsables de nombreuses innovations, y compris le transistor, les lasers et le système d'exploitation Unix.

Les technologues individuels dans certaines entreprises sont souvent des sources d'innovation. 3M, par exemple, a ce qu'ils appellent une "Culture 15 %", où les employés sont autorisés à utiliser le temps et l'espace de l'entreprise pour poursuivre des recherches basées sur leurs propres idées et intérêts.

Au fil des ans, le programme a généré des produits réussis pour l'entreprise, y compris leurs Post-it en papier collant. Dans un autre exemple, Percy Spencer, travaillant sur le radar pour le sous-traitant de la défense américaine Raytheon, a accidentellement découvert que les micro-ondes pouvaient cuire les aliments.

Il convient de noter que toutes les innovations d'entreprise ne sont pas vraiment maison. Beaucoup d'entre elles sont en fait financées indirectement par l'argent du gouvernement sous forme d'incitations fiscales ou de crédits.

Dans le cadre de tels programmes, les entreprises peuvent être autorisées à utiliser les dépenses liées à la recherche (y compris les dépenses de salaire) pour réduire les impôts sur le revenu qu'elles devraient autrement payer.

### Principaux domaines de la recherche technologique commerciale

Essayer de saisir toute l'ampleur du développement technologique à ce stade de l'histoire est une perte de temps impardonnable.

Il y a de l'innovation sérieuse qui se produit chaque minute de la journée, dans chaque fuseau horaire, à travers d'innombrables laboratoires, tours de bureaux, entrepôts, garages, sous-sols, chambres à coucher et, bien sûr, invisiblement dans l'esprit des personnes créatives.

Personne ne suit tout cela parce que ce n'est pas possible. Sans compter le fait que beaucoup de cette innovation se produit sous un épais voile de secret.

Mais il vaut probablement la peine d'offrir juste quelques exemples pour vous donner une idée de l'endroit où chercher.

#### Informatique quantique (et pourquoi nous devrions nous en soucier)

Un cousin à moi, titulaire d'un diplôme avancé en physique de l'Université de Cambridge, a un jour essayé de m'expliquer la mécanique quantique.

Il a échoué. Misérablement.

Mon pauvre vieux cerveau ne pouvait tout simplement pas l'absorber. Donc, ne vous attendez pas à des descriptions complètes et mesurées de la science sous-jacente ici. Au lieu de cela, j'essaierai de vous montrer comment les technologies de _calcul_ expérimentales qui dépendent de la physique pourraient fonctionner, et ce que l'on peut faire avec elles.

La version ultra-rapide du résumé exécutif de ceci est que les ordinateurs alimentés par une technologie quantique ou une autre fonctionneront _beaucoup_ plus rapidement que n'importe lequel des super-ordinateurs les plus performants que nous avons actuellement. Tellement plus rapidement, en fait, qu'ils pourraient être capables de résoudre des problèmes qui seraient simplement irréalisables en utilisant des ordinateurs traditionnels (une réalisation connue sous le nom de _suprématie quantique_).

Cela signifierait que certaines hypothèses de longue date sur le fonctionnement des logiciels ne s'appliqueraient plus.

Par exemple, la raison pour laquelle nous utilisons les outils de chiffrement que nous utilisons aujourd'hui pour protéger les données sensibles est qu'il faudrait des centaines, voire des milliers, d'heures de temps de calcul haute performance pour casser une clé de chiffrement.

Dans la plupart des cas, cela ne vaut tout simplement pas l'effort et les dépenses.

Mais si vous pouviez facilement acheter du temps sur un ordinateur qui traite les opérations de manière exponentiellement plus rapide, alors deux choses se produiraient immédiatement :

* Le craquage des algorithmes de chiffrement deviendrait trivial
* Les gens honnêtes devraient sérieusement chercher un nouveau moyen de protéger leurs données

Actuellement, Google et IBM sont parmi les principales entreprises qui ont investi massivement dans des projets de recherche en calcul quantique.

Autant que je puisse le comprendre, les ordinateurs quantiques mesureraient l'état des particules subatomiques et utiliseraient cette mesure binaire pour représenter une valeur de calcul.

La description de cet état est connue sous le nom de _qubit_, qui est effectivement l'équivalent quantique du _bit_ de l'informatique traditionnelle.

Mais parce qu'un qubit peut également exister dans ce qu'on appelle la _superposition cohérente_ - ce qui signifie que sa valeur peut exister dans une _superposition_ de deux états possibles - il peut être utilisé pour représenter une gamme plus complexe de valeurs.

Et _cela_, je suis porté à croire, signifie que de tels ordinateurs seront capables de faire des choses beaucoup, beaucoup plus rapidement qu'ils ne le peuvent maintenant. Si cela se produit réellement, ce sera énorme.

#### Technologies énergétiques

Le monde moderne consomme une quantité énorme d'énergie.

Nous nous déplaçons constamment, contrôlons nos conditions climatiques intérieures (et en transit), échangeons des informations et attendons que toutes les richesses du monde soient livrées à notre porte. D'ici demain.

Mais ces activités gourmandes en énergie ont un coût, et non des moindres, les émissions qu'elles laissent derrière elles. La recherche de sources d'énergie fiables, stables et abordables qui peuvent nous aider à trouver un équilibre sain entre consommation et émissions est en cours ; et incroyablement coûteuse.

Les petits réacteurs nucléaires modulaires (SMR) ont été au centre de certains développements sérieux ces dernières années. Ils semblent promettre une énergie fiable, stable et abordable de manière que leurs prédécesseurs nucléaires coûteux et complexes ne pouvaient pas.

Les réacteurs de première et deuxième génération étaient, dans l'ensemble, fiables et stables - et ils étaient propres - mais leurs coûts en capital massifs et leurs grandes empreintes physiques les rendaient plus qu'un peu inflexibles.

L'idée derrière les SMR est que des réacteurs hautement efficaces peuvent être fabriqués hors site et livrés sur des camions, un module à la fois, pour un assemblage sur site. Cela rend la génération de puissance par mégawatt beaucoup moins chère et l'achèvement du projet beaucoup plus rapide. Et cela permet le déploiement de l'énergie nucléaire pour desservir des marchés plus petits qui ne pouvaient pas auparavant la considérer comme une option réaliste.

Comme le nom l'indique, les SMR sont plus petits que les réacteurs traditionnels. Ils sont conçus pour fournir entre 50 et 300 MW d'électricité chacun, contre les 800 à 1 200 MW de production qui étaient auparavant courants.

Les entreprises fortement impliquées dans cette recherche incluent Rolls-Royce de Grande-Bretagne et une entreprise américaine ayant des liens historiques avec le département américain de l'Énergie appelée NuScale Power.

Divers gouvernements à travers le monde ont également investi dans cette technologie d'une manière ou d'une autre.

#### Recherche en technologie médicale

Si vous pensez que nous dépensons beaucoup d'argent pour l'énergie, attendez de voir combien coûtent les soins de santé.

Dans les 37 pays de l'Organisation de coopération et de développement économiques (OCDE), les dépenses de l'industrie de la santé représentent environ 10 % du produit intérieur brut total. Cela représente plus de 3 000 dollars par an pour chaque homme, femme et enfant.

D'une part, avec tout cet argent qui circule, il y a sans aucun doute de nombreuses opportunités commerciales à découvrir. Mais il y a aussi beaucoup de place pour de nouvelles technologies innovantes qui peuvent améliorer la prestation des soins de santé tout en réduisant les coûts.

La télémédecine et la téléchirurgie sont deux excellents candidats.

La télémédecine implique la fourniture de services de santé (comme les consultations médecin-patient) par le biais d'un moyen de télécommunication. Cela pourrait signifier avoir une simple conversation téléphonique plutôt qu'une visite au cabinet, mais cela pourrait également incorporer des outils de visioconférence ou même l'utilisation d'équipements de diagnostic à distance.

Par exemple, de petites communautés éloignées pourraient maintenir des installations d'imagerie et des techniciens même à des centaines de kilomètres des laboratoires médicaux et des spécialistes en radiologie les plus proches.

Les connexions numériques peuvent permettre aux médecins éloignés de visualiser, par exemple, les résultats d'une échographie, de parler directement avec les patients et de poser des diagnostics en toute confiance. Et tout cela sans que personne n'ait à entreprendre des voyages épuisants et coûteux.

La télémédecine permet également un contact significatif entre le médecin et le patient sans le risque de propagation de maladies.

La téléchirurgie est une extension de la télémédecine qui peut permettre certaines procédures chirurgicales, même lorsque les médecins sont à des kilomètres de leurs patients. La technologie utilise des flux vidéo haute définition et des bras robotisés conçus à cet effet qui peuvent être contrôlés à distance par les médecins.

Les outils de téléchirurgie ont le potentiel d'économiser de l'argent pour les systèmes de santé en difficulté financière, mais plus important encore, ils peuvent améliorer les soins de santé et sauver des vies.

## Chapitre 6 : Où les tendances chaudes vont mourir

Vous lisez ce livre, donc je suppose que vous avez un intérêt actif à apprendre sur les tendances technologiques chaudes. Mais vous ne voulez pas prendre toutes ces gadgets et modes commerciales trop au sérieux : certaines sont destinées à décevoir.

(Bien que vous ne devriez pas penser que vous pouvez me tenir personnellement responsable de mes prédictions : au moment où ce livre sera publié, je m'attends à vivre sur une île tropicale ensoleillée sous le programme de protection des témoins.)

Pour avoir une idée de la fragilité du secteur de l'innovation, gardez à l'esprit la sagesse populaire qui nous enseigne comment neuf startups sur dix échoueront.

Maintenant, multipliez cela par la nature particulièrement spéculative de l'industrie technologique en particulier, et vous apprécierez à quel point les choses peuvent souvent mal tourner de manière spectaculaire.

Cela ne signifie pas que les personnes qui ont imaginé toutes les entreprises condamnées que nous allons bientôt discuter étaient des imbéciles ou des fraudeurs. Il est facile pour nous, profitant des avantages de la rétrospective historique, de juger leurs efforts.

Nous devrions être sensibles à la manière dont les choses devaient paraître dans le feu de l'action. Néanmoins, en gardant cela à l'esprit, il y a de la valeur à tirer de la tentative de comprendre au moins ce qui a mal tourné.

Voici donc quelques exemples particulièrement impressionnants du cimetière de l'histoire technologique. Il peut être très amusant de revivre certaines des plus grandes catastrophes commerciales de l'histoire, mais il y a aussi des leçons importantes que nous pouvons appliquer lors de l'évaluation de la récolte de cette année de dispositifs "à succès garanti".

### La recherche de marché bat la pensée souhaitable à chaque fois

Je ne suis pas sûr qu'il soit possible de compter de manière fiable toutes les personnes et entreprises qui nous ont assuré que nous avions enfin atteint l'ère de contourner les autoroutes encombrées en utilisant des voitures volantes tout en discutant joyeusement avec nos proches par des appels vidéo.

Il y a eu des prototypes hybrides à roues/ailes peu après la Seconde Guerre mondiale, et des téléphones pour montrer au monde à quoi vous ressemblez en pyjama, en théorie au moins, disponibles depuis le début des années 1970.

Eh bien, les appels vidéo sont maintenant facilement disponibles via n'importe quel smartphone ou PC. Et, 75 ans d'échec plus tard, la ruée pour livrer des vols de consommateurs n'a pas ralenti d'un iota.

Mais les deux technologies sont surtout remarquables pour être si rarement utilisées : les voitures volantes parce qu'aucune n'a jamais atteint la production complète, et les téléphones vidéo parce que très peu de gens semblent intéressés.

Quel a été le problème ? Il y a eu certainement des hoquets d'ingénierie, de sécurité et de réglementation au fil des ans. Et il ne fait aucun doute que les fabricants de voitures volantes auraient du mal à trouver une grande base de clients de conducteurs qui étaient également des pilotes qualifiés (bien que les versions auto-conductrices/volantes pourraient, en théorie, éviter ce problème).

Mais je soupçonne qu'une grande partie du problème était le marketing : personne n'a pris la peine de demander à Joe Q. Client ce qu'il en pensait.

### Mais le marketing n'est pas tout

Au début, il y avait des commentaires d'initiés de la technologie sur la façon dont un nouveau dispositif serait la plus grande chose depuis, eh bien, toujours. Ensuite, un livre non autorisé a fuité des informations intrigantes, des affirmations publiques ambitieuses, et un lancement de produit.

À la fin, il y avait le Segway : un dispositif de transport personnel qui était trop grand et rapide pour les trottoirs, trop grand et lent pour les routes, et trop cher pour la plupart des clients. Et l'utiliser sous la pluie ou la neige n'était pas très amusant.

Aujourd'hui, vous devriez probablement chercher très fort pour trouver un Segway vivant et respirant près de votre quartier. Ils sont parfois utilisés pour les patrouilles de rue de la police et les visites touristiques, mais ils n'ont pas éliminé la voiture ou révolutionné le développement urbain.

Ni, autant que je sache, n'ont-ils rendu les investisseurs de l'entreprise fantastiquement riches. En fait, l'usine de fabrication de l'entreprise à Bedford, New Hampshire, a cessé ses activités à l'été 2020.

Qu'est-ce qui a mal tourné ?

Eh bien, peut-être que le battage médiatique était un peu excessif. D'accord, disons que c'était bien trop excessif. Ce n'est jamais une bonne chose de gonfler les attentes au point qu'elles ne peuvent pas être satisfaites.

Il y a eu aussi l'échec de faire correspondre l'outil à un environnement approprié. Où, après tout, était-il censé être utilisé ?

Mais, pour être vraiment réussi, un nouveau produit doit être construit sur plus qu'un ingénierie astucieuse. Il doit aussi résoudre un problème réel et urgent.

### Quand trop de puissance n'est pas une bonne chose

En 2013, Google a introduit un nouveau produit de calcul pour les consommateurs qu'ils ont appelé _Glass_. Il s'agissait d'un casque élégant qui pouvait être porté comme un accessoire sur une paire de lunettes de prescription de créateur.

Une fois allumé, Glass pouvait accepter des commandes vocales et tactiles pour enregistrer une vidéo de tout ce que le porteur voit, et afficher des données - souvent avec une pleine "conscience" de la localisation physique actuelle du porteur.

Glass était un seul appareil destiné à remplacer une grande partie de la fonction actuellement servie par les smartphones, les ordinateurs portables et les lecteurs multimédias.

Pour la tâche d'intégrer notre monde physique avec les données sans fin qui le décrivent, cela allait être parfait. Et puis ce ne l'était plus.

À mesure que plus de détails sur Glass devenaient connus, des questions étaient soulevées dans le monde technologique plus large. Était-il approprié - ou même légal - d'enregistrer silencieusement des vidéos d'autres personnes ? Le logiciel de reconnaissance faciale devait-il être appliqué à des piétons aléatoires passant sur le trottoir sans leur consentement ? Était-il sûr de conduire en portant Glass ?

Les clients potentiels avaient leurs propres questions. Le produit est-il abordable (ils commençaient à 1 500 $) ? Est-il nécessaire ? Correspond-il à la vision que j'ai de mon image publique ?

Plus ces questions flottaient sur l'internet, plus les réponses revenaient. Des réponses, dans l'ensemble, consistant en un seul mot : "Non."

Google Glass, en tant que produit grand public, a lentement disparu et a finalement disparu complètement. La massive campagne de promotion médiatique était restée vide.

Ce qui ne signifie pas que le produit lui-même a complètement échoué.

Il s'avère que Glass a trouvé un succès considérable dans les environnements médicaux où, par exemple, il pourrait être utilisé pour permettre des expériences chirurgicales à distance. Il a également trouvé une place dans les milieux industriels, où les travailleurs de première ligne ont souvent besoin d'un accès instantané et sans les mains aux schémas et directions pertinents.

Mais il s'est écoulé un long moment avant que toute cette bonté ne se produise.

Peut-être que quelqu'un aurait dû ralentir les choses à un moment donné, en disant : Même si c'est _possible_ d'intégrer toutes ces fonctionnalités dans un produit grand public, est-ce nécessairement une bonne idée ?

### Quand mille pièces ne tombent pas toutes là où elles devraient

Parfois, mesurer le succès et l'échec n'est pas si facile. Prenez WebTV comme exemple.

Qui ne possède pas de télévision ? (À part moi, je veux dire.) Ne serait-il pas logique de créer un produit peu coûteux et facile à utiliser qui exploite des milliards de téléviseurs domestiques existants pour des usages non standard mais populaires ? Que diriez-vous d'un appareil qui peut transformer la télévision que vous possédez déjà en un navigateur web et un portail de messagerie ?

Si cela ne semble pas si excitant aujourd'hui, à la moitié des années 90, l'idée derrière WebTV avait ses charmes certains.

Imaginez simplement les flux de revenus secondaires que cela pourrait générer. Les annonceurs ne se bousculeraient-ils pas pour payer gros pour que leurs produits soient présentés à tous ces téléviseurs ?

Si WebTV avait réussi à livrer sur l'angle "facile à utiliser", les choses auraient pu se passer différemment.

Mais il s'est avéré que la démographie principale pour l'appareil était fortement orientée vers les personnes âgées ; qui avaient besoin de beaucoup de (coûteux) soutien client pour les guider à travers le processus de configuration.

Leur incapacité à suivre les normes de navigation internet en constante évolution a également rendu difficile la fourniture d'une expérience de navigation constamment optimale - surtout pour les utilisateurs assis à trois mètres de l'écran sur leurs canapés.

Comment les choses se sont-elles réellement passées ?

D'une part, dans les deux ans suivant leur lancement, l'entreprise a été rachetée par Microsoft pour plus de 400 millions de dollars, qui a renommé le service "MSN TV". Sous une forme ou une autre, ils sont restés jusqu'à bien après la mort de l'accès internet par ligne commutée. Donc, c'est une bonne chose.

Mais, on peut dire qu'ils n'ont pas capté autant d'intérêt et d'adoption qu'ils auraient pu.

Le vrai prix était de devenir un portail dominant pour l'accès internet. Parce que la plateforme était propriétaire, l'entreprise aurait pu effectivement contrôler toute l'expérience internet de centaines de millions d'utilisateurs.

La portée potentielle du produit aurait éclipsé les modestes revenus qu'ils ont réellement réalisés. Donc, ce n'est pas une bonne chose.

Étaient-ils trop en avance sur leur temps ? Ont-ils mal calculé en insistant sur une plateforme fermée et propriétaire ? N'ont-ils pas vu la croissance monstrueuse de l'industrie des ordinateurs personnels (PC) autonomes venir ?

Dans tous les cas, ce n'était pas exactement une fin de conte de fées.

### Quand le timing n'est pas votre truc

L'industrie technologique évolue rapidement. Je suis sûr que cette petite pépite de sagesse ne laissera aucun d'entre vous enveloppé dans un silence stupéfait.

Mais lorsque vous pensez à la quantité de travail nécessaire avant de pouvoir transformer une idée fraîche et nouvelle en un produit prêt à être expédié, il est remarquable que quelque chose d'innovant parvienne à décoller.

Un mauvais timing est donc un risque encouru par les personnes derrière presque toute nouvelle technologie alors qu'elle se fraye un chemin vers le marché.

À titre d'exemple, l'existence d'une forte concurrence de la part d'entreprises comme Nintendo et la PlayStation de Sony était probablement largement responsable de la mort prématurée de la console de jeu Bandai Pippin d'Apple au milieu des années quatre-vingt-dix.

Bien que le fait qu'il n'y ait jamais eu plus de 25 titres de jeux qui fonctionnaient sur l'appareil, et que, comme tous les produits Apple, il était vendu beaucoup plus cher que la concurrence, n'a pas dû aider.

Tout n'était pas sombre et menaçant pour Apple à cette époque.

En regardant en arrière avec ce que nous savons maintenant, la forte présence de leur plateforme de lecteur de musique numérique iPod était probablement ce qui a condamné le Zune de Microsoft.

Avec le Zune, Microsoft a eu la malchance (ou le manque de prévoyance) de se retrouver coincé entre un appareil iPod rendu dominant par sa simplicité, et l'âge imminent du smartphone (où les lecteurs de musique portables autonomes deviennent obsolètes).

Clairement, comme Shakespeare l'aurait dit, "la maturité est tout".

Mais il y a une autre chose à propos du timing : finalement, vous devrez livrer la marchandise.

Il y a une limite à la durée pendant laquelle les consommateurs attendront cette nouvelle technologie brillante qui figure sur la liste des "must-have" de tout le monde depuis trop longtemps sans faire une apparition réelle dans le monde réel. Méfiez-vous des promesses vides.

Vous devriez également garder un œil critique sur les bonnes vieilles pratiques commerciales - celles qui ne semblent jamais se démoder : des plans d'affaires irréalistes ; une méconnaissance des fondamentaux sous-jacents d'une entreprise ; et des coûts de démarrage déraisonnables et avides.

De plus, la catastrophe qui a caractérisé le boom des dot-com et le krach subséquent autour du début du 21e siècle me vient à l'esprit. Le paradigme de prendre n'importe quel modèle d'entreprise et de lui construire un site web semblait bon, mais il a été appliqué beaucoup trop largement et a souvent ignoré le contexte évident dans le processus.

Ne faites pas aveuglément confiance aux tendances populaires et aux phrases à la mode.

Jusqu'à présent, nous avons couvert certains sujets technologiques "à grande échelle" comme la confidentialité et la connectivité, en suivant leurs tentacules sinueux là où ils nous mèneraient.

Dans les prochains chapitres, nous allons nous concentrer sur six grandes catégories, une catégorie par chapitre, chacune avec une poignée de technologies spécifiques.

Ces technologies ont des noms que vous avez probablement rencontrés et qui, pour la plupart, jouent déjà des rôles économiques importants. Parfois, leur signification et leur impact peuvent être exagérés, mais elles sont toutes authentiques.

## Chapitre 7 : Plateformes de calcul

La façon dont les choses se présentent maintenant, si vous étiez d'une manière ou d'une autre allergique aux ordinateurs, vous seriez bien en peine de vraiment les bannir de votre vie, où que vous vous trouviez.

Faire une promenade tranquille dans les bois ? Et ce smartphone dans votre poche ?

Avez-vous laissé votre téléphone dans la voiture ? Voyez-vous ce pylône de téléphone portable juste derrière ces arbres ?

Les chances sont bonnes que la tour soit plus qu'une simple antenne - elle pourrait également héberger un serveur de calcul en périphérie.

Et ne pensez pas qu'il n'y avait pas d'ordinateurs intégrés dans les mécanismes sous le capot de la voiture (ou du bus) qui vous a conduit ici.

Mis à part les allergies, si vous voulez pleinement comprendre l'état actuel du monde du calcul, il sera utile de comprendre tous les endroits où les ordinateurs peuvent apparaître et à quoi ils pourraient ressembler.

Dans ce chapitre, nous énumérerons les classes dans lesquelles les appareils de calcul modernes peuvent être classés, et nous décrirons leurs forces, leurs faiblesses et leur potentiel.

### Qu'est-ce qu'un serveur ?

Honêtement, j'avais travaillé comme administrateur système professionnel depuis un certain temps avant de pouvoir répondre correctement à cette question.

La vérité est que chaque serveur est un ordinateur, et tout ordinateur peut être un serveur. Le terme _serveur_ implique simplement que l'appareil fournit un _service_ à au moins un appareil externe (appelé _client_).

Si l'imprimante branchée sur votre ordinateur de bureau peut être partagée par les autres ordinateurs de votre réseau local, alors votre ordinateur de bureau est un serveur (un _serveur d'impression_, pour être précis).

Le routeur WiFi fourni par votre fournisseur d'accès Internet est, par toutes les définitions, un _serveur réseau_ - car il _fournit_ un accès réseau à ses clients.

Et le minuscule appareil Raspberry Pi Zero à carte unique (figure 7.1) qui alimente votre caméra de surveillance maison est un _serveur vidéo_ - bien que cela ne fonctionnera pas sans attacher un module de caméra de 7 $.

![Figure 7.1 : Un ordinateur à carte unique Raspberry Pi Zero.](https://www.freecodecamp.org/news/content/images/2022/05/figure7-1.jpg)
_Figure 7.1_

Mais ce n'est pas ce que la plupart des gens ont en tête lorsqu'ils utilisent le terme.

La première fois que je suis entré dans la salle des serveurs d'une entreprise de taille moyenne, j'ai été frappé par le son de dizaines de ventilateurs de châssis puissants et la chaleur des CPU travaillant dur et des disques durs tournant rapidement.

Instantanément, j'ai su comment les gens utilisent normalement le mot.

(Aussi, j'ai rapidement découvert que la chaleur était un énorme problème : les administrateurs luttaient pour garder leur salle des serveurs correctement refroidie et finiraient, avec le temps, par devoir amortir du matériel coûteux en raison de pannes liées à la chaleur.)

Donc, par "serveur", nous entendons généralement des ordinateurs installés dans ces boîtiers empilables montés en rack, conçus pour loger et protéger efficacement des composants très performants, coûteux et délicats.

Les racks de serveurs vivront normalement dans des salles bien ventilées et refroidies avec un accès facile à une alimentation électrique abondante. Vous devrez peut-être les chercher, mais de telles salles contiendront toujours des faisceaux colorés de câbles, reliant les serveurs aux réseaux.

En règle générale, les serveurs n'auront généralement pas d'écrans ni même de claviers branchés, car ils sont susceptibles d'être gérés à distance ou, encore plus probablement, entièrement automatisés et ne nécessitant aucune administration.

Les fermes de serveurs appartenant à de grands fournisseurs de cloud comme Amazon Web Services auront des milliers d'ordinateurs de commodité fonctionnant dans des allées après des allées de vastes entrepôts.

Lorsque l'un tombe en panne, un panneau de surveillance quelque part s'allume et un technicien est finalement envoyé pour retirer le serveur, le jeter et glisser un remplacement dans le rack nouvellement disponible.

Aucune larme n'est versée lorsque nous disons au revoir au matériel travailleur et dévoué dans ces endroits.

### Qu'est-ce que Linux ?

En parlant de serveurs, ai-je mentionné qu'ils ont tous besoin d'un système d'exploitation installé ? Et ai-je mentionné en outre que la grande majorité des serveurs alimentant la grande majorité des opérations qui rendent l'internet et toutes ses fonctionnalités possibles fonctionnent sous le système d'exploitation Linux ? Oh, et saviez-vous que le système d'exploitation open source Linux est disponible gratuitement ?

Je n'ai pas mentionné tout cela ? Mon erreur.

Eh bien, les serveurs ont besoin de systèmes d'exploitation. La plupart des serveurs (bien plus de 90 pour cent des instances de machines virtuelles fonctionnant sur Amazon AWS EC2, par exemple) fonctionnent sous Linux. Et Linux est, en effet, librement disponible pour toute utilisation sur tout serveur, ordinateur portable, bureau, routeur, système embarqué ou supercalculateur.

En fait, chacun des 100 premiers supercalculateurs du monde utilise Linux. Et le système d'exploitation Android pour smartphones ? Oui. C'est aussi Linux.

Strictement parlant, "Linux" est le noyau logiciel qui permet à un utilisateur d'ordinateur de prendre le contrôle des éléments matériels physiques d'un ordinateur. Le noyau traduit vos frappes en un format qui sera compris par les pilotes contrôlant vos disques de stockage, votre mémoire, vos interfaces réseau, vos écrans et - en fait - votre clavier et votre souris.

Des milliers de programmes logiciels supplémentaires sont étroitement associés à Linux, mais ils font en réalité partie de l'espace utilisateur qui "survole" le noyau Linux.

Cela dit, Linux, y compris son écosystème logiciel plus large, domine le marché du calcul serveur en ce moment. Le fait que vous puissiez installer et lancer gratuitement autant d'instances physiques ou virtuelles que vous le souhaitez rend Linux très attractif, surtout dans le monde de l'orchestration des charges de travail scriptées.

Les instances Linux virtualisées seront souvent mises en vie et, après avoir accompli une tâche qui prend même quelques secondes, éteintes à nouveau.

La polyvalence et la flexibilité que Linux apporte à l'informatique ont été l'étincelle de certaines innovations et créativités profondément impressionnantes.

Une partie de la polyvalence de Linux est le fait que vous pouvez choisir parmi des centaines de variations (connues sous le nom de _distributions_).

Cherchez-vous à exécuter des serveurs supportés par une entreprise ? Des appareils de l'Internet des objets (IoT) ? Des machines de test de sécurité ? De la gestion multimédia ? De la production vidéo ou audio ? Tout ce qui précède ? Aucun de ce qui précède ? Il y a certainement une distribution qui vous correspond bien.

Et si les spécifications exactes dont vous avez besoin ne peuvent pas être trouvées, n'hésitez pas à réécrire le noyau lui-même et à créer votre propre distribution.

Divulgation complète : Je connais une ou deux choses sur Linux, étant l'auteur de Linux in Action (Manning), un coauteur de Ubuntu Bible (Wiley), et l'auteur du parcours d'apprentissage Linux Fundamentals chez Pluralsight.

Divulgation encore plus complète : J'écris ceci sur une station de travail Ubuntu Linux à la maison, où tous nos nombreux appareils sont alimentés par Linux depuis plus d'une décennie.

### Qu'est-ce que la virtualisation ?

Nous avons déjà discuté de la virtualisation en profondeur dans le cadre du Chapitre 3 (Comprendre le Cloud), donc nous ne couvrirons ici que quelques bases conceptuelles générales.

Dans le temps, vous aviez une idée pour un nouveau projet informatique et vous soumettiez une proposition à vos gestionnaires en demandant de l'argent.

Lorsque le projet était approuvé, vous estimiez vos besoins, sollicitiez des offres de fournisseurs de matériel, commandiez un nouveau serveur et, lorsqu'il arrivait enfin, vous le chargiez avec votre logiciel d'application, vous le lanciez et laissiez le monde voir ce que vous aviez fait.

C'est ainsi que les choses fonctionnaient généralement : Un projet. Un serveur. Beaucoup de temps d'attente.

Mais que se passe-t-il si vous surestimiez vos besoins en calcul de 50 pour cent ? Cela représenterait quelques milliers de dollars perdus. Et si un projet important mais léger n'avait pas vraiment besoin d'un serveur autonome complet, vous deviez souvent l'acheter quand même.

Et si le projet ne devait fonctionner que quelques mois ? Dépensez l'argent et espérez trouver une nouvelle utilisation pour la chose une fois votre projet initial terminé.

Gênant. Des montagnes de gêne.

La virtualisation est un (principalement) tour de magie logiciel qui vous permet de tromper plusieurs systèmes d'exploitation installés en leur faisant croire qu'ils sont seuls sur un ordinateur physique alors qu'ils le partagent en réalité avec d'autres systèmes d'exploitation.

Vous pouvez provisionner et exécuter un seul hôte de virtualisation d'un type ou d'un autre et le remplir avec un ou cent serveurs virtuels.

L'un de ces serveurs pourrait avoir besoin de beaucoup de mémoire système mais seulement d'un Go ou deux d'espace de stockage. Un autre pourrait être lourd en tâches de conversion vidéo et de stockage mais n'est nécessaire que pendant une demi-heure par jour. Un troisième pourrait être un système de surveillance 24/7 qui a juste besoin d'un endroit tranquille pour faire son travail sans que personne ne le dérange.

Tant que vous ne poussez pas l'hôte physique au-delà de ses limites de ressources globales, les machines virtuelles peuvent toutes coexister heureusement ensemble. Et lorsqu'un service n'est plus nécessaire, vous pouvez réaffecter ses ressources libérées à autre chose.

Les montées et descentes en puissance du cycle de vie d'un serveur virtuel typique sont rapides. Pour toutes les intentions et tous les buts, ils se lanceront et s'éteindront généralement instantanément.

Cela est possible parce que le matériel sous-jacent est toujours en cours d'exécution - et parce que l'image du système d'exploitation est petite et, généralement, optimisée pour les environnements virtuels.

Comme nous l'avons vu dans le Chapitre 3, les services hébergés dans le cloud sont tous virtualisés. À mesure que de plus en plus d'infrastructures informatiques passent au cloud, de plus en plus de vos activités en ligne seront alimentées par des machines virtuelles. Vous ne remarquerez pas la différence, mais chaque fois que vous recherchez sur l'internet ou vous authentifiez sur un compte en ligne, il y a de fortes chances que ce soit un conteneur ou une machine virtuelle à laquelle vous vous connectez, et non directement à une machine physique.

### Où allez-vous pour obtenir un peu de ce cloud ?

Comme la virtualisation, nous avons également parlé du cloud dans le chapitre 3 - ce qui aurait du sens, étant donné que le chapitre s'appelait "Comprendre le Cloud".

Nous avons mentionné comment le marché du cloud public était dominé par AWS et, dans une moindre mesure, par Microsoft Azure.

Je vais juste prendre une minute ou deux ici pour ajouter un guide rapide à travers certains des pires jargons de l'industrie du cloud.

Les environnements **Infrastructure en tant que Service (IaaS)** vous donnent un accès complet aux instances de serveurs virtuels. Le fournisseur s'assurera que les éléments matériels, réseau et de sécurité sous-jacents sont en place et fonctionnent, tandis qu'il est de votre responsabilité de gérer le système d'exploitation et les autres logiciels s'exécutant sur votre instance.

Les principaux acteurs de l'IaaS incluent Amazon Elastic Compute Cloud (EC2) et Azure Compute.

Les environnements **Plateforme en tant que Service (PaaS)** masquent la plupart ou la totalité des tâches d'administration de l'infrastructure, vous laissant avec une interface où vous pouvez exécuter vos propres données ou code.

Un bon exemple est AWS Elastic Beanstalk, qui vous permet de télécharger votre code d'application à partir duquel il sera automatiquement déployé sur le cloud d'Amazon. D'autres fournisseurs dans ce domaine incluent Heroku et Salesforce Lightning Platform.

Les environnements **Logiciel en tant que Service (SaaS)** n'exposent qu'une interface utilisateur finale, gérant toutes les couches de l'infrastructure d'administration de manière invisible.

Microsoft Office 365 et Google G Suite sont des outils de productivité bureautique SaaS largement utilisés. Mais il existe un marché croissant d'outils SaaS offrant des équivalents logiciels en ligne pour de nombreuses applications qui, dans les années passées, ne pouvaient être utilisées que sur des postes de travail autonomes. Ces applications incluent la comptabilité, la conception assistée par ordinateur (CAO) et les solutions de conception graphique.

La **tarification basée sur la consommation** ou, comme on l'appelle parfois, la facturation à l'usage, est un pilier du concept de cloud. L'idée est que vous n'avez pas à parier en investissant à l'avance dans l'infrastructure, mais vous pouvez payer des montants incrémentiels pour des unités de services informatiques à mesure que vous les utilisez.

Cela ne sera peut-être pas toujours moins cher à long terme, mais le paiement à l'usage facilite grandement le test des piles d'applications et l'expérimentation de plusieurs configurations alternatives avant de se lancer dans un déploiement complet.

Cela signifie également que - en supposant que vous ne fassiez pas d'erreurs de configuration stupides - il est presque impossible de sur-provisionner gravement.

**À la demande** est également parfois appelé auto-service. La capacité de demander une livraison instantanée de ressources informatiques à tout moment de la journée/semaine/année vous donne un contrôle complet sur les cycles de vie des applications de votre organisation. Vous n'êtes jamais à la merci des horaires et des limitations des autres.

Les **Accords de niveau de service (SLA)** sont des déclarations légales publiées par les entreprises dans le domaine de la fourniture de services. Même si le niveau de fiabilité des ressources fourni par les principales plateformes de cloud public est généralement excellent, des accidents se produiront.

Lorsque vous payez des frais horaires ou mensuels pour les services cloud, le SLA de l'entreprise vous indique que vous devez anticiper un temps d'arrêt d'un certain nombre de minutes ou d'heures chaque mois.

Par exemple, l'Amazon SLA fixe son taux de disponibilité EC2 à 99,99 % chaque mois. Si, dans un mois particulier, vous rencontrez un temps d'arrêt plus important, vous pourriez être éligible à des crédits de service ou à des remboursements.

La **multilocation** est le placement d'instances virtuelles appartenant à plusieurs comptes clients de cloud sur une seule ressource matérielle.

Une configuration de multilocation pour une instance de serveur sera probablement significativement moins chère qu'une instance dédiée. Choisir une instance dédiée, cependant, garantirait que votre instance ne sera jamais hébergée sur un serveur physique aux côtés d'une instance d'un deuxième compte. Des considérations de sécurité ou réglementaires pourraient vous obliger à éviter la multilocation.

La **migration** décrit le processus impliqué dans le déplacement des charges de travail existantes des applications et bases de données commerciales des déploiements locaux (sur site) vers un fournisseur de cloud. Les fournisseurs mettent souvent à disposition des outils spécialisés et un support technique gratuit pour les migrations.

L'**élasticité** décrit les façons dont les ressources cloud virtualisées peuvent être rapidement ajoutées pour répondre à une demande croissante ou, tout aussi rapidement, réduites en réponse à une demande décroissante.

Les ressources élastiques sont particulièrement bien adaptées pour maintenir la disponibilité et la santé des applications sans encourir de coûts inutiles. L'élasticité peut généralement être automatisée, de sorte que les applications répondront instantanément aux environnements changeants sans nécessiter d'intervention manuelle.

### Qu'est-ce que le calcul "serverless" ?

Le calcul serverless n'est pas différent du calcul serveur. C'est juste que, même si vous plissez les yeux très fort, vous ne voyez pas le serveur.

Ou, pour le dire autrement, le calcul serverless est comme exécuter une instance de serveur virtuel, mais sans avoir à configurer ses paramètres d'instance ou à se connecter pour tout configurer.

En d'autres termes, vous ne pouvez pas exécuter de code logiciel de quelque nature que ce soit sans qu'un ordinateur quelque part ne traite vos commandes.

Donc, disons que le serverless est une forme de virtualisation où tout sauf votre code d'application est abstrait. En ce sens, les plateformes serverless comme Lambda d'Amazon et Functions d'Azure sont très similaires au modèle utilisé par Amazon Elastic Beanstalk, sauf qu'elles sont si simples à utiliser qu'elles peuvent facilement être incorporées dans une charge de travail multi-niveaux plus large et hautement automatisée.

### Qu'est-ce que l'informatique en périphérie ?

La latence est le terme que nous utilisons pour décrire le temps qu'il faut aux données pour voyager d'un serveur distant à travers un réseau jusqu'à votre ordinateur - ou dans l'autre sens.

En supposant que vous préfériez un service rapide à un service lent (ce qui semble être une supposition sûre), des chiffres de latence élevés sont une mauvaise chose.

Les ingénieurs réseau peuvent invoquer divers sorts magiques - Oups ! Je veux dire des efficacités de configuration astucieuses - pour réduire les retards dus à la latence.

Mais peu importe le nombre de tours qu'ils cachent dans leurs sacs noirs mystérieux, ils ne peuvent pas ignorer les lois de la physique. Même en utilisant les meilleures connexions et profils de configuration, les données doivent encore se déplacer physiquement sur les distances entre les emplacements distants.

La seule façon de réduire ce type de latence est de raccourcir la distance. Je suppose qu'une façon serait pour les fournisseurs de services en ligne de demander très poliment à leurs clients de vendre leurs maisons et de déménager quelque part plus près des serveurs fonctionnant dans le bureau (comme si les prix de l'immobilier n'étaient pas déjà assez élevés dans la Silicon Valley). Alternativement, que diriez-vous de déplacer le serveur plus près du client ?

Ah. Vous avez découvert l'informatique en périphérie : l'art de l'installation de grands réseaux distribués de serveurs plus petits où des copies miroir des données du serveur peuvent être stockées et, lorsque nécessaire, fournies à tout client de la région qui initie des requêtes.

Si vous avez suffisamment de ces serveurs répartis uniformément dans les régions géographiques où vivent vos clients, alors vous pouvez réduire significativement la latence qu'ils subissent.

Un type d'informatique en périphérie qui remplit cette fonction est connu sous le nom de réseau de distribution de contenu (CDN). Cloudflare et CloudFront d'Amazon sont parmi les plus grands CDN actuellement en opération.

Les ressources d'informatique en périphérie comme celles utilisées par les CDN ont également été de plus en plus utilisées pour gérer de grands flux de données vers et depuis des appareils IoT comme les ordinateurs intégrés dans les voitures.

Placer des appareils de calcul capables aux extrémités de grands réseaux permet de consommer et de transformer de tels ensembles de données plus rapidement qu'en déplaçant les données jusqu'au cloud plus distant.

### Quels sont les principaux facteurs de forme de calcul ?

Les ordinateurs, comme les égos, se présentent sous toutes les formes et tailles. Souhaitez-vous transporter un rack rempli de serveurs bare metal dans votre poche pour payer vos achats ? Vous seriez probablement mieux loti en utilisant une sorte d'application de paiement mobile sur votre smartphone.

La taille compte. Beaucoup. Le facteur de forme d'un appareil déterminera les dimensions et la capacité de ses composants internes. Cela signifie que la carte mère particulière, les modules de mémoire, les disques de stockage, les ports périphériques et l'alimentation que vous sélectionnez pour un appareil seront limités par votre facteur de forme global.

Le facteur de forme que vous choisissez - pour un nouveau projet ou simplement pour votre usage personnel - sera généralement évident (les racks de serveurs peuvent être lourds et ne supportent pas bien les voyages). Mais savoir ce qui est disponible peut faciliter la planification.

#### Appareils utilisant des écrans vidéo

Le terme _ordinateur personnel_ (PC), de nos jours, est utilisé pour décrire les ordinateurs de bureau ou portables.

Les ordinateurs portables, conçus pour être mobiles, sont largement autonomes. Les ordinateurs de bureau, en revanche, sont généralement livrés avec les éléments de calcul de base dans une boîte qui inclut des ports externes pour connecter des périphériques comme des claviers et des moniteurs.

Bien que vous puissiez trouver des ordinateurs avec une puissance et une fonctionnalité comparables à celles des PC dans des boîtiers très petits (de la taille d'une carte de crédit), les boîtiers plus grands utilisés par les ordinateurs de bureau permettent une personnalisation et des mises à niveau plus faciles.

Les consoles de jeu - comme la PlayStation de Sony, la Xbox de Microsoft et la Nintendo Switch - sont effectivement l'équivalent des ordinateurs de bureau, sauf que leur logiciel est construit sur des systèmes fermés.

Elles sont "fermées" dans le sens où leur interface logicielle n'expose que la fonctionnalité que le fabricant veut que vous voyiez. Modifier ou personnaliser le système d'exploitation ou les mécanismes internes d'une console de jeu est normalement impossible.

Un appareil à écran tactile utilise les gestes et les tapotements qu'il détecte des utilisateurs comme dispositifs d'entrée à la place de la souris ou du clavier traditionnel. Les technologies d'écran tactile sont la principale inspiration derrière les facteurs de forme plus petits pour les consommateurs, puisqu'il n'y a pas besoin de dispositifs d'entrée externes.

Cela, plus que toute autre chose, a stimulé la croissance énorme du marché des tablettes et des smartphones. (Cela explique également les pouces agiles de manière presque surnaturelle de toute une génération de jeunes.)

#### Appareils sans écrans vidéo

Le routeur qui connecte les appareils à un réseau via le WiFi ou des câbles Ethernet contient à peu près la même carte mère interne et les mêmes interfaces réseau que vous trouveriez dans tout autre appareil informatique. La grande différence est qu'il n'y a pas de port vidéo HDMI, DVI ou VGA.

Les routeurs sont conçus pour fonctionner de manière autonome et, lorsqu'une administration est nécessaire, elle se fera généralement via une interface de navigateur sur un réseau.

Vous lancez une session d'administration avec votre routeur en entrant son adresse IP dans votre navigateur et en vous authentifiant lorsque vous y êtes invité. Dans certains cas, vous pouvez également lancer des sessions de terminal via le protocole Secure Shell (SSH).

Ce modèle d'administration à distance est partagé par de nombreux types d'appareils sans écran. Ceux-ci incluront les implants médicaux (et non médicaux) ou les _wearables_ qui sont équipés de minuscules ordinateurs conçus pour surveiller, signaler ou même interagir avec leurs environnements hôtes.

(Dans le contexte des wearables, je devrais au moins brièvement discuter des montres intelligentes ici, mais, pour la vie de moi, je ne comprends pas pourquoi quelqu'un en voudrait une.)

Les ordinateurs sans écran sont également intégrés dans les dispositifs médicaux, les appareils électroménagers, les voitures, les flottes logistiques et les machines industrielles. Tous ces ordinateurs intégrés sont des composants de l'internet des objets en croissance.

## Chapitre 8 : Sécurité et confidentialité

Commençons par quelques formalités administratives. Vous vous souvenez sans doute comment la sécurité et la confidentialité ont été couvertes comme une couverture dans les deux premiers chapitres (intitulés "Comprendre la sécurité numérique" et "Comprendre la confidentialité numérique" respectivement). Alors pourquoi fouettons-nous ce cheval certifié mort maintenant ?

Parce qu'il n'est pas mort. La sécurité et la confidentialité sont aussi ou plus importantes que tout autre chose dans le domaine des technologies de l'information. La plupart d'entre nous n'y pensons pas assez, mais c'est quelque chose que vous ne pouvez vraiment pas trop faire.

Comme le dirait un professionnel des technologies de l'information exceptionnel avec qui j'ai travaillé : "Paranoïaque n'est que le début." Et en plus, il y a encore quelques sujets urgents et fascinants que nous n'avons pas abordés.

Nous passerons donc un peu de temps à explorer comment les outils de sécurité de base (comme les contrôles d'authentification et le chiffrement) peuvent être appliqués pour résoudre une gamme beaucoup plus large de problèmes de sécurité et de confidentialité. Et nous irons également face à face avec un couple de menaces significatives qui existent grâce aux appareils mêmes que nous avons appris à aimer.

### Blockchains

La machine à hype des nouvelles technologies adorait les blockchains lorsqu'elles sont apparues pour la première fois. Il y avait des articles enthousiastes fréquents dans les médias sur la façon dont c'était _ça_ : les blockchains étaient sur le point de changer le monde, inaugurant un âge d'or de joie sans fin et de licornes féeriques duveteuses. Réjouissez-vous ! Le salut est arrivé.

Mais malgré tout cela, les technologies de blockchain sont, en fait, une grande affaire. Avant d'aller là-bas, cependant, de quoi s'agit-il exactement ?

Une blockchain est une chaîne distribuée d'enregistrements numériques utilisée pour enregistrer et valider des transactions. L'objectif est de maintenir un "grand livre" public fiable et incorruptible des transactions pour sécuriser et améliorer la manière dont les opérations financières et de marchandises sont enregistrées.

Les _blocs_ dans les _blockchains_ sont en fait des paquets de données contenant certaines méta-informations d'identification (y compris un horodatage) et un hachage cryptographique.

Le hachage - qui est produit par un logiciel s'exécutant sur l'ordinateur qui génère le bloc - est dérivé du contenu unique du bloc précédent dans la chaîne qui, à son tour, était basé sur le bloc qui l'a précédé.

Parce que le contenu d'un bloc dépend de l'état des autres, aucun bloc unique ne peut être modifié sans laisser derrière lui des preuves évidentes et facilement traçables.

Cela explique pourquoi on l'appelle une _chaîne_, car si un seul maillon (bloc) est altéré, toute la chaîne se brisera. En effet, une chaîne ne sera jamais fiable à moins qu'elle ne maintienne le consensus clair des créateurs de tous ses blocs.

La génération des hachages pour les blockchains est intensive en calcul et peut entraîner des coûts significatifs en puissance de calcul et en électricité.

C'est intentionnel, car cela force presque les blockchains entre les mains de communautés distribuées, plutôt que d'individus ou de petits groupes. Cette décentralisation rend les chaînes moins vulnérables aux attaques et ajoute une fiabilité robuste aux données qui sont gérées.

#### Blockchains et cryptomonnaie

Comme la plupart des gens, j'ai d'abord entendu parler des blockchains dans le contexte des cryptomonnaies comme Bitcoin et Ethereum. Les cryptomonnaies sont des actifs numériques qui peuvent être utilisés comme alternatives à la monnaie fiduciaire (c'est-à-dire le type de représentations virtuelles et mutuellement acceptées de valeur trouvées dans des instruments d'échange comme les monnaies nationales).

En utilisant les fonds d'un compte de cryptomonnaie, je pourrais payer des biens ou des services tout en conservant, dans de nombreux cas, l'anonymat. Bien sûr, cette même anonymat comporte des risques significatifs.

Les cryptomonnaies ont, par exemple, été utilisées pour soutenir des activités criminelles. Les personnes derrière les attaques de ransomware exigent souvent des paiements en cryptomonnaie en échange des clés de déchiffrement que vous _espérez_ restaureront l'accès à vos données perdues.

Et le contenu de grands comptes de cryptomonnaie a été effectivement perdu lorsque des serveurs de contrôle se sont écrasés (ou ont été forcés de s'arrêter) ou, dans au moins un cas, lorsque l'administrateur d'une monnaie valant des millions de dollars est décédé sans partager ses informations d'authentification.

Il est intéressant de noter que la valeur relative des fonds dans le compte lui-même - lorsqu'elle est mesurée par rapport à la capacité de les échanger contre de la monnaie fiduciaire - a historiquement été volatile, subissant de manière imprévisible des fluctuations violentes du marché.

#### Blockchains et comptabilité

Les blockchains peuvent résoudre de nombreux problèmes anciens abordés par les pratiques comptables traditionnelles. Plus précisément, l'intégration de la vérification par blockchain dans les processus financiers d'une entreprise peut fournir des transactions sécurisées et un accès à la demande à des enregistrements immuables et transparents.

L'existence continue et en temps réel de tels enregistrements pourrait éventuellement éliminer le besoin d'audits périodiques et de réconciliations mensuelles.

De nombreuses caractéristiques de ces blockchains pourraient profondément changer la nature et la valeur des contrats - un changement qui pourrait se répandre au-delà de la comptabilité, dans la pratique du droit.

#### Blockchains et assurance

Les caractéristiques potentielles de sécurité et de confidentialité des blockchains bien conçues peuvent également créer des efficacités et de la valeur dans l'industrie de l'assurance.

Par exemple, avoir une seule blockchain où tous les assureurs d'un marché particulier peuvent partager de manière fiable leurs informations sur les comptes clients peut aider à réduire la fraude aux réclamations.

Les comportements suspects et les multiples réclamations pour un seul événement seront plus facilement visibles dans un système transparent et hautement accessible qui inclut des données de toutes les parties participantes.

Pouvoir réduire la duplication administrative peut également grandement rationaliser le traitement des réclamations légitimes.

Vous apprécierez cela lorsque vous considérerez comment l'assureur d'une victime traitera souvent la réclamation de son client en utilisant des étapes similaires à celles utilisées par l'assureur que vous réclamez. Mais si les deux entreprises sont capables de partager ouvertement leurs données, le processus peut être unifié et, encore mieux, automatisé.

Peut-être, plus significativement, la prestation des soins de santé peut être améliorée et rendue plus efficace si les dossiers personnels critiques peuvent être consultés en toute sécurité et instantanément. Et - vous l'avez deviné - les blockchains peuvent être utiles ici aussi.

De quels types d'automatisation parlons-nous ? Eh bien, en revenant aux réclamations d'accidents, un "contrat intelligent" est un logiciel qui vérifie régulièrement les changements de statut des objets associés. L'approbation par un simple clic de souris d'un expert en sinistres, par exemple, pourrait déclencher tous les événements nécessaires pour payer une réclamation, notifier toutes les parties concernées et mettre à jour les dossiers existants.

Peut-être - juste peut-être - l'assurance n'est pas aussi ennuyeuse que les gens le pensent.

### Authentification multi-facteurs

Les mots de passe sont des choses terribles. Bien sûr, nous ne pouvons pas simplement laisser nos appareils et comptes en ligne ouverts à n'importe qui. Mais qui a décidé que demander aux gens de mémoriser de longues chaînes de texte sans signification (comme _sIIkdm^&sv234LKi_) était la solution ?

Bien sûr, vous pourriez choisir des mots de passe faciles à retenir comme _mysecret_ ou cette variation astucieuse : _mysecret22_, mais tout ce qui est si facile à retenir est tout aussi facile à deviner. Et doublez cela si vous utilisez le même mot de passe pour plusieurs comptes. En d'autres termes, ce type de protection ne vaut tout simplement pas l'effort.

Il y a, soit dit en passant, deux façons d'améliorer vos mots de passe :

* Utilisez un coffre-fort de mots de passe pour générer et stocker en toute sécurité des mots de passe incroyablement complexes que vous n'aurez pas besoin de retenir : vous pouvez simplement les copier et les coller dans les pages de connexion que vous visitez.
* Utilisez des mots de passe longs (15-20 caractères) qui incorporent des mots mémorables mais non connectés. Quelque chose comme :

_maison-soixante-dix-guerre-veau_.

Mathématiquement parlant, il est hautement improbable que quelqu'un ait la puissance de calcul et le temps nécessaires pour craquer celui-ci. Et ce n'est pas si difficile à mémoriser.

Mais lorsqu'il s'agit de sites particulièrement sensibles - comme ceux où vous faites vos opérations bancaires - même les bons mots de passe ne suffisent pas. Pour cette raison, de plus en plus d'organisations intègrent l'authentification multi-facteurs (MFA) dans leurs profils de sécurité.

Un site web ou une application configuré avec MFA vous demande de présenter plus d'un type de preuve que vous êtes bien celui que vous prétendez être. L'un pourrait être basé sur quelque chose que vous savez, et un autre pourrait être une preuve basée sur quelque chose que vous possédez.

"Quelque chose que vous savez" pourrait être un mot de passe, tandis que "quelque chose que vous possédez" pourrait être un appareil MFA autonome ou une application s'exécutant sur votre smartphone.

Cela fonctionne souvent en faisant en sorte que l'application envoie un code à durée de vie courte via un message instantané à un numéro de téléphone prédéfini. Vous serez invité à entrer le code sur la page de connexion d'authentification.

### Identités fédérées

Une fois que vous avez maîtrisé les bases de l'authentification, grâce à des mots de passe forts et/ou à la MFA, il y a la question de l'autorisation. En d'autres termes, quelles ressources votre compte connecté pourra accéder.

Les systèmes individuels contrôleront les utilisateurs grâce à un certain type de contrôles d'accès. Microsoft Windows, par exemple, utilise Active Directory, Linux a des permissions d'objet, et les fournisseurs de cloud comme Amazon Web Services peuvent appliquer des rôles et des politiques.

Mais si vous voulez que vos utilisateurs puissent se déplacer _entre_ les services sans avoir à se connecter à chaque service individuellement, ou si vous préférez simplement ne pas avoir à gérer l'authentification du tout, vous pouvez implémenter une identité fédérée.

Vous avez probablement déjà expérimenté la fédération sans même le savoir. Se connecter à un service web tiers en utilisant votre compte Google est une forme de fédération.

Le service intègre son système d'authentification avec un fournisseur de fédération en utilisant une technologie d'identité comme Security Assertion Markup Language (SAML) ou OAuth. Lorsque vous acceptez les termes et vous connectez, le fournisseur partagera juste assez d'informations d'identité avec le service tiers pour activer un compte.

### Surveillance numérique

Parce qu'elle peut à la fois vous protéger du mal et envahir votre vie privée, la surveillance est une épée à double tranchant. Mais la surveillance _numérique_ est une épée à double tranchant qui est beaucoup plus tranchante. Permettez-moi d'expliquer pourquoi.

Les caméras vidéo en circuit fermé sont utilisées dans les systèmes de sécurité depuis au moins les années 1930, mais elles ne faisaient vraiment qu'une seule chose : enregistrer des images qui étaient généralement stockées localement et ensuite, après quelques jours, écrasées par de nouveaux enregistrements.

C'était utile, mais pour être utile, vous deviez physiquement accéder à la bande et ensuite rechercher laborieusement, trouver et visualiser les images d'intérêt.

Les caméras de surveillance numériques sont certainement moins chères que leurs équivalents analogiques, beaucoup plus faciles à cacher physiquement et faciles à accéder via les réseaux.

Mais il y a aussi beaucoup plus de choses que vous pouvez faire avec les flux vidéo numériques. Vous pouvez, par exemple, configurer des alertes par e-mail chaque fois que la caméra détecte un mouvement. Ou vous pouvez rediriger un flux vidéo vers des services cloud (comme Kinesis d'Amazon) où il peut être intégré à vos opérations d'analyse de données et d'apprentissage automatique ou interprété en temps quasi réel par un service de reconnaissance d'objets et de visages (comme Rekognition d'Amazon).

Tous ces outils peuvent être utilisés au service de buts à la fois positifs et nuisibles. Le fait est qu'il existe désormais des millions de ces caméras déployées dans le monde qui sont, dans de nombreux cas, connectées à des opérations de surveillance à grande échelle. Au minimum, vous devriez être conscient du potentiel et des risques que présentent ces technologies.

### Portes dérobées

Une _porte dérobée_ est une vulnérabilité matérielle ou logicielle qui a été intentionnellement intégrée dans un appareil ou le système d'exploitation qui l'exécute.

Dans certains cas, la porte dérobée existe avec la pleine connaissance du client, car elle était destinée à permettre un support à distance ou l'installation automatisée de correctifs et de mises à jour. Mais ce n'est pas toujours le cas.

Les gouvernements, les entreprises associées aux gouvernements et les organisations criminelles ont été pris en train d'expédier des appareils informatiques et de mise en réseau sensibles avec des portes dérobées dangereuses. De telles vulnérabilités ont été utilisées pour contourner la protection par chiffrement afin de surveiller les communications, voler des données de recherche et récolter des informations d'authentification.

Les portes dérobées peuvent prendre la forme de logiciels malveillants actifs qui collectent des données locales et les envoient ensuite à des serveurs d'attaque distants, ou permettent passivement des connexions à distance via des environnements réseau non sécurisés.

Se protéger contre les portes dérobées nécessite des défenses à plusieurs niveaux, notamment :

* Une vérification minutieuse des fournisseurs de matériel potentiels (en tenant compte de leurs pays d'origine et de leurs associations)
* Une surveillance régulière des sources d'information technologique fiables pour les nouvelles découvertes de vulnérabilités
* Une surveillance minutieuse des activités réseau de vos appareils
* Un correctif régulier de vos systèmes de mise en réseau et de calcul
* Une bonne dose de chance aveugle et stupide

## Chapitre 9 : Gestion du stockage des données

Nous sommes tous dans cette affaire du 21e siècle depuis un certain temps et il est désormais clair que les données sont le principal moteur de, eh bien, de tout.

Les gouvernements construisent leurs politiques autour des données économiques et démographiques. Les scientifiques construisent leurs théories autour des données environnementales, physiques et biologiques. Les entreprises construisent leurs plans autour des données de production, de vente et de comportement des consommateurs.

Les données sont générées à des rythmes jamais rêvés auparavant. J'ai lu que les capteurs d'une paire de moteurs GEnx de General Electric sur un Boeing 787 Dreamliner génèrent un téraoctet de données chaque jour.

Une seule voiture connectée au réseau (comme une Tesla) pourrait télécharger environ 100 Mo de données de localisation, de performance et de maintenance en une journée moyenne.

Multipliez cela par les millions de ces voitures qui seront bientôt en service dans le monde, et multipliez _ce_ nombre par les milliers d'autres appareils qui sont là-bas, et l'ampleur du "problème" des données devrait être claire.

Vous avez des plans pour ajouter vos propres données à l'inondation et vous sentez le besoin de les sauvegarder et de les stocker aussi ? Vous devrez être capable d'expliquer pourquoi vous en avez besoin afin de savoir comment cela devrait être fait. Je ne peux pas vous aider avec ce "pourquoi", mais je pense pouvoir vous donner quelques idées utiles sur le "comment".

La _manière_ dont vous stockez les données dépendra de leur apparence lorsqu'elles sont produites et de la façon dont vous pourriez avoir besoin d'y accéder plus tard. _L'endroit_ où vous stockez vos données dépendra de la quantité de données que vous avez, de l'impact que leur perte aurait sur vous et de la fréquence à laquelle vous devrez les sortir et jouer avec elles. Jetons un coup d'œil à ces deux variables.

### Formats de stockage de données

Puisque toutes les données ne sont pas créées égales, il sera logique de chercher les outils et environnements qui correspondront le plus étroitement au travail que vous prévoyez de faire. Voici quelques options :

#### Tableurs

Ils peuvent être des applications flashy, colorées et orientées vers les consommateurs, mais les tableurs ne sont pas des poids légers lorsqu'il s'agit de traitement de données sérieux.

Comme nous le verrons plus en détail un peu plus tard, les tableurs ont leurs limites. Mais lorsqu'il s'agit de présenter des données de manière visuellement accessible, d'appliquer des opérations mathématiques, statistiques et financières à ces données, et même d'intégrer des sources de données distantes (comme les cotations boursières), aucun autre outil ne s'en approche.

Les tableurs peuvent importer des données textuelles simples et brutes à partir de fichiers de presque n'importe quelle taille, à condition que le texte puisse être délimité. C'est-à-dire que les ruptures entre les divisions de données doivent être marquées par un caractère cohérent.

Lorsque vous importez les données, vous pouvez spécifier le délimiteur approprié. Les tabulations, les retours à la ligne et les virgules sont des caractères de délimitation courants. En fait, l'acronyme populaire _CSV_ signifie _valeurs séparées par des virgules_.

Voici à quoi pourraient ressembler quelques lignes de texte CSV. Notez que la première ligne contient les en-têtes de colonne. Les tableurs peuvent facilement comprendre comment celles-ci doivent être traitées différemment.

```
Année,Volume,Taux,Croissance
2015,56,10,15
2020,90,11,(2)
2022,109,8,12

```

Les tableurs affichent leurs données dans des cellules, qui sont disposées en lignes horizontales et en colonnes verticales.

Des fonctions peuvent être appliquées au contenu de cellules individuelles ou à certaines ou à toutes les cellules d'une colonne ou d'une ligne, et peuvent incorporer des valeurs dans des cellules à des emplacements relatifs.

Les ensembles de données dans un tableur peuvent être rendus sous forme de graphiques. Les tableurs peuvent être utilisés comme des formulaires web où les utilisateurs peuvent saisir des données qui sont sauvegardées pour une utilisation future.

Le tableur le plus populaire est probablement Excel de Microsoft, qui fait partie de leur suite Office Microsoft 365. Mais fonctionnalité pour fonctionnalité, le Calc open source qui accompagne la suite LibreOffice est une alternative viable. Google Sheets est une solution de tableur basée sur le cloud qui peut manquer de certaines des fonctionnalités des autres, mais est un outil de collaboration puissant.

#### Bases de données

En règle générale, les bases de données ne sont pas conçues pour visualiser les données dans des formats attrayants et intuitifs. Et, par elles-mêmes, elles ne sont pas connues pour les calculs mathématiques complexes non plus. Mais elles peuvent gérer des ensembles de données très volumineux et des relations multi-tables.

Lorsque je dis que les bases de données ne vous aident pas vraiment à visualiser vos données, c'est généralement parce qu'elles sont destinées à être utilisées "derrière" des applications frontales dans des déploiements multi-niveaux.

Par exemple, un site web de commerce électronique affichera des pages web où les utilisateurs peuvent parcourir ce que vous avez à vendre, ajouter des articles à un panier d'achat virtuel et passer à la caisse en utilisant leurs informations de paiement.

La page web elle-même ne fait que dessiner une interface graphique et vous montre où cliquer avec votre souris, mais les informations sur les articles que vous vendez - y compris leur prix et les images associées - sont probablement récupérées à partir d'une base de données backend chaque fois que la page se charge.

De même, vos sélections et, finalement, les informations de paiement seront écrites dans une base de données différente. Le processus logiciel qui gère votre expédition pourrait ensuite consulter la base de données de paiement pour l'adresse de livraison.

Les bases de données sont présentes à chaque étape, mais personne ne les verra jamais.

L'administration de grandes bases de données pour qu'elles soient efficaces, sécurisées et fiables nécessite une ingénierie sérieuse et, dans certains cas, une énorme quantité d'argent.

Avant de construire votre déploiement de base de données, vous devrez savoir si votre opération nécessite une forte atomicité, cohérence, isolation et durabilité (ACID) et un support pour des requêtes complexes et flexibles. Si c'est le cas, vous pourriez chercher un moteur de base de données relationnelle comme SQL Server, MariaDB ou Aurora d'Amazon.

Ou peut-être avez-vous besoin de performances rapides et préféreriez-vous un environnement sans schéma plus flexible (ce qui suggère que vous seriez mieux avec une solution NoSQL, comme MongoDB ou Redis).

_SQL_, soit dit en passant, signifie _langage de requête structuré_ - qui est une syntaxe établie pour utiliser un code de type langage pour interagir avec vos données.

De manière contre-intuitive, selon à qui vous demandez, _NoSQL_ pourrait ne pas signifier _Not SQL_. Certains préfèrent le considérer comme _Not Only SQL_.

#### Jupyter Notebook

Ne pensez pas que vous devez consommer vos données en utilisant le même outil qui les stocke. Il est possible, par exemple, d'importer des données existantes stockées localement ou sur un site distant dans un environnement de calcul interactif comme un Jupyter Notebook.

L'avantage de ce type de configuration est que les données peuvent maintenant être adressées dans le contexte, par exemple, d'un environnement de programmation Python robuste sans toucher - ou potentiellement corrompre - la source originale.

Le JupyterLab open source est une ressource populaire pour travailler avec de grands ensembles de données en utilisant Python. Vous pouvez télécharger et construire votre propre JupyterLab ou l'exécuter à distance via un fournisseur de cloud comme le service Elastic Map Reduce d'Amazon ou les Azure Notebooks de Microsoft.

Pour des ensembles de données particulièrement grands - surtout ceux qui vivent déjà dans le cloud - une plateforme cloud existante peut avoir du sens.

### Dispositifs de stockage de données

Bien que ce ne soit pas tout à fait aussi simple, disons qu'il existe quatre grandes catégories de supports de stockage de données :

* Bande magnétique sur bobines ouvertes, cartouches ou cassettes
* Optique incluant le disque compact (CD) et le disque vidéo numérique (DVD)
* Supports magnétiques dans des boîtiers de disque de 2,5 et 3,5 pouces - incluant les disques durs
* État solide incluant les disques SSD dans des boîtiers de disque de 2,5 et 3,5 pouces, les cartes SD et les clés USB

Quelques systèmes de bande magnétique peuvent encore exister ici et là, mais les jours de la copie laborieuse et lente de grands ensembles de données sur des banques de multiples bandes de sauvegarde - et de l'espoir que la sauvegarde fonctionnerait réellement - sont pratiquement révolus.

Croyez-moi : personne ne se plaint. Les CD et DVD suivent la même direction. Leurs capacités maximales ne sont pas à la hauteur du volume énorme des besoins en données d'entreprise d'aujourd'hui, et les consommateurs ne font pas de copies locales de presque autant de grands fichiers multimédias qu'auparavant.

Ce qui laisse les disques magnétiques et les disques à semi-conducteurs.

Gigaoctet pour gigaoctet, les disques durs sont probablement encore un peu moins chers que leurs équivalents à semi-conducteurs (bien que la différence de prix se réduise), mais les gains de performance offerts par les SSD sont très perceptibles.

Il y a quelque temps, j'ai réalisé que je pouvais en fait _économiser_ de l'argent en achetant des SSD de plus petite capacité pour mes postes de travail et ordinateurs portables personnels au lieu de disques durs (HDD) de plus grande capacité.

Permettez-moi d'expliquer. La manière dont nous utilisons les données sur nos ordinateurs personnels a changé ces dernières années. Plutôt que de stocker des médias et des archives de logiciels localement, nous sommes beaucoup plus susceptibles de supposer qu'ils seront disponibles pour le streaming ou le téléchargement chaque fois que nous en avons besoin.

Pour la plupart d'entre nous, des vitesses de téléchargement plus rapides ont rendu "vivre dans le cloud" facile. Donc, nous n'avons généralement plus besoin d'autant d'espace de stockage. Le disque SSD de 500 Go branché sur mon poste de travail très utilisé est à peine rempli à moitié - même en tenant compte de la douzaine de machines virtuelles et des nombreuses images ISO que j'ai là. Et le disque m'a coûté moins que ce que j'aurais payé pour un disque dur de un ou deux téraoctets.

L'un des rôles principaux du stockage est la sauvegarde des données. Plutôt que de transférer physiquement les sauvegardes entre les supports, l'archivage local des données - en utilisant des supports SSD ou HDD - fonctionne généralement en déplaçant les archives à travers les réseaux.

Le truc est de concevoir un système de sauvegarde qui vous fournit automatiquement des duplicatas suffisants de vos archives, les fait tourner à travers des cycles de vie appropriés (où, éventuellement, ils sont retirés et détruits), et tout cela sans générer de surcharge de trafic réseau inutile.

Outre les sauvegardes, vous voudrez souvent partager des données entre les utilisateurs travaillant dans tout votre campus.

Deux outils pour gérer à la fois les sauvegardes et le partage de fichiers sont le stockage en réseau (NAS) et les réseaux de stockage (SAN). Leurs noms similaires suggèrent qu'ils sont dans le même domaine. Croyez-moi : ils ne le sont pas.

#### Stockage en réseau (NAS)

Le NAS est un moyen relativement simple et peu coûteux de partager des fichiers sur un réseau local. Il fonctionne via un serveur autonome qui contient plusieurs disques de stockage. Les disques seront normalement configurés en tant que matrice redondante de disques indépendants (RAID) pour fournir des avantages de redondance et de performance.

Le dispositif NAS se connecte au réseau via des câbles Ethernet et utilise un réseau TCP/IP standard. Les machines clientes du LAN verront les ressources NAS via des protocoles de partage de fichiers standard comme Server Message Block (SMB) et Network File System (NFS).

Les solutions NAS peuvent être idéales pour les petits environnements domestiques ou de bureau, mais le plaisir s'estompera rapidement à mesure que vous grandirez. Les dispositifs NAS eux-mêmes ne sont généralement pas assez puissants pour gérer trop de charge de travail client, et travailler avec de grands fichiers sur un réseau Ethernet peut ralentir les choses.

#### Réseau de stockage (SAN)

Si les configurations NAS sont "relativement simples et peu coûteuses", les SAN sont complexes et coûteux. Ce n'est pas un hasard s'ils ont été conçus pour les déploiements d'entreprise à grande échelle. Grâce au matériel haut de gamme que vous mettez dans un système NAS, les performances seront excellentes et vous pourrez évoluer beaucoup plus loin.

Plutôt que l'Ethernet, les SAN fonctionnent via des commutateurs Fibre Channel beaucoup plus rapides (ou, parfois, l'iSCSI plus lent). Ils fournissent un stockage basé sur des blocs plutôt que des systèmes de fichiers et sont montés sur des machines clientes comme des disques locaux.

### Services de stockage de données

À mesure que les vitesses de connexion internet se sont améliorées, il est devenu plus pratique de déplacer au moins certaines archives de données vers le cloud.

Au lieu de sauvegardes locales - qui pourraient être perdues lors d'un événement catastrophique comme un incendie - les données pourraient être régulièrement sauvegardées sur des plateformes en ligne. Une fois là-bas, vous auriez une sauvegarde viable et hors site. Mais, si vous le souhaitiez, vous auriez également accès à ces données depuis n'importe quel endroit sur terre. Si vous travaillez à distance avec une équipe distribuée, cela peut être utile.

Vous possédez probablement déjà et avez même collaboré sur des documents qui vivent sur Dropbox, Microsoft 365 ou Google Drive.

Pour la plupart des gens, le point d'interaction principal pour ces services est un navigateur web. Mais la gestion sérieuse des données - ou même des sauvegardes de fichiers relativement complexes et régulières - ne sont pas pratiques dans un navigateur. Les fournisseurs de cloud computing offrent donc des services de stockage et d'archivage dont l'administration peut être scriptée et automatisée.

Les services de stockage cloud, comme Simple Storage Service (S3) d'Amazon, fournissent une gestion complète du cycle de vie des archives. Les données qui doivent rester hautement disponibles pourraient, par exemple, être sauvegardées dans la classe de stockage S3 Standard.

Après quelques mois - lorsque vous êtes moins susceptible d'avoir besoin des données, mais devez toujours conserver une copie pour des raisons réglementaires - vous pourriez déplacer votre archive vers la classe S3 Glacier moins chère. Les données dans Glacier sont sécurisées et durables, mais prendraient beaucoup plus de temps à accéder.

Après une année complète, vous pourriez être en mesure de les supprimer complètement. Mieux encore, il existe des moyens simples d'automatiser la manière dont vos données se déplacent dans leur cycle de vie.

Tous les principaux fournisseurs de cloud auront leurs propres services de stockage de données comparables. Naturellement, les prix et les fonctionnalités exactes des services différeront les uns des autres. Et, bien sûr, les détails des fonctionnalités et des prix changeront souvent.

Il n'est pas toujours pratique de transférer des données vers le cloud via l'internet. Les ensembles de données extrêmement volumineux peuvent prendre très longtemps à télécharger, même en utilisant des connexions internet rapides.

Bien sûr, si vous avez la chance d'avoir une connexion par fibre optique vous donnant un gigaoctet/seconde, alors un téléchargement d'un téraoctet ne prendrait que deux heures et demie environ (en supposant que personne d'autre n'utilise la connexion).

Mais qu'en est-il de 100 To de données (cela vous prendra plus de dix jours) ? Et si vous n'avez que 100 Mo/seconde (plus de trois mois) ? Si vous téléchargez des archives de taille jumbo chaque semaine ou avez d'autres utilisations pour votre connexion internet, alors le téléchargement n'est pas une option.

Pour de tels cas, vous pouvez toujours obtenir vos données dans le cloud, mais elles devront trouver un autre moyen de transport.

AWS, comme il se trouve, propose leurs services Snow Family. Snowball est un grand dispositif de stockage sécurisé. Il peut être expédié en toute sécurité aux clients d'AWS, chargé de dizaines de téraoctets de données, puis renvoyé. Une fois de retour chez Amazon, les données seront directement téléchargées dans un bucket dans le compte du client. Alternativement, les Snowballs peuvent être conservés sur place et utilisés comme dispositifs de calcul en périphérie.

Le grand frère de Snowball est AWS Snowmobile, un conteneur d'expédition sécurisé de 45 pieds de long capable de gérer la migration numérique à l'échelle de l'exaoctet.

Le petit cousin de Snowball, AWS Snowcone, est un conteneur robuste de la taille d'une boîte à mouchoirs qui peut gérer 8 To de stockage utilisable, ainsi que la possibilité d'instances cloud virtuelles et de connectivité réseau au cloud AWS. En plus de transférer vos données, les Snowcones peuvent être utilisés comme dispositifs de calcul en périphérie hautement mobiles à part entière.

### Merci d'avoir lu !

J'espère que vous avez apprécié le livre. Si vous souhaitez vous procurer un exemplaire physique, vous pouvez utiliser [ce lien](https://www.amazon.com/gp/product/B08HL9WQ1H/).

Ou si vous souhaitez consulter mes autres livres sur les tests d'intrusion, la gestion de la configuration logicielle et l'internet des objets, jetez un coup d'œil à [ma page d'auteur](https://www.amazon.com/David-Clinton/e/B01BR0PTT8/).