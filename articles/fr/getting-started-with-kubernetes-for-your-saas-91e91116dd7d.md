---
title: Prise en main de Kubernetes pour votre SaaS
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2018-01-29T16:21:53.000Z'
originalURL: https://freecodecamp.org/news/getting-started-with-kubernetes-for-your-saas-91e91116dd7d
coverImage: https://cdn-media-1.freecodecamp.org/images/1*hZx56ZEx75a9_xlC1smdOQ.png
tags:
- name: Cloud Computing
  slug: cloud-computing
- name: Devops
  slug: devops
- name: SaaS
  slug: saas
- name: software
  slug: software
- name: 'tech '
  slug: tech
seo_title: Prise en main de Kubernetes pour votre SaaS
seo_desc: 'By Ben Sears

  Kubernetes is a platform to manage and orchestrate your cloud infrastructure. It
  provides a configuration-driven framework where you can define a few different pieces
  and with one click get an entire network, disk, and application spun u...'
---

Par Ben Sears

[Kubernetes](https://kubernetes.io/) est une plateforme pour g√©rer et orchestrer votre infrastructure cloud. Il fournit un framework pilot√© par la configuration o√π vous pouvez d√©finir diff√©rents √©l√©ments et, en un clic, obtenir un r√©seau complet, un disque et une application d√©ploy√©s de mani√®re scalable et facile √† g√©rer.

D√©placer votre application vers Kubernetes est une activit√© √† forte intensit√© si vous n'avez pas con√ßu votre application avec des conteneurs d√®s le d√©part. Le but de cet article est de vous aider sur votre chemin vers la conteneurisation de vos applications avec une int√©gration Kubernetes en t√™te.

Soyez conscient que si vous essayez de forcer votre application dans Kubernetes sans l'architecture appropri√©e, vous vous tirerez essentiellement une balle dans le pied en perdant du temps et en accumulant de la dette technique.

### √âtape 1 ‚Äî Conteneurisez votre application ‚ú®

Un conteneur est essentiellement une section partitionn√©e du syst√®me d'exploitation qui peut fonctionner comme une machine ind√©pendante. Contrairement aux machines virtuelles traditionnelles, qui reposent sur un hyperviseur pour simuler un syst√®me d'exploitation, les conteneurs utilisent diverses fonctionnalit√©s du noyau pour fournir un environnement isol√© de la machine h√¥te.

![Image](https://cdn-media-1.freecodecamp.org/images/OnPF9sW3GZAZqG0BxOcBdRlVYyQHLUT9jjR1)
_Les applications conteneuris√©es peuvent s'ex√©cuter de mani√®re pr√©visible sur toutes les machines, pas seulement la v√¥tre_

La conteneurisation est un processus assez simple ‚Äî en utilisant Docker, il suffit de d√©finir un Dockerfile qui d√©crit les √©tapes n√©cessaires pour installer votre application sur un syst√®me d'exploitation (t√©l√©charger des packages, installer des d√©pendances, etc.).

Ensuite, construisez une image qui peut √™tre utilis√©e par les d√©veloppeurs. Plus d'informations sur le processus de conteneurisation peuvent √™tre trouv√©es sur [le site web de Docker](https://docs.docker.com/engine/examples/).

### √âtape 2 ‚Äî Adoptez une architecture multi-instances üöÄ

![Image](https://cdn-media-1.freecodecamp.org/images/Xmd3dBrgwkSRtjoOgvq-1uy-qn6duclrLyyx)
_La d√©cision d'opter pour une architecture multi-locataire ou multi-instances vous m√®nera sur des chemins diff√©rents_

Avant de passer √† Kubernetes, vous devez examiner attentivement la mani√®re dont vous livrez actuellement votre application √† l'utilisateur final.

Les applications web traditionnelles utilisent une architecture **multi-locataire**. Cela signifie que tous vos utilisateurs partageront une seule instance de base de donn√©es et une seule instance d'une application. Cela peut fonctionner dans Kubernetes ‚Äî cependant, je vous exhorte √† envisager de mettre en ≈ìuvre une architecture **multi-instances** pour tirer pleinement parti de la puissance de Kubernetes et des applications conteneuris√©es.

Certains avantages majeurs de l'adoption d'une architecture multi-instances sont :

* **Stabilit√©** ‚Äî Au lieu d'un seul point de d√©faillance (l'instance unique de l'application), chaque client peut exister dans sa propre instance. Si une instance tombe en panne, les autres resteront indemnes.
* **Scalabilit√©** ‚Äî Avec une architecture multi-instances, la mont√©e en charge est une simple question d'ajout de plus de ressources. Cependant, avec une architecture multi-locataire, vous pourriez atteindre un point o√π vous devez concevoir une architecture d'application en cluster dont le d√©ploiement est g√©n√©ralement loin d'√™tre trivial.
* **S√©curit√©** ‚Äî Lorsque vous utilisez une seule base de donn√©es, toutes vos donn√©es coexistent. Cela devient un probl√®me majeur en cas de violation de s√©curit√©, car les donn√©es de tous les clients peuvent devenir vuln√©rables lorsqu'un seul compte est compromis. Avec une architecture multi-instances, seules les donn√©es d'un seul client peuvent √™tre √† risque.

### √âtape 3 ‚Äî D√©terminez la consommation de ressources de votre application ‚öôÔ∏è

Pour avoir l'infrastructure la plus rentable, vous devez d√©terminer combien de CPU, de m√©moire et de stockage seront n√©cessaires pour ex√©cuter une seule instance de votre application.

De cette mani√®re, vous pouvez d√©finir des limites pour obtenir une lecture pr√©cise de l'espace dont vos n≈ìuds Kubernetes ont besoin, ainsi que pour vous assurer que vos n≈ìuds ne vont pas devenir surcharg√©s et peu fiables.

C'est g√©n√©ralement un processus d'essais et d'erreurs, mais vous pouvez utiliser une solution de surveillance telle que [Heapster](https://github.com/kubernetes/heapster/) pour obtenir une r√©partition claire des ressources que vos pods consomment. Cela vous permettra d'√©valuer combien allouer.

![Image](https://cdn-media-1.freecodecamp.org/images/3SWNHqbaF-aFU8eHKYfW6YZwegsKrnKQR2UG)
_Heapster fournit des visualisations de l'utilisation des ressources de votre charge de travail_

Une fois que vous avez d√©termin√© votre allocation de ressources, vous pouvez calculer les tailles optimales des serveurs pour vos n≈ìuds Kubernetes afin d'obtenir le meilleur rapport qualit√©-prix.

Vous prenez la m√©moire ou le CPU dont chaque instance a besoin pour fonctionner, et vous le multipliez par 100 (le nombre maximum de pods qu'un n≈ìud peut contenir). Cela vous donnera une estimation approximative de la quantit√© de m√©moire/CPU que vos n≈ìuds devraient avoir.

Toutefois, vous devriez toujours tester votre application sous charge pour vous assurer qu'elle fonctionne correctement lorsque le n≈ìud est rempli.

### √âtape 4 ‚Äî Int√©grez avec Kubernetes ‚öì

Une fois que votre cluster Kubernetes est op√©rationnel, il existe de nombreuses pratiques DevOps que vous pouvez commencer √† d√©velopper pour vous faciliter la vie. Certains de ces points d'int√©gration prennent les formes suivantes :

#### Mise √† l'√©chelle automatique des n≈ìuds Kubernetes

Lorsque vos n≈ìuds deviennent pleins, g√©n√©ralement vous souhaitez approvisionner plus de n≈ìuds pour que tout continue √† fonctionner correctement. Une fa√ßon de faire cela est avec un outil comme [kops](https://github.com/kubernetes/kops).

#### Mise √† l'√©chelle automatique des applications

Certaines applications devront √™tre mises √† l'√©chelle en fonction de l'utilisation actuelle. Kubernetes fournit cette fonctionnalit√© directement avec des d√©clencheurs qui mettent automatiquement √† l'√©chelle les d√©ploiements. Par exemple, ex√©cuter cette commande :

```
kubectl autoscale deployment myapp --cpu-percent=50 --min=1 --max=10
```

d√©finira le d√©ploiement _myapp_ pour qu'il monte jusqu'√† 10 pods lorsque le pourcentage de CPU d√©passe 50.

#### Approvisionnement automatique des instances √† l'action de l'utilisateur

Pour une architecture multi-instances, les utilisateurs finaux demanderont finalement que des applications soient d√©ploy√©es dans Kubernetes. Pour fournir cela, vous devriez envisager d'int√©grer votre application avec l'[API Kubernetes](https://kubernetes.io/docs/api-reference/v1.9/), ou utiliser une solution tierce telle que [ServiceBot](https://servicebot.io) pour fournir un portail de demande d'instances.

#### D√©finition personnalis√©e du nom d'h√¥te par l'action de l'utilisateur

Une tendance croissante ces derniers temps a √©t√© que les utilisateurs finaux attachent leur domaine aux applications. Kubernetes dispose d'outils pour faciliter ce processus et m√™me en arriver au point o√π il devient en libre-service (les utilisateurs appuient sur un bouton pour que leur domaine pointe vers le pod). Vous pouvez utiliser un syst√®me tel que [Nginx Ingress](https://github.com/kubernetes/ingress-nginx) pour y parvenir.

### Conclusion

Kubernetes est un excellent moyen de g√©rer votre infrastructure cloud. Si vous √™tes dans une situation o√π vous avez du mal √† mettre √† l'√©chelle votre application, envisagez de passer √† une architecture bas√©e sur Kubernetes. Vous verrez une augmentation significative de votre productivit√© DevOps en mati√®re de d√©ploiements, de clustering et de stabilit√© globale.

[_ServiceBot_](https://servicebot.io) _est une plateforme qui vous aide √† g√©rer votre SaaS en automatisant la facturation, les d√©ploiements et votre pipeline de ventes._

#### Vous cherchez √† mettre √† l'√©chelle votre SaaS ? [Parlons-en](http://bit.ly/sbotconsult).