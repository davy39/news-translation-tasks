---
title: 'Le manuel d''architecture Serverless : Comment publier une image Docker Node
  Js sur AWS ECR et d√©ployer le conteneur sur AWS Lambda'
subtitle: ''
author: Prince Onukwili
co_authors: []
series: null
date: '2025-04-17T02:19:13.327Z'
originalURL: https://freecodecamp.org/news/serverless-architecture-with-aws-lambda
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1744843935296/c359998f-1657-482f-adf4-5ab023cb1c02.png
tags:
- name: AWS
  slug: aws
- name: aws lambda
  slug: aws-lambda
- name: Docker
  slug: docker
- name: Node.js
  slug: nodejs
- name: serverless
  slug: serverless
- name: ecr
  slug: ecr
seo_title: 'Le manuel d''architecture Serverless : Comment publier une image Docker
  Node Js sur AWS ECR et d√©ployer le conteneur sur AWS Lambda'
seo_desc: 'Imagine you‚Äôre tasked with building a web application that can handle incoming
  traffic surges as your users grow without accumulating too much cost. Sounds like
  a dream, right?

  But here‚Äôs the thing: traditionally, to do this, you would have to manage...'
---

Imaginez que vous √™tes charg√© de construire une application web capable de g√©rer les pics de trafic √† mesure que vos utilisateurs augmentent, sans accumuler trop de co√ªts. Cela semble √™tre un r√™ve, n'est-ce pas ?

Mais voici le probl√®me : traditionnellement, pour faire cela, vous deviez g√©rer beaucoup d'infrastructure ‚Äì des ressources sur lesquelles votre application sera d√©ploy√©e ‚Äì ce qui peut √™tre un vrai casse-t√™te. Vous aviez des serveurs (instances VM ou ordinateurs physiques) √† configurer, des bases de donn√©es √† mettre √† l'√©chelle, des √©quilibreurs de charge √† surveiller... c'est beaucoup de travail üò©

C'est l√† que l'architecture Serverless vient √† la rescousse. Avec le mod√®le Serverless, vous pouvez d√©ployer vos applications pour g√©rer des milliers d'utilisateurs sans avoir √† vous soucier d'engendrer trop de co√ªts, de g√©rer l'infrastructure, les serveurs, le r√©seau, etc.

Dans cet article, vous apprendrez tout sur l'architecture Serverless : de quoi il s'agit, et comment d√©ployer votre propre application en utilisant AWS Lambda. Nous allons parcourir tout le processus √©tape par √©tape :

* Comment cloner le d√©p√¥t de votre application en utilisant Git.

* Comment construire une image de votre application en utilisant Docker.

* Comment installer l'AWS CLI sur votre machine locale et cr√©er des utilisateurs AWS IAM avec les bonnes permissions pour pousser votre image Docker vers AWS Elastic Container Registry (ECR).

Une fois l'image en cours d'ex√©cution sur ECR, nous la connecterons √† AWS Lambda et d√©ployerons le conteneur sur Lambda pour une exp√©rience enti√®rement serverless. üí°‚ú®

Pr√™t √† passer au serverless ? C'est parti ! üöÄ

## Table des mati√®res

1. [Qu'est-ce que l'architecture Serverless ?](#heading-quest-ce-que-larchitecture-serverless)

2. [Diff√©rences entre Serverless et autres mod√®les de d√©ploiement ‚ö°](#heading-differences-entre-serverless-et-autres-modeles-de-deploiement)

3. [üßë‚Äçüíª Pr√©requis ‚Äì Ce que vous devez savoir avant de suivre !](#heading-prerequis-ce-que-vous-devez-savoir-avant-de-suivre)

4. [Comment configurer l'application en utilisant Git üêô](#heading-comment-installer-lapplication-en-utilisant-git)

5. [Comprendre la base de code üîç](#heading-comprendre-la-base-de-code)

6. [Comment cr√©er une image Docker de l'application üê≥](#heading-comment-creer-une-image-docker-de-lapplication)

7. [Comment cr√©er un registre de conteneurs sur AWS Elastic Container Registry (ECR) üìÅ](#heading-comment-creer-un-registre-de-conteneurs-sur-aws-elastic-container-registry-ecr)

8. [IAM avec AWS : Comment cr√©er un utilisateur sur AWS IAM pour permettre l'acc√®s √† votre AWS ECR üë®‚Äçüíªüîë](#heading-iam-avec-aws-comment-creer-un-utilisateur-sur-aws-iam-pour-permettre-lacces-a-votre-aws-ecr)

9. [Comment t√©l√©charger votre image Docker vers le d√©p√¥t AWS ECR ‚§∂Ô∏è](#heading-comment-telecharger-votre-image-docker-vers-le-depot-aws-ecr)

10. [Comment d√©ployer le conteneur de l'application sur AWS Lambda √† partir de l'image sur AWS ECR üöÄ](#heading-comment-deployer-le-conteneur-de-lapplication-sur-aws-lambda-a-partir-de-limage-sur-aws-ecr)

11. [Avantages de l'adoption du mod√®le Serverless dans les entreprises üìú](#heading-avantages-de-ladoption-du-modele-serverless-dans-les-entreprises)

12. [Inconv√©nients du mod√®le Serverless üö´](#heading-inconvenients-du-modele-serverless)

13. [Quand adopter le mod√®le Serverless ü§î](#heading-quand-adopter-le-modele-serverless)

14. [Conclusion üìù](#heading-conclusion)

15. [√Ä propos de l'auteur üë®‚Äçüíª](#heading-a-propos-de-lauteur)

## Qu'est-ce que l'architecture Serverless ?

Avant d'aller plus loin, d√©composons ce que nous entendons par serveurs. Dans le monde de la tech, les serveurs sont des ordinateurs puissants qui stockent, traitent et g√®rent les donn√©es. Consid√©rez-les comme les travailleurs de l'ombre qui :

* **Stockent vos donn√©es** : Comme un classeur central pour vos documents num√©riques.

* **Ex√©cutent vos applications** : Ils ex√©cutent le code qui maintient votre application ou site web en fonctionnement.

* **G√®rent les requ√™tes** : Les serveurs r√©pondent aux requ√™tes des utilisateurs ‚Äì comme le chargement d'une page web ou le traitement d'une connexion.

D'accord, parlons maintenant de l'architecture Serverless ‚Äì mais d'abord, clarifions une id√©e re√ßue courante. Lorsque la plupart des gens entendent le mot "Serverless", ils pensent imm√©diatement, "Attendez‚Ä¶ pas de serveurs ? Comment cela fonctionne-t-il ?!" üòÖ

Voici la v√©rit√© : Serverless ne signifie pas qu'il n'y a pas de serveurs impliqu√©s (surprise, surprise ! üòâ). Au lieu de cela, cela signifie que vous, en tant que d√©veloppeur, n'avez pas √† vous soucier de la gestion des serveurs sur lesquels votre application s'ex√©cute. L'infrastructure c√¥t√© serveur est enti√®rement g√©r√©e par le fournisseur de cloud ‚Äì dans ce cas, AWS Lambda. Vous vous concentrez uniquement sur l'√©criture de code et son d√©ploiement, et AWS s'occupe du reste.

### Alors, quel est l'int√©r√™t du Serverless ?

Dans une configuration traditionnelle, lorsque vous d√©ployez votre application, vous √™tes responsable de choses comme :

* **L'approvisionnement des serveurs** (combien de serveurs avez-vous besoin ? Quelle taille ?)

* **La mise √† l'√©chelle des ressources** (comment g√©rer les pics de trafic sans trop payer ?)

* **La surveillance** et le maintien de tout en fonctionnement.

Cela semble √™tre beaucoup, n'est-ce pas ? ü§Ø Eh bien, l'architecture Serverless simplifie tout cela en vous permettant de vous concentrer uniquement sur le code de votre application. Avec Lambda, vous pouvez ex√©cuter du code en r√©ponse √† des √©v√©nements (comme une requ√™te HTTP, un t√©l√©chargement de fichier ou une modification de base de donn√©es) sans vous soucier de l'infrastructure derri√®re. AWS met automatiquement √† l'√©chelle les ressources de calcul selon les besoins, en vous facturant uniquement pour le temps o√π votre code est r√©ellement en cours d'ex√©cution. ‚è≥üí∞

Imaginez que vous √™tes dans un restaurant. Au lieu de g√©rer la cuisine vous-m√™me (comme g√©rer vos propres serveurs), vous passez simplement une commande (votre code) et le chef (AWS Lambda) la pr√©pare pour vous, √† la demande, en fonction de ce dont vous avez besoin. üçΩÔ∏èüç¥

## Diff√©rences entre Serverless et autres mod√®les de d√©ploiement ‚ö°

Maintenant que vous comprenez comment fonctionne Serverless, faisons un petit d√©tour et explorons les autres mod√®les utilis√©s pour d√©ployer des applications. Apr√®s tout, Serverless n'est pas le seul mod√®le sur le march√©, et cela vous donnera une perspective importante lorsque vous choisirez le bon mod√®le pour votre cas d'utilisation. üëÄ

Lorsque vous construisez une application, vous avez besoin d'un endroit pour l'h√©berger ‚Äì un foyer pour que votre code vive et s'ex√©cute. Au fil des ans, le monde de la tech a invent√© diff√©rentes fa√ßons de g√©rer cela, et chacune vous donne un niveau diff√©rent de contr√¥le (et de responsabilit√©) sur vos serveurs.

D√©composons cela.

### üè† Infrastructure as a Service (IaaS)

Avec l'IaaS, les fournisseurs de cloud comme AWS, Google Cloud ou Microsoft Azure vous donnent les √©l√©ments de base ‚Äì des serveurs virtuels (√©galement appel√©s instances), du stockage et des outils de mise en r√©seau ‚Äì mais c'est toujours √† vous de tout configurer.

C'est comme louer un appartement vide. Vous obtenez les murs, les portes et le toit, mais vous devez encore apporter vos propres meubles, configurer votre Wi-Fi et nettoyer r√©guli√®rement l'endroit. üè°üßπ

Lorsque vous choisissez l'IaaS, vous √™tes responsable de :

* La configuration des serveurs (choix de la taille, du syst√®me d'exploitation et de l'installation des logiciels).

* La gestion des mises √† jour, des correctifs et de la s√©curit√©.

* La mise √† l'√©chelle vers le haut ou vers le bas lorsque le trafic change.

**Exemple :** Amazon EC2 (Elastic Compute Cloud) est un service IaaS classique. Vous louez une machine virtuelle, vous la configurez vous-m√™me et vous la g√©rez comme un propri√©taire num√©rique.

### üè≠ Platform as a Service (PaaS)

Ensuite, nous avons le PaaS ‚Äì une configuration plus aboutie.

Dans ce mod√®le, le fournisseur de cloud s'occupe de l'infrastructure et du syst√®me d'exploitation sous-jacent, donc vous n'avez pas √† le faire. Vous t√©l√©chargez simplement votre code, configurez quelques param√®tres, et la plateforme ex√©cute votre application.

C'est comme emm√©nager dans un appartement enti√®rement meubl√© ‚Äì la cuisine fonctionne, les lumi√®res sont allum√©es et le Wi-Fi est d√©j√† connect√©. Vous arrivez simplement avec vos bagages et vous mettez au travail ! üè†‚ú®

**Exemple :** AWS Elastic Beanstalk, Heroku ou Google App Engine.

### ‚òÅÔ∏è Serverless : Le PaaS Sp√©cial

Maintenant, voici o√π les choses deviennent int√©ressantes : Serverless rel√®ve en fait de l'ombrelle PaaS, mais il m√©rite sa propre lumi√®re. Pourquoi ? Parce qu'il prend la commodit√© du PaaS et la pousse au niveau sup√©rieur.

Dans un mod√®le PaaS traditionnel (comme AWS Fargate ou Heroku), votre application fonctionne 24h/24 et 7j/7, que vous ayez des visiteurs qui l'utilisent ou non. Vous payez pour l'espace r√©serv√© et la puissance de calcul tout au long du mois, comme si vous louiez un appartement. M√™me si vous n'y avez pas dormi tout le mois, la facture arrive quand m√™me √† la fin. üí∞üè†

Mais avec Serverless, les r√®gles changent. Vous ne payez que lorsque votre code est r√©ellement utilis√©.

#### Comment les applications fonctionnent dans le mod√®le Serverless ‚öôÔ∏è

Dans un mod√®le Serverless, votre application n'est pas simplement l√† √† fonctionner toute la journ√©e. Elle se "r√©veille" uniquement lorsqu'elle est n√©cessaire. Mais qu'est-ce qui la r√©veille exactement ? C'est l√† que les d√©clencheurs entrent en jeu.

Les d√©clencheurs sont des √©v√©nements qui disent √† votre application Serverless, "H√©, il est temps de faire quelque chose !" Ces √©v√©nements peuvent √™tre toutes sortes de choses, comme :

* Un utilisateur visitant votre site web et cliquant sur un bouton.

* Quelqu'un t√©l√©chargeant un fichier vers votre stockage cloud (comme une image ou un document).

* Une nouvelle ligne ajout√©e √† une base de donn√©es.

* Une planification automatis√©e (comme un rappel qui s'ex√©cute tous les jours √† 8h).

Lorsque l'un de ces √©v√©nements se produit, votre application se met instantan√©ment en vie, ex√©cute la t√¢che exacte que vous avez programm√©e, puis retourne "dormir" jusqu'au prochain d√©clencheur. C'est ainsi que Serverless maintient vos co√ªts cloud bas et vos ressources efficaces ‚Äì pas de fonctionnement constant en arri√®re-plan, seulement de l'action lorsqu'il y a r√©ellement quelque chose √† faire !.‚ö°üòä

Par exemple, si un utilisateur envoie une requ√™te qui d√©clenche l'ex√©cution de votre application pendant seulement 10 secondes et utilise 20 Mo de m√©moire, c'est tout ce que vous payez ‚Äì le temps exact et les ressources consomm√©es.

Pas d'utilisateurs ? Pas de requ√™tes ? Pas de paiement. Maintenant, c'est une fa√ßon intelligente d'√©conomiser de l'argent. ü§ëüí∞

### üí° Comparaison rapide : PaaS vs Serverless

| **Fonctionnalit√©** | **PaaS Traditionnel (exemple : AWS Fargate)** | **PaaS Serverless (exemple : AWS Lambda)** |
| --- | --- | --- |
| Configuration du serveur | Vous s√©lectionnez la taille et les limites de calcul. | Pas besoin ‚Äì AWS g√®re tout. |
| Mise √† l'√©chelle | Vous configurez les politiques de mise √† l'√©chelle. | Mise √† l'√©chelle automatique, bas√©e sur les √©v√©nements (en fonction du trafic entrant). Plus le trafic est √©lev√©, plus de puissance de calcul est ajout√©e √† votre application, et vice versa. üòÉ |
| Facturation | Factur√© pour les instances en cours d'ex√©cution 24h/24, m√™me lorsqu'elles sont inactives. | Factur√© uniquement lorsque votre code s'ex√©cute. ‚è≥üí∞ |
| D√©ploiement | D√©ployer des applications compl√®tes. | D√©ployer de petits morceaux de code (fonctions). Vous pouvez √©galement d√©ployer des microservices et des applications web √† grande √©chelle |

---

## üßë‚Äçüíª Pr√©requis ‚Äì Ce que vous devez savoir avant de suivre

Avant de plonger, voici la meilleure partie : j'ai √©crit cet article pour qu'il soit super adapt√© aux d√©butants et d√©taill√©, donc m√™me si vous avez peu ou pas de connaissances en programmation, vous pourrez toujours suivre.

Que vous soyez un d√©veloppeur, une startup curieuse de technologie, ou un chef d'entreprise essayant de comprendre les solutions cloud modernes, ce guide a √©t√© √©crit pour vous.

Cela dit, avoir quelques connaissances l√©g√®res dans ces domaines rendra le voyage encore plus fluide :

* üßë‚Äçüíª Concepts de programmation de base ‚Äì comme le fonctionnement des applications Node.js et ce que fait un serveur.

* üí° Familiarit√© avec les termes techniques courants ‚Äì des mots comme "d√©ployer", "application", "CPU" et "logiciel" appara√Ætront, mais ne vous inqui√©tez pas : j'ai fait de mon mieux pour d√©composer ces termes en explications simples et compr√©hensibles.

Aucune exp√©rience pr√©alable du cloud ? Pas de probl√®me ! Ce guide vous tient la main tout au long du processus, de la configuration au d√©ploiement ‚Äì tout en langage clair, sans jargon.

Alors attachez votre ceinture, et proc√©dons au d√©ploiement de votre propre application sur AWS Lambda. üòÅ

## Comment configurer l'application en utilisant Git üêô

Avant de nous lancer dans l'√©criture de code ou le d√©ploiement de quoi que ce soit, la toute premi√®re √©tape consiste √† r√©cup√©rer l'application avec laquelle nous allons travailler ‚Äì et pour cela, nous allons utiliser Git.

Mais attendez... qu'est-ce que Git ? ‚Äì C'est un syst√®me de contr√¥le de version (VCS) qui aide les d√©veloppeurs √† suivre les modifications de leur code, √† collaborer avec leurs co√©quipiers sans se marcher sur les pieds, et √† stocker leur travail en toute s√©curit√© dans un endroit central ‚Äì comme GitHub.

### Cloner le d√©p√¥t de l'application üßë‚Äçüíª

J'ai d√©j√† cr√©√© un projet simple pour que nous l'utilisions dans ce tutoriel ‚Äì il est joliment install√© sur GitHub, en attendant que vous le r√©cup√©riez.

Pour cloner le projet sur votre machine locale, ouvrez votre terminal et ex√©cutez :

```bash
git clone https://github.com/onukwilip/lambda-tutorial.git
```

Cette commande t√©l√©chargera tout le code du d√©p√¥t `lambda-tutorial` dans un dossier sur votre ordinateur. üìÅ

Une fois le clonage termin√©, naviguez dans le r√©pertoire du projet comme ceci :

```bash
cd lambda-tutorial
```

Boum üí• ‚Äì juste comme √ßa, votre machine locale est maintenant configur√©e avec le m√™me code que celui stock√© dans le d√©p√¥t GitHub. üè†

## Comprendre la base de code üîç

### Ouvrir la base de code dans votre IDE pr√©f√©r√© üßë‚Äçüíª

Pour ce tutoriel, nous allons utiliser Visual Studio Code (VS Code), mais n'h√©sitez pas √† utiliser l'√©diteur avec lequel vous √™tes √† l'aise.

Une fois que vous avez ouvert le dossier du projet `lambda-tutorial`, vous remarquerez qu'il s'agit d'un serveur web Node.js simple. Rien de trop compliqu√© ‚Äì juste un serveur capable de g√©rer les requ√™tes et de r√©pondre avec des donn√©es.

Maintenant, il est important de comprendre ce qui se passe dans notre base de code, surtout si vous venez de d√©ployer sur des plateformes comme Render, Vercel ou Google Cloud Run.

### **D√©ploiement sur Lambda vs autres plateformes Serverless ‚ö°**

Lorsque vous d√©ployez sur des plateformes comme Vercel, Render ou Google Cloud Run, vous emballez g√©n√©ralement votre serveur web tel que vous l'avez √©crit ‚Äì qu'il s'agisse d'un serveur Node.js Express ou d'une application Next.js ‚Äì et la plateforme le g√®re presque tel quel.

Ces plateformes ex√©cutent votre serveur comme un mini-conteneur (ou microservice) qui est toujours pr√™t √† g√©rer le trafic entrant, comme un serveur attendant √† votre table, pr√™t √† prendre votre commande.

Mais AWS Lambda fonctionne un peu diff√©remment.

Lambda attend que votre code soit organis√© autour de fonctions ‚Äì et non de serveurs web complets. Consid√©rez Lambda comme un chef qui n'appara√Æt que lorsqu'une commande est pass√©e, pr√©pare la nourriture et dispara√Æt une fois le travail termin√©. üë®‚Äçüç≥üçΩÔ∏èüç¥

Ainsi, si vous avez un serveur Node.js Express complet, vous devrez effectuer une petite "traduction" pour r√©pondre aux attentes de Lambda ‚Äì et c'est l√† qu'intervient le fichier lambda.js.

#### Le fichier `lambda.js` ‚Äì Votre traducteur Lambda üîç

Voici √† quoi ressemble le fichier :

```javascript
const serverless = require("serverless-http");
const app = require("./app");

const handler = serverless(app);
module.exports.handler = handler;
```

D√©composons cela :

* `const serverless = require("serverless-http");`: Cela importe une petite biblioth√®que pratique appel√©e serverless-http. (La biblioth√®que `serverless-http` est importante pour que notre plateforme fonctionne correctement sur AWS Lambda.) Elle agit comme un traducteur : elle prend votre application Express r√©guli√®re et l'enveloppe de sorte qu'AWS Lambda puisse la comprendre.

* `const handler = serverless(app);`: Voici la magie. Cela enveloppe votre application Express dans une fonction compatible avec Lambda.

* `module.exports.handler = handler;`: Cela exporte votre fonction envelopp√©e afin qu'AWS Lambda puisse l'appeler lorsque l'application est d√©clench√©e.

Ainsi, au lieu de d√©marrer votre serveur comme ceci :

```javascript
app.listen(5000, () => {
  console.log("Server running on port 5000");
});
```

Vous confiez votre application √† Lambda et le laissez g√©rer les requ√™tes entrantes, la mise √† l'√©chelle et l'ex√©cution de l'application uniquement lorsqu'elle est n√©cessaire.

#### Le fichier `app.js` ‚Äì Votre application Express classique üìÇ

Votre `app.js` est l'endroit o√π r√©side la logique principale de l'application. C'est g√©n√©ralement l√† que vous :

* Configurez Express.

* D√©finissez les routes (comme `/api`, `/users`, `/hello`).

* Appliquez des middlewares (comme l'analyse JSON, la journalisation, CORS, etc.).

* G√©rez les requ√™tes HTTP et envoyez des r√©ponses.

Dans un d√©ploiement normal (Render, Google Cloud Run, DigitalOcean ou votre propre serveur), vous d√©marreriez le serveur en utilisant `app.listen(PORT)` en bas de ce fichier.

Mais puisque nous d√©ployons sur Lambda, vous ne d√©marrez pas directement le serveur ici. Au lieu de cela, vous exportez l'`app` comme ceci :

```javascript
module.exports = app;
```

De cette fa√ßon, votre application reste "agnostique du serveur" ‚Äì elle n'est pas cod√©e en dur pour s'ex√©cuter sur un serveur traditionnel. Lambda (via le fichier `lambda.js`) se charge de d√©marrer et d'arr√™ter votre application chaque fois qu'elle est d√©clench√©e par un √©v√©nement (comme une requ√™te HTTP). Intelligent, n'est-ce pas ? üí°

Pourquoi cette configuration ? ü§î

Cette petite s√©paration vous donne de la flexibilit√© :

* Vous pouvez √©crire votre application Node.js comme vous l'avez toujours fait (en utilisant `Express`) √† l'int√©rieur de `app.js`.

* Et vous ne modifiez que le point d'entr√©e (via `lambda.js`) pour r√©pondre aux attentes d'AWS Lambda.

## Comment cr√©er une image Docker de l'application üê≥

Maintenant que nous avons bien examin√© le code, emballons-le de mani√®re intelligente ‚Äì en utilisant Docker.

### Qu'est-ce que Docker ? üê≥

Vous vous demandez peut-√™tre, *"Pourquoi utilisons-nous Docker ?"*

Docker est un logiciel permettant de cr√©er des images de vos applications et d'ex√©cuter ces images en tant que conteneurs. Tout comme les conteneurs de transport du monde r√©el contiennent des marchandises en toute s√©curit√©, les conteneurs Docker contiennent votre application, regroup√©e avec tout ce dont elle a besoin pour fonctionner : son code, ses biblioth√®ques, ses d√©pendances et ses param√®tres. Tout est bien emball√©, de sorte que votre application fonctionne de la m√™me mani√®re partout, que ce soit sur votre ordinateur portable, AWS Lambda, ou m√™me sur la machine de votre ami.

### Examinons le Dockerfile üìÑ

Dans votre dossier de projet, vous trouverez un fichier nomm√© `Dockerfile`. Il s'agit essentiellement de la recette que Docker utilise pour construire l'image du conteneur de votre application.

Voici √† quoi il ressemble :

```dockerfile
FROM node:18-slim AS builder

WORKDIR /app

COPY package.json .

RUN npm i -f

COPY . .

USER root

FROM amazon/aws-lambda-nodejs

ENV PORT=5000

COPY --from=builder /app/ ${LAMBDA_TASK_ROOT}
COPY --from=builder /app/node_modules ${LAMBDA_TASK_ROOT}/node_modules
COPY --from=builder /app/package.json ${LAMBDA_TASK_ROOT}
COPY --from=builder /app/package-lock.json ${LAMBDA_TASK_ROOT}

EXPOSE 5000

CMD [ "lambda.handler" ]
```

D√©composons les √©tapes importantes ‚Äì en anglais simple : üòä

* `FROM node:18-slim AS builder`: Nous commen√ßons par utiliser une version l√©g√®re de Node.js appel√©e `node:18-slim` et lui donnons une √©tiquette nomm√©e `builder` (consid√©rez cela comme l'√©tape 1). Cela nous donne les outils n√©cessaires pour construire une application Node.js, mais sans les √©l√©ments suppl√©mentaires qui alourdissent l'image. L'√©tiquette `builder` nous permet de r√©utiliser le contenu de cette construction dans l'√©tape suivante.

* `WORKDIR /app`: Nous d√©finissons le r√©pertoire de travail √† l'int√©rieur du conteneur sur `/app`. Consid√©rez cela comme dire √† Docker : *"H√©, c'est le dossier o√π je vais travailler !"*

* `COPY package.json .`: Cela copie le fichier `package.json` (qui liste les d√©pendances de votre application) dans le dossier `/app` √† l'int√©rieur du conteneur.

* `RUN npm i -f`: Cela installe toutes les d√©pendances Node.js (les packages dont votre application a besoin pour fonctionner). Le drapeau `-f` force npm √† r√©soudre les conflits s'ils apparaissent.

* `COPY . .`: Cela copie le reste de vos fichiers de projet depuis votre ordinateur dans le conteneur.

* `USER root`: Cela d√©finit l'utilisateur sur root (niveau administrateur) √† l'int√©rieur du conteneur. Utile lorsque des permissions suppl√©mentaires sont n√©cessaires pour certaines t√¢ches.

* `FROM amazon/aws-lambda-nodejs`: Maintenant, voici le changement : nous passons √† l'image de base officielle AWS Lambda pour Node.js ! C'est-√†-dire, l'√©tape 2. Cette image est con√ßue pour fonctionner en douceur lors du d√©ploiement de conteneurs sur Lambda.

* `ENV PORT=5000`: Nous d√©finissons une variable d'environnement pour le port du serveur. Notre application √©coutera sur le port 5000.

* `COPY --from=builder /app/ ${LAMBDA_TASK_ROOT}`: Cela prend tous les fichiers de l'√©tape de construction et les copie dans le r√©pertoire de travail sp√©cial de Lambda (`${LAMBDA_TASK_ROOT}`).

* `COPY --from=builder /app/node_modules ${LAMBDA_TASK_ROOT}/node_modules`: M√™me chose, mais cela copie sp√©cifiquement le dossier node_modules (toutes vos d√©pendances install√©es) dans le r√©pertoire de travail de Lambda.

* `COPY --from=builder /app/package.json ${LAMBDA_TASK_ROOT}`: Copie le fichier `package.json` dans le r√©pertoire de travail de Lambda.

* `COPY --from=builder /app/package-lock.json ${LAMBDA_TASK_ROOT}`: Copie le fichier de verrouillage pour vos d√©pendances ‚Äì afin que Lambda sache exactement quelles versions des biblioth√®ques utiliser.

* `EXPOSE 5000`: Cela indique √† Docker, *"H√©, mon application va √©couter les requ√™tes sur le port 5000 !"* (Bien que Lambda n'utilise pas cela directement, c'est utile pour les tests locaux.)

* `CMD [ "lambda.handler" ]`: Cela indique √† AWS Lambda quelle fonction ex√©cuter lorsque le conteneur d√©marre. Dans ce cas, il recherche une fonction `handler` √† l'int√©rieur de votre application ‚Äì c'est le point d'entr√©e !

### Comment cr√©er notre propre image Docker

Avant de continuer, vous devez avoir Docker en cours d'ex√©cution sur votre machine. Si vous n'avez pas encore install√© Docker, consultez le guide d'installation officiel ici : [Tutoriel d'installation de Docker](https://docs.docker.com/engine/install/). C'est une excellente ressource pour mettre Docker en route.

#### Assurez-vous que Docker est en cours d'ex√©cution

Assurez-vous que Docker Desktop est install√© et en cours d'ex√©cution. Vous pouvez g√©n√©ralement le savoir gr√¢ce √† l'ic√¥ne Docker dans votre barre des t√¢ches. Si ce n'est pas le cas, d√©marrez-le avant de continuer.

#### Construire l'image Docker

Maintenant, il est temps de cr√©er une image Docker de notre application. Dans votre terminal, naviguez jusqu'au r√©pertoire racine de votre projet (o√π se trouve votre Dockerfile). Ensuite, ex√©cutez la commande suivante :

```bash
docker build -t demo-lambda-project:latest .
```

* La commande `docker build` indique √† Docker de cr√©er une image.

* Le drapeau `-t demo-lambda-project:latest` attribue une √©tiquette (ou un nom) √† votre image (nous changerons cela plus tard pour la convention de nommage des images prise en charge par AWS Elastic Container Registry ‚Äì ECR).

* Ici, `demo-lambda-project` est le nom, et `latest` est l'√©tiquette indiquant la construction la plus r√©cente.

* Le `.` √† la fin indique √† Docker de rechercher le Dockerfile dans le r√©pertoire actuel.

#### Ce que cela fait

Docker va maintenant suivre les instructions de votre Dockerfile √©tape par √©tape. Il commence par construire votre application Node.js (en utilisant l'image l√©g√®re Node 18), installe les d√©pendances, puis copie tout dans une image pr√™te pour AWS Lambda. Une fois termin√©, vous avez une image bien rang√©e √©tiquet√©e `demo-lambda-project:latest` qui est pr√™te pour le d√©ploiement.

## Comment cr√©er un registre de conteneurs sur AWS Elastic Container Registry (ECR) üìÅ

D'accord, plongeons dans la cr√©ation d'un registre d'images sur AWS Elastic Container Registry (ECR). Suivez ces √©tapes de pr√®s pour configurer votre d√©p√¥t nomm√© lambda-practice :

### √âtape 1 : Connectez-vous et acc√©dez √† AWS ECR

Connectez-vous √† votre console de gestion AWS : [https://console.aws.amazon.com/console/home](https://console.aws.amazon.com/console/home).

Dans la barre de recherche en haut, tapez "ECR". Vous devriez voir Amazon ECR appara√Ætre dans les r√©sultats du menu d√©roulant. Cliquez dessus pour acc√©der √† la section Elastic Container Registry.

### √âtape 2 : Commencez √† cr√©er votre d√©p√¥t

Une fois dans la section ECR, cherchez un bouton qui dit "Cr√©er un d√©p√¥t". Cliquez sur ce bouton pour commencer √† configurer votre nouveau registre de conteneurs.

![Cr√©er un nouveau d√©p√¥t AWS ECR](https://cdn.hashnode.com/res/hashnode/image/upload/v1744649904087/615bbd21-c6ed-4243-9a18-10042eec9634.png align="center")

### √âtape 3 : Configurer les d√©tails du d√©p√¥t

Vous devrez ajouter des informations comme :

* **Nom du d√©p√¥t** : Dans le formulaire qui appara√Æt, entrez `lambda-practice` comme nom du d√©p√¥t. Ce nom sera utilis√© pour r√©f√©rencer votre d√©p√¥t plus tard lors du t√©l√©chargement de votre image Docker.

* **Mutabilit√© des balises** : Vous verrez √©galement une option pour la mutabilit√© des balises. Pour ce tutoriel, d√©finissez-la sur Mutable. Cela signifie que si vous devez mettre √† jour ou modifier une balise sur votre image plus tard, vous pouvez le faire. (Gardez √† l'esprit que dans certains sc√©narios, vous pourriez vouloir des balises immuables pour les images utilis√©es dans les environnements de production ‚Äì mais les balises mutables sont id√©ales pour les tests et le d√©veloppement, surtout puisque nous voulons utiliser la balise `latest` pour nos images.)

Lorsque vous √™tes satisfait des param√®tres, cliquez sur le bouton "Cr√©er un d√©p√¥t" en bas du formulaire.

![Configurer le d√©p√¥t AWS ECR](https://cdn.hashnode.com/res/hashnode/image/upload/v1744650070919/3010590f-f2e3-4d52-9631-8c5d4e1a5239.png align="center")

### D√©p√¥t cr√©√© ‚Äì Maintenant, jetons un coup d'≈ìil

Apr√®s avoir cr√©√© le d√©p√¥t, AWS vous redirigera vers la page listant vos d√©p√¥ts.

Trouvez le d√©p√¥t nomm√© `lambda-practice` dans la liste. Il s'agit de votre nouveau registre de conteneurs o√π vous pouvez pousser des images Docker.

Copiez l'URI du d√©p√¥t `lambda-practice`, dont nous aurons besoin plus tard lorsque nous pousserons notre image depuis notre machine locale. L'URI doit √™tre dans un format similaire √† celui-ci - `<aws_account_id>.dkr.ecr.<region>.amazonaws.com/lambda-practice`

![Cr√©ation termin√©e du d√©p√¥t AWS ECR](https://cdn.hashnode.com/res/hashnode/image/upload/v1744650192129/67d724c7-15da-4ff1-8e38-638c3a8d1aa4.png align="center")

Et c'est tout ! Vous avez maintenant cr√©√© avec succ√®s un registre de conteneurs sur AWS ECR et avez votre d√©p√¥t (`lambda-practice`) pr√™t √† recevoir votre image Docker. üöÄ

## IAM avec AWS : Comment cr√©er un utilisateur sur AWS IAM pour permettre l'acc√®s √† votre AWS ECR üë®‚Äçüíªüîë

Maintenant que nous avons cr√©√© avec succ√®s notre registre de conteneurs AWS ECR (le foyer pour notre image Docker), il est temps de s'assurer que notre machine locale dispose des autorisations n√©cessaires pour interagir avec ce registre. Sans une autorisation appropri√©e, nous ne pourrons pas t√©l√©charger notre image.

Pour cela, nous allons cr√©er un utilisateur IAM avec les autorisations appropri√©es.

### √âtape 1 : Acc√©der √† la console IAM

Commencez par vous connecter √† votre console de gestion AWS : [https://console.aws.amazon.com/console/home](https://console.aws.amazon.com/console/home).

Dans la barre de recherche en haut, tapez "IAM" et s√©lectionnez le service IAM dans le menu d√©roulant. Cela vous am√®ne au tableau de bord IAM o√π vous pouvez g√©rer les utilisateurs, les r√¥les, les politiques, etc.

### √âtape 2 : Acc√©der √† la section Utilisateurs

Dans la barre lat√©rale gauche du tableau de bord IAM, cliquez sur "Utilisateurs". Vous verrez ici une liste des utilisateurs existants, et c'est l√† que vous en ajouterez un nouveau.

![Cr√©er un utilisateur AWS IAM](https://cdn.hashnode.com/res/hashnode/image/upload/v1744651384601/085a25ca-82eb-447b-8106-46df32264a85.png align="center")

### √âtape 3 : Cr√©er un nouvel utilisateur

Cliquez sur le bouton "Ajouter des utilisateurs" en haut. Dans l'√©tape "D√©finir les d√©tails de l'utilisateur", entrez le nom d'utilisateur comme `lambda-practice`.

### √âtape 4 : Attacher des autorisations directement

Dans l'√©tape "D√©finir les autorisations", choisissez "Attacher des politiques directement". Dans la bo√Æte de recherche, tapez `AmazonEC2ContainerRegistryPowerUser`. S√©lectionnez la politique `AmazonEC2ContainerRegistryPowerUser` en cochant sa case. Cette politique accorde les autorisations n√©cessaires pour travailler avec AWS ECR, telles que pousser et tirer des images Docker.

Cliquez sur Suivant, et v√©rifiez que le nom d'utilisateur est `lambda-practice` et que la politique AmazonEC2ContainerRegistryPowerUser est attach√©e. Si tout semble bon, cliquez sur "Cr√©er un utilisateur".

![Ajouter une politique √† l'utilisateur AWS IAM](https://cdn.hashnode.com/res/hashnode/image/upload/v1744651476901/c6d91c8c-9757-4cc6-a00f-c23d3a72de59.png align="center")

### √âtape 5 : G√©n√©rer des cl√©s d'acc√®s pour l'utilisateur

Une fois l'utilisateur cr√©√©, vous serez redirig√© vers la page listant tous les utilisateurs IAM. Localisez et cliquez sur l'utilisateur `lambda-practice`. Cette action vous am√®nera √† la page de r√©sum√© de l'utilisateur.

* Acc√©dez √† l'onglet "Informations d'identification de s√©curit√©".

* Sous "Cl√©s d'acc√®s", cliquez sur le bouton "Cr√©er une cl√© d'acc√®s".

* Une page appara√Ætra pour configurer la nouvelle cl√© d'acc√®s.

![Cr√©er une cl√© d'acc√®s pour l'utilisateur AWS IAM](https://cdn.hashnode.com/res/hashnode/image/upload/v1744652284582/f6a586e9-d09e-467f-ad12-81ccf538bc34.png align="center")

Dans l'√©tape "Meilleures pratiques pour les cl√©s d'acc√®s et alternatives", s√©lectionnez "Interface de ligne de commande (CLI)".

**Pourquoi devriez-vous s√©lectionner cette option ?** Choisir CLI garantit que la cl√© d'acc√®s g√©n√©r√©e est optimis√©e pour une utilisation avec l'AWS CLI et d'autres outils en ligne de commande (comme les commandes Docker qui poussent des images vers ECR), ce qui est exactement ce dont nous avons besoin pour notre flux de travail.

Laissez les autres configurations avec leurs param√®tres par d√©faut, puis cliquez sur "Cr√©er une cl√© d'acc√®s".

Une fois la cl√© cr√©√©e, vous verrez la nouvelle ID de cl√© d'acc√®s et la cl√© d'acc√®s secr√®te. Assurez-vous de copier et de stocker ces informations d'identification en toute s√©curit√©. Elles sont essentielles pour autoriser votre machine locale √† acc√©der √† AWS ECR et √† effectuer des op√©rations avec les permissions attribu√©es √† l'utilisateur `lambda-practice`.

![Cr√©ation termin√©e de la cl√© d'acc√®s pour l'utilisateur AWS IAM](https://cdn.hashnode.com/res/hashnode/image/upload/v1744652339772/c3d94e2a-f823-4d73-9a46-ab4d829289e9.png align="center")

### **Comment autoriser votre PC local √† publier des images dans le d√©p√¥t AWS ECR**

Maintenant que nous avons configur√© notre utilisateur IAM et que nous avons les cl√©s d'acc√®s en main, il est temps d'authentifier notre PC local afin que nous puissions pousser en toute s√©curit√© nos images Docker vers AWS ECR en utilisant l'AWS CLI. Suivez ces √©tapes :

#### √âtape 1 : Installer l'AWS CLI

Si vous n'avez pas encore install√© l'AWS CLI sur votre machine, t√©l√©chargez-le et installez-le en utilisant le guide officiel ici : [Installer l'AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).

Cet outil vous permet d'interagir avec votre compte AWS directement depuis la ligne de commande, ce qui est essentiel pour pousser des images vers ECR.

#### √âtape 2 : Configurer vos informations d'identification AWS CLI

Une fois install√©, vous devez configurer votre AWS CLI pour utiliser les informations d'identification associ√©es √† l'utilisateur `lambda-practice`. Ouvrez votre terminal et ex√©cutez la commande suivante pour configurer un nouveau profil nomm√© `lambda` :

```bash
aws configure --profile lambda
```

Vous serez invit√© √† entrer les d√©tails suivants :

* **ID de cl√© d'acc√®s AWS** : Collez l'ID de cl√© d'acc√®s que vous avez g√©n√©r√© pour l'utilisateur `lambda-practice`.

* **Cl√© d'acc√®s secr√®te AWS** : Collez la cl√© d'acc√®s secr√®te correspondante.

* **Nom de la r√©gion par d√©faut** : Entrez votre r√©gion AWS pr√©f√©r√©e (par exemple, `us-east-1` ou votre r√©gion pertinente).

* **Format de sortie par d√©faut** : Vous pouvez laisser cela comme `json` ou choisir votre format pr√©f√©r√©.

Cette commande configure un nouveau profil CLI appel√© `lambda` avec les informations d'identification de notre utilisateur IAM.

![Authentifier et autoriser AWS CLI avec la cl√© d'acc√®s de l'utilisateur AWS IAM](https://cdn.hashnode.com/res/hashnode/image/upload/v1744652931837/650c93af-25f0-4d7b-a202-50d825a6b77a.png align="center")

#### √âtape 3 : V√©rifier la configuration

Pour vous assurer que tout est configur√© correctement, ex√©cutez :

```bash
aws sts get-caller-identity --profile lambda
```

Cette commande retournera des d√©tails sur l'utilisateur IAM configur√© pour le profil `lambda`, confirmant que votre PC local est maintenant authentifi√© correctement.

Vous √™tes maintenant pr√™t ! Votre AWS CLI est configur√© avec le profil `lambda`, ce qui signifie que votre machine locale dispose des bonnes informations d'identification pour interagir avec votre d√©p√¥t AWS ECR et pousser des images Docker en utilisant les permissions attribu√©es √† votre utilisateur IAM `lambda-practice`.

## Comment t√©l√©charger votre image Docker vers le d√©p√¥t AWS ECR ‚§∂Ô∏è

Le t√©l√©chargement de votre image Docker vers AWS ECR est le moment o√π votre travail acharn√© est envoy√© √† votre d√©p√¥t afin qu'AWS Lambda puisse ensuite r√©cup√©rer et ex√©cuter votre conteneur. Maintenant que votre PC est autoris√© √† communiquer avec ECR, voyons comment t√©l√©charger l'image.

### √âtape 1 : Connectez-vous √† ECR avec Docker

Avant de pouvoir pousser votre image, vous devez authentifier Docker aupr√®s de votre compte AWS ECR. Vous faites cela en ex√©cutant une commande qui obtient un jeton d'authentification aupr√®s d'AWS et le transmet √† Docker. Par exemple :

```bash
aws ecr get-login-password --region <YOUR_REGION> --profile lambda | docker login --username AWS --password-stdin <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.amazonaws.com
```

D√©composons cela :

* `aws ecr get-login-password --region <YOUR_REGION> --profile lambda` : Cette partie utilise l'AWS CLI pour obtenir un mot de passe de connexion temporaire pour ECR. Assurez-vous de remplacer `<YOUR_REGION>` par la r√©gion dans laquelle votre d√©p√¥t ECR a √©t√© cr√©√© (par exemple, `us-east-1`).

* `| docker login --username AWS --password-stdin <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.`[`amazonaws.com`](http://amazonaws.com) : Le pipe (`|`) prend le mot de passe de la commande AWS CLI et le transmet en entr√©e √† `docker login`. La commande de connexion connecte ensuite Docker √† ECR en utilisant le nom d'utilisateur fourni (`AWS`) et le mot de passe. Remplacez `<YOUR_AWS_ACCOUNT_ID>` par votre v√©ritable ID de compte AWS.

### √âtape 2 : Consid√©rations environnementales

Cette commande fonctionne sur des environnements shell comme Powershell, zsh et bash.

**Utilisateurs Windows (CMD)** : 
Si vous utilisez l'invite de commande classique de Windows (CMD), la syntaxe de canalisation peut ne pas fonctionner de la m√™me mani√®re. Dans ce cas, vous pouvez envisager d'utiliser Windows PowerShell ou Git Bash. Alternativement, vous pouvez ex√©cuter la commande dans un environnement comme Windows Subsystem for Linux (WSL).

#### Pourquoi utiliser la bonne r√©gion ?

Il est crucial d'utiliser exactement la r√©gion o√π votre d√©p√¥t ECR a √©t√© cr√©√©. La r√©gion fait partie de l'URI de votre d√©p√¥t. Si vous utilisez la mauvaise r√©gion, la connexion √©chouera car elle ne trouvera pas le point de terminaison du d√©p√¥t correct.

#### Comment v√©rifier la r√©gion :

Connectez-vous √† votre console AWS, acc√©dez √† la section ECR et s√©lectionnez votre d√©p√¥t. L'URI ressemblera √† ceci : `<YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.amazonaws.com/lambda-practice`. Ici, `<YOUR_REGION>` est la r√©gion que vous devez utiliser dans votre commande de connexion.

### √âtape 3 : Construire votre image Docker avec la bonne √©tiquette

Avant de pousser l'image vers ECR, vous devez la construire sur votre machine locale et l'√©tiqueter avec le nom de votre d√©p√¥t. Dans votre terminal, naviguez jusqu'au dossier racine de votre projet (o√π se trouve votre Dockerfile), puis ex√©cutez (remplacez les espaces r√©serv√©s `<YOUR_AWS_ACCOUNT_ID>` et `<YOUR_REGION>` par votre ID de compte AWS et la r√©gion de votre d√©p√¥t AWS ECR) :

```bash
docker build -t <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.amazonaws.com/lambda-practice:latest
```

### √âtape 4 : Pousser votre image Docker vers AWS ECR

Une fois votre image construite et √©tiquet√©e, il est temps de la pousser vers votre d√©p√¥t ECR distant. Ex√©cutez la commande suivante :

```bash
docker push <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.amazonaws.com/lambda-practice:latest
```

Cette commande indique √† Docker de t√©l√©charger (ou "pousser") votre image vers le d√©p√¥t que vous avez cr√©√© pr√©c√©demment.

* Assurez-vous que l'URI du d√©p√¥t et l'√©tiquette correspondent √† ceux que vous avez utilis√©s dans la commande de construction.

* N'oubliez pas que si vous utilisez une r√©gion diff√©rente de celle de l'URI de votre d√©p√¥t, la pouss√©e √©chouera car AWS ne reconna√Ætra pas le point de terminaison du d√©p√¥t.

## Comment d√©ployer le conteneur de l'application sur AWS Lambda √† partir de l'image sur AWS ECR üöÄ

Vous pouvez d√©ployer votre fonction sur AWS Lambda de plusieurs mani√®res, chacune r√©pondant √† diff√©rents cas d'utilisation. Voici un bref aper√ßu :

1. **T√©l√©chargement de fichier ZIP** : Compressez simplement votre code et vos d√©pendances dans un fichier ZIP, puis t√©l√©chargez-le directement via la console AWS Lambda. Cette m√©thode traditionnelle est id√©ale pour les petites bases de code qui ne n√©cessitent pas de runtimes personnalis√©s.

2. **√âdition directe dans la console** : √âcrivez ou modifiez le code de votre fonction directement dans l'√©diteur de code AWS Lambda. Pratique pour des ajustements rapides, mais pas id√©al pour des projets plus importants.

3. **Image de conteneur** : Emballez votre application en tant qu'image de conteneur Docker et d√©ployez-la. Cette approche est particuli√®rement utile si vous avez des d√©pendances complexes, avez besoin d'un runtime personnalis√© ou souhaitez des environnements coh√©rents entre le d√©veloppement et la production.

Dans ce tutoriel, nous adoptons la voie de l'image de conteneur car elle offre flexibilit√©, coh√©rence et √©volutivit√© ‚Äì tout en nous permettant de r√©utiliser notre configuration Docker existante. Voici les √©tapes pour d√©ployer votre application conteneuris√©e sur AWS Lambda :

### √âtape 1 : Acc√©der √† la console AWS Lambda

Connectez-vous √† votre console de gestion AWS. Dans la barre de recherche en haut, tapez "Lambda" et s√©lectionnez le service AWS Lambda dans les r√©sultats du menu d√©roulant.

### √âtape 2 : Cr√©er une nouvelle fonction Lambda

Une fois sur la page Lambda, cliquez sur le bouton "Cr√©er une fonction". Vous verrez plusieurs options de cr√©ation de fonction. Pour nos besoins, s√©lectionnez l'option "Image de conteneur". Ce choix indique √† AWS que vous allez d√©ployer une application conteneuris√©e au lieu de t√©l√©charger un fichier ZIP.

### √âtape 3 : Nommer votre fonction

Dans l'√©cran de configuration de la fonction, entrez `lambda-practice` comme nom de votre nouvelle fonction Lambda. Ce nom identifie votre fonction dans AWS.

### √âtape 4 : Configurer l'image de conteneur

Sous les param√®tres "Image de conteneur", cliquez sur le bouton "Parcourir les images". Une nouvelle fen√™tre devrait appara√Ætre, listant vos images disponibles depuis AWS Elastic Container Registry (ECR).

S√©lectionnez le d√©p√¥t que vous avez pr√©c√©demment cr√©√© (par exemple, celui nomm√© `lambda-practice`), et choisissez l'image √©tiquet√©e comme `latest`.

![Cr√©er une fonction AWS Lambda](https://cdn.hashnode.com/res/hashnode/image/upload/v1744655907615/df0e3576-5fe6-4387-8da5-d2964b36a2af.png align="center")

![Connecter l'image AWS ECR √† la fonction AWS Lambda](https://cdn.hashnode.com/res/hashnode/image/upload/v1744655978526/fafd6b35-579a-4439-b15e-dd5e3dba2acf.png align="center")

![S√©lectionner l'image du d√©p√¥t AWS ECR](https://cdn.hashnode.com/res/hashnode/image/upload/v1744656031049/3de3bcc1-2034-4518-acb6-84adb6136752.png align="center")

### √âtape 5 : Finaliser et cr√©er

Maintenant, vous voudrez passer en revue les param√®tres de base. Dans cette √©tape, vous pourriez √©galement configurer des options suppl√©mentaires telles que l'allocation de m√©moire, les limites de temps d'attente et les variables d'environnement, en fonction des besoins de votre application.

Une fois tout configur√©, cliquez sur "Cr√©er une fonction" pour finaliser le d√©ploiement.

### Comment activer l'acc√®s √† votre fonction Lambda

Super ‚Äì bravo, vous avez d√©ploy√© avec succ√®s votre image depuis AWS ECR vers AWS Lambda ! Maintenant, l'√©tape suivante consiste √† vous assurer que votre fonction est op√©rationnelle et peut √™tre d√©clench√©e correctement. Mais vous vous demandez peut-√™tre, "Comment acc√©der √† ma fonction Lambda pour voir si elle fonctionne ?" D√©composons cela :

#### Comprendre les d√©clencheurs de fonction Lambda

Il existe plusieurs fa√ßons d'invoquer une fonction Lambda, et AWS prend en charge plusieurs options de d√©clenchement. En voici quelques-unes :

* **Mappage de source d'√©v√©nement** : D√©clenche automatiquement votre fonction en r√©ponse aux changements dans des services comme DynamoDB, Kinesis ou S3.

* **√âv√©nements planifi√©s** : Configurez des invocations planifi√©es de type cron via Amazon CloudWatch Events.

* **API Gateway** : Cr√©ez des API RESTful qui appellent votre fonction.

* **AWS SDK/CLI** : Invoquez directement la fonction en utilisant l'AWS SDK ou les commandes CLI.

* **URL de fonction** : Une mani√®re simple d'exposer votre fonction via HTTPS, vous donnant une URL publique que les utilisateurs ou les applications peuvent appeler directement.

Dans ce tutoriel, nous allons utiliser une URL de fonction pour d√©clencher notre fonction Lambda via un √©v√©nement HTTP. Cette m√©thode vous permet d'invoquer votre fonction depuis l'internet public et est parfaite pour tester ou construire des API publiques.

### Comment cr√©er une URL de fonction pour votre fonction Lambda

Maintenant que vous √™tes sur la page des d√©tails de votre fonction Lambda, voici comment cr√©er une URL de fonction √©tape par √©tape :

Tout d'abord, sur la page de votre fonction Lambda, cliquez sur l'onglet "Configuration" en haut. Dans la section Configuration, trouvez et s√©lectionnez le sous-onglet "URL de fonction". C'est ici que vous g√©rez l'URL publique de votre fonction.

Cliquez sur le bouton "Cr√©er une URL de fonction". Cela ouvrira un nouvel √©cran de configuration pour la configuration de votre URL de fonction.

![Cr√©er une URL de fonction pour la fonction AWS Lambda](https://cdn.hashnode.com/res/hashnode/image/upload/v1744656877335/835422c5-8c88-418a-b1f2-3650360069c3.png align="center")

* **Type d'authentification** : D√©finissez le type d'authentification sur AUCUN. Ce param√®tre permet un acc√®s public et non authentifi√© √† votre fonction depuis Internet, ce qui signifie que toute personne disposant de l'URL peut l'invoquer. (C'est id√©al pour les tests ou la cr√©ation de services publics, mais soyez prudent avec la s√©curit√© dans les environnements de production !)

* **Param√®tres suppl√©mentaires** : Dans la section Param√®tres suppl√©mentaires, activez Configurer le partage des ressources cross-origin (CORS). Cela est utile si vous pr√©voyez d'appeler votre fonction depuis des applications c√¥t√© client h√©berg√©es sur diff√©rents domaines. Consid√©rez cela comme une fen√™tre ouverte pour que votre application communique avec d'autres pages web ou services.

Apr√®s avoir configur√© vos param√®tres, cliquez sur le bouton appropri√© pour cr√©er ou enregistrer l'URL de la fonction.

![Configurer l'URL de la fonction AWS pour la fonction AWS Lambda](https://cdn.hashnode.com/res/hashnode/image/upload/v1744656860868/cd98ce34-7fdf-4cb6-be85-a25d3718e2e6.png align="center")

#### V√©rifier votre URL de fonction

Une fois configur√©e, vous verrez l'URL de la fonction affich√©e sur la m√™me page. Vous pouvez maintenant copier cette URL.

Collez l'URL dans un navigateur ou utilisez des outils comme `curl` ou Postman pour envoyer une requ√™te HTTP, d√©clenchant votre fonction Lambda et v√©rifiant qu'elle fonctionne comme pr√©vu.

Vous devriez obtenir une r√©ponse comme celle-ci sur votre navigateur :

![Application d√©ploy√©e sur AWS Lambda](https://cdn.hashnode.com/res/hashnode/image/upload/v1744656939019/fcda2621-8057-438b-8d5a-8ac8936b6322.png align="center")

Et c'est tout ! Vous avez r√©ussi √† configurer un point de terminaison HTTP public qui d√©clenche votre fonction AWS Lambda. Que vous testiez votre d√©ploiement ou construisiez une API publique, l'URL de la fonction facilite l'interaction de quiconque avec votre fonction.

### **F√©licitations ‚Äì Vous l'avez fait !**

Vous venez de parcourir tout le chemin du d√©ploiement d'un serveur web Node.js, conteneuris√© avec Docker, jusqu'√† AWS Lambda en utilisant AWS ECR comme votre d√©p√¥t d'images. üöÄ

De l'√©criture et de la conteneurisation de votre application Node.js, √† la cr√©ation d'un d√©p√¥t AWS ECR, en passant par la configuration des utilisateurs IAM et des cl√©s d'acc√®s, la pouss√©e de votre image Docker vers ECR, jusqu'√† son d√©ploiement sur Lambda ‚Äì vous avez tout couvert comme un pro. üí™

Non seulement cela, mais vous avez √©galement configur√© une URL de fonction publique afin que votre application serverless puisse d√©sormais g√©rer les requ√™tes depuis n'importe o√π dans le monde üåç.

Vous venez de combiner des flux de travail cloud natifs modernes avec un d√©ploiement serverless ‚Äì vous offrant flexibilit√©, √©volutivit√© et des temps de r√©ponse ultra-rapides sans le casse-t√™te de la gestion des serveurs üòÅ.

üëè Donnez-vous une tape dans le dos. Vous avez officiellement conteneuris√© et d√©ploy√© votre serveur web Node.js sur AWS Lambda !

## Avantages de l'adoption du mod√®le Serverless dans les entreprises üìú

En ce qui concerne le d√©ploiement d'applications dans le cloud, le mod√®le serverless a vraiment boulevers√© l'ancien manuel et a aid√© les entreprises √† √©conomiser sur les co√ªts du cloud ! D√©composons cela en termes simples et concrets.

### **Efficacit√© des co√ªts üí∞**

Pour la plupart des entreprises ‚Äì en particulier les startups ‚Äì le serverless offre un avantage financier majeur. Voici pourquoi :

Dans les mod√®les traditionnels comme l'IaaS (Infrastructure as a Service) et le PaaS (Platform as a Service), tels que l'utilisation d'AWS EC2 ou d'AWS Elastic Beanstalk, vous provisionnez des ressources √† l'avance.

Par exemple : Vous lancez un serveur avec 4 Go de RAM et 4 vCPU, et AWS vous facture 100 $/mois (cela couvre 730 heures ‚Äì le mois entier). M√™me si votre application ne fait presque rien ‚Äì disons qu'elle ne traite que des requ√™tes r√©elles pendant 120 heures et n'utilise que 1 Go de m√©moire ‚Äì vous payez toujours les 100 $ complets, car les ressources √©taient r√©serv√©es et en attente de trafic 24h/24 et 7j/7.

Mais avec le Serverless :

* Vous n'allouez pas ou ne r√©servez pas de puissance de calcul √† l'avance.

* Votre application ne fonctionne que lorsque quelqu'un en a r√©ellement besoin (par exemple, lorsqu'un utilisateur effectue une requ√™te HTTP).

* Vous ne payez que pour le temps d'ex√©cution r√©el et les ressources utilis√©es.

Par exemple, si votre fonction ne fonctionne que pendant 50 heures dans un mois et utilise 1,5 Go de RAM, vous pourriez payer quelque chose comme 30 $, contre les 100 $ fixes que vous auriez pay√©s sur EC2 ou Elastic Beanstalk.

### **√âvolutivit√© sans stress üìà**

Les plateformes Serverless comme AWS Lambda g√®rent automatiquement :

* La mise √† l'√©chelle lors d'une forte demande.

* La r√©duction √† z√©ro lorsqu'elles sont inactives.

Cela signifie que votre √©quipe n'aura pas besoin de pr√©dire ou de provisionner des ressources pendant les pics de trafic. Que 1 ou 1 million d'utilisateurs visitent votre application, le fournisseur de cloud g√®re le reste.

### **Op√©rations simplifi√©es ‚öôÔ∏è**

Pour votre √©quipe logicielle :

* Plus besoin de surveiller les serveurs, d'appliquer des mises √† jour de s√©curit√© ou de s'inqui√©ter des √©quilibreurs de charge.

* Vous vous concentrez uniquement sur l'√©criture de la logique m√©tier et le d√©ploiement du code.

* Le fournisseur de cloud g√®re l'infrastructure en arri√®re-plan.

Cela lib√®re le temps de votre √©quipe, r√©duit les t√¢ches de maintenance et acc√©l√®re les temps de d√©veloppement.

### **Meilleur retour sur investissement (ROI) üíπ**

Parce que vous ne payez que ce que vous utilisez, le rapport co√ªt-valeur s'am√©liore consid√©rablement. Les startups et les entreprises peuvent :

* Lancer plus rapidement.

* Exp√©rimenter sans risque financier.

* Mettre √† l'√©chelle sans factures surprises.

* √âviter de trop payer pour des ressources inactives.

## Inconv√©nients du mod√®le Serverless üö´

Aussi excitant et √©conomique que semble le mod√®le serverless, la r√®gle d'or de la technologie s'applique toujours : chaque solution a ses compromis.

Examinons quelques inconv√©nients importants que vous devriez consid√©rer :

### **Pas de support int√©gr√© pour les t√¢ches en arri√®re-plan ‚è∞**

Contrairement aux serveurs traditionnels o√π vous pouvez ex√©cuter des processus en arri√®re-plan ‚Äì comme envoyer des newsletters √† minuit ou nettoyer des bases de donn√©es √† des heures planifi√©es ‚Äì les plateformes serverless telles qu'AWS Lambda ne prennent pas en charge nativement les t√¢ches en arri√®re-plan ou les travaux r√©currents.

Par exemple, supposons que vous souhaitiez que votre application g√©n√®re automatiquement des rapports tous les jours √† 3 heures du matin. Dans une configuration de serveur typique, vous √©criviez simplement un cron job et c'√©tait r√©gl√©.

Mais avec Lambda ou serverless, vous ne pouvez pas faire cela directement √† l'int√©rieur de votre fonction d√©ploy√©e. Au lieu de cela, vous avez besoin d'outils externes comme :

* AWS EventBridge (pour la planification et le d√©clenchement de fonctions Lambda)

* Ou d'autres planificateurs natifs du cloud.

Cela ajoute un peu de configuration suppl√©mentaire, de gestion et parfois des co√ªts suppl√©mentaires.

### **Co√ªts cloud impr√©visibles üí∞**

L'un des principaux arguments de vente du serverless est le "pay-as-you-use" ‚Äì mais cela peut aussi devenir un angle mort financier, car :

* Les co√ªts d√©pendent du volume de trafic et de l'utilisation des ressources.

* Si votre application devient soudainement virale ou conna√Æt un pic de trafic, votre facture cloud pourrait s'envoler sans avertissement.

Par exemple, une application qui fonctionne de mani√®re stable √† 30 $/mois pour un trafic faible pourrait atteindre 1000 $ ou plus si une campagne marketing ou un √©v√©nement externe attire un grand nombre d'utilisateurs vers votre service. Bien que cela signifie que votre application r√©ussit, votre budget pourrait en prendre un coup.

En revanche, avec les mod√®les traditionnels comme AWS EC2 ou Elastic Beanstalk, vos co√ªts sont g√©n√©ralement pr√©visibles ‚Äì m√™me si votre serveur reste inactif tout le mois.

## Quand adopter le mod√®le Serverless ü§î

Alors, le Serverless est-il toujours le bon choix ? Pas n√©cessairement !

Si vous pr√©voyez :

* **Des charges de travail stables et pr√©visibles**, EC2 ou Elastic Beanstalk pourraient offrir plus de certitude en termes de co√ªts.

* **Des t√¢ches en arri√®re-plan de longue dur√©e**, le serverless n'est pas id√©al sans services suppl√©mentaires.

* **Un contr√¥le en temps r√©el sur les limites des ressources**, les serveurs traditionnels vous offrent plus de flexibilit√©.

Mais si votre application a un trafic par √†-coups (les utilisateurs viennent et partent), une logique bas√©e sur des √©v√©nements (comme des API ou des webhooks), ou si vous voulez un minimum de frais g√©n√©raux op√©rationnels, alors le Serverless peut vous faire gagner du temps, des efforts et de l'argent.

### **Quand le Serverless est le choix parfait : Une startup construisant une API bas√©e sur des √©v√©nements**

Imaginez que vous dirigez une petite startup technologique qui vient de lancer une application pour r√©server des cours de fitness. Votre √©quipe est petite, les budgets sont serr√©s et le trafic est impr√©visible ‚Äì certains jours vous avez 50 utilisateurs, d'autres jours 5 000.

Dans ce cas :

* Votre backend g√®re principalement des requ√™tes HTTP : nouvelles inscriptions, r√©servations de cours, annulations et paiements.

* Le trafic augmente pendant les pauses d√©jeuner et les week-ends, mais est calme la nuit.

* Vous ne voulez pas embaucher un ing√©nieur DevOps √† temps plein juste pour g√©rer les serveurs.

üëâ **Pourquoi le Serverless est parfait dans ce cas :**

* Vous ne payez que lorsque les gens utilisent votre application.

* Pas besoin de g√©rer ou de provisionner des serveurs.

* AWS Lambda se met √† l'√©chelle automatiquement en fonction de la demande.

* Rapide √† d√©ployer, facile √† connecter √† d'autres services AWS (comme DynamoDB pour votre base de donn√©es, S3 pour les images et SES pour les emails).

En utilisant le Serverless dans ce cas, vous pouvez √©conomiser de l'argent, vous mettre √† l'√©chelle automatiquement et rester concentr√© sur les fonctionnalit√©s ‚Äì pas sur l'infrastructure.

### **Quand le Serverless n'est pas une bonne id√©e : Une plateforme de streaming vid√©o**

Maintenant, imaginez que vous construisez le prochain service de type YouTube pour un public de niche ‚Äì disons, du contenu √©ducatif pour les universit√©s.

Dans ce cas :

* Votre plateforme n√©cessite un traitement en arri√®re-plan continu : encodage de vid√©os, g√©n√©ration de miniatures et leur envoi vers un CDN.

* Les utilisateurs diffusent du contenu 24h/24 et 7j/7, ce qui signifie que votre application est toujours sous charge.

* Les t√¢ches en arri√®re-plan comme les mises √† jour du moteur de recommandation ou les rapports nocturnes doivent s'ex√©cuter fr√©quemment.

üëâ **Pourquoi le Serverless pourrait √™tre une mauvaise id√©e :**

* Les fonctions comme AWS Lambda ont une limite de temps d'ex√©cution (par exemple, 15 minutes maximum par ex√©cution).

* Le traitement continu ou le streaming ne correspondent pas √† la nature √† la demande et √©ph√©m√®re du serverless.

* Les co√ªts pourraient s'envoler puisque l'application fonctionne presque tout le temps, ce qui la rend plus ch√®re qu'un cluster EC2 ou Kubernetes d√©di√©.

**Alternative meilleure :** 
Pour ce type de cas d'utilisation, une configuration bas√©e sur des serveurs traditionnels ‚Äì comme EC2 ou l'orchestration de conteneurs via ECS ou Kubernetes ‚Äì offrirait plus de contr√¥le, une tarification pr√©visible et un support pour les processus de longue dur√©e.

‚úÖ **En r√©sum√© :** 
Le Serverless est fantastique pour les applications modernes, mais comme tout outil, il est pr√©f√©rable utilis√© lorsque ses forces correspondent aux besoins de votre projet.

## Conclusion üìù

F√©licitations pour √™tre arriv√© √† la fin de ce tutoriel ! üöÄ

Dans cet article, nous avons explor√© la puissance de l'informatique serverless en parcourant √©tape par √©tape le processus de d√©ploiement d'un serveur web Node.js en utilisant Docker et AWS Lambda.

De la construction de votre image de conteneur, √† son envoi vers AWS ECR, et enfin √† son d√©ploiement sur Lambda ‚Äì vous avez maintenant vu √† quel point il est facile de faire fonctionner une application sans le tracas de l'approvisionnement des serveurs.

Nous avons √©galement discut√© des avantages de l'adoption du mod√®le Serverless pour le d√©ploiement de vos applications, de ses inconv√©nients et des cas d'utilisation r√©els dans lesquels vous devriez adopter l'approche serverless.

## **√Ä propos de l'auteur üë®‚Äçüíª**

Bonjour, je suis Prince ! Je suis un ing√©nieur DevOps et architecte cloud passionn√© par la construction, le d√©ploiement et la gestion d'applications √©volutives et le partage de connaissances avec la communaut√© technologique.

Si vous avez appr√©ci√© cet article, vous pouvez en apprendre plus sur moi en explorant davantage mes blogs et projets sur mon [profil LinkedIn](https://www.linkedin.com/in/prince-onukwili-a82143233/). Vous pouvez trouver mes [articles LinkedIn ici](https://www.linkedin.com/in/prince-onukwili-a82143233/details/publications/). Vous pouvez √©galement [visiter mon site web](https://prince-onuk.vercel.app/achievements#articles) pour lire plus de mes articles. Restons en contact et grandissons ensemble ! üòä