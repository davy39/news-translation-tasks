---
title: Utiliser Scrapy pour le Web Scraping en Python
subtitle: ''
author: Beau Carnes
co_authors: []
series: null
date: '2023-04-27T15:44:42.000Z'
originalURL: https://freecodecamp.org/news/use-scrapy-for-web-scraping-in-python
coverImage: https://www.freecodecamp.org/news/content/images/2023/04/scrapy.png
tags:
- name: Python
  slug: python
- name: youtube
  slug: youtube
seo_title: Utiliser Scrapy pour le Web Scraping en Python
seo_desc: 'Are you tired of manually collecting data from websites? Have you ever
  wished you could automate the process and gather massive amounts of data in a fraction
  of the time?

  We just published a course on the freeCodeCamp.org YouTube channel that will te...'
---

En avez-vous assez de collecter manuellement des données depuis des sites web ? Avez-vous déjà souhaité automatiser le processus et recueillir d'énormes quantités de données en un temps record ?

Nous venons de publier un cours sur la chaîne YouTube freeCodeCamp.org qui vous apprendra à scraper des sites web avec Python en utilisant Scrapy.

Joe Kearney a développé ce cours. Il est développeur full stack et expert en web scraping.

Ce cours vidéo complet couvre tout ce que vous devez savoir pour commencer avec le web scraping en utilisant Scrapy. Vous apprendrez à créer votre premier spider Scrapy, à parcourir des sites web et à extraire des données de chaque page, à nettoyer les données avec Items et Item Pipelines, et à sauvegarder les données dans des fichiers CSV, des bases de données MySQL et Postgres. De plus, vous découvrirez comment utiliser des user-agents et des en-têtes fictifs pour éviter d'être bloqué, et comment utiliser des proxies pour augmenter vos efforts de web scraping sans être banni.

Mais ce n'est pas tout - ce cours pour débutants sur Scrapy va au-delà des bases et vous enseigne également comment déployer votre scraper dans le cloud et le planifier pour qu'il s'exécute périodiquement. Vous apprendrez à utiliser Scrapyd, ScrapeOps et Scrapy Cloud pour exécuter vos spiders dans le cloud, ce qui facilite l'augmentation de vos efforts de scraping et l'automatisation de votre extraction de données.

Le cours pour débutants sur Scrapy est divisé en 13 parties faciles à suivre qui couvrent :

1. Une introduction à Scrapy et un aperçu du contenu du cours.
2. Configuration d'un environnement virtuel et installation de Scrapy.
3. Création d'un nouveau projet Scrapy.
4. Construction de votre premier spider Scrapy pour parcourir et extraire des données.
5. Développement d'un spider de découverte et d'extraction pour des tâches de scraping plus complexes.
6. Nettoyage des données avec Items et Item Pipelines.
7. Sauvegarde des données extraites dans des fichiers CSV, MySQL et des bases de données Postgres.
8. Utilisation de user-agents et d'en-têtes de navigateur fictifs pour éviter d'être bloqué par les sites web.
9. Augmentation de vos efforts de web scraping avec des proxies rotatifs et des API de proxy.
10. Déploiement de vos spiders dans le cloud en utilisant Scrapyd.
11. Exécution de spiders dans le cloud avec ScrapeOps.
12. Planification de l'exécution périodique des spiders dans le cloud en utilisant Scrapy Cloud.
13. Conclusion du cours et discussion des prochaines étapes pour une maîtrise approfondie.

À la fin de ce cours, vous aurez une solide base en Python Scrapy et serez prêt à relever même les projets de web scraping les plus difficiles. Que vous soyez scientifique des données, marketeur ou développeur, ce cours vous fournira les compétences nécessaires pour exploiter tout le potentiel des données web.

Regardez le cours complet sur [la chaîne YouTube freeCodeCamp.org](https://www.youtube.com/watch?v=mBoX_JCKZTE) (5 heures de visionnage).

%[https://www.youtube.com/watch?v=mBoX_JCKZTE]