---
title: Comment am√©liorer les LLMs en math√©matiques √† l'aide d'agents IA, MathJS et
  des appels d'outils BaseAI
subtitle: ''
author: Maham Codes
co_authors: []
series: null
date: '2024-12-19T14:53:46.717Z'
originalURL: https://freecodecamp.org/news/make-llms-better-at-math-with-ai-agents
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1734537732263/2ec966b6-d1d3-4d0f-ae37-982ef26ebc55.jpeg
tags:
- name: llm
  slug: llm
- name: AI
  slug: ai
- name: ai agents
  slug: ai-agents
- name: openai
  slug: openai
seo_title: Comment am√©liorer les LLMs en math√©matiques √† l'aide d'agents IA, MathJS
  et des appels d'outils BaseAI
seo_desc: Large Language Models (LLMs) like GPT often struggle to answer mathematical
  questions. In fact, if you ask a human a tough math question, like what is 185 cm
  in ft, they‚Äôll struggle as well. They‚Äôd likely need a calculator to perform this
  conversion ...
---

Les grands mod√®les de langage (LLMs) comme GPT ont souvent du mal √† r√©pondre aux questions math√©matiques. En fait, si vous posez une question de maths difficile √† un humain, comme "Qu'est-ce que 185 cm en pieds", il aura aussi du mal. Il aurait probablement besoin d'une calculatrice pour effectuer cette conversion ‚Äì et il en va de m√™me pour les LLMs.

Les LLMs sont con√ßus pour g√©rer le langage naturel. Bien qu'ils soient g√©n√©ralement bons pour g√©n√©rer des mots et assembler le langage, lorsqu'il s'agit de math√©matiques, ils ont souvent besoin d'aide.

Contrairement √† une calculatrice ou √† une biblioth√®que math√©matique, les LLMs ne peuvent parfois pas raisonner ou traiter la logique symbolique. Ainsi, bien qu'ils puissent g√©rer l'arithm√©tique de base, surtout si c'est quelque chose de familier de leurs donn√©es d'entra√Ænement, ils ont g√©n√©ralement du mal avec des probl√®mes plus complexes, en particulier les probl√®mes √©crits.

La question principale est de savoir comment corriger cette limitation des LLMs ?

Sans aucun doute, les LLMs ont √©volu√© avec le lancement de mod√®les de raisonnement comme GPT-o1 ou Llama 3.3. Mais ils hallucinent toujours, manquent d'acc√®s aux donn√©es en temps r√©el, ont du mal avec les math√©matiques complexes et produisent des r√©sultats non d√©terministes. Heureusement, nous pouvons r√©soudre ce probl√®me en utilisant des agents IA.

## Qu'est-ce qu'un agent IA ?

Les agents IA sont des logiciels autonomes qui utilisent les LLMs pour effectuer des t√¢ches au-del√† de la simple g√©n√©ration de texte.

Ils prennent des d√©cisions et ex√©cutent des actions. Les agents IA s'appuient sur les LLMs pour la compr√©hension du langage mais ajoutent des capacit√©s comme la m√©moire, l'interaction en temps r√©el et la prise de d√©cision.

## Comment les agents IA r√©solvent les limitations des LLMs

Les agents augmentent les capacit√©s des LLMs de plusieurs mani√®res :

* **M√©moire :** Les agents IA aident les LLMs √† conserver le contexte des interactions pass√©es, am√©liorant la coh√©rence des conversations √† long terme.

* **Traitement asynchrone :** Les agents g√®rent plusieurs t√¢ches √† la fois, am√©liorant l'efficacit√©.

* **V√©rification des faits :** Ils se connectent √† des sources de donn√©es en temps r√©el pour v√©rifier les informations.

* **Math√©matiques am√©lior√©es :** Ils int√®grent des outils pour g√©rer des calculs complexes.

* **Sortie coh√©rente :** Les agents standardisent les sorties des LLMs pour un formatage uniforme.

Pour aider √† r√©soudre certaines des limitations math√©matiques des LLMs, cr√©ons un agent IA qui construit une calculatrice en utilisant MathJS et les appels d'outils BaseAI.

## Pr√©requis

Dans ce tutoriel, j'utiliserai la pile technologique suivante :

* [MathJS](https://mathjs.org/) ‚Äî une biblioth√®que math√©matique compl√®te pour JavaScript et Node.js.

* [BaseAI](https://baseai.dev) ‚Äî le framework web pour construire des agents IA localement.

* [Langbase](https://langbase.com) ‚Äî la plateforme pour construire et d√©ployer vos agents IA serverless.

* [OpenAI](https://openai.com) ‚Äî pour obtenir la cl√© LLM pour le mod√®le pr√©f√©r√©.

Vous devrez √©galement :

* Vous inscrire sur Langbase pour obtenir acc√®s √† la cl√© API.

* Vous inscrire sur OpenAI pour g√©n√©rer la cl√© LLM pour le mod√®le que vous souhaitez utiliser (pour cette d√©monstration, j'utiliserai GPT-4o mini).

Commen√ßons !

## √âtape 1 : Cr√©er un r√©pertoire et initialiser npm

Pour commencer √† cr√©er un agent IA, vous devez cr√©er un r√©pertoire sur votre machine locale et installer toutes les d√©pendances de d√©veloppement pertinentes. Vous pouvez le faire en naviguant vers celui-ci et en ex√©cutant la commande suivante dans le terminal :

```bash
mkdir my-project

npm init -y

npm install dotenv mathjs
```

Cette commande cr√©era un fichier `package.json` dans votre r√©pertoire de projet avec des valeurs par d√©faut. Elle installera √©galement le package `dotenv` pour lire les variables d'environnement √† partir du fichier `.env`, et `mathjs` pour g√©rer les op√©rations math√©matiques.

## √âtape 2 : Cr√©er un Pipe d'agent IA

Ensuite, nous allons cr√©er un pipe d'agent IA. Les pipes sont diff√©rents des autres agents, car ils **sont des agents IA serverless avec des outils agentiques** qui peuvent fonctionner avec n'importe quel langage ou framework. Ils sont facilement d√©ployables, et avec une seule API, ils vous permettent de connecter 100+ LLMs √† n'importe quelle donn√©e pour construire n'importe quel workflow d'API de d√©veloppeur.

Pour cr√©er votre pipe d'agent IA, naviguez vers votre r√©pertoire de projet. Ex√©cutez la commande suivante :

```bash
npx baseai@latest pipe
```

En ex√©cutant cette commande, vous verrez les invites suivantes :

```bash
BaseAI n'est pas install√© mais est requis pour fonctionner. Souhaitez-vous l'installer ? Oui/Non

Nom du pipe ? pipe-with-tool

Description du pipe ? Un pipe d'agent IA qui peut appeler des outils

Statut du pipe ? Public/Priv√©

Prompt syst√®me ? Vous √™tes un assistant IA utile
```

Une fois que vous avez termin√© avec le nom, la description et le statut du pipe d'agent IA, tout sera configur√© automatiquement pour vous. Votre pipe sera cr√©√© avec succ√®s √† `/baseai/pipes/pipe-with-tool.ts`.

<div data-node-type="callout">
<div data-node-type="callout-emoji">üí°</div>
<div data-node-type="callout-text">Pipe est un agent IA serverless. Il a une m√©moire agentique et des outils.</div>
</div>

## √âtape 3 : Ajouter un fichier .env

Cr√©ez un fichier `.env` dans le r√©pertoire racine de votre projet et ajoutez-y la cl√© API [OpenAI](https://platform.openai.com/api-keys) et Langbase. Vous pouvez acc√©der √† votre cl√© API Langbase depuis [ici](https://langbase.com/docs/api-reference/api-keys).

## √âtape 4 : Configurer le Pipe d'agent IA

Dans cette √©tape, nous allons configurer le pipe d'agent IA cr√©√© selon nos besoins.

Naviguez vers votre r√©pertoire de projet et ouvrez le pipe d'agent IA que vous avez cr√©√©. Vous pouvez ajouter un prompt syst√®me au pipe si vous le souhaitez. Je vais utiliser `Vous √™tes un assistant IA utile qui fonctionnera comme une calculatrice.` Voici √† quoi cela ressemblera :

```typescript
import { PipeI } from '@baseai/core';

const pipePipeWithTool = (): PipeI => ({
   apiKey: process.env.LANGBASE_API_KEY!,
   name: 'pipe-with-tool',
   description: 'Un pipe d\'agent IA qui peut appeler des outils',
   status: 'private',
   model: 'openai:gpt-4o-mini',
   stream: true,
   json: false,
   store: true,
   moderate: true,
   top_p: 1,
   max_tokens: 1000,
   temperature: 0.7,
   presence_penalty: 1,
   frequency_penalty: 1,
   stop: [],
   tool_choice: 'auto',
   parallel_tool_calls: true,
   messages: [{ role: 'system', content: `Vous √™tes un assistant IA utile qui fonctionnera comme une calculatrice.` }],
   variables: [],
   memory: [],
   tools: []
});

export default pipePipeWithTool;
```

## √âtape 5 : Cr√©er un outil Calculatrice

L'appel d'outil permet √† un LLM d'utiliser des outils externes, tels que des fonctions, des APIs ou d'autres ressources, pour obtenir des informations ou effectuer des t√¢ches au-del√† de ses connaissances int√©gr√©es.

Dans cette √©tape, nous allons cr√©er un **Outil Calculatrice** en utilisant les outils BaseAI. Cet outil g√©rera tous les calculs math√©matiques dans votre projet, garantissant qu'ils sont sans erreur et fiables. L'outil est polyvalent et adapt√© √† la fois aux calculs simples (par exemple, `5+7`) et aux calculs plus avanc√©s (par exemple, `sin(pi/4) + log(10)`).

Il sera √©galement particuli√®rement utile pour r√©duire les hallucinations, ce qu'il peut faire en d√©chargeant les calculs vers un outil externe. Cela √©vite les r√©ponses incorrectes ou fabriqu√©es que les LLMs pourraient autrement g√©n√©rer. Cela r√©duit √©galement la probabilit√© d'obtenir des r√©ponses incorrectes du LLM en rev√©rifiant ou en recueillant des donn√©es suppl√©mentaires pour garantir l'exactitude.

En utilisant les fonctionnalit√©s d'appel d'outil intelligent et de m√©moire de BaseAI, nous pouvons r√©duire les hallucinations de l'IA de **21%** tout en am√©liorant la capacit√© du mod√®le √† auto-corriger ses sorties.

Ces am√©liorations sont utiles lorsqu'il s'agit d'expressions math√©matiques complexes ou d'√©valuations de formules et devraient vraiment am√©liorer la qualit√© et l'exactitude des r√©ponses du LLM.

Pour cr√©er un outil calculatrice dans votre projet qui sera responsable de l'ex√©cution de tous les calculs sans erreur, ex√©cutez cette commande dans votre terminal :

```bash
npx baseai@latest tool
```

Vous serez invit√© √† fournir un nom et une description de l'outil dans votre terminal. Voici ce que je fournis :

```bash
Nom de l'outil ? Calculator

Description de l'outil ? √âvaluer les expressions math√©matiques
```

Votre outil sera cr√©√© √† `/baseai/tools/calculator.ts`.

## √âtape 6 : Configurer l'outil Calculatrice

Pour configurer l'outil, naviguez vers votre r√©pertoire de projet et ouvrez l'outil que vous avez cr√©√©. Vous pouvez le trouver √† `/baseai/tools/calculator.ts`.

Voici √† quoi ressemblera le code :

```typescript
import { ToolI } from '@baseai/core';

export async function calculator() {
   // Ajoutez votre logique d'outil ici
   // Cette fonction sera appel√©e lorsque l'outil sera ex√©cut√©
}

const toolCalculator = (): ToolI => ({
   run: calculator,
   type: 'function' as const,
   function: {
       name: 'toolCalculator',
       description: '√âvaluer les expressions math√©matiques',
       parameters: {}
   }
});

export default toolCalculator;
```

La cl√© `run` dans l'objet `toolCalculator` est la fonction qui sera ex√©cut√©e lorsque l'outil sera appel√©. Vous pouvez √©crire votre logique pour obtenir les calculs math√©matiques pour une fonction donn√©e.

Mettez √† jour la description et le code de l'outil calculatrice en ajoutant des param√®tres √† la fonction calculatrice. Le LLM donnera des valeurs √† ces param√®tres lorsqu'il appellera l'outil. Et il importera m√™me math depuis `mathjs`. Voici le code final :

```typescript
import * as math from 'mathjs';

export async function calculator({expression}: {expression: string}) {
   return math.evaluate(expression);
}

const toolCalculator = () => ({
   run: calculator,
   type: 'function' as const,
   function: {
       name: 'calculator',
       description:
           `Un outil qui peut √©valuer des expressions math√©matiques. ` +
           `Exemples d'expressions : ` +
           `'5.6 * (5 + 10.5)', '7.86 cm to inch', 'cos(80 deg) ^ 4'.`,
       parameters: {
           type: 'object',
           required: ['expression'],
           properties: {
               expression: {
                   type: 'string',
                   description: 'L\'expression math√©matique √† √©valuer.',
               },
           },
       },
   },
});

export default toolCalculator;
```

## √âtape 7 : Int√©grer l'outil dans le Pipe d'agent IA

Dans cette √©tape, nous allons int√©grer l'outil dans le pipe d'agent IA que nous avons cr√©√©. Pour cela, ouvrez le fichier pipe pr√©sent √† `/baseai/pipes/pipe-with-tool.ts` et importez l'outil calculatrice en haut du fichier. Nous allons √©galement appeler l'outil calculatrice dans le tableau des outils du pipe.

```typescript
import {PipeI} from '@baseai/core';
import toolCalculator from '../tools/calculator';

const pipeWithTools = (): PipeI => ({
   apiKey: process.env.LANGBASE_API_KEY!,
   name: 'pipe-with-tool',
   description: 'Un pipe d\'agent IA qui peut appeler des outils',
   status: 'public',
   model: 'openai:gpt-4o-mini',
   stream: false,
   json: false,
   store: true,
   moderate: true,
   top_p: 1,
   max_tokens: 1000,
   temperature: 0.7,
   presence_penalty: 1,
   frequency_penalty: 1,
   stop: [],
   tool_choice: 'auto',
   parallel_tool_calls: true,
   messages: [{role: 'system', content: `Vous √™tes un assistant IA utile qui fonctionnera comme une calculatrice.`}],
   variables: [],
   memory: [],
   tools: [ toolCalculator()],
});

export default pipeWithTools;
```

## √âtape 8 : Int√©grer le Pipe d'agent IA dans Node.js

Maintenant, nous allons int√©grer le pipe d'agent IA que vous avez cr√©√© dans le projet Node.js pour construire une interface de ligne de commande (CLI) interactive pour l'outil calculatrice. Ce projet Node.js servira de base pour tester et interagir avec le pipe d'agent IA (au d√©but du tutoriel, nous avons configur√© un projet Node.js en initialisant npm).

Maintenant, cr√©ez un fichier `index.ts` :

```bash
touch index.ts
```

Dans ce fichier TypeScript, importez le pipe d'agent IA que vous avez cr√©√©. Nous utiliserons le primitif pipe depuis `@baseai/core` pour ex√©cuter le pipe.

Ajoutez le code suivant au fichier `index.ts` :

```typescript
import 'dotenv/config';
import { Pipe } from '@baseai/core';
import inquirer from 'inquirer';
import ora from 'ora';
import chalk from 'chalk';
import pipePipeWithTool from './baseai/pipes/pipe-with-tool';

const pipe = new Pipe(pipePipeWithTool());

async function main() {

   const initialSpinner = ora('Conversation avec l\'agent Math...').start();
   try {
       const { completion: calculatorTool} = await pipe.run({
           messages: [{ role: 'user', content: 'Bonjour' }],
       });
       initialSpinner.stop();
       console.log(chalk.cyan('R√©ponse de l\'agent g√©n√©rateur de rapports...'));
       console.log(calculatorTool);
   } catch (error) {
       initialSpinner.stop();
       console.error(chalk.red('Erreur lors du traitement de la demande initiale :'), error);
   }

   while (true) {
       const { userMsg } = await inquirer.prompt([
           {
               type: 'input',
               name: 'userMsg',
               message: chalk.blue('Entrez votre requ√™te (ou tapez "exit" pour quitter) :'),
           },
       ]);

       if (userMsg.toLowerCase() === 'exit') {
           console.log(chalk.green('Au revoir !'));
           break;
       }

       const spinner = ora('Traitement de votre demande...').start();

       try {
           const { completion: reportAgentResponse } = await pipe.run({
               messages: [{ role: 'user', content: userMsg }],
           });

           spinner.stop();
           console.log(chalk.cyan('Agent :'));
           console.log(reportAgentResponse);
       } catch (error) {
           spinner.stop();
           console.error(chalk.red('Erreur lors du traitement de votre demande :'), error);
       }
   }
}

main();
```

Ce code cr√©e une CLI interactive pour discuter avec un agent IA, en utilisant un pipe de la biblioth√®que `@baseai/core` pour traiter les entr√©es de l'utilisateur. Voici ce qui se passe :

* Il importe les biblioth√®ques n√©cessaires telles que `dotenv` pour la configuration de l'environnement, `inquirer` pour les entr√©es de l'utilisateur, `ora` pour les spinners de chargement, et `chalk` pour les sorties color√©es. Assurez-vous d'abord d'installer ces biblioth√®ques en utilisant cette commande dans votre terminal `npm install ora inquirer`.

* Un objet pipe est cr√©√© √† partir de la biblioth√®que BaseAI en utilisant un outil pr√©d√©fini appel√© `pipe-with-tool`.

Dans la fonction `main()` :

* Un spinner d√©marre pendant qu'une conversation initiale avec l'agent IA est initi√©e avec le message 'Bonjour'.

* La r√©ponse de l'IA est affich√©e.

* Une boucle s'ex√©cute pour demander continuellement √† l'utilisateur une entr√©e et envoyer des requ√™tes √† l'agent IA.

* Les r√©ponses de l'IA sont affich√©es, et le processus continue jusqu'√† ce que l'utilisateur tape "exit".

## √âtape 9 : D√©marrer le serveur BaseAI

Pour ex√©cuter le pipe d'agent IA localement, vous devez d√©marrer le serveur BaseAI. Ex√©cutez la commande suivante dans votre terminal :

```bash
npx baseai@latest dev
```

## √âtape 10 : Ex√©cuter le Pipe d'agent IA

Ex√©cutez le fichier `index.ts` en utilisant la commande suivante :

```bash
npx tsx index.ts
```

## R√©sultat

Dans votre terminal, vous serez invit√© √† **"Entrez votre requ√™te."** Par exemple, demandons : **"Qu'est-ce que 120 cm en pieds ?"** Les LLMs hallucinent g√©n√©ralement lors de la conversion en pieds. Mais gr√¢ce √† l'auto-correction des appels d'outils du framework BaseAI, l'outil d√©tecte et corrige ses propres erreurs.

Avec cette configuration, nous avons r√©ussi √† construire un agent IA qui utilise **MathJS** et les **appels d'outils BaseAI** pour √©liminer les limitations math√©matiques des LLMs.

Voici une d√©monstration du r√©sultat final :

%[https://youtu.be/bBukL1Vte0g]

## Conclusion

Les grands mod√®les de langage (LLMs) ont souvent du mal avec le raisonnement math√©matique en raison de leur concentration sur le langage, ce qui conduit √† des erreurs fr√©quentes dans les calculs, en particulier avec les probl√®mes de math√©matiques complexes.

Les agents IA √©tendent les capacit√©s des LLMs en int√©grant des appels d'outils. Ils g√®rent les donn√©es en temps r√©el, assurent des sorties plus coh√©rentes et r√©duisent les hallucinations.

En incorporant MathJS et les appels d'outils via le framework BaseAI, les d√©veloppeurs peuvent cr√©er des agents IA serverless personnalis√©s appel√©s pipes qui servent de calculatrices fiables et r√©pondent aux limitations inh√©rentes des LLMs.