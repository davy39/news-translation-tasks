---
title: Le syndrome de l'imposteur frappe les hommes aussi fort que les femmes… et
  autres découvertes issues de milliers d'entretiens…
subtitle: ''
author: freeCodeCamp
co_authors: []
series: null
date: '2018-11-28T21:49:29.000Z'
originalURL: https://freecodecamp.org/news/impostor-syndrome-strikes-men-just-as-hard-as-women-and-other-findings-from-thousands-of-d9af80a58a5a
coverImage: https://cdn-media-1.freecodecamp.org/images/1*bEEt_IXW6wWTmE2N6cucZQ.png
tags:
- name: interview
  slug: interview
- name: jobs
  slug: jobs
- name: General Programming
  slug: programming
- name: 'tech '
  slug: tech
- name: technology
  slug: technology
seo_title: Le syndrome de l'imposteur frappe les hommes aussi fort que les femmes…
  et autres découvertes issues de milliers d'entretiens…
seo_desc: 'By Cat Hicks

  The modern technical interview is a rite of passage for software engineers and (hopefully!)
  the precursor to a great job. But it’s also a huge source of stress and endless
  questions for new candidates. Just searching “how do I prepare fo...'
---

Par Cat Hicks

L'entretien technique moderne est un rite de passage pour les ingénieurs logiciels et (espérons-le !) le précurseur d'un excellent emploi. Mais c'est aussi une énorme source de stress et de questions sans fin pour les nouveaux candidats. Une simple recherche sur "comment me préparer pour un entretien technique" donne des millions de résultats : articles sur Medium, blogs de bootcamps de codage, discussions sur Quora et même des livres entiers.

Malgré toutes ces conversations, les gens ont du mal à savoir comment ils s'en sortent lors des entretiens. [Dans un précédent article](http://blog.interviewing.io/people-are-still-bad-at-gauging-their-own-interview-performance-heres-the-data/), nous avons découvert qu'un nombre surprenant d'utilisateurs d'interviewing.io sous-estiment systématiquement leur performance, ce qui les rend plus susceptibles d'abandonner le processus et, en fin de compte, plus difficiles à embaucher.

Maintenant, avec considérablement plus de données (plus de 10 000 entretiens menés par de vrais ingénieurs logiciels !), nous avons voulu approfondir la question : **qu'est-ce qui semble rendre les candidats moins capables d'évaluer leur propre performance ?**

Nous savons que certains facteurs généraux rendent l'exactitude difficile : les gens ne sont pas toujours doués pour évaluer ou même se souvenir de leur performance sur des tâches cognitives difficiles comme l'écriture de code [[1](http://blog.interviewing.io/#imposter-fn1)]. Les entretiens techniques peuvent être particulièrement difficiles à juger si les candidats n'ont pas beaucoup d'expérience avec des questions n'ayant pas une seule bonne réponse.

Puisque de nombreuses entreprises ne partagent aucun type de retour détaillé post-entretien (au-delà d'un oui/non) avec les candidats pour des raisons de responsabilité, beaucoup de gens n'ont jamais aucune idée de leur performance, de ce qu'ils ont bien fait, ou de ce qui aurait pu être mieux [[2](http://blog.interviewing.io/#imposter-fn2), [3](http://blog.interviewing.io/#imposter-fn3)]. En effet, lever le voile sur les entretiens, **à travers l'industrie**, était l'une des principales motivations pour créer interviewing.io !

Mais à notre connaissance, il y a peu de données disponibles examinant spécifiquement comment les gens se sentent après de vrais entretiens à cette échelle, à travers différentes entreprises — alors nous les avons rassemblées, nous donnant la capacité de tester des hypothèses intéressantes de l'industrie sur les ingénieurs et la confiance en codage.

Un grand facteur qui nous intéressait était le syndrome de l'imposteur. Le syndrome de l'imposteur résonne avec beaucoup d'ingénieurs [[4](http://blog.interviewing.io/#imposter-fn4)], indiquant que beaucoup se demandent s'ils correspondent vraiment à leurs collègues et minimisent même des preuves solides de compétence comme un coup de chance. Le syndrome de l'imposteur peut nous faire douter de la fiabilité des retours positifs sur notre performance et de la mesure dans laquelle nos opportunités viennent de nos propres efforts, par opposition à la chance.

Ce qui nous intéressait particulièrement, c'était de savoir si cela se manifesterait pour les femmes sur notre plateforme. Il existe de nombreuses preuves de recherche que les candidats issus de milieux sous-représentés ressentent un plus grand manque d'appartenance qui alimente le syndrome de l'imposteur [[5](http://blog.interviewing.io/#imposter-fn5)], et cela pourrait se manifester par une inexactitude dans l'évaluation de leur propre performance en entretien.

### **L'installation**

interviewing.io est une plateforme où les gens peuvent pratiquer des entretiens techniques de manière anonyme, et si tout se passe bien, obtenir des emplois dans des entreprises de premier plan. Nous l'avons créée parce que les CV sont nuls et parce que nous croyons que chacun, indépendamment de son apparence sur le papier, devrait avoir l'opportunité de prouver sa valeur.

Lorsque qu'un interviewer et un candidat se rencontrent sur interviewing.io, ils se retrouvent dans un environnement de codage collaboratif avec voix, chat texte et un tableau blanc, et se lancent directement dans une question technique (n'hésitez pas à [regarder ce processus en action sur notre page d'enregistrements d'entretiens](https://interviewing.io/recordings/)). Après chaque entretien, les personnes se laissent des retours, et chaque partie peut voir ce que l'autre personne a dit à leur sujet une fois qu'ils ont tous deux soumis leurs évaluations.

Voici un exemple de formulaire de retour pour un interviewer :

![Image](https://cdn-media-1.freecodecamp.org/images/rUejiWD-QpW3yIhTLxdSMUOdB-E2nBBELDr1)
_Formulaire de retour pour les interviewers_

Immédiatement après l'entretien, les candidats ont répondu à une question sur la façon dont ils pensaient avoir performé sur la même échelle de 1 à 4 :

![Image](https://cdn-media-1.freecodecamp.org/images/qTemiehT3G4R8MmU3uC-zCWJnkjGJEQ3scGv)
_Formulaire de retour pour les candidats_

Pour cet article, nous avons examiné plus de 10 000 entretiens techniques menés par de vrais ingénieurs logiciels de grandes entreprises. Dans chaque entretien, un candidat était évalué par un interviewer sur sa capacité à résoudre des problèmes, ses compétences techniques et ses compétences en communication, ainsi que sur le fait que l'interviewer les ferait passer à l'étape suivante. Cela nous a donné une mesure de la différence entre l'auto-évaluation de quelqu'un et l'évaluation que l'interviewer leur a réellement donnée, et dans quelle direction. En d'autres termes, à quel point leur estimation était-elle éloignée de leur véritable performance ?

En commençant, nous avions quelques intuitions sur ce qui pourrait importer :

* **Genre**. Les femmes seraient-elles plus dures envers leur performance en codage que les hommes ?
* **Avoir été interviewer auparavant**. Il semblait raisonnable que le fait d'avoir été de l'autre côté lèverait le voile sur les entretiens.
* **Travailler dans une grande entreprise**. Similaire au point précédent.
* **Être un candidat performant** sur interviewing.io — les personnes qui sont de meilleurs candidats en général pourraient avoir plus de confiance et de conscience de quand ils ont bien (ou mal !) fait les choses.
* **Être dans la région de la Baie** ou non. Puisque la tech est encore si géographiquement centrée sur la Baie, nous avons considéré que les personnes vivant dans une culture plus saturée d'ingénierie pourraient avoir une plus grande familiarité avec les normes professionnelles autour des entretiens.
* Au sein de l'entretien lui-même, **la qualité de la question** et **la qualité de l'interviewer**. Supposément, un meilleur interviewer est aussi un meilleur communicateur, tandis qu'un interviewer confus pourrait fausser l'évaluation entière de la performance du candidat par ce dernier. Nous avons également examiné si c'était un entretien de pratique, ou pour un rôle spécifique dans une entreprise.
* Pour certains candidats, nous avons également pu examiner quelques mesures de leur **marque personnelle** au sein de l'industrie, comme leur nombre d'abonnés sur GitHub et Twitter. Peut-être que les personnes avec une forte présence en ligne sont plus sûres d'elles lors des entretiens ?

### Alors, qu'avons-nous trouvé ?

#### **Les femmes sont aussi précises que les hommes pour évaluer leurs compétences techniques**

Contrairement aux attentes concernant le genre et la confiance, nous n'avons pas trouvé de différence statistiquement significative fiable en matière de précision entre les genres. Au début, il semblait que les candidates étaient plus susceptibles de sous-estimer leur performance, mais lorsque nous avons contrôlé d'autres variables, comme l'expérience et les compétences techniques évaluées, il s'est avéré que **le principal facteur de différenciation était l'expérience**. Les ingénieurs plus expérimentés sont plus précis quant à leur performance en entretien, et les hommes sont plus susceptibles d'être des ingénieurs expérimentés. Mais les ingénieurs expérimentées sont tout aussi précises quant à leurs compétences techniques.

Sur la base de recherches précédentes, nous avons émis l'hypothèse que le syndrome de l'imposteur et un plus grand manque d'appartenance pourraient amener les candidates à pénaliser leur performance en entretien, mais nous n'avons pas trouvé ce schéma [[6](http://blog.interviewing.io/#imposter-fn6)].

Cependant, notre découverte fait écho à [un projet de recherche de l'Institut Clayman pour la recherche sur le genre de Stanford](https://gender.stanford.edu/sites/default/files/publications/climbing_the_technical_ladder.pdf), qui a examiné 1 795 travailleurs techniques de niveau intermédiaire provenant de grandes entreprises technologiques. Ils ont découvert que les femmes dans la tech ne sont pas nécessairement moins précises lorsqu'elles évaluent leurs propres capacités, mais ont des idées significativement différentes sur ce que le succès nécessite (par exemple, de longues heures de travail et la prise de risques). En d'autres termes, **les femmes dans la tech ne doutent pas nécessairement de leurs propres capacités mais pourraient avoir des idées différentes sur ce qui est attendu**.

[Et une enquête de Harvard Business Review](https://hbr.org/2014/08/why-women-dont-apply-for-jobs-unless-theyre-100-qualified) demandant à plus d'un millier de professionnels leurs décisions de candidature pour un emploi a également souligné ce point. Leurs résultats ont mis en avant que les écarts de genre dans les scénarios d'évaluation pourraient être plus liés à **des attentes différentes quant à la manière dont des scénarios comme les entretiens sont jugés**.

Cela dit, nous avons trouvé une différence intéressante : les femmes ont passé moins d'entretiens de pratique au total que les hommes. La différence était faible mais statistiquement significative, et rappelle [notre découverte précédente selon laquelle les femmes quittent interviewing.io environ 7 fois plus souvent que les hommes](http://blog.interviewing.io/we-built-voice-modulation-to-mask-gender-in-technical-interviews-heres-what-happened/), après un mauvais entretien.

Mais dans ce même article précédent, nous avons également découvert que le masquage des voix n'avait pas d'impact sur les résultats des entretiens. Cet ensemble de découvertes confirme ce que nous soupçonnions et ce que les personnes réalisant [des études approfondies sur le genre dans la tech](https://gender.stanford.edu/sites/default/files/publications/climbing_the_technical_ladder.pdf) ont trouvé : **c'est compliqué**. Le manque de persévérance des femmes lors des entretiens ne peut pas être expliqué uniquement par le syndrome de l'imposteur concernant leurs propres capacités, mais il est toujours probable qu'elles interprètent les retours négatifs plus sévèrement et fassent des hypothèses différentes sur les entretiens.

Voici la distribution de la distance de précision pour les candidates et les candidats sur notre plateforme (zéro indique une évaluation correspondant au score de l'interviewer, tandis que les valeurs négatives indiquent un score sous-estimé, et les valeurs positives indiquent un score surestimé). Les deux groupes semblent presque identiques :

![Image](https://cdn-media-1.freecodecamp.org/images/rCbQS0KYerTPE5v9SCqTwgnZAfgz8bTq6wJd)

#### Qu'est-ce qui n'a pas eu d'importance ?

Une autre surprise : **le fait d'avoir été interviewer n'a pas aidé**. Même les personnes qui avaient été interviewers elles-mêmes ne semblent pas obtenir un avantage de précision de cela.

**La marque personnelle était un autre non-resultat**. Les personnes avec plus d'abonnés sur GitHub n'étaient pas plus précises que celles avec peu ou pas d'abonnés sur GitHub.

**La note de l'interviewer n'a pas non plus eu d'importance** (c'est-à-dire à quel point un interviewer était bien noté par ses candidats), bien qu'il soit juste de dire que les interviewers sont généralement très bien notés sur le site.

#### Alors, qu'est-ce qui a donné un coup de pouce statistiquement significatif aux jugements précis de la performance en entretien ? Principalement, l'expérience.

Les ingénieurs expérimentés ont un meilleur sens de leur performance lors des entretiens, par rapport aux ingénieurs en début de carrière [[7](http://blog.interviewing.io/#imposter-fn7)]. Mais cela ne semble pas être uniquement parce qu'ils sont meilleurs pour évaluer leur performance en entretien parce qu'ils sont meilleurs en écriture de code ; bien qu'il y ait un léger avantage à cela, avec les ingénieurs mieux notés étant plus précis. Mais lorsque vous regardez les ingénieurs juniors, **même les candidats juniors les mieux performants ont eu du mal à évaluer avec précision leur performance.** [[8](http://blog.interviewing.io/#imposter-fn8)]

![Image](https://cdn-media-1.freecodecamp.org/images/hiFZy8I2mgxhskD5M2CX80Det2nK2yvEk23k)

Nos données reflètent une tendance observée dans [l'enquête sur les développeurs 2018 de Stack Overflow](https://insights.stackoverflow.com/survey/2018#connection-and-competition). Ils ont posé aux répondants plusieurs questions sur la confiance et la compétition avec d'autres développeurs, et ont noté que les ingénieurs plus expérimentés se sentent moins compétitifs et plus confiants [[9](http://blog.interviewing.io/#imposter-fn9)].

Cela n'est pas nécessairement surprenant : l'expérience est corrélée avec le niveau de compétence, après tout, et les personnes très compétentes sont susceptibles d'être plus confiantes. Mais notre analyse nous a permis de contrôler la performance et les compétences en codage au sein des groupes de carrière, et nous avons **toujours** trouvé que les ingénieurs expérimentés étaient meilleurs pour prédire leurs scores d'entretien.

Il y a probablement plusieurs facteurs ici : les ingénieurs expérimentés ont passé plus d'entretiens, ont mené des entretiens eux-mêmes, et ont un sentiment d'appartenance plus fort, ce qui peut aider à combattre le syndrome de l'imposteur.

#### **Les connaissances internes et le contexte semblent également aider.**

Être dans la région de la Baie et travailler dans une grande entreprise rendaient les gens plus précis. Comme le groupe de carrière expérimenté, les ingénieurs qui semblent plus susceptibles d'avoir des **connaissances contextuelles de l'industrie** sont également plus précis. Nous avons trouvé de petites mais statistiquement significatives améliorations grâce à des facteurs comme être situé dans la région de la Baie et travailler dans une grande entreprise. Cependant, l'amélioration due au travail dans une grande entreprise semble principalement mesurer une amélioration des compétences techniques globales : travailler dans une grande entreprise est essentiellement une mesure proxy pour être un ingénieur plus expérimenté et de meilleure qualité.

#### **Enfin, à mesure que vous devenez meilleur en entretien et que vous passez à des entretiens en entreprise, vous devenez plus précis.**

Les personnes étaient plus précises quant à leur performance lors des entretiens en entreprise par rapport aux entretiens de pratique, et leur classement global sur le site interviewing.io prédisait également une amélioration de la précision : interviewing.io donne également aux utilisateurs un classement global, basé sur leur performance sur plusieurs entretiens et pondéré vers les mesures les plus récentes. Les personnes qui ont obtenu un score dans le top 25 % étaient plus susceptibles d'être précises quant à leur performance en entretien.

En général, comment les gens évaluent-ils leur performance globale en entretien ? [Nous avons déjà examiné cela](http://blog.interviewing.io/people-are-still-bad-at-gauging-their-own-interview-performance-heres-the-data/), avec environ mille entretiens, et maintenant, avec dix mille, la découverte continue de se confirmer. Les candidats étaient précis sur leur performance dans seulement 46 % des entretiens, et se sous-estimaient dans 35 % des entretiens (et les 19 % restants, bien sûr, sont les surestimateurs).

Néanmoins, les candidats sont généralement sur la bonne voie — ce n'est pas comme si les personnes qui obtiennent un 4 se donnaient toujours un 1 [[10](http://blog.interviewing.io/#imposter-fn10)]. Les auto-évaluations **sont** statistiquement significativement prédictives des scores réels d'entretien (et positivement corrélées), mais cette relation est bruyante.

### Les implications

Évaluer avec précision sa propre performance en entretien est une compétence à part entière, et une compétence que les ingénieurs doivent apprendre par l'expérience et le contexte dans l'industrie technologique. Mais nous avons également appris que **nombreuses des hypothèses que nous avions faites sur la précision de la performance n'ont pas résisté à l'examen** — les ingénieurs femmes avaient une vision aussi précise de leurs propres compétences que les ingénieurs hommes, et les ingénieurs qui avaient mené plus d'entretiens ou étaient bien connus sur GitHub n'étaient pas particulièrement meilleurs pour évaluer leur performance.

Que signifie cela pour l'industrie dans son ensemble ? Tout d'abord, le syndrome de l'imposteur semble être le monstre aux yeux troubles qui attaque indépendamment du genre et des compétences, et à quel point vous êtes bon, où vous êtes, ou à quel point vous êtes célèbre n'est pas si important. L'ancienneté aide à atténuer une partie de la douleur, mais le syndrome de l'imposteur affecte tout le monde, indépendamment de qui ils sont ou d'où ils viennent.

Alors, peut-être est-il temps pour une culture d'entretien plus gentille et plus empathique. Et une culture qui est gentille envers tout le monde, car bien que les groupes marginalisés qui n'ont pas été socialisés dans les entretiens techniques soient [les plus touchés par les lacunes du processus d'entretien](http://blog.interviewing.io/you-cant-fix-diversity-in-tech-without-fixing-the-technical-interview/), personne n'est immunisé contre le doute de soi.

Nous avons précédemment discuté de ce qui fait de quelqu'un un bon interviewer, et [l'empathie joue un rôle disproportionné](http://blog.interviewing.io/what-do-the-best-interviewers-have-in-common-we-looked-at-thousands-of-real-interviews-to-find-out/). Et nous avons vu que [fournir un retour immédiat post-entretien est vraiment important pour empêcher les candidats d'abandonner](http://blog.interviewing.io/people-are-still-bad-at-gauging-their-own-interview-performance-heres-the-data/). Donc, que vous soyez motivé par la gentillesse et l'idéologie ou par un pragmatisme froid et dur, un peu plus de gentillesse et de compréhension envers vos candidats est de mise.

[_Cat Hicks_](https://www.drcathicks.com/), l'auteure de cet article invité, est une chercheuse et scientifique des données spécialisée dans l'apprentissage. Elle a publié des recherches empiriques sur les environnements d'apprentissage et a dirigé des recherches sur le travail cognitif des équipes d'ingénierie chez Google et Travr.se. Elle est titulaire d'un doctorat en psychologie de l'UC San Diego.