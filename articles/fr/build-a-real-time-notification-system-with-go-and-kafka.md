---
title: Comment construire un syst√®me de notifications en temps r√©el avec Go et Kafka
date: '2023-08-25T21:41:27.000Z'
authorURL: ''
originalURL: https://freecodecamp.org/news/build-a-real-time-notification-system-with-go-and-kafka
posteditor: ''
proofreader: ''
author: freeCodeCamp
co_authors: []
series: null
coverImage: https://www.freecodecamp.org/news/content/images/2023/08/Go_Kafka_Vert_Rev2.svg
tags:
- name: Apache Kafka
  slug: apache-kafka
- name: golang
  slug: golang
- name: message broker
  slug: message-broker
seo_desc: 'By Hermann R√∂sch

  These days, applications need to have instant data access and processing capabilities.
  Whether it''s updating real-time stock trades for financial institutions or navigating
  through live traffic data, the ability to process and react ...'
---


Par Hermann R√∂sch

<!-- more -->

De nos jours, les applications ont besoin d'un acc√®s aux donn√©es et de capacit√©s de traitement instantan√©s. Qu'il s'agisse de mettre √† jour des transactions boursi√®res en temps r√©el pour des institutions financi√®res ou de naviguer √† travers des donn√©es de trafic en direct, la capacit√© √† traiter et √† r√©agir aux donn√©es en temps r√©el est cruciale.

Dans ce tutoriel, vous allez explorer les m√©canismes de **Kafka**, puis l'int√©grer avec **Go** pour d√©velopper un syst√®me de notifications en temps r√©el.

Afin de comprendre pleinement cet article, vous devriez avoir des connaissances pr√©alables sur les [**Goroutines**][1], le [**framework**][2] [**Gin**][2] et les outils de conteneurisation comme [**Docker**][3].

## Table des mati√®res

1.  [Qu'est-ce que Kafka ?][4]
2.  [Comment configurer l'espace de travail du projet][5]
3.  [Comment cr√©er les mod√®les User et Notification][6]
4.  [Comment configurer le Producer Kafka][7]
5.  [Comment configurer le Consumer Kafka][8]
6.  [Testons le syst√®me de notifications en temps r√©el][9]
7.  [Conclusion][10]

## Qu'est-ce que Kafka ? ü§î

[Kafka][11] est une plateforme de streaming d'√©v√©nements distribu√©e. Initialement d√©velopp√© par LinkedIn, Kafka a ensuite √©t√© confi√© √† la Apache Software Foundation et rendu open-source. Cette transition a marqu√© son r√¥le en tant qu'acteur cl√© du streaming de donn√©es en temps r√©el.

Plus qu'un simple outil de communication, Kafka est un ¬´ event broker ¬ª ‚Äî un syst√®me qui contr√¥le et g√®re les √©v√©nements ou les messages entre diverses applications ou services. Il peut g√©rer des volumes d'√©v√©nements quotidiens massifs en tant que plateforme de streaming d'√©v√©nements distribu√©e, garantissant que les donn√©es sont transport√©es et analys√©es de mani√®re transparente en temps r√©el.

Outre son r√¥le fondamental de broker d'√©v√©nements, Kafka offre des fonctionnalit√©s de durabilit√©, de scalabilit√© et de tol√©rance aux pannes. Il permet √©galement de s'assurer que les flux de donn√©es √† grande √©chelle sont g√©r√©s de mani√®re efficace et fiable avec une latence tr√®s faible.

### Les composants cl√©s de Kafka ‚öôÔ∏è

Maintenant que vous avez fait connaissance avec Kafka, plongeons dans les principaux √©l√©ments qui composent son architecture :

#### √âv√©nements (Events)

Un √©v√©nement enregistre le fait que ¬´ quelque chose s'est produit ¬ª. Il peut √™tre consid√©r√© comme un message ou une donn√©e repr√©sentant un changement ou une action. Dans le contexte de notre syst√®me de notifications en temps r√©el, vous pourriez consid√©rer un √©v√©nement comme suit :

-   Cl√© de l'√©v√©nement : `‚Äú1‚Äù` (repr√©sentant l'**ID** de l'utilisateur **Emma**)
-   Valeur de l'√©v√©nement : `‚ÄúBruno a commenc√© √† vous suivre.‚Äù`

#### Brokers

Un broker Kafka est un serveur qui ex√©cute le logiciel Kafka et stocke les donn√©es. Bien que les configurations de production √† grande √©chelle impliquent souvent plusieurs brokers sur plusieurs machines, vous utiliserez une configuration √† broker unique pour ce tutoriel.

#### Topics

Les topics dans Kafka sont similaires aux dossiers dans un syst√®me de fichiers. Ils repr√©sentent des cat√©gories sous lesquelles les donn√©es ou les √©v√©nements sont stock√©s. Par exemple, un nom de topic pourrait √™tre `"notifications"`.

#### Producers

Les producers sont des entit√©s qui publient (√©crivent) ou envoient des messages √† Kafka, comme un programme Go ou un service. Lorsqu'un producer a un √©v√©nement √† envoyer, il choisit un topic auquel adresser l'√©v√©nement.

#### Consumers

Les consumers lisent et traitent les √©v√©nements ou les messages de Kafka. Une fois que les producers ont envoy√© des messages aux topics, les consumers peuvent s'abonner √† un ou plusieurs topics pour recevoir les messages.

#### Partitions

Chaque topic dans Kafka peut √™tre divis√© en partitions. Consid√©rez les partitions comme des segments au sein d'un topic qui permettent √† Kafka de g√©rer les donn√©es plus efficacement, en particulier dans les configurations avec plusieurs brokers.

Nous nous en tiendrons √† une configuration de base sans approfondir les partitions multiples, mais vous devez comprendre leur r√¥le dans les d√©ploiements Kafka plus importants.

#### Groupes de consumers (Consumer groups)

Alors que les consumers individuels g√®rent les messages de partitions sp√©cifiques, les groupes de consumers g√®rent la coordination entre plusieurs consumers.

Un groupe de consumers se compose de plusieurs consumers traitant collaborativement des messages de diff√©rentes partitions d'un topic. Cela garantit que chaque message d'une partition n'est trait√© que par un seul consumer du groupe, permettant une consommation efficace et √©volutive.

Consid√©rez cela comme une √©quipe de consumers travaillant ensemble, chaque membre √©tant responsable des messages de partitions sp√©cifiques, garantissant qu'aucun message n'est oubli√©.

#### R√©plicas (Replicas)

La r√©plication garantit la s√©curit√© des donn√©es. Dans les d√©ploiements Kafka plus importants, le stockage de plusieurs r√©plicas de donn√©es est courant pour aider √† la r√©cup√©ration apr√®s des d√©faillances inattendues.

Vous n'utiliserez pas de r√©plicas dans ce tutoriel, mais il est b√©n√©fique de comprendre leur importance pour assurer la durabilit√© des donn√©es dans Kafka.

#### KRaft

[KRaft][12] est le propre protocole de consensus de Kafka introduit pour √©liminer le besoin de [ZooKeeper][13]. En r√©sum√©, KRaft g√®re les m√©tadonn√©es directement au sein de Kafka, offrant scalabilit√©, simplicit√© et une meilleure reprise sur panne, entre autres avantages.

Pour lier tous ces composants ensemble, voici une repr√©sentation visuelle de l'architecture de base de Kafka, illustrant un broker, des topics, des partitions et des groupes de consumers :

![Image](https://www.freecodecamp.org/news/content/images/2023/08/Kafka_Architecture_Transparent_V2.png) _Visualisation de l'architecture de streaming d'√©v√©nements de Kafka_

## Comment configurer l'espace de travail du projet üë®‚Äçüíªüë©‚Äçüíª {#heading-comment-configurer-l-espace-de-travail-du-projet}

Assez de th√©orie pour l'instant ! Mettons les mains dans le cambouis avec le projet r√©el.

En supposant que Docker et Go soient install√©s sur votre machine, cr√©ons un r√©pertoire pour le projet nomm√© `kafka-notify`. Ensuite, vous allez r√©cup√©rer [**l'image Docker Kafka de Bitnami**][14] pour la configuration de Kafka, offrant une installation sans tracas :

```
mkdir kafka-notify && cd kafka-notify

curl -sSL \
https://raw.githubusercontent.com/bitnami/containers/main/bitnami/kafka/docker-compose.yml > docker-compose.yml
```

Avant de d√©marrer le broker Kafka, une l√©g√®re modification est requise dans le fichier `docker-compose.yml`. Trouvez la cha√Æne suivante :

```
KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
```

Et remplacez-la par :

```
KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
```

Le changement ci-dessus garantit que Kafka annonce son listener sur `localhost`, ce qui permet √† notre application Go locale de se connecter de mani√®re transparente. Maintenant, vous pouvez d√©marrer le broker Kafka via la commande Docker suivante :

```
docker-compose up -d
```

Ensuite, vous devrez cr√©er quelques r√©pertoires pour organiser les fichiers du projet. Les r√©pertoires `cmd/producer` et `cmd/consumer` contiendront les fichiers principaux de l'application, et le r√©pertoire `pkg/models` stockera les d√©clarations de mod√®les :

```
mkdir -p cmd/producer cmd/consumer pkg/models
```

La derni√®re √©tape consiste √† initialiser les modules Go et √† installer les packages externes. Vous utiliserez `sarama` pour √©tablir une connexion avec le broker Kafka et `gin` pour g√©rer les points de terminaison de l'API pour le syst√®me de notifications :

```
go mod init kafka-notify
go get github.com/IBM/sarama github.com/gin-gonic/gin
```

## Comment cr√©er les mod√®les User et Notification {#heading-comment-creer-les-modeles-user-et-notification}

Une fois l'espace de travail configur√©, la premi√®re √©tape consiste √† cr√©er les structs `User` et `Notification`. Allez dans le r√©pertoire `pkg/models`, puis cr√©ez un nouveau fichier nomm√© `models.go` et d√©clarez ces structs √† l'int√©rieur :

```
package models

type User struct {
    ID   int    `json:"id"`
    Name string `json:"name"`
}

type Notification struct {
    From    User   `json:"from"`
    To      User   `json:"to"`
    Message string `json:"message"`
}
```

## Comment configurer le Producer Kafka üì§ {#heading-comment-configurer-le-producer-kafka}

L'√©tape suivante consiste √† √©crire le code pour le producer. Vous allez cr√©er une API web Gin simple o√π un utilisateur peut envoyer une notification √† un autre utilisateur via une requ√™te HTTP POST. Cette requ√™te va ensuite ¬´ produire ¬ª (envoyer) un message vers un topic Kafka nomm√© `"notifications"`.

Naviguons vers le r√©pertoire `cmd/producer` et cr√©ons un nouveau fichier nomm√© `producer.go`. √Ä l'int√©rieur, vous allez configurer la logique du producer :

```
package main

import (
    "encoding/json"
    "errors"
    "fmt"
    "log"
    "net/http"
    "strconv"

    "kafka-notify/pkg/models"

    "github.com/IBM/sarama"
    "github.com/gin-gonic/gin"
)

const (
    ProducerPort       = ":8080"
    KafkaServerAddress = "localhost:9092"
    KafkaTopic         = "notifications"
)

// ============== HELPER FUNCTIONS ==============
var ErrUserNotFoundInProducer = errors.New("user not found")

func findUserByID(id int, users []models.User) (models.User, error) {
    for _, user := range users {
        if user.ID == id {
            return user, nil
        }
    }
    return models.User{}, ErrUserNotFoundInProducer
}

func getIDFromRequest(formValue string, ctx *gin.Context) (int, error) {
    id, err := strconv.Atoi(ctx.PostForm(formValue))
    if err != nil {
        return 0, fmt.Errorf(
            "failed to parse ID from form value %s: %w", formValue, err)
    }
    return id, nil
}

// ============== KAFKA RELATED FUNCTIONS ==============
func sendKafkaMessage(producer sarama.SyncProducer,
    users []models.User, ctx *gin.Context, fromID, toID int) error {
    message := ctx.PostForm("message")

    fromUser, err := findUserByID(fromID, users)
    if err != nil {
        return err
    }

    toUser, err := findUserByID(toID, users)
    if err != nil {
        return err
    }

    notification := models.Notification{
        From: fromUser,
        To:   toUser, Message: message,
    }

    notificationJSON, err := json.Marshal(notification)
    if err != nil {
        return fmt.Errorf("failed to marshal notification: %w", err)
    }

    msg := &sarama.ProducerMessage{
        Topic: KafkaTopic,
        Key:   sarama.StringEncoder(strconv.Itoa(toUser.ID)),
        Value: sarama.StringEncoder(notificationJSON),
    }

    _, _, err = producer.SendMessage(msg)
    return err
}

func sendMessageHandler(producer sarama.SyncProducer,
    users []models.User) gin.HandlerFunc {
    return func(ctx *gin.Context) {
        fromID, err := getIDFromRequest("fromID", ctx)
        if err != nil {
            ctx.JSON(http.StatusBadRequest, gin.H{"message": err.Error()})
            return
        }

        toID, err := getIDFromRequest("toID", ctx)
        if err != nil {
            ctx.JSON(http.StatusBadRequest, gin.H{"message": err.Error()})
            return
        }

        err = sendKafkaMessage(producer, users, ctx, fromID, toID)
        if errors.Is(err, ErrUserNotFoundInProducer) {
            ctx.JSON(http.StatusNotFound, gin.H{"message": "User not found"})
            return
        }
        if err != nil {
            ctx.JSON(http.StatusInternalServerError, gin.H{
                "message": err.Error(),
            })
            return
        }

        ctx.JSON(http.StatusOK, gin.H{
            "message": "Notification sent successfully!",
        })
    }
}

func setupProducer() (sarama.SyncProducer, error) {
    config := sarama.NewConfig()
    config.Producer.Return.Successes = true
    producer, err := sarama.NewSyncProducer([]string{KafkaServerAddress},
        config)
    if err != nil {
        return nil, fmt.Errorf("failed to setup producer: %w", err)
    }
    return producer, nil
}

func main() {
    users := []models.User{
        {ID: 1, Name: "Emma"},
        {ID: 2, Name: "Bruno"},
        {ID: 3, Name: "Rick"},
        {ID: 4, Name: "Lena"},
    }

    producer, err := setupProducer()
    if err != nil {
        log.Fatalf("failed to initialize producer: %v", err)
    }
    defer producer.Close()

    gin.SetMode(gin.ReleaseMode)
    router := gin.Default()
    router.POST("/send", sendMessageHandler(producer, users))

    fmt.Printf("Kafka PRODUCER üì® started at http://localhost%s\n",
        ProducerPort)

    if err := router.Run(ProducerPort); err != nil {
        log.Printf("failed to run the server: %v", err)
    }
}
```

Analysons les composants li√©s √† Kafka au sein de `producer.go` :

Dans la fonction `**setupProducer()**` :

-   `config := sarama.NewConfig()` : Initialise une nouvelle configuration par d√©faut pour Kafka. Consid√©rez cela comme le r√©glage des param√®tres avant de se connecter au broker.
-   `config.Producer.Return.Successes = true` : Garantit que le producer re√ßoit un acquittement une fois que le message est stock√© avec succ√®s dans le topic `"notifications"`.
-   `producer, err := sarama.NewSyncProducer(‚Ä¶)` : Initialise un producer Kafka synchrone qui se connecte au broker Kafka s'ex√©cutant sur `localhost:9092`.

Dans la fonction `**sendKafkaMessage()**` :

-   Cette fonction commence par r√©cup√©rer le `message` du contexte, puis tente de trouver √† la fois l'exp√©diteur et le destinataire √† l'aide de leurs IDs.
-   `notification := models.Notification{‚Ä¶}` : Initialise une struct `Notification` qui encapsule les informations sur l'exp√©diteur, le destinataire et le message r√©el.
-   `msg := &sarama.ProducerMessage{‚Ä¶}` : Construit un `ProducerMessage` pour le topic `"notifications"`, en d√©finissant l'ID du destinataire comme `Key` et le contenu du message, qui est la forme s√©rialis√©e de la `Notification`, comme `Value`.
-   `producer.SendMessage(msg)` : Envoie le message construit au topic `"notifications"`.

Dans la fonction `**sendMessageHandler()**` :

-   Cette fonction sert de gestionnaire de point de terminaison (endpoint) pour la requ√™te POST `/send`. Elle traite la requ√™te entrante pour s'assurer que des IDs d'exp√©diteur et de destinataire valides sont fournis.
-   Apr√®s avoir r√©cup√©r√© les IDs, elle invoque la fonction `sendKafkaMessage()` pour envoyer le message Kafka. Selon le r√©sultat, elle envoie les r√©ponses HTTP appropri√©es : un `404 Not Found` pour les utilisateurs inexistants, un `400 Bad Request` pour les IDs invalides, et un `500 Internal Server Error` pour les autres √©checs, accompagn√©s d'un message d'erreur sp√©cifique.

Enfin, dans la fonction `**main()**` :

-   Vous initialisez un producer Kafka via la fonction `setupProducer()`.
-   Ensuite, vous cr√©ez un `router` Gin via `gin.Default()`, configurant un serveur web. Puis, vous d√©finissez un endpoint POST `/send` pour g√©rer les notifications. Cet endpoint attend les IDs de l'exp√©diteur et du destinataire ainsi que le contenu du message.
-   La notification est trait√©e lors de la r√©ception d'une requ√™te POST via la fonction `sendMessageHandler()`, et une r√©ponse HTTP appropri√©e est envoy√©e.

Cette configuration offre un moyen simple de simuler des utilisateurs s'envoyant des notifications et montre comment ces notifications sont produites dans le topic `"notifications"`.

## Comment configurer le Consumer Kafka üì• {#heading-comment-configurer-le-consumer-kafka}

Apr√®s avoir cr√©√© le producer, l'√©tape suivante consiste √† configurer un consumer qui √©coute le topic `"notifications"` et fournit un point de terminaison pour lister les notifications d'un utilisateur sp√©cifique.

D√©pla√ßons-nous vers le r√©pertoire `cmd/consumer` et cr√©ons un nouveau fichier nomm√© `consumer.go`. √Ä l'int√©rieur, vous allez configurer la logique du consumer et l'API bas√©e sur Gin :

```
package main

import (
    "context"
    "encoding/json"
    "errors"
    "fmt"
    "log"
    "net/http"
    "sync"

    "kafka-notify/pkg/models"

    "github.com/IBM/sarama"
    "github.com/gin-gonic/gin"
)

const (
    ConsumerGroup      = "notifications-group"
    ConsumerTopic      = "notifications"
    ConsumerPort       = ":8081"
    KafkaServerAddress = "localhost:9092"
)

// ============== HELPER FUNCTIONS ==============
var ErrNoMessagesFound = errors.New("no messages found")

func getUserIDFromRequest(ctx *gin.Context) (string, error) {
    userID := ctx.Param("userID")
    if userID == "" {
        return "", ErrNoMessagesFound
    }
    return userID, nil
}

// ====== NOTIFICATION STORAGE ======
type UserNotifications map[string][]models.Notification

type NotificationStore struct {
    data UserNotifications
    mu   sync.RWMutex
}

func (ns *NotificationStore) Add(userID string,
    notification models.Notification) {
    ns.mu.Lock()
    defer ns.mu.Unlock()
    ns.data[userID] = append(ns.data[userID], notification)
}

func (ns *NotificationStore) Get(userID string) []models.Notification {
    ns.mu.RLock()
    defer ns.mu.RUnlock()
    return ns.data[userID]
}

// ============== KAFKA RELATED FUNCTIONS ==============
type Consumer struct {
    store *NotificationStore
}

func (*Consumer) Setup(sarama.ConsumerGroupSession) error   { return nil }
func (*Consumer) Cleanup(sarama.ConsumerGroupSession) error { return nil }

func (consumer *Consumer) ConsumeClaim(
    sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for msg := range claim.Messages() {
        userID := string(msg.Key)
        var notification models.Notification
        err := json.Unmarshal(msg.Value, &notification)
        if err != nil {
            log.Printf("failed to unmarshal notification: %v", err)
            continue
        }
        consumer.store.Add(userID, notification)
        sess.MarkMessage(msg, "")
    }
    return nil
}

func initializeConsumerGroup() (sarama.ConsumerGroup, error) {
    config := sarama.NewConfig()

    consumerGroup, err := sarama.NewConsumerGroup(
        []string{KafkaServerAddress}, ConsumerGroup, config)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize consumer group: %w", err)
    }

    return consumerGroup, nil
}

func setupConsumerGroup(ctx context.Context, store *NotificationStore) {
    consumerGroup, err := initializeConsumerGroup()
    if err != nil {
        log.Printf("initialization error: %v", err)
    }
    defer consumerGroup.Close()

    consumer := &Consumer{
        store: store,
    }

    for {
        err = consumerGroup.Consume(ctx, []string{ConsumerTopic}, consumer)
        if err != nil {
            log.Printf("error from consumer: %v", err)
        }
        if ctx.Err() != nil {
            return
        }
    }
}

func handleNotifications(ctx *gin.Context, store *NotificationStore) {
    userID, err := getUserIDFromRequest(ctx)
    if err != nil {
        ctx.JSON(http.StatusNotFound, gin.H{"message": err.Error()})
        return
    }

    notes := store.Get(userID)
    if len(notes) == 0 {
        ctx.JSON(http.StatusOK,
            gin.H{
                "message":       "No notifications found for user",
                "notifications": []models.Notification{},
            })
        return
    }

    ctx.JSON(http.StatusOK, gin.H{"notifications": notes})
}

func main() {
    store := &NotificationStore{
        data: make(UserNotifications),
    }

    ctx, cancel := context.WithCancel(context.Background())
    go setupConsumerGroup(ctx, store)
    defer cancel()

    gin.SetMode(gin.ReleaseMode)
    router := gin.Default()
    router.GET("/notifications/:userID", func(ctx *gin.Context) {
        handleNotifications(ctx, store)
    })

    fmt.Printf("Kafka CONSUMER (Group: %s) üë•üì• "+
        "started at http://localhost%s\n", ConsumerGroup, ConsumerPort)

    if err := router.Run(ConsumerPort); err != nil {
        log.Printf("failed to run the server: %v", err)
    }
}
```

Examinons les op√©rations li√©es √† Kafka au sein de `consumer.go` :

Dans la fonction `**initializeConsumerGroup()**` :

-   `config := sarama.NewConfig()` : Initialise une nouvelle configuration par d√©faut pour Kafka.
-   `consumerGroup, err := sarama.NewConsumerGroup(‚Ä¶)` : Cr√©e un nouveau groupe de consumers Kafka qui se connecte au broker s'ex√©cutant sur `localhost:9092`. Le nom du groupe est `"notifications-group"`.

√Ä l'int√©rieur de la struct `**Consumer**` et de ses m√©thodes :

-   La struct `Consumer` poss√®de un champ `store`, qui est une r√©f√©rence au `NotificationStore` pour garder une trace des notifications re√ßues.
-   Les m√©thodes `Setup()` et `Cleanup()` sont requises pour satisfaire l'interface `sarama.ConsumerGroupHandler`. Bien qu'elles ne soient PAS utilis√©es dans ce tutoriel, elles peuvent jouer des r√¥les potentiels pour l'initialisation et le nettoyage pendant la consommation de messages, mais agissent ici comme des points de r√©servation (placeholders).
-   Dans la m√©thode `ConsumeClaim()` : Le consumer √©coute les nouveaux messages sur le topic. Pour chaque message, il r√©cup√®re le `userID` (la `Key` du message), d√©s√©rialise (unmarshal) le message dans une struct `Notification`, et ajoute la notification au `NotificationStore`.

Dans la fonction `**setupConsumerGroup()**` :

-   Cette fonction configure le groupe de consumers Kafka, √©coute les messages entrants et les traite √† l'aide des m√©thodes de la struct `Consumer`.
-   Elle ex√©cute une boucle `for` ind√©finiment, consommant les messages du topic `‚Äúnotifications‚Äù` et traitant toutes les erreurs qui surviennent.

La fonction `**handleNotifications()**` :

-   Initialement, elle tente de r√©cup√©rer le `userID` de la requ√™te. S'il n'existe pas, elle renvoie un statut `404 Not Found`.
-   Ensuite, elle r√©cup√®re les notifications pour l'ID utilisateur fourni √† partir du `NotificationStore`. Selon que l'utilisateur a des notifications ou non, elle r√©pond avec un statut `200 OK` et soit une tranche (slice) de notifications vide, soit les notifications actuelles.

Enfin, dans la fonction `**main()**` :

-   `store := &NotificationStore{‚Ä¶}` : Cr√©e une instance de `NotificationStore` pour contenir les notifications.
-   `ctx, cancel := context.WithCancel(context.Background())` : Configure un contexte annulable qui peut √™tre utilis√© pour arr√™ter le groupe de consumers.
-   `go setupConsumerGroup(ctx, store)` : D√©marre le groupe de consumers dans une Goroutine s√©par√©e, lui permettant de fonctionner de mani√®re concurrente sans bloquer le thread principal.
-   La derni√®re √©tape consiste √† cr√©er un `router` Gin et √† d√©finir un endpoint GET `/notifications/:userID` qui r√©cup√©rera les notifications pour un utilisateur sp√©cifique via la fonction `handleNotifications()` lors de l'acc√®s.

Cette configuration offre un moyen simple de consommer des messages du topic `"notifications"` et de les pr√©senter aux utilisateurs via un point de terminaison web.

## Testons le syst√®me de notifications en temps r√©elüë®‚Äçüî¨üñ•Ô∏èüë©‚Äçüî¨ {#heading-testons-le-systeme-de-notifications-en-temps-reel}

Maintenant que le producer et le consumer sont pr√™ts, il est temps de voir le syst√®me en action.

### 1. D√©marrer le producer

Ouvrez un terminal, d√©placez-vous dans le r√©pertoire `kafka-notify`, et lancez le producer avec la commande suivante :

```
go run cmd/producer/producer.go
```

### 2. D√©marrer le consumer

Ouvrez une deuxi√®me fen√™tre de terminal, naviguez vers le r√©pertoire `kafka-notify`, et d√©marrez le consumer en ex√©cutant :

```
go run cmd/consumer/consumer.go
```

### 3. Envoi de notifications

Avec le producer et le consumer en cours d'ex√©cution, vous pouvez simuler l'envoi de notifications. Ouvrez un troisi√®me terminal et utilisez les commandes `curl` ci-dessous pour envoyer des notifications :

**L'utilisateur 1 (Emma) re√ßoit une notification de l'utilisateur 2 (Bruno) :**

```
curl -X POST http://localhost:8080/send \
-d "fromID=2&toID=1&message=Bruno started following you."
```

**L'utilisateur 2 (Bruno) re√ßoit une notification de l'utilisateur 1 (Emma) :**

```
curl -X POST http://localhost:8080/send \
-d "fromID=1&toID=2&message=Emma mentioned you in a comment: 'Great seeing you yesterday, @Bruno!'"
```

**L'utilisateur 1 (Emma) re√ßoit une notification de l'utilisateur 4 (Lena) :**

```
curl -X POST http://localhost:8080/send \
-d "fromID=4&toID=1&message=Lena liked your post: 'My weekend getaway!'"
```

### 4. R√©cup√©ration des notifications

Enfin, vous pouvez r√©cup√©rer les notifications d'un utilisateur sp√©cifique. Vous pouvez utiliser les commandes `curl` ci-dessous :

**R√©cup√©ration des notifications pour l'utilisateur 1 (Emma) :**

```
curl http://localhost:8081/notifications/1
```

**Sortie :**

```
{"notifications": [{"from": {"id": 2, "name": "Bruno"}, "to": {"id": 1, "name": "Emma"}, "message": "Bruno started following you."}]}
{"notifications": [{"from": {"id": 4, "name": "Lena"}, "to": {"id": 1, "name": "Emma"}, "message": "Lena liked your post: 'My weekend getaway!'"}]}
```

Dans la sortie ci-dessus, vous voyez une r√©ponse `JSON` listant toutes les notifications pour **Emma**. √Ä mesure que vous envoyez plus de notifications, elles s'accumulent et vous pouvez les r√©cup√©rer via l'API du consumer.

## Conclusion üìù {#heading-conclusion}

Dans ce tutoriel, vous avez appris √† configurer un syst√®me de notifications en temps r√©el de base en utilisant Kafka avec Go.

En simulant le processus d'envoi et de r√©cup√©ration de notifications par les utilisateurs, vous avez acquis une exp√©rience pratique des composants de Kafka. Il s'agit d'une √©tape fondamentale pour comprendre comment Kafka peut √™tre int√©gr√© dans des applications Go pour diverses t√¢ches de traitement de donn√©es en temps r√©el.

Vous pouvez acc√©der √† l'int√©gralit√© du code source de ce projet dans le d√©p√¥t GitHub suivant : [https://github.com/gutyoh/kafka-notify][15]

Si vous avez trouv√© cet article utile et que vous souhaitez approfondir vos connaissances sur Golang üêøÔ∏è, Docker üê≥ et Gin üç∏, n'h√©sitez pas √† consulter le parcours **[Introduction to Go][16]**, qui couvre les concepts de base de Golang.

Les utilisateurs enregistr√©s peuvent √©galement consulter les parcours **[Go Developer][17]** et **[Introduction to Docker][18]** sur Hyperskill. J'ai √©t√© activement impliqu√© en tant qu'expert dans la cr√©ation de ces parcours, en veillant √† ce qu'ils fournissent un contenu √©ducatif de premier ordre.

Avant de conclure, je dois un grand merci √† mon cher ami **Anton Illarionov**. Son expertise dans l'int√©gration de Go avec Kafka a inspir√© l'id√©e de cet article. Vous pouvez explorer ses projets sur [GitHub][19].

Faites-moi savoir si vous avez des questions ou des commentaires concernant cet article.

Merci de m'avoir lu, et continuez √† coder !

[1]: https://go.dev/tour/concurrency/1#:~:text=A%20goroutine%20is%20a%20lightweight,happens%20in%20the%20new%20goroutine.
[2]: https://gin-gonic.com/docs/introduction/
[3]: https://www.docker.com/
[4]: #heading-qu-est-ce-que-kafka
[5]: #heading-comment-configurer-l-espace-de-travail-du-projet
[6]: #heading-comment-creer-les-modeles-user-et-notification
[7]: #heading-comment-configurer-le-producer-kafka
[8]: #heading-comment-configurer-le-consumer-kafka
[9]: #heading-testons-le-systeme-de-notifications-en-temps-reel
[10]: #heading-conclusion
[11]: https://kafka.apache.org/intro
[12]: https://developer.confluent.io/learn/kraft/
[13]: https://kafka.apache.org/documentation/#zk_depr
[14]: https://hub.docker.com/r/bitnami/kafka/
[15]: https://github.com/gutyoh/kafka-notify
[16]: https://hyperskill.org/tracks/25?category=12&utm_source=fc_hs&utm_medium=social&utm_campaign=hermann
[17]: https://hyperskill.org/tracks/43?category=20&utm_source=fc_hs&utm_medium=social&utm_campaign=hermann
[18]: https://hyperskill.org/tracks/64?category=20&utm_source=fc_hs&utm_medium=social&utm_campaign=hermann
[19]: https://github.com/ant1k9