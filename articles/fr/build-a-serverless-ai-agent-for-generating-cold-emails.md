---
title: Comment cr√©er un agent IA Serverless pour g√©n√©rer des emails de prospection
  pour votre emploi de r√™ve
subtitle: ''
author: Maham Codes
co_authors: []
series: null
date: '2025-02-19T13:41:44.886Z'
originalURL: https://freecodecamp.org/news/build-a-serverless-ai-agent-for-generating-cold-emails
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1739971173263/869c0c1c-9b45-48af-a1d1-0982436b8630.png
tags:
- name: AI
  slug: ai
- name: llm
  slug: llm
- name: ai-agent
  slug: ai-agent
seo_title: Comment cr√©er un agent IA Serverless pour g√©n√©rer des emails de prospection
  pour votre emploi de r√™ve
seo_desc: 'Cold emails can make a huge difference in your job search, but writing
  the perfect one takes time. You need to match your skills with the job description,
  find the right tone, and do it over and over again‚Äîit‚Äôs exhausting.

  This guide will walk you th...'
---

Les emails de prospection peuvent faire une √©norme diff√©rence dans votre recherche d'emploi, mais √©crire le parfait prend du temps. Vous devez faire correspondre vos comp√©tences avec la description de poste, trouver le bon ton, et le faire encore et encore‚Äîc'est √©puisant.

Ce guide vous expliquera comment cr√©er un agent g√©n√©rateur d'emails de prospection en utilisant des agents de m√©moire serverless de Langbase pour automatiser ce processus entier. Nous int√©grerons l'agent de m√©moire dans un projet Node.js, lui permettant de lire votre CV, d'analyser la description de poste, et de g√©n√©rer un email de prospection personnalis√© et percutant en quelques secondes.

### Voici ce que je vais couvrir :

1. [Les grands mod√®les de langage (LLMs) sont sans √©tat par nature](#heading-les-grands-modeles-de-langage-llms-sont-sans-etat-par-nature)

2. [Qu'est-ce que les agents de m√©moire ?](#heading-quest-ce-que-les-agents-de-memoire)

3. [Pr√©requis](#heading-prerequis)

4. [Architecture de r√©f√©rence](#heading-architecture-de-reference)

5. [√âtape 1 : Cr√©er un r√©pertoire et initialiser npm](#heading-etape-1-creer-un-repertoire-et-initialiser-npm)

6. [√âtape 2 : Cr√©er un agent Pipe serverless](#heading-etape-2-creer-un-agent-pipe-serverless)

7. [√âtape 3 : Ajouter un fichier .env](#heading-etape-3-ajouter-un-fichier-env)

8. [√âtape 4 : Cr√©er un agent de m√©moire serverless](#heading-etape-4-creer-un-agent-de-memoire-serverless)

9. [√âtape 5 : Ajouter des documents √† l'agent de m√©moire](#heading-etape-5-ajouter-des-documents-a-lagent-de-memoire)

10. [√âtape 6 : G√©n√©rer des embeddings de m√©moire](#heading-etape-6-generer-des-embeddings-de-memoire)

    * [Comprendre les embeddings de m√©moire](#heading-comprendre-les-embeddings-de-memoire)

    * [Comment g√©n√©rer des embeddings ?](#heading-comment-generer-des-embeddings)

11. [√âtape 7 : Int√©grer la m√©moire dans l'agent Pipe](#heading-etape-7-integrer-la-memoire-dans-lagent-pipe)

12. [√âtape 8 : Int√©grer l'agent de m√©moire dans Node.js](#heading-etape-8-integrer-lagent-de-memoire-dans-nodejs)

13. [√âtape 9 : D√©marrer le serveur BaseAI](#heading-etape-9-demarrer-le-serveur-baseai)

14. [√âtape 10 : Ex√©cuter l'agent de m√©moire](#heading-etape-10-executer-lagent-de-memoire)

15. [Le r√©sultat](#heading-le-resultat)

## Les grands mod√®les de langage (LLMs) sont sans √©tat par nature

Les LLMs (grands mod√®les de langage) sont sans √©tat car ils ne conservent aucune m√©moire des interactions pr√©c√©dentes ou du contexte des requ√™tes pass√©es au-del√† de l'entr√©e qui leur est donn√©e dans une session. Chaque fois qu'un LLM traite une invite, il fonctionne sur cette invite sp√©cifique sans aucun historique des pr√©c√©dentes.

Cette nature sans √©tat permet au mod√®le de traiter chaque demande de mani√®re ind√©pendante, ce qui simplifie son architecture et son processus de formation. Mais cela signifie √©galement que, sans m√©canismes comme le RAG (Retrieval-Augmented Generation) ou la m√©moire (long terme), les LLMs ne peuvent pas transmettre d'informations d'une interaction √† l'autre.

Pour introduire une continuit√© ou un contexte, les d√©veloppeurs peuvent impl√©menter des syst√®mes externes pour g√©rer et injecter du contexte, mais le mod√®le lui-m√™me ne "se souvient" de rien entre les requ√™tes.

### Comment r√©soudre ce probl√®me ?

En int√©grant les **agents de m√©moire** de Langbase, nous pouvons donner aux LLMs une m√©moire √† long terme, leur permettant de stocker, r√©cup√©rer et utiliser des informations de mani√®re dynamique, les rendant ainsi beaucoup plus utiles pour des applications r√©elles.

## Qu'est-ce que les agents de m√©moire ?

Les [agents de m√©moire serverless de Langbase](https://langbase.com/docs/memory) (solution de m√©moire √† long terme) sont con√ßus pour acqu√©rir, traiter, conserver et r√©cup√©rer des informations de mani√®re transparente. Ils attachent dynamiquement des donn√©es priv√©es √† n'importe quel LLM, permettant des r√©ponses contextuelles en temps r√©el et r√©duisant les hallucinations.

Ces agents combinent le stockage vectoriel, la g√©n√©ration augment√©e par r√©cup√©ration (RAG) et l'acc√®s √† Internet pour cr√©er une API de recherche de contexte puissante et g√©r√©e. Les d√©veloppeurs peuvent les utiliser pour construire des applications IA plus intelligentes et plus capables.

Dans une configuration RAG, la m√©moire, lorsqu'elle est connect√©e directement √† un agent Pipe de Langbase, devient un agent de m√©moire. Ce couplage donne au LLM la capacit√© de r√©cup√©rer des donn√©es pertinentes et de fournir des r√©ponses pr√©cises et contextuellement exactes, r√©pondant aux limitations des LLMs en mati√®re de gestion de donn√©es priv√©es.

Les agents de m√©moire garantissent un stockage s√©curis√© de la m√©moire locale. Les donn√©es utilis√©es pour cr√©er des embeddings de m√©moire restent prot√©g√©es, trait√©es dans des environnements s√©curis√©s et envoy√©es √† l'ext√©rieur uniquement si explicitement configur√©es. L'acc√®s est strictement contr√¥l√© via des cl√©s API, garantissant que les informations sensibles restent en s√©curit√©.

Notez que pipe est un agent IA serverless. Il dispose d'une m√©moire agentique et d'outils.

## Pr√©requis

Avant de commencer √† cr√©er un agent g√©n√©rateur d'emails de prospection, vous devrez avoir la configuration et les outils suivants pr√™ts √† l'emploi.

Dans ce tutoriel, j'utiliserai cette stack technologique :

* [BaseAI](http://baseai.dev/) ‚Äî le framework web pour construire des agents IA localement.

* [Langbase](http://langbase.com/) ‚Äî la plateforme pour construire et d√©ployer vos agents IA serverless.

* [OpenAI](https://openai.com/) ‚Äî pour obtenir la cl√© LLM pour le mod√®le pr√©f√©r√©.

Vous devrez √©galement :

* Vous inscrire sur Langbase pour obtenir acc√®s √† la cl√© API.

* Vous inscrire sur OpenAI pour g√©n√©rer la cl√© LLM pour le mod√®le que vous souhaitez utiliser (pour cette d√©monstration, j'utiliserai GPT-4o mini). Vous pouvez g√©n√©rer la cl√© [ici](https://platform.openai.com/api-keys).

## Architecture de r√©f√©rence

Voici une repr√©sentation diagramme de l'ensemble du processus de construction d'un agent IA serverless pour g√©n√©rer des emails de prospection pour les candidatures √† des emplois :

![Architecture de r√©f√©rence des agents de m√©moire en fonctionnement](https://cdn.hashnode.com/res/hashnode/image/upload/v1739900463621/e2b6753e-287f-4d69-b453-36d50f316fb8.png align="center")

Commen√ßons √† construire l'agent !

## √âtape 1 : Cr√©er un r√©pertoire et initialiser npm

Pour commencer √† cr√©er un agent IA serverless qui g√©n√®re des emails de prospection pour une offre d'emploi, vous devez cr√©er un r√©pertoire dans votre machine locale et y installer toutes les d√©pendances de d√©veloppement pertinentes. Vous pouvez le faire en naviguant vers celui-ci et en ex√©cutant la commande suivante dans le terminal :

```bash
mkdir my-project
npm init -y
npm install dotenv
```

Cette commande cr√©era un fichier package.json dans votre r√©pertoire de projet avec des valeurs par d√©faut. Elle installera √©galement le package `dotenv` pour lire les variables d'environnement depuis le fichier `.env`.

## √âtape 2 : Cr√©er un agent Pipe serverless

Ensuite, nous allons cr√©er un [agent pipe](https://langbase.com/docs/pipe/quickstart). Les Pipes sont diff√©rents des autres agents, car ils sont des agents IA serverless avec des outils agentiques qui peuvent fonctionner avec n'importe quel langage ou framework. Ils sont facilement d√©ployables, et avec une seule API, ils vous permettent de connecter plus de 250 LLMs √† n'importe quelle donn√©e pour construire n'importe quel workflow d'API de d√©veloppeur.

Pour cr√©er votre pipe d'agent IA, naviguez vers votre r√©pertoire de projet. Ex√©cutez la commande suivante :

```bash
npx baseai@latest pipe
```

Lors de l'ex√©cution, vous verrez les invites suivantes :

```bash
BaseAI n'est pas install√© mais est requis pour fonctionner. Souhaitez-vous l'installer ? Oui/Non
Nom du pipe ? email-generator-agent
Description du pipe ? G√©n√®re des emails pour votre emploi de r√™ve en quelques secondes
Statut du pipe ? Public/Priv√©
Invite syst√®me ? Vous √™tes un assistant IA utile
```

Une fois que vous avez termin√© avec le nom, la description et le statut du pipe de l'agent IA, tout sera configur√© automatiquement pour vous. Votre pipe sera cr√©√© avec succ√®s √† `/baseai/pipes/email-generator-agent.ts`.

## √âtape 3 : Ajouter un fichier .env

Cr√©ez un fichier `.env` dans le r√©pertoire racine de votre projet et ajoutez-y les cl√©s API OpenAI et Langbase. Vous pouvez acc√©der √† votre cl√© API Langbase depuis [ici](https://langbase.com/docs/api-reference/api-keys).

## √âtape 4 : Cr√©er un agent de m√©moire serverless

Ensuite, nous allons cr√©er une m√©moire puis l'attacher au Pipe pour en faire un agent de m√©moire. Pour ce faire, ex√©cutez cette commande dans votre terminal :

```bash
npx baseai@latest memory
```

Lors de l'ex√©cution de cette commande, vous verrez les invites suivantes :

```bash
Nom de la m√©moire ? email-generator-memory
Description de la m√©moire ? Contient mon CV
Souhaitez-vous cr√©er une m√©moire √† partir du d√©p√¥t git du projet actuel ? Oui/Non
```

Apr√®s cela, tout sera configur√© automatiquement pour vous et vous pourrez acc√©der √† votre m√©moire cr√©√©e avec succ√®s √† `/baseai/memory/email-generator-memory.ts`.

## √âtape 5 : Ajouter des documents √† l'agent de m√©moire

√Ä l'int√©rieur de `/baseai/memory/email-generator-memory.ts`, vous verrez un autre dossier appel√© documents. C'est l√† que vous stockerez les fichiers que vous souhaitez que votre agent IA acc√®de. Enregistrons votre CV sous forme de fichier `.pdf` ou `.txt`. Ensuite, je vais le convertir en fichier markdown et le placer dans le r√©pertoire `/baseai/memory/email-generator-memory/documents`.

Cette √©tape garantit que l'agent de m√©moire peut traiter et r√©cup√©rer des informations √† partir de vos documents, rendant l'agent IA capable de g√©n√©rer des emails de prospection pr√©cis bas√©s sur les exp√©riences et comp√©tences fournies dans le CV joint.

## √âtape 6 : G√©n√©rer des embeddings de m√©moire

Avec vos documents ajout√©s √† la m√©moire, l'√©tape suivante consiste √† g√©n√©rer des embeddings de m√©moire. Mais avant cela, laissez-moi expliquer rapidement ce que sont les embeddings et pourquoi ils sont importants.

### Comprendre les embeddings de m√©moire

Les embeddings de m√©moire sont des repr√©sentations num√©riques de vos documents qui permettent √† une IA de saisir le contexte, les relations et le sens dans le texte. Ils agissent comme un pont, convertissant les donn√©es brutes en un format structur√© que l'IA peut traiter pour la recherche s√©mantique et la r√©cup√©ration.

Sans embeddings, les agents IA ne pourraient pas connecter efficacement les requ√™tes des utilisateurs avec le contenu pertinent. La g√©n√©ration d'embeddings cr√©e un index recherchable, permettant √† l'agent de m√©moire de fournir des r√©ponses pr√©cises et contextuellement conscientes de mani√®re efficace.

### Comment g√©n√©rer des embeddings

Pour g√©n√©rer des embeddings pour vos documents, ex√©cutez la commande suivante dans votre terminal :

```bash
npx baseai@latest embed -m email-generator-memory
```

Votre m√©moire est maintenant pr√™te √† √™tre connect√©e √† un Pipe (agent de m√©moire), permettant √† votre agent IA de r√©cup√©rer des r√©ponses pr√©cises et contextuellement conscientes √† partir de vos documents.

## √âtape 7 : Int√©grer la m√©moire dans l'agent Pipe

Ensuite, vous devez attacher la m√©moire que vous avez cr√©√©e √† votre agent Pipe pour en faire un agent de m√©moire. Pour cela, allez dans `/baseai/pipes/email-generator-agent.ts`. Voici √† quoi cela ressemblera pour le moment :

```typescript
import { PipeI } from '@baseai/core';

const pipePipeWithMemory = (): PipeI => ({
  apiKey: process.env.LANGBASE_API_KEY!, // Remplacez par votre cl√© API https://langbase.com/docs/api-reference/api-keys
  name: 'email-generator-agent',
  description: 'G√©n√®re des emails pour votre emploi de r√™ve en quelques secondes',
  status: 'public',
  model: 'openai:gpt-4o-mini',
  stream: true,
  json: false,
  store: true,
  moderate: true,
  top_p: 1,
  max_tokens: 1000,
  temperature: 0.7,
  presence_penalty: 1,
  frequency_penalty: 1,
  stop: [],
  tool_choice: 'auto',
  parallel_tool_calls: false,
  messages: [
    { role: 'system', content: Vous √™tes un assistant IA utile. }],
  variables: [],
  memory: [],
  tools: []
});

export default pipePipeWithMemory;
```

Maintenant, int√©grez la m√©moire dans le pipe en l'important en haut et en l'appelant en tant que fonction dans le tableau `memory`. Ajoutez √©galement ce qui suit dans le contenu des messages :

```bash
Sur la base de la description de poste et de mon CV joint, r√©digez un email de prospection convaincant adapt√© au poste, mettant en avant mes comp√©tences, r√©alisations et exp√©riences les plus pertinentes. Assurez-vous que le ton est professionnel mais accessible, et incluez un appel √† l'action fort pour un suivi ou un entretien.
```

Voici √† quoi ressemblera le code apr√®s avoir fait tout cela :

```typescript
import { PipeI } from '@baseai/core';
import emailGeneratorMemoryMemory from '../memory/email-generator-memory';

const pipeEmailGeneratorAgent = (): PipeI => ({
  // Remplacez par votre cl√© API https://langbase.com/docs/api-reference/api-keys
  apiKey: process.env.LANGBASE_API_KEY!,
  name: 'email-generator-agent',
  description: 'G√©n√®re des emails pour votre emploi de r√™ve en quelques secondes',
  status: 'private',
  model: 'openai:gpt-4o-mini',
  stream: true,
  json: false,
  store: true,
  moderate: true,
  top_p: 1,
  max_tokens: 1000,
  temperature: 0.7,
  presence_penalty: 1,
  frequency_penalty: 1,
  stop: [],
  tool_choice: 'auto',
  parallel_tool_calls: true,
  messages: [{ role: 'system', content: Sur la base de la description de poste et de mon CV joint, r√©digez un email de prospection convaincant adapt√© au poste, mettant en avant mes comp√©tences, r√©alisations et exp√©riences les plus pertinentes. Assurez-vous que le ton est professionnel mais accessible, et incluez un appel √† l'action fort pour un suivi ou un entretien. }],
  variables: [],
  memory: [emailGeneratorMemoryMemory()],
  tools: []
});

export default pipeEmailGeneratorAgent;
```

## √âtape 8 : Int√©grer l'agent de m√©moire dans Node.js

Maintenant, nous allons int√©grer l'agent de m√©moire que vous avez cr√©√© dans le projet Node.js pour construire une interface de ligne de commande (CLI) interactive pour le document joint. Ce projet Node.js servira de base pour tester et interagir avec l'agent de m√©moire (au d√©but du tutoriel, nous avons configur√© un projet Node.js en initialisant npm).

Maintenant, cr√©ez un fichier index.ts :

```bash
touch index.ts
```

Dans ce fichier TypeScript, importez l'agent pipe que vous avez cr√©√©. Nous utiliserons le primitif pipe de `@baseai/core` pour ex√©cuter le pipe.

Ajoutez le code suivant au fichier `index.ts` :

```typescript
import 'dotenv/config';
import { Pipe } from '@baseai/core';
import inquirer from 'inquirer';
import ora from 'ora';
import chalk from 'chalk';
import pipeEmailGeneratorAgent from './baseai/pipes/email-generator-agent';

const pipe = new Pipe(pipeEmailGeneratorAgent());

async function main() {

  const initialSpinner = ora('Conversation avec l\'agent de m√©moire...').start();
  try {
    const { completion: calculatorTool} = await pipe.run({
      messages: [{ role: 'user', content: 'Bonjour' }],
    });
    initialSpinner.stop();
    console.log(chalk.cyan('R√©ponse de l\'agent g√©n√©rateur de rapport...'));
    console.log(calculatorTool);
  } catch (error) {
    initialSpinner.stop();
    console.error(chalk.red('Erreur lors du traitement de la demande initiale :'), error);
  }

  while (true) {
    const { userMsg } = await inquirer.prompt([
      {
        type: 'input',
        name: 'userMsg',
        message: chalk.blue('Entrez votre requ√™te (ou tapez "exit" pour quitter) :'),
      },
    ]);


    if (userMsg.toLowerCase() === 'exit') {
      console.log(chalk.green('Au revoir !'));
      break;
    }


    const spinner = ora('Traitement de votre demande...').start();


    try {
      const { completion: reportAgentResponse } = await pipe.run({
        messages: [{ role: 'user', content: userMsg }],
      });


      spinner.stop();
      console.log(chalk.cyan('Agent :'));
      console.log(reportAgentResponse);
    } catch (error) {
      spinner.stop();
      console.error(chalk.red('Erreur lors du traitement de votre demande :'), error);
    }
  }
}

main();
```

Ce code cr√©e une CLI interactive pour discuter avec un agent IA, en utilisant un pipe de la biblioth√®que `@baseai/core` pour traiter l'entr√©e de l'utilisateur. Voici ce qui se passe :

* Il importe les biblioth√®ques n√©cessaires telles que `dotenv` pour la configuration de l'environnement, `inquirer` pour l'entr√©e de l'utilisateur, `ora` pour les spinners de chargement, et `chalk` pour la sortie color√©e. Assurez-vous d'abord d'installer ces biblioth√®ques en utilisant cette commande dans votre terminal : `npm install ora inquirer`.

* Un objet pipe est cr√©√© √† partir de la biblioth√®que BaseAI en utilisant une m√©moire pr√©d√©finie appel√©e `email-generator-agent`.

Dans la fonction `main()` :

* Un spinner d√©marre pendant qu'une conversation initiale avec l'agent IA est initi√©e avec le message 'Bonjour'.

* La r√©ponse de l'IA est affich√©e.

* Une boucle s'ex√©cute pour demander continuellement √† l'utilisateur une entr√©e et envoyer des requ√™tes √† l'agent IA.

* Les r√©ponses de l'IA sont affich√©es, et le processus continue jusqu'√† ce que l'utilisateur tape "exit".

## √âtape 9 : D√©marrer le serveur BaseAI

Pour ex√©cuter l'agent de m√©moire localement, vous devez d'abord d√©marrer le serveur BaseAI. Ex√©cutez la commande suivante dans votre terminal :

```bash
npx baseai@latest dev
```

## √âtape 10 : Ex√©cuter l'agent de m√©moire

Ex√©cutez le fichier `index.ts` en utilisant la commande suivante :

```bash
npx tsx index.ts
```

## Le r√©sultat

Dans votre terminal, vous serez invit√© √† "Entrez votre requ√™te". Par exemple, collons une description de poste et demandons de g√©n√©rer un email de notre c√¥t√© montrant de l'int√©r√™t. Et il nous donnera la r√©ponse avec les bonnes sources/citations √©galement.

Avec cette configuration, nous avons construit un agent g√©n√©rateur d'emails de prospection qui utilise la puissance des LLMs et des agents de m√©moire de Langbase pour surmonter les limitations des LLMs, garantissant des r√©ponses pr√©cises sans hallucinations sur les donn√©es priv√©es.

Voici une d√©monstration du r√©sultat final :

%[https://youtu.be/ns7UqX6Ycs8]

Merci d'avoir lu !

Connectez-vous avec moi par üëå :

* En vous abonnant √† ma cha√Æne [YouTube](https://www.youtube.com/@AIwithMahamCodes). Si vous souhaitez apprendre sur l'IA et les agents.

* En vous abonnant √† ma newsletter gratuite ["The Agentic Engineer"](https://mahamcodes.substack.com/) o√π je partage toutes les derni√®res nouvelles/tendances/emplois en IA et agents, et bien plus encore.

* Suivez-moi sur [X (Twitter)](https://x.com/MahamDev).