---
title: Comment construire un chatbot IA conversationnel avec Stream Chat et React
subtitle: ''
author: Timothy Olanrewaju
co_authors: []
series: null
date: '2025-06-17T20:29:11.402Z'
originalURL: https://freecodecamp.org/news/build-a-conversational-ai-chatbot-with-stream-chat-and-react
coverImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1750192110424/b23653af-c2de-4631-973f-dcac3c0bdb41.png
tags:
- name: React
  slug: reactjs
- name: AI
  slug: ai
- name: chatbot
  slug: chatbot
seo_title: Comment construire un chatbot IA conversationnel avec Stream Chat et React
seo_desc: Modern chat applications are increasingly incorporating voice input capabilities
  because they offer a more engaging and versatile user experience. This also improves
  accessibility, allowing users with different needs to interact more comfortably
  with...
---

Les applications de chat modernes int√®grent de plus en plus des capacit√©s de saisie vocale car elles offrent une exp√©rience utilisateur plus engageante et polyvalente. Cela am√©liore √©galement l'accessibilit√©, permettant aux utilisateurs ayant des besoins diff√©rents d'interagir plus confortablement avec de telles applications.

Dans ce tutoriel, je vais vous guider √† travers le processus de cr√©ation d'une application IA conversationnelle qui int√®gre une fonctionnalit√© de chat en temps r√©el avec reconnaissance vocale. En tirant parti de Stream Chat pour une messagerie robuste et de l'API Web Speech pour la conversion de la parole en texte, vous construirez une application de chat multifacette qui prend en charge √† la fois les interactions vocales et textuelles.

## Table des mati√®res

* [Pr√©requis](#heading-pr√©requis)
    
* [Aper√ßu](#heading-aper√ßu)
    
* [Technologies principales](#heading-technologies-principales)
    
* [Guide d'impl√©mentation du backend](#heading-guide-dimpl√©mentation-du-backend)
    
    * [Installation du projet](#heading-installation-du-projet)
        
* [Guide d'impl√©mentation du frontend](#heading-guide-dimpl√©mentation-du-frontend)
    
    * [Installation du projet](#heading-installation-du-projet-1)
        
    * [Comprendre le composant App](#heading-comprendre-le-composant-app)
        
    * [Ajout de l'IA au canal](#heading-ajout-de-lia-au-canal)
        
    * [Configuration du ChannelHeader](#heading-configuration-du-channelheader)
        
    * [Ajout d'un indicateur d'√©tat de l'IA](#heading-ajout-dun-indicateur-d√©tat-de-lia)
        
    * [Construction de la fonctionnalit√© de reconnaissance vocale](#heading-construction-de-la-fonctionnalit√©-de-reconnaissance-vocale)
        
* [Flux de processus complet](#heading-flux-de-processus-complet)
    
* [Conclusion](#heading-conclusion)
    

## Pr√©requis

Avant de commencer, assurez-vous d'avoir les √©l√©ments suivants :

* Un compte Stream avec une cl√© API et un secret (Lisez comment les obtenir [ici](https://getstream.io/blog/stream-getting-started-guide/))
    
* Acc√®s √† une API LLM (comme OpenAI, Anthropic).
    
* Node.js et npm/yarn install√©s.
    
* Connaissance de base de React et TypeScript.
    
* Navigateur moderne avec support de l'API WebSpeech (comme Chrome, Edge)
    

## Aper√ßu

Prenons un rapide aper√ßu de l'application que nous allons construire dans ce tutoriel. Ainsi, vous aurez une id√©e de ce qu'elle fait avant de plonger dans les d√©tails.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1749925010635/5228ae93-ff56-4b0f-8ea8-c7a160973191.gif align="center")

Si vous √™tes maintenant excit√©, commen√ßons tout de suite !

## Technologies principales

Cette application est aliment√©e par trois principaux acteurs : Stream Chat, l'API Web Speech et un backend Node.js + Express.

[Stream Chat](https://getstream.io/) est une plateforme qui vous aide √† construire et int√©grer facilement des exp√©riences de chat et de messagerie riches et en temps r√©el dans vos applications. Il offre une vari√©t√© de SDK (Software Development Kits) pour diff√©rentes plateformes (comme Android, iOS, React) et des composants d'interface utilisateur pr√©-construits pour rationaliser le d√©veloppement. Sa robustesse et ses fonctionnalit√©s de chat engageantes en font un excellent choix pour cette application - nous n'avons pas besoin de construire quoi que ce soit √† partir de z√©ro.

[Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) est une norme de navigateur qui vous permet d'int√©grer l'entr√©e et la sortie vocales dans vos applications, permettant des fonctionnalit√©s comme la reconnaissance vocale (conversion de la parole en texte) et la synth√®se vocale (conversion du texte en parole). Nous utiliserons la fonctionnalit√© de reconnaissance vocale dans ce projet.

Le backend Node.js + Express g√®re l'instantiation correcte de l'agent et traite les r√©ponses conversationnelles g√©n√©r√©es par notre API LLM.

## Guide d'impl√©mentation du backend

Commen√ßons par notre backend, la salle des machines - o√π l'entr√©e de l'utilisateur est achemin√©e vers le mod√®le IA appropri√©, et une r√©ponse trait√©e est retourn√©e. Notre backend prend en charge plusieurs mod√®les IA, sp√©cifiquement OpenAI et Anthropic.

### Installation du projet

1. Cr√©ez un dossier, appelez-le 'My-Chat-Application'.
    
2. Clonez ce [d√©p√¥t Github](https://github.com/GetStream/ai-assistant-nodejs.git)
    
3. Apr√®s le clonage, renommez le dossier en 'backend'
    
4. Ouvrez le fichier `.env.example` et fournissez les cl√©s n√©cessaires (vous devrez fournir soit la cl√© OpenAI soit la cl√© Anthropic - la cl√© Open Weather est facultative).
    
5. Renommez le fichier `env.example` en `.env`
    
6. Installez les d√©pendances en ex√©cutant cette commande :
    
    ```javascript
    npm install
    ```
    
7. Ex√©cutez le projet en entrant cette commande :
    
    ```javascript
    npm start
    ```
    
    Votre backend devrait fonctionner sans probl√®me sur `localhost:3000`.
    

## Guide d'impl√©mentation du frontend

Cette section explore deux composants larges et interd√©pendants : la structure du chat et la reconnaissance vocale.

### Installation du projet

Nous allons cr√©er et configurer notre projet React avec le SDK Stream Chat React. Nous utiliserons Vite avec le mod√®le TypeScript. Pour cela, naviguez vers votre dossier **My-Chat-Application**, ouvrez votre terminal et entrez cette commande :

```javascript
npm create vite frontend -- --template react-ts
cd chat-example
npm i stream-chat stream-chat-react
```

Avec notre projet frontend configur√©, nous pouvons maintenant ex√©cuter l'application :

```javascript
npm run dev
```

### Comprendre le composant App

L'objectif principal ici est d'initialiser un client de chat, de connecter un utilisateur, de cr√©er un canal et de rendre l'interface de chat. Nous allons passer par tous ces processus √©tape par √©tape pour vous aider √† mieux les comprendre :

#### D√©finir les constantes

Tout d'abord, nous devons fournir certaines informations d'identification importantes dont nous avons besoin pour la cr√©ation d'utilisateurs et la configuration du client de chat. Vous pouvez trouver ces informations d'identification sur votre tableau de bord Stream [dashboard](https://dashboard.getstream.io/).

```javascript
const apiKey = "xxxxxxxxxxxxx";
const userId = "111111111";
const userName = "John Doe";
const userToken = "xxxxxxxxxx.xxxxxxxxxxxx.xx_xxxxxxx-xxxxx_xxxxxxxx"; // votre cl√© secr√®te stream
```

> Note : Ce sont des informations d'identification factices. Assurez-vous d'utiliser vos propres informations d'identification.

#### Cr√©er un utilisateur

Ensuite, nous devons cr√©er un objet utilisateur. Nous allons le cr√©er en utilisant un ID, un nom et une URL d'avatar g√©n√©r√©e :

```javascript
const user: User = {
  id: userId,
  name: userName,
  image: `https://getstream.io/random_png/?name=${userName}`,
};
```

#### Configurer un client

Nous devons suivre l'√©tat du canal de chat actif en utilisant le hook `useState` pour garantir une messagerie en temps r√©el sans faille dans cette application Stream Chat. Un hook personnalis√© appel√© `useCreateChatClient` initialise le client de chat avec une cl√© API, un jeton utilisateur et des donn√©es utilisateur :

```javascript
  const [channel, setChannel] = useState<StreamChannel>();
  const client = useCreateChatClient({
    apiKey,
    tokenOrProvider: userToken,
    userData: user,
  });
```

#### Initialiser le canal

Maintenant, nous initialisons un canal de messagerie pour permettre la communication en temps r√©el dans l'application Stream Chat. Lorsque le client de chat est pr√™t, le hook `useEffect` d√©clenche la cr√©ation d'un canal de messagerie nomm√© `my_channel`, ajoutant l'utilisateur comme membre. Ce canal est ensuite stock√© dans l'√©tat du canal, garantissant que l'application est pr√™te pour le rendu dynamique de la conversation.

```javascript
  useEffect(() => {
    if (!client) return;
    const channel = client.channel("messaging", "my_channel", {
      members: [userId],
    });

    setChannel(channel);
  }, [client]);
```

#### Rendre l'interface de chat

Avec toutes les parties int√©grales de notre application de chat configur√©es, nous allons retourner un JSX pour d√©finir la structure et les composants de l'interface de chat :

```javascript
 if (!client) return <div>Configuration du client et de la connexion...</div>;

  return (
    <Chat client={client}>
      <Channel channel={channel}>
        <Window>
          <MessageList />
          <MessageInput />
        </Window>
        <Thread />
      </Channel>
    </Chat>
  );
```

Dans cette structure JSX :

* Si le client n'est pas pr√™t, il affiche un message "Configuration du client et de la connexion...".
    
* Une fois le client pr√™t, il rend l'interface de chat en utilisant :
    
    * `<Chat>` : Enveloppe le contexte Stream Chat avec le client initialis√©.
        
    * `<Channel>` : D√©finit le canal actif.
        
    * `<Window>` : Contient les principaux composants de l'interface utilisateur de chat :
        
        * `<MessageList>` : Affiche la liste des messages.
            
        * `<MessageInput>` : Utilise un `CustomMessageInput` personnalis√© pour envoyer des messages.
            
    * `<Thread>` : Rend les r√©ponses en fil de discussion.
        

Avec cela, nous avons configur√© notre interface de chat et notre canal, et nous avons un client pr√™t. Voici √† quoi ressemble notre interface jusqu'√† pr√©sent :

![interface de chat stream](https://cdn.hashnode.com/res/hashnode/image/upload/v1749901280964/4b788065-27ae-40b4-9882-c74bacef0fc4.png align="center")

### Ajout de l'IA au canal

Rappelez-vous, cette application de chat est con√ßue pour interagir avec une IA, donc nous devons pouvoir √† la fois ajouter et supprimer l'IA du canal. Sur l'interface utilisateur, nous allons ajouter un bouton dans l'en-t√™te du canal pour permettre aux utilisateurs d'ajouter et de supprimer l'IA. Mais nous devons encore d√©terminer si nous l'avons d√©j√† dans le canal pour savoir quelle option afficher.

Pour cela, nous allons cr√©er un hook personnalis√© appel√© `useWatchers`. Il surveille la pr√©sence de l'IA en utilisant un concept appel√© `watchers` :

```javascript
import { useCallback, useEffect, useState } from 'react';
import { Channel } from 'stream-chat';

export const useWatchers = ({ channel }: { channel: Channel }) => {
  const [watchers, setWatchers] = useState<string[]>([]);
  const [error, setError] = useState<Error | null>(null);

  const queryWatchers = useCallback(async () => {
    setError(null);

    try {
      const result = await channel.query({ watchers: { limit: 5, offset: 0 } });
      setWatchers(result?.watchers?.map((watcher) => watcher.id).filter((id): id is string => id !== undefined) || [])
      return;
    } catch (err) {
      setError(err as Error);
    }
  }, [channel]);

  useEffect(() => {
    queryWatchers();
  }, [queryWatchers]);

  useEffect(() => {
    const watchingStartListener = channel.on('user.watching.start', (event) => {
      const userId = event?.user?.id;
      if (userId && userId.startsWith('ai-bot')) {
        setWatchers((prevWatchers) => [
          userId,
          ...(prevWatchers || []).filter((watcherId) => watcherId !== userId),
        ]);
      }
    });

    const watchingStopListener = channel.on('user.watching.stop', (event) => {
      const userId = event?.user?.id;
      if (userId && userId.startsWith('ai-bot')) {
        setWatchers((prevWatchers) =>
          (prevWatchers || []).filter((watcherId) => watcherId !== userId)
        );
      }
    });

    return () => {
      watchingStartListener.unsubscribe();
      watchingStopListener.unsubscribe();
    };
  }, [channel]);

  return { watchers, error };
};
```

### Configuration du ChannelHeader

Nous pouvons maintenant construire un nouveau composant d'en-t√™te de canal en utilisant le hook `useChannelStateContext` pour acc√©der au canal et initialiser le hook personnalis√© `useWatchers`. En utilisant les donn√©es des observateurs, nous d√©finissons une variable `aiInChannel` pour afficher le texte pertinent. En fonction de cette variable, nous invoquons soit le point de terminaison `start-ai-agent` soit `stop-ai-agent` sur le backend Node.js.

```javascript
import { useChannelStateContext } from 'stream-chat-react';
import { useWatchers } from './useWatchers';

export default function ChannelHeader() {
  const { channel } = useChannelStateContext();
  const { watchers } = useWatchers({ channel });

  const aiInChannel =
    (watchers ?? []).filter((watcher) => watcher.includes('ai-bot')).length > 0;
  return (
    <div className='my-channel-header'>
      <h2>{(channel?.data as { name?: string })?.name ?? 'Chat IA vocale et textuelle'}</h2>
      <button onClick={addOrRemoveAgent}>
        {aiInChannel ? 'Retirer l\'IA' : 'Ajouter l\'IA'}
      </button>
    </div>
  );

  async function addOrRemoveAgent() {
    if (!channel) return;
    const endpoint = aiInChannel ? 'stop-ai-agent' : 'start-ai-agent';
    await fetch(`http://127.0.0.1:3000/${endpoint}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ channel_id: channel.id, platform: 'openai' }),
    });
  }
}
```

### Ajout d'un indicateur d'√©tat de l'IA

Les IA prennent un peu de temps pour traiter les informations, donc pendant que l'IA traite, nous ajoutons un indicateur pour refl√©ter son statut. Nous cr√©ons un `AIStateIndicator` qui fait cela pour nous :

```javascript
import { AIState } from 'stream-chat';
import { useAIState, useChannelStateContext } from 'stream-chat-react';

export default function MyAIStateIndicator() {
  const { channel } = useChannelStateContext();
  const { aiState } = useAIState(channel);
  const text = textForState(aiState);
  return text && <p className='my-ai-state-indicator'>{text}</p>;

  function textForState(aiState: AIState): string {
    switch (aiState) {
      case 'AI_STATE_ERROR':
        return 'Quelque chose s\'est mal pass√©...';
      case 'AI_STATE_CHECKING_SOURCES':
        return 'V√©rification des ressources externes...';
      case 'AI_STATE_THINKING':
        return "Je r√©fl√©chis actuellement...";
      case 'AI_STATE_GENERATING':
        return 'G√©n√©ration d\'une r√©ponse pour vous...';
      default:
        return '';
    }
  }
}
```

### Construction de la fonctionnalit√© de reconnaissance vocale

Jusqu'√† pr√©sent, nous avons une application de chat fonctionnelle qui envoie des messages et re√ßoit des commentaires d'une IA. Maintenant, nous voulons activer l'interaction vocale, permettant aux utilisateurs de parler √† l'IA au lieu de taper manuellement.

Pour y parvenir, nous allons configurer la fonctionnalit√© de reconnaissance vocale dans un composant `CustomMessageInput`. Passons en revue l'ensemble du processus, √©tape par √©tape, pour comprendre comment y parvenir.

#### Configuration initiale des √©tats

Lorsque le composant `CustomMessageInput` est mont√© pour la premi√®re fois, il commence par √©tablir sa structure d'√©tat fondamentale :

```javascript
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [isRecognitionReady, setIsRecognitionReady] = useState<boolean>(false);
  const recognitionRef = useRef<any>(null);
  const isManualStopRef = useRef<boolean>(false);
  const currentTranscriptRef = useRef<string>("");
```

Cette √©tape d'initialisation est cruciale car elle √©tablit la capacit√© du composant √† suivre plusieurs √©tats concurrents : si l'enregistrement est actif, si l'API de reconnaissance vocale est pr√™te, et divers m√©canismes de persistance pour g√©rer le cycle de vie de la reconnaissance vocale.

#### Int√©gration du contexte

Dans Stream Chat, le `MessageInputContext` est √©tabli dans le composant `MessageInput`. Il fournit des donn√©es au composant d'interface utilisateur Input et √† ses enfants. Puisque nous voulons utiliser les valeurs stock√©es dans le `MessageInputContext` pour construire notre propre composant d'interface utilisateur d'entr√©e personnalis√©, nous allons appeler le hook personnalis√© `useMessageInputContext` :

```javascript
  // Acc√©der au contexte MessageInput
  const { handleSubmit, textareaRef } = useMessageInputContext();
```

Cette √©tape garantit que la fonctionnalit√© d'entr√©e vocale s'int√®gre de mani√®re transparente avec l'infrastructure de chat existante, partageant la m√™me r√©f√©rence `textarea` et les m√©canismes de soumission que les autres m√©thodes d'entr√©e utilisent.

#### D√©tection et initialisation de l'API Web Speech

L'API Web Speech n'est pas prise en charge par certains navigateurs, c'est pourquoi nous devons v√©rifier si le navigateur ex√©cutant cette application est compatible. Le premier processus majeur du composant implique la d√©tection et l'initialisation de l'API Web Speech :

```javascript
 const SpeechRecognition = (window as any).SpeechRecognition||(window as any).webkitSpeechRecognition;
```

Une fois l'API d√©tect√©e, le composant configure le service de reconnaissance vocale avec des param√®tres optimaux.

#### Configuration des gestionnaires d'√©v√©nements

Nous aurons deux gestionnaires d'√©v√©nements : le gestionnaire de traitement des r√©sultats et le gestionnaire d'√©v√©nements de cycle de vie.

Le gestionnaire de traitement des r√©sultats traite la sortie de la reconnaissance vocale. Il d√©montre une approche de traitement en deux phases o√π les r√©sultats interm√©diaires fournissent un retour imm√©diat tandis que les r√©sultats finaux sont accumul√©s pour la pr√©cision.

```javascript
      recognition.onresult = (event: any) => {
        let finalTranscript = "";
        let interimTranscript = "";

        // Traiter tous les r√©sultats √† partir du dernier index trait√©
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcriptSegment = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcriptSegment + " ";
          } else {
            interimTranscript += transcriptSegment;
          }
        }

        // Mettre √† jour la transcription actuelle
        if (finalTranscript) {
          currentTranscriptRef.current += finalTranscript;
        }

        // Combiner la transcription finale stock√©e avec les r√©sultats interm√©diaires actuels
        const combinedTranscript = (currentTranscriptRef.current + interimTranscript).trim();
        
        // Mettre √† jour le textarea
        if (combinedTranscript) {
          updateTextareaValue(combinedTranscript);
        }
      };
```

Le gestionnaire d'√©v√©nements de cycle de vie garantit que le composant r√©pond de mani√®re appropri√©e √† chaque phase des √©v√©nements de cycle de vie de la reconnaissance vocale (`onstart`, `onend` et `onerror`) :

```javascript
      recognition.onstart = () => {
        console.log("La reconnaissance vocale a commenc√©");
        setIsRecording(true);
        currentTranscriptRef.current = ""; // R√©initialiser la transcription au d√©marrage
      };

      recognition.onend = () => {
        console.log("La reconnaissance vocale s'est termin√©e");
        setIsRecording(false);
        
        // Si ce n'√©tait pas un arr√™t manuel et que nous devons encore enregistrer, red√©marrer
        if (!isManualStopRef.current && isRecording) {
          try {
            recognition.start();
          } catch (error) {
            console.error("Erreur de red√©marrage de la reconnaissance :", error);
          }
        }
        
        isManualStopRef.current = false;
      };

      recognition.onerror = (event: any) => {
        console.error("Erreur de reconnaissance vocale :", event.error);
        setIsRecording(false);
        isManualStopRef.current = false;

        switch (event.error) {
          case "no-speech":
            console.warn("Aucune parole d√©tect√©e");
            // Ne pas afficher d'alerte pour l'absence de parole, simplement la journaliser
            break;
          case "not-allowed":
            alert(
              "Acc√®s au microphone refus√©. Veuillez autoriser les permissions du microphone.",
            );
            break;
          case "network":
            alert("Une erreur r√©seau s'est produite. Veuillez v√©rifier votre connexion.");
            break;
          case "aborted":
            console.log("Reconnaissance vocale abandonn√©e");
            break;
          default:
            console.error("Erreur de reconnaissance vocale :", event.error);
        }
      };

      recognitionRef.current = recognition;
      setIsRecognitionReady(true);
      } else {
      console.warn("L'API Web Speech n'est pas prise en charge dans ce navigateur.");
      setIsRecognitionReady(false);
      }
```

#### D√©marrage de l'entr√©e vocale

Lorsque l'utilisateur clique sur le bouton du microphone, le composant initie un processus en plusieurs √©tapes qui implique la demande de permissions pour le microphone et la gestion claire des erreurs si les utilisateurs refusent l'acc√®s.

```javascript
 const toggleRecording = async (): Promise<void> => {
    if (!recognitionRef.current) {
      alert("La reconnaissance vocale n'est pas disponible");
      return;
    }

    if (isRecording) {
      // Arr√™ter l'enregistrement
      isManualStopRef.current = true;
      recognitionRef.current.stop();
    } else {
      try {
        // Demander la permission du microphone
        await navigator.mediaDevices.getUserMedia({ audio: true });

        // Effacer le texte actuel et r√©initialiser la transcription avant de commencer
        currentTranscriptRef.current = "";
        updateTextareaValue("");

        // D√©marrer la reconnaissance
        recognitionRef.current.start();
      } catch (error) {
        console.error("Erreur d'acc√®s au microphone :", error);
        alert(
          "Impossible d'acc√©der au microphone. Veuillez v√©rifier les permissions et r√©essayer.",
        );
      }
    }
  };
```

#### R√©initialisation de l'√©tat et d√©marrage de la reconnaissance

Avant de commencer la reconnaissance vocale, le composant r√©initialise son √©tat interne. Cette r√©initialisation garantit que chaque nouvelle session d'entr√©e vocale commence avec une ardoise propre, emp√™chant les interf√©rences des sessions pr√©c√©dentes.

```javascript
currentTranscriptRef.current = "";
updateTextareaValue("");
recognitionRef.current.start();
```

#### Traitement de la parole en temps r√©el

Deux choses se produisent simultan√©ment pendant ce processus :

1. **Traitement continu des r√©sultats :** Alors que l'utilisateur parle, le composant traite en continu les donn√©es vocales entrantes via un pipeline sophistiqu√© :
    
    * Chaque segment de parole est class√© comme interm√©diaire (temporaire) ou final (confirm√©).
        
    * Les r√©sultats finaux sont accumul√©s dans la r√©f√©rence de transcription persistante.
        
    * Les r√©sultats interm√©diaires sont combin√©s avec les r√©sultats finaux accumul√©s pour un affichage imm√©diat.
        
2. **Mises √† jour dynamiques du Textarea :** Le composant met √† jour le `textarea` en temps r√©el en utilisant une approche de manipulation DOM personnalis√©e :
    
    ```javascript
    const updateTextareaValue = (value: string) => {
      const nativeInputValueSetter = Object.getOwnPropertyDescriptor(
        window.HTMLTextAreaElement.prototype,
        'value'
      )?.set;
      
      if (nativeInputValueSetter) {
        nativeInputValueSetter.call(textareaRef.current, value);
        const inputEvent = new Event('input', { bubbles: true });
        textareaRef.current.dispatchEvent(inputEvent);
      }
    };
    ```
    
    Cette √©tape implique de contourner le comportement conventionnel des composants contr√¥l√©s de React pour fournir un retour imm√©diat, tout en maintenant la compatibilit√© avec le syst√®me d'√©v√©nements de React.
    

#### Retour d'information de l'interface utilisateur

Pour rendre les interactions vocales plus fluides pour les utilisateurs, nous allons ajouter quelques fonctionnalit√©s de retour visuel. Celles-ci incluent :

1. **Basculer entre les ic√¥nes de micro et d'arr√™t**
    
    Nous affichons une ic√¥ne de microphone lorsque le syst√®me est inactif et une ic√¥ne d'arr√™t lorsque l'enregistrement est actif. Cela fournit une indication claire de l'√©tat de l'enregistrement.
    
    ```javascript
    <button
      className={`voice-input-button ${isRecording ? 'recording' : 'idle'}`}
      title={isRecording ? "Arr√™ter l'enregistrement" : "D√©marrer l'entr√©e vocale"}
    >
      {isRecording ? (
        <Square size={20} className="voice-icon recording-icon" />
      ) : (
        <Mic size={20} className="voice-icon idle-icon" />
      )}
    </button>
    ```
    
2. **Banni√®re de notification d'enregistrement**
    
    Une banni√®re de notification appara√Æt en haut de l'√©cran pour indiquer que l'enregistrement vocal est en cours. Cette notification garantit que les utilisateurs sont conscients lorsque le microphone est actif, r√©pondant aux pr√©occupations de confidentialit√© et d'utilisabilit√©.
    
    ```javascript
    {isRecording && (
      <div className="recording-notification show">
        <span className="recording-icon">üé§</span>
        Enregistrement... Cliquez sur arr√™ter lorsque vous avez termin√©
      </div>
    )}
    ```
    

#### Int√©gration et soumission des messages

Le texte transcrit s'int√®gre de mani√®re transparente avec le syst√®me de chat existant via la r√©f√©rence `textarea` partag√©e et le gestionnaire de soumission fourni par le contexte :

```javascript
<SendButton sendMessage={handleSubmit} />
```

Cette int√©gration signifie que les messages g√©n√©r√©s par la voix suivent le m√™me chemin de soumission que les messages tap√©s, maintenant la coh√©rence avec le comportement du syst√®me de chat. Apr√®s la soumission du message, le composant garantit un nettoyage appropri√© de son √©tat interne, se pr√©parant pour la prochaine session d'entr√©e vocale.

#### Passage du composant CustomMessageInput

Ayant construit notre composant d'entr√©e de messagerie personnalis√©, nous allons maintenant le passer √† la prop `Input` du composant `MessageInput` dans notre `App.tsx` :

```javascript
<MessageInput Input={CustomMessageInput} />
```

## **Flux de processus complet**

Voici comment fonctionne l'application :

1. Apr√®s le montage du composant, vous ajoutez l'IA au chat en cliquant sur le bouton **Ajouter l'IA**.
    
2. Cliquez sur l'**ic√¥ne du micro** pour commencer l'enregistrement.
    
3. Votre navigateur demandera la permission d'utiliser le microphone.
    
4. Si vous **refusez** la permission, l'enregistrement ne commencera pas.
    
5. Si vous **autorisez** la permission, l'enregistrement et la transcription commencent simultan√©ment.
    
6. Cliquez sur l'**ic√¥ne d'arr√™t (carr√©)** pour terminer l'enregistrement.
    
7. Cliquez sur le **bouton d'envoi** pour soumettre votre message.
    
8. L'IA traite votre entr√©e et g√©n√®re une r√©ponse.
    
## Conclusion

Dans ce tutoriel, vous avez appris √† construire un puissant chatbot conversationnel en utilisant Stream Chat et React. L'application prend en charge √† la fois les entr√©es textuelles et vocales.

Si vous souhaitez cr√©er vos propres exp√©riences de chat engageantes, vous pouvez explorer les fonctionnalit√©s Stream [Chat](https://getstream.io/chat/) et [Video](https://getstream.io/video/) pour faire passer vos projets au niveau sup√©rieur.

Obtenez le code source complet de ce projet [ici](https://github.com/TimothyOlanrewaju/My-Chat-Application). Si vous avez aim√© lire cet article, connectez-vous avec moi sur [LinkedIn](https://www.linkedin.com/in/timothy-olanrewaju750) ou suivez-moi sur [X](https://x.com/SmoothTee_DC) pour plus de publications et d'articles li√©s √† la programmation.

√Ä la prochaine !