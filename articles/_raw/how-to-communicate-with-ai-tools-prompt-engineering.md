---
title: How to Communicate with ChatGPT â€“ A Guide to Prompt Engineering
subtitle: ''
author: Hillary Nyakundi
co_authors: []
series: null
date: '2023-04-20T20:54:11.000Z'
originalURL: https://freecodecamp.org/news/how-to-communicate-with-ai-tools-prompt-engineering
coverImage: https://www.freecodecamp.org/news/content/images/2023/04/ChatGPT--1-.png
tags:
- name: Artificial Intelligence
  slug: artificial-intelligence
- name: chatgpt
  slug: chatgpt
- name: communication
  slug: communication
- name: Machine Learning
  slug: machine-learning
seo_title: null
seo_desc: "AI has become an integral part of our lives and businesses. Over the past\
  \ few years, weâ€™ve seen the rapid rise of AI tools, and their impact on our day-to-day\
  \ activities can't be ignored. \nFrom virtual assistants to chatbots, AI just keeps\
  \ getting sm..."
---

AI has become an integral part of our lives and businesses. Over the past few years, weâ€™ve seen the rapid rise of AI tools, and their impact on our day-to-day activities can't be ignored. 

From virtual assistants to chatbots, AI just keeps getting smarter with more functionalities than before. This technology has changed the way we interact with both humans and machines.

As this evolution continues, there's a constant need to improve the communication between humans and machines. By fully understanding how to effectively communicate with AI, it can take us a step closer to unlocking its full potential. 

This will not only enable us to extract relevant information but also allow us to gain new insights, making us more informed on different fields of interest. To get these advantages, understanding prompt engineering is essential.

As a growing developer, I spend the better part of my time on learning and implementation. In the process, I may need to do research, and it might take forever to find what I need browsing the net. But with new technologies like ChatGPT, I am able to easily get what I need as long as I ask the right questions. 

Just like many others, figuring out the platform wasn't easy. It took me a while before I could understand how to communicate with the model. A key aspect is knowing how to structure and phrase the prompts. With this, you will be able to improve the quality and accuracy of the responses you get.

In this guide, youâ€™ll learn what prompt engineering is and how you can use it to improve your communication with AI tools. In addition to this, weâ€™ll also explore different categories of prompts and the design principles used to craft effective prompts. 

By the end of this guide, you should be able to write good prompts and tailor them to your needs, facilitating a better interaction between you and the language models. 

Let's get started!

## What is Prompt Engineering?
Communication with AI is crucial and understanding how to communicate with it effectively is helpful. The entire communication process revolves around writing commands which are referred to as prompts. 

With that said, we can easily define prompt engineering as the step-by-step process of creating inputs that determine the output to be generated by an AI language model.

High quality inputs will result in better output. Similarly, poorly defined prompts will lead to inaccurate responses or responses that might negatively impact the user. After all, "With great power comes great responsibility".

Prompt engineering cuts across different applications, including chatbots, content generation tools, language translation tools, and virtual assistants. But you might be wondering how AI technology generates its responses. Letâ€™s find out in the next section.

## How do Language Models Work?
AI language models such as GPT-4 rely on deep learning algorithms and natural language processing (NLP) to fully understand human language. 

All this is made possible through training that consists of large datasets. These datasets include articles, books, journals, reports, and so on. This helps the language models develop their language understanding capabilities. With the data, the model is fine-tuned in a way that enables it to respond to particular tasks assigned to it.

Depending on the language model, there are two main learning methods â€“ supervised or unsupervised learning. 

Supervised learning is where the model uses a labeled dataset where the data is already tagged with the right answers. In unsupervised learning, the model uses unlabeled datasets, meaning the model has to analyze the data for possible and accurate responses. Models like GPT-4 use the unsupervised learning technique to give responses.

The model has the ability to generate text based on the prompt given. This process is referred to as language modeling, and it's the foundation of many AI language applications. Learn more about [Supervised vs Unsupervised Learning from IBM](https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning).

At this point, you should understand that the performance of an AI language model mainly depends on the quality and quantity of the training data. Training the model with tons of data from different sources will help the model understand human language including grammar, syntax, and semantics.

Note that, irrespective of the quantity of data used to train these models, there will always be challenges when it comes to understanding natural language. After all, this is an artificial being and understanding things like sarcasm, irony, or human feelings can be difficult for an AI model to interpret.

Now that we have an understanding of how the AI language model works, let's look at different prompt categories that are available to help us communicate with the models.  

## What are Prompt Categories?
You can use prompts to ensure smooth communication with AI language models. The first step to writing quality prompts is understanding their different classifications so you can easily structure the prompts with a given target response in mind. 

Some of the major prompt categories include:

1. **Information-seeking prompts** - These prompts are specifically designed to gather information. The prompts mostly answer the question **What** and **How**. Examples of such prompts: "What are the most popular tourist attractions in Kenya?", "How do I prepare for a job interview?"
2. **Instruction-based prompts** - These are used to give instructions to the model to perform a specific task. A good example of such prompts is the use of Siri, Alexa, or Google Assistant. For example, an instruction prompt might be "Call momâ€, or â€œPlay the latest episode from my favorite TV show." 
3. **Context-providing prompts** - Just as the name suggests, these prompts provide information to the AI to help it better understand what the user needs as a response. For example, if youâ€™re planning a party and need some decoration ideas and activities for attendees, you can structure your prompt like so: "I am planning a party for my child, what are some decoration ideas and activities that the attendees might do to make it enjoyable and memorable?"
4. **Comparative prompts** - These are used to compare or evaluate different options given to the model to help the user make an appropriate decision. For example: "What are the strengths and weaknesses of Option A compared to Option B?"
5. **Opinion-seeking prompts** - These are designed to get the AI's opinion on a given topic. For example: "What would happen if we could travel back in time?"
6. **Reflective prompts** - These prompts are designed to help individuals gain a deeper understanding of themselves, their beliefs, and their actions. They are more like encouragement/self-growth prompts based on a topic or personal experience. You might be required to give the model a bit of info before getting a desirable response.
7. **Role-based prompts** - These prompts provide responses by framing the user's request within a specific role. It's the most commonly used category of prompts. By giving the AI a role, it gives responses based on the role given. 
A trick that has worked for this particular category is making use of the **5 Ws framework**, that is: 

* Who - Assigns the role you need the model to play. A role like a teacher, developer, chef, and so on.
* What - Refers to the action you want the model to do.
* When - Your desired timeline to complete a particular task.
* Where - Refers to the location or context of a particular prompt.
* Why - Refers to the reasons, motivations, or goals for a particular prompt.

An example of a role-based prompt is:
```
As a coding tutor, your role is to create personalized study plans to help individuals learn how to code. Your responsibilities will include understanding the goals, time commitment, and preferred learning resources of each student, and using that information to develop a comprehensive study plan with clear timelines and links to relevant resources. You should be able to adapt your teaching style to meet the individual needs of each student and provide ongoing support and guidance throughout the learning process. Your ultimate goal will be to help each student develop the skills and knowledge they need to achieve their coding goals.
``` 
This prompt should also include what you intend to learn, the intended learning period, and your goal for learning. Remember that the more details you give, the more tailored results you will get.

**NOTE:** If you lack prior knowledge on what you need help with, you shouldnâ€™t fully rely on the response you get from the model. Be sure to crosscheck with other sources if you doubt the modelâ€™s responses, as the model is not always correct.

## Principles of Effective Prompt Engineering
Now that we have covered the different prompt categories, let's look at how you can craft good prompts. To help you understand better, weâ€™ll go through different prompt engineering frames that optimize the responses we get by providing clear queries meant for NLP. 

You should keep the following in mind when creating prompts:

* **Clarity** â€“ In any communication setting, clarity is very important. The same principles apply to prompt engineering. If you want to craft a good prompt, it's important to be clear about what you want. A good prompt helps the AI provide more accurate responses.

* **Provide context and examples** â€“ This involves providing additional info that can help the AI better understand what the prompt is meant to achieve. By doing this, you increase the chances of getting more accurate responses. 

* **Set limitations and constraints** â€“ This involves setting boundaries within which the AI should operate. This increases the chances of getting the intended response, and avoiding undesired/irrelevant information.

* **Break down queries** â€“ Breaking down queries into smaller and more manageable blocks will make it easier for the AI to process the info. This will help the model understand each query and produce better responses.

* **Iterate and rephrase** â€“ In some cases, after giving the AI a query, you might not be satisfied with the response you get. In such cases you can rephrase your prompt and also provide more context for better results.

* **Prioritize important info** â€“ This is where you highlight the most important information in the prompt. By doing this you are telling the AI to focus on providing responses that are relevant to the highlighted information.

* **Use multiple choice questions** â€“ In a situation where you're stuck with choosing from multiple options, you can provide the AI with different options to work with so you can save time.

* **Request step-by-step explanation** â€“ Let's say you need detailed information or a breakdown of a complex topic. You can structure your prompt in a way that instructs the AI to give responses in a more thorough manner by breaking down each step.

* **Encourage critical thinking** â€“ This can be useful when you are relying on information like a piece of advice from the AI. By encouraging the AI to think critically, you increase the chances of getting a response based on realistic logic.

* **Verify the accuracy of generated response** â€“ Last, but not least, **it's always important to verify the AI-generated responses**. This involves making sure the information is accurate and up to date. By doing this you are able to make sure that you are making an informed decision based on the response generated.

## Practical Example of a Prompt
Having discussed the different prompt categories and principles for effective prompt writing, let's take a closer look at how to apply these concepts in a real-world setting. 

To fully utilize what we have covered so far, we'll look at some practical examples, address some common AI response issues, and also take a look at how AI is being used across different industries.

I know crafting a good question isn't easy, but believe me when I say I have been there. The process becomes easier when you learn how to create appropriate prompts. 

For example, let's say that you want to get started with learning to code with front-end technologies, and you're confused and don't know where to start. Instead of asking an open question like: "Where can I learn about front-end development?", you can use a more specific and targeted prompt like: 

![crafting-prompts](https://www.freecodecamp.org/news/content/images/2023/04/crafting-prompts.png)

As you can see in the image above, here's the prompt I gave:

> "When it comes to learning front-end web development online, what are the differences between various coding education platforms in terms of curriculum content, learning resources, and community support? For example, which platform provides more comprehensive and up-to-date courses in HTML, CSS, and JavaScript, and which have a more active and engaged community to support learners in their front-end development journey?"

The AI provided a reasonably detailed and informative answer based on the information I provided.

The good thing about this prompt is that it is applicable across different industries. We're increasingly seeing different applications of AI in fields like entertainment, finance, law, medicine, education, and so on.

Among these fields, the entertainment field is one of the most common where AI has been used. We've seen people use AI to create YouTube content from scratch. This involves a series of steps that includes creating a long conversation between you and the AI in such a scenario that the AI is given a role and you follow its instructions. 

As much as we can rely on the AI to accomplish a specific task, it's also important to consider the task we are assigning to the AI and if it's appropriate. These language models mostly excel at tasks that require processing large amounts of data which help them identify unique response patterns. 

In addition to this it's also important to choose an appropriate model for a specific task, as different models are trained to handle different tasks.

## AI Pitfalls and Limitations

Despite all the advancements that AI has made in the recent years, we can agree that they aren't that perfect either.

One of the major concerns highlighted by multiple sources is that the AI models have potential for biasness. 

How is this possible? Well, machine learning algorithms rely on human data to make predictions. In cases where the data fed to the model is biased, the resulting responses would also be biased. So, it's important to carefully evaluate the training data for any form of biasness and make adjustments at an early stage. 

Also, while we can trust AI to automate certain tasks, the results of their findings may not always be accurate. If the AI isn't restricted by well defined parameters, it may go overboard beyond the user's capability. 

To avoid these circumstances, it's always a good practice to have human oversight to continually monitor the model and also help in identifying errors with the model.

Another common area where AI struggles is understanding complex language and relating to how a real human would feel in different situations. Because it can't "feel", many of its decisions related to normal human behaviour aren't accurate and can't be fully trusted.

And finally, if the training data is incomplete, the model may not be able to give the most accurate responses. When this happens, a model might opt to generate ideas based on what it thinks the user might be asking for. This means that the model is struggling as it doesn't have enough accurate data to generate a good response.

### Current issues with AI responses

The unfortunate truth at this point is that AI-generated responses aren't always correct. I have fallen victim to this. But luckily for me, I was aware of the error and was able to correct it. 

Another thing to note is that if you give an AI alternative information that's not a correct response, the AI will always try to agree with you even if you are wrong. That's why it's a good idea to **make sure you have some idea of what you are asking the AI about**. In a case where the AI gives you an incorrect response, you can always try to rephrase your prompt by providing more context.

## Conclusion 
It seems clear that AI technology will play a very important role in our lives in the future. This technology will continue to revolutionize the way we go through our daily routines at work, home, or school. 

To fully take advantage of this, we need to make sure that we are able to communicate effectively with these systems. And that's where prompt engineering comes in. By understanding how to craft a good prompt, we can improve the interaction between humans and machines.

As we try to rely on information provided by AI, it's essential to consider the possible implications it can bring to our lives. One major issue is that AI systems are often biased, which might lead to discriminatory outcomes. 

But regardless of the situation, it seems that AI is here to stay. So the earlier you learn to communicate with it, the better. Don't be left out of the party ðŸ˜Š.


